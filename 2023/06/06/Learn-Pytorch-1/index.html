<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>Learn_Pytorch_1 | Hello World!</title><meta name="author" content="Charlie Chen"><meta name="copyright" content="Charlie Chen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Pytorch学习学习加载数据集​        我们首先需要学会导入数据集。在Pytorch里，负责导入数据集的有两个大类：DataSet 和DataLoader. ​        DataSet 可以认为是提供一种方式来获取数据和对应的标签 ​        DataLoader为后面的网络提供不同的数据形式（需要dataSet来作为源数据集） class Dataset(Generic[T">
<meta property="og:type" content="article">
<meta property="og:title" content="Learn_Pytorch_1">
<meta property="og:url" content="http://charliechen114514.github.io/2023/06/06/Learn-Pytorch-1/index.html">
<meta property="og:site_name" content="Hello World!">
<meta property="og:description" content="Pytorch学习学习加载数据集​        我们首先需要学会导入数据集。在Pytorch里，负责导入数据集的有两个大类：DataSet 和DataLoader. ​        DataSet 可以认为是提供一种方式来获取数据和对应的标签 ​        DataLoader为后面的网络提供不同的数据形式（需要dataSet来作为源数据集） class Dataset(Generic[T">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://charliechen114514.github.io/img/passagepage.png">
<meta property="article:published_time" content="2023-06-06T14:32:53.000Z">
<meta property="article:modified_time" content="2023-06-06T15:06:14.820Z">
<meta property="article:author" content="Charlie Chen">
<meta property="article:tag" content="Pytorch">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://charliechen114514.github.io/img/passagepage.png"><link rel="shortcut icon" href="/img/webicon.png"><link rel="canonical" href="http://charliechen114514.github.io/2023/06/06/Learn-Pytorch-1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Learn_Pytorch_1',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-06-06 23:06:14'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = url => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      link.onload = () => resolve()
      link.onerror = () => reject()
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/webicon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">50</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">25</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 大爹们</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/passagepage.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Hello World!"><span class="site-name">Hello World!</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 大爹们</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Learn_Pytorch_1</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-06T14:32:53.000Z" title="发表于 2023-06-06 22:32:53">2023-06-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-06T15:06:14.820Z" title="更新于 2023-06-06 23:06:14">2023-06-06</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">7.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>36分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Learn_Pytorch_1"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Pytorch学习"><a href="#Pytorch学习" class="headerlink" title="Pytorch学习"></a>Pytorch学习</h1><h2 id="学习加载数据集"><a href="#学习加载数据集" class="headerlink" title="学习加载数据集"></a>学习加载数据集</h2><p>​        我们首先需要学会导入数据集。在Pytorch里，负责导入数据集的有两个大类：DataSet 和DataLoader.</p>
<p>​        DataSet 可以认为是提供一种方式来获取数据和对应的标签</p>
<p>​        DataLoader为后面的网络提供不同的数据形式（需要dataSet来作为源数据集）</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Dataset</span><span class="token punctuation">(</span>Generic<span class="token punctuation">[</span>T_co<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">r"""An abstract class representing a :class:`Dataset`.

    All datasets that represent a map from keys to data samples should subclass
    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a
    data sample for a given key. Subclasses could also optionally overwrite
    :meth:`__len__`, which is expected to return the size of the dataset by many
    :class:`~torch.utils.data.Sampler` implementations and the default options
    of :class:`~torch.utils.data.DataLoader`.

    .. note::
      :class:`~torch.utils.data.DataLoader` by default constructs a index
      sampler that yields integral indices.  To make it work with a map-style
      dataset with non-integral indices/keys, a custom sampler must be provided.
    """</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> T_co<span class="token punctuation">:</span>
        <span class="token keyword">raise</span> NotImplementedError

    <span class="token keyword">def</span> <span class="token function">__add__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">:</span> <span class="token string">'Dataset[T_co]'</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token string">'ConcatDataset[T_co]'</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> ConcatDataset<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">,</span> other<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># No `def __len__(self)` default?</span>
    <span class="token comment"># See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]</span>
    <span class="token comment"># in pytorch/torch/utils/data/sampler.py</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        可以看到这是抽象类，需要我们重写DataSet 来运行：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> os
<span class="token keyword">class</span> <span class="token class-name">Mydata</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token comment"># 准备一下路径</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>rootDir<span class="token punctuation">,</span>label_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        :param rootDir: the root image source
        :param label_dir: whether it is ants or bees
        """</span>
        self<span class="token punctuation">.</span>rootDir <span class="token operator">=</span> rootDir
        self<span class="token punctuation">.</span>label_dir <span class="token operator">=</span>label_dir
        self<span class="token punctuation">.</span>path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>rootDir<span class="token punctuation">,</span>self<span class="token punctuation">.</span>label_dir<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>imagePath <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>self<span class="token punctuation">.</span>path<span class="token punctuation">)</span>
	<span class="token comment">#获取东西</span>
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        img_name <span class="token operator">=</span> self<span class="token punctuation">.</span>imagePath<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        img_item_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>path<span class="token punctuation">,</span>img_name<span class="token punctuation">)</span>
        img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_item_path<span class="token punctuation">)</span>
        label <span class="token operator">=</span> self<span class="token punctuation">.</span>label_dir
        <span class="token keyword">return</span> img<span class="token punctuation">,</span>label

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>imagePath<span class="token punctuation">)</span>


rootDir <span class="token operator">=</span> <span class="token string">"hymenoptera_data/train"</span>
labelDir <span class="token operator">=</span> <span class="token string">"ants"</span>
ants_dataset <span class="token operator">=</span> Mydata<span class="token punctuation">(</span>rootDir<span class="token punctuation">,</span>labelDir<span class="token punctuation">)</span>

img<span class="token punctuation">,</span>label <span class="token operator">=</span> ants_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
img<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="TensorBoard的基本使用"><a href="#TensorBoard的基本使用" class="headerlink" title="TensorBoard的基本使用"></a>TensorBoard的基本使用</h2><p>​        我们为了使用 tensorBoard可视化，需要在我们自己的源代码文件中引入 SummaryWriter类。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​        我们就是在这里实现可视化的！</p>
<p>​        来看看简介怎么说</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""Writes entries directly to event files in the log_dir to be
   consumed by TensorBoard.

   The `SummaryWriter` class provides a high-level API to create an event file
   in a given directory and add summaries and events to it. The class updates the
   file contents asynchronously. This allows a training program to call methods
   to add data to the file directly from the training loop, without slowing down
   training.
   """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        简单来讲。就是通过生成event file(事件文件)来预备可视化，在cmd或者是已经被激活的 pytorch环境下来整指令：</p>
<pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">tensorboard --logdir&#x3D;&lt;logFileName&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​        SummaryWriter的构造函数（<strong> init </strong>()）是这样说的：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
    self<span class="token punctuation">,</span> <span class="token comment"># this 指针一样的东西</span>
    log_dir<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    comment<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">,</span>
    purge_step<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    max_queue<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    flush_secs<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span>
    filename_suffix<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Creates a `SummaryWriter` that will write out events and summaries
    to the event file.

    Args:
        log_dir (str): Save directory location. Default is
          runs/**CURRENT_DATETIME_HOSTNAME**, which changes after each run.
          Use hierarchical folder structure to compare
          between runs easily. e.g. pass in 'runs/exp1', 'runs/exp2', etc.
          for each new experiment to compare across them.
        comment (str): Comment log_dir suffix appended to the default
          ``log_dir``. If ``log_dir`` is assigned, this argument has no effect.
        purge_step (int):
          When logging crashes at step :math:`T+X` and restarts at step :math:`T`,
          any events whose global_step larger or equal to :math:`T` will be
          purged and hidden from TensorBoard.
          Note that crashed and resumed experiments should have the same ``log_dir``.
        max_queue (int): Size of the queue for pending events and
          summaries before one of the 'add' calls forces a flush to disk.
          Default is ten items.
        flush_secs (int): How often, in seconds, to flush the
          pending events and summaries to disk. Default is every two minutes.
        filename_suffix (str): Suffix added to all event filenames in
          the log_dir directory. More details on filename construction in
          tensorboard.summary.writer.event_file_writer.EventFileWriter.

    Examples::

        from torch.utils.tensorboard import SummaryWriter

        # create a summary writer with automatically generated folder name.
        writer = SummaryWriter()
        # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/

        # create a summary writer using the specified folder name.
        writer = SummaryWriter("my_experiment")
        # folder location: my_experiment

        # create a summary writer with comment appended.
        writer = SummaryWriter(comment="LR_0.1_BATCH_16")
        # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/

    """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        于是，我们实例化一个SummaryWriter,只需要告诉构造函数一个文件夹的名字即可</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>
<span class="token comment"># 产生一个logs文件夹，其事件文件就在里面！</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​        向里头输入样本点，比如说函数”y = x”，就需要加入：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
     writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"y = x"</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>i<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​        不要忘记关闭文件流</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="经验来了"><a href="#经验来了" class="headerlink" title="经验来了"></a>经验来了</h3><p>​        首先，如果你打开终端，发现是PS控制台，那就麻烦你手动改成cmd控制台，他在Files - settings - tools - terminal里，选择CMD控制台</p>
<p><img src="image-20230329201937164.png" alt="image-20230329201937164"></p>
<p>​        回到终端，他就是这样的了。</p>
<p><img src="image-20230329202008458.png" alt="image-20230329202008458"></p>
<p>​        但是，这个时候输入 tensorboard —logdir=logs(你自己看看你指定的文件夹的名字是什么，比如说我的是这个，以及如果你发现你甚至没有log文件夹那就检查代码，去文件的上级找找，但大概率是你代码出错了！)</p>
<p><img src="image-20230329202055328.png" alt="image-20230329202055328"></p>
<p><img src="image-20230329202202553.png" alt="image-20230329202202553"></p>
<p>​        出现了上图的 bug，说明cmd没认识，不知道tensorboard.那就这样，输入</p>
<pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">pip install tensorboard -i --trusted-host  http:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​        这是使用pip 来下载tensorboard, 其中，后面信任域名是为了防止下图种类的报错</p>
<p><img src="image-20230329202344121.png" alt="image-20230329202344121"></p>
<p>​        但是，即使这样，我还是遇到了另一个奇怪的错误：</p>
<p><img src="image-20230329202418314.png" alt="image-20230329202418314"></p>
<p>​        这个时候马上换源即可，是源的问题</p>
<pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">pip install tensorboard -i https:&#x2F;&#x2F;pypi.douban.com&#x2F;simple --trusted-host https:&#x2F;&#x2F;pypi.douban.com&#x2F;simple <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="image-20230329202505259.png" alt="image-20230329202505259"></p>
<p>​        我们再试一次，成功了！</p>
<p>​        对了。如果发现端口冲突了，可以手动指定端口，就是在指令的后面在塞上一个—port=</p>
<p><img src="image-20230329202803683.png" alt="image-20230329202803683"></p>
<p>下面来看图片的添加！在Pytorch下，我们使用add_image来添加图片</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">add_image</span><span class="token punctuation">(</span>
    self<span class="token punctuation">,</span> tag<span class="token punctuation">,</span> img_tensor<span class="token punctuation">,</span> global_step<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> walltime<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> dataformats<span class="token operator">=</span><span class="token string">"CHW"</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Add image data to summary.

    Note that this requires the ``pillow`` package.

    Args:
        tag (str): Data identifier
        img_tensor (torch.Tensor, numpy.ndarray, or string/blobname): Image data
        global_step (int): Global step value to record
        walltime (float): Optional override default walltime (time.time())
          seconds after epoch of event
        dataformats (str): Image data format specification of the form
          CHW, HWC, HW, WH, etc.
    Shape:
        img_tensor: Default is :math:`(3, H, W)`. You can use ``torchvision.utils.make_grid()`` to
        convert a batch of tensor into 3xHxW format or call ``add_images`` and let us do the job.
        Tensor with :math:`(1, H, W)`, :math:`(H, W)`, :math:`(H, W, 3)` is also suitable as long as
        corresponding ``dataformats`` argument is passed, e.g. ``CHW``, ``HWC``, ``HW``.

    Examples::

        from torch.utils.tensorboard import SummaryWriter
        import numpy as np
        img = np.zeros((3, 100, 100))
        img[0] = np.arange(0, 10000).reshape(100, 100) / 10000
        img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000

        img_HWC = np.zeros((100, 100, 3))
        img_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000
        img_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000

        writer = SummaryWriter()
        writer.add_image('my_image', img, 0)

        # If you have non-default dimension setting, set the dataformats argument.
        writer.add_image('my_image_HWC', img_HWC, 0, dataformats='HWC')
        writer.close()

    Expected result:

    .. image:: _static/img/tensorboard/add_image.png
       :scale: 50 %

    """</span>
    torch<span class="token punctuation">.</span>_C<span class="token punctuation">.</span>_log_api_usage_once<span class="token punctuation">(</span><span class="token string">"tensorboard.logging.add_image"</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_check_caffe2_blob<span class="token punctuation">(</span>img_tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> caffe2<span class="token punctuation">.</span>python <span class="token keyword">import</span> workspace

        img_tensor <span class="token operator">=</span> workspace<span class="token punctuation">.</span>FetchBlob<span class="token punctuation">(</span>img_tensor<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>_get_file_writer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>add_summary<span class="token punctuation">(</span>
        image<span class="token punctuation">(</span>tag<span class="token punctuation">,</span> img_tensor<span class="token punctuation">,</span> dataformats<span class="token operator">=</span>dataformats<span class="token punctuation">)</span><span class="token punctuation">,</span> global_step<span class="token punctuation">,</span> walltime
    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        是的，当我们加载图片的时候，函数的参数接受Tensor类型的图片和ndarray类型，这就需要我们调用API来进行转化</p>
<pre class="line-numbers language-Python" data-language="Python"><code class="language-Python">from torch.utils.tensorboard import SummaryWriter
from PIL import Image
import numpy as np
writer &#x3D; SummaryWriter(&quot;logs&quot;)

imgPath &#x3D; &quot;hymenoptera_data&#x2F;train&#x2F;ants&#x2F;0013035.jpg&quot;


imgPIL &#x3D; Image.open(imgPath)
imgArray &#x3D; np.array(imgPIL) # 转化
writer.add_image(&quot;test&quot;,imgArray,1,dataformats&#x3D;&quot;HWC&quot;) #指明通道是如何的！


writer.close()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="常见的transformer"><a href="#常见的transformer" class="headerlink" title="常见的transformer"></a>常见的transformer</h2><p><img src="image-20230503184731008.png" alt="image-20230503184731008"></p>
<p>​        下面我们通过Run Demo的方式来实现记忆常见的transformer！</p>
<p>​        这是我们要处理的图片：</p>
<p><img src="image-20230503185022804.png" alt="image-20230503185022804"></p>
<h3 id="PIL-Image库读入图片"><a href="#PIL-Image库读入图片" class="headerlink" title="PIL-Image库读入图片"></a>PIL-Image库读入图片</h3><p>​        下面通过PIL的Image库来读取图片文件：</p>
<pre class="line-numbers language-C++" data-language="C++"><code class="language-C++">from PIL import Image
img &#x3D; Image.open(&quot;1.png&quot;);
print(img);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">&lt;PIL.PngImagePlugin.PngImageFile image mode&#x3D;RGBA size&#x3D;1717x1227 at 0x21AEC1CB880&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​        这是我们得到的！导入成功！</p>
<h4 id="小插曲：-call-的用法"><a href="#小插曲：-call-的用法" class="headerlink" title="小插曲： __call__的用法"></a>小插曲： __call__的用法</h4><p>​        在Python类里存在内置函数__call__，我们这样的使用它：我们选择新建一个Python文件，</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Person</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"__call__ calls for:"</span><span class="token operator">+</span> <span class="token string">"hello"</span><span class="token operator">+</span><span class="token string">"name"</span><span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">hello</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>name<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token operator">+</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

person <span class="token operator">=</span> Person<span class="token punctuation">(</span><span class="token punctuation">)</span>
person<span class="token punctuation">.</span>hello<span class="token punctuation">(</span><span class="token string">"李四"</span><span class="token punctuation">)</span>
person<span class="token punctuation">(</span><span class="token string">"张三"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        书写上面的代码</p>
<p><img src="image-20230503190321481.png" alt="image-20230503190321481"></p>
<p>​        有点像C++的内置构建函数的感觉，只需要类对象（）后传对应参数就好了。</p>
<h4 id="继续："><a href="#继续：" class="headerlink" title="继续："></a>继续：</h4><p>​        看看这个Compose类：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Compose</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Composes several transforms together. This transform does not support torchscript.
    Please, see the note below.

    Args:
        transforms (list of ``Transform`` objects): list of transforms to compose.

    Example:
        >>> transforms.Compose([
        >>>     transforms.CenterCrop(10),
        >>>     transforms.PILToTensor(),
        >>>     transforms.ConvertImageDtype(torch.float),
        >>> ])

    .. note::
        In order to script the transformations, please use ``torch.nn.Sequential`` as below.

        >>> transforms = torch.nn.Sequential(
        >>>     transforms.CenterCrop(10),
        >>>     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
        >>> )
        >>> scripted_transforms = torch.jit.script(transforms)

        Make sure to use only scriptable transformations, i.e. that work with ``torch.Tensor``, does not require
        `lambda` functions or ``PIL.Image``.

    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> transforms<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> torch<span class="token punctuation">.</span>jit<span class="token punctuation">.</span>is_scripting<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token keyword">not</span> torch<span class="token punctuation">.</span>jit<span class="token punctuation">.</span>is_tracing<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            _log_api_usage_once<span class="token punctuation">(</span>self<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>transforms <span class="token operator">=</span> transforms

    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> t <span class="token keyword">in</span> self<span class="token punctuation">.</span>transforms<span class="token punctuation">:</span>
            img <span class="token operator">=</span> t<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
        <span class="token keyword">return</span> img

    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">str</span><span class="token punctuation">:</span>
        format_string <span class="token operator">=</span> self<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__ <span class="token operator">+</span> <span class="token string">"("</span>
        <span class="token keyword">for</span> t <span class="token keyword">in</span> self<span class="token punctuation">.</span>transforms<span class="token punctuation">:</span>
            format_string <span class="token operator">+=</span> <span class="token string">"\n"</span>
            format_string <span class="token operator">+=</span> <span class="token string-interpolation"><span class="token string">f"    </span><span class="token interpolation"><span class="token punctuation">&#123;</span>t<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span>
        format_string <span class="token operator">+=</span> <span class="token string">"\n)"</span>
        <span class="token keyword">return</span> format_string


<span class="token keyword">class</span> <span class="token class-name">ToTensor</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Convert a PIL Image or ndarray to tensor and scale the values accordingly.

    This transform does not support torchscript.

    Converts a PIL Image or numpy.ndarray (H x W x C) in the range
    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]
    if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1)
    or if the numpy.ndarray has dtype = np.uint8

    In the other cases, tensors are returned without scaling.

    .. note::
        Because the input image is scaled to [0.0, 1.0], this transformation should not be used when
        transforming target image masks. See the `references`_ for implementing the transforms for image masks.

    .. _references: https://github.com/pytorch/vision/tree/main/references/segmentation
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        _log_api_usage_once<span class="token punctuation">(</span>self<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pic<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Args:
            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.

        Returns:
            Tensor: Converted image.
        """</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>pic<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">str</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>self<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__<span class="token punctuation">&#125;</span></span><span class="token string">()"</span></span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​            先看后面的ToTensor这个类，其负责把一些PIL Image数据转换为Tensor数据类型，举个例子，就处理我刚刚说的那张图片！</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span>
img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"1.png"</span><span class="token punctuation">)</span>

trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
img_tensor <span class="token operator">=</span> trans<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"ToTensor"</span><span class="token punctuation">,</span>img_tensor<span class="token punctuation">)</span>
writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="To-PILImage"><a href="#To-PILImage" class="headerlink" title="To PILImage"></a>To PILImage</h3><pre class="line-numbers language-C++" data-language="C++"><code class="language-C++">class ToPILImage:
    &quot;&quot;&quot;Convert a tensor or an ndarray to PIL Image - this does not scale values.

    This transform does not support torchscript.

    Converts a torch.*Tensor of shape C x H x W or a numpy ndarray of shape
    H x W x C to a PIL Image while preserving the value range.

    Args:
        mode (&#96;PIL.Image mode&#96;_): color space and pixel depth of input data (optional).
            If &#96;&#96;mode&#96;&#96; is &#96;&#96;None&#96;&#96; (default) there are some assumptions made about the input data:
            - If the input has 4 channels, the &#96;&#96;mode&#96;&#96; is assumed to be &#96;&#96;RGBA&#96;&#96;.
            - If the input has 3 channels, the &#96;&#96;mode&#96;&#96; is assumed to be &#96;&#96;RGB&#96;&#96;.
            - If the input has 2 channels, the &#96;&#96;mode&#96;&#96; is assumed to be &#96;&#96;LA&#96;&#96;.
            - If the input has 1 channel, the &#96;&#96;mode&#96;&#96; is determined by the data type (i.e &#96;&#96;int&#96;&#96;, &#96;&#96;float&#96;&#96;,
            &#96;&#96;short&#96;&#96;).

    .. _PIL.Image mode: https:&#x2F;&#x2F;pillow.readthedocs.io&#x2F;en&#x2F;latest&#x2F;handbook&#x2F;concepts.html#concept-modes
    &quot;&quot;&quot;

    def __init__(self, mode&#x3D;None):
        _log_api_usage_once(self)
        self.mode &#x3D; mode

    def __call__(self, pic):
        &quot;&quot;&quot;
        Args:
            pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.

        Returns:
            PIL Image: Image converted to PIL Image.

        &quot;&quot;&quot;
        return F.to_pil_image(pic, self.mode)

    def __repr__(self) -&gt; str:
        format_string &#x3D; self.__class__.__name__ + &quot;(&quot;
        if self.mode is not None:
            format_string +&#x3D; f&quot;mode&#x3D;&#123;self.mode&#125;&quot;
        format_string +&#x3D; &quot;)&quot;
        return format_string<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        把其他数据转换成PIL数据类型，不多讲，当成接口就好！</p>
<h3 id="Normalize方法类"><a href="#Normalize方法类" class="headerlink" title="Normalize方法类"></a>Normalize方法类</h3><p>​        </p>
<pre class="line-numbers language-Python" data-language="Python"><code class="language-Python">class Normalize(torch.nn.Module):
    &quot;&quot;&quot;Normalize a tensor image with mean and standard deviation.
    This transform does not support PIL Image.
    Given mean: &#96;&#96;(mean[1],...,mean[n])&#96;&#96; and std: &#96;&#96;(std[1],..,std[n])&#96;&#96; for &#96;&#96;n&#96;&#96;
    channels, this transform will normalize each channel of the input
    &#96;&#96;torch.*Tensor&#96;&#96; i.e.,
    &#96;&#96;output[channel] &#x3D; (input[channel] - mean[channel]) &#x2F; std[channel]&#96;&#96;

    .. note::
        This transform acts out of place, i.e., it does not mutate the input tensor.

    Args:
        mean (sequence): Sequence of means for each channel.
        std (sequence): Sequence of standard deviations for each channel.
        inplace(bool,optional): Bool to make this operation in-place.

    &quot;&quot;&quot;

    def __init__(self, mean, std, inplace&#x3D;False):
        super().__init__()
        _log_api_usage_once(self)
        self.mean &#x3D; mean
        self.std &#x3D; std
        self.inplace &#x3D; inplace

    def forward(self, tensor: Tensor) -&gt; Tensor:
        &quot;&quot;&quot;
        Args:
            tensor (Tensor): Tensor image to be normalized.

        Returns:
            Tensor: Normalized Tensor image.
        &quot;&quot;&quot;
        return F.normalize(tensor, self.mean, self.std, self.inplace)

    def __repr__(self) -&gt; str:
        return f&quot;&#123;self.__class__.__name__&#125;(mean&#x3D;&#123;self.mean&#125;, std&#x3D;&#123;self.std&#125;)&quot;
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        说白了这个就是标准化过程！重要的是这个公式</p>
<pre class="line-numbers language-none"><code class="language-none">output[channel] &#x3D; (input[channel] - mean[channel]) &#x2F; std[channel]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="Resize"><a href="#Resize" class="headerlink" title="Resize"></a>Resize</h3><pre class="line-numbers language-C++" data-language="C++"><code class="language-C++">class Resize(torch.nn.Module):
    &quot;&quot;&quot;Resize the input image to the given size.
    If the image is torch Tensor, it is expected
    to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions

    .. warning::
        The output image might be different depending on its type: when downsampling, the interpolation of PIL images
        and tensors is slightly different, because PIL applies antialiasing. This may lead to significant differences
        in the performance of a network. Therefore, it is preferable to train and serve a model with the same input
        types. See also below the &#96;&#96;antialias&#96;&#96; parameter, which can help making the output of PIL images and tensors
        closer.

    Args:
        size (sequence or int): Desired output size. If size is a sequence like
            (h, w), output size will be matched to this. If size is an int,
            smaller edge of the image will be matched to this number.
            i.e, if height &gt; width, then image will be rescaled to
            (size * height &#x2F; width, size).

            .. note::
                In torchscript mode size as single int is not supported, use a sequence of length 1: &#96;&#96;[size, ]&#96;&#96;.
        interpolation (InterpolationMode): Desired interpolation enum defined by
            :class:&#96;torchvision.transforms.InterpolationMode&#96;. Default is &#96;&#96;InterpolationMode.BILINEAR&#96;&#96;.
            If input is Tensor, only &#96;&#96;InterpolationMode.NEAREST&#96;&#96;, &#96;&#96;InterpolationMode.NEAREST_EXACT&#96;&#96;,
            &#96;&#96;InterpolationMode.BILINEAR&#96;&#96; and &#96;&#96;InterpolationMode.BICUBIC&#96;&#96; are supported.
            The corresponding Pillow integer constants, e.g. &#96;&#96;PIL.Image.BILINEAR&#96;&#96; are accepted as well.
        max_size (int, optional): The maximum allowed for the longer edge of
            the resized image: if the longer edge of the image is greater
            than &#96;&#96;max_size&#96;&#96; after being resized according to &#96;&#96;size&#96;&#96;, then
            the image is resized again so that the longer edge is equal to
            &#96;&#96;max_size&#96;&#96;. As a result, &#96;&#96;size&#96;&#96; might be overruled, i.e. the
            smaller edge may be shorter than &#96;&#96;size&#96;&#96;. This is only supported
            if &#96;&#96;size&#96;&#96; is an int (or a sequence of length 1 in torchscript
            mode).
        antialias (bool, optional): Whether to apply antialiasing.
            It only affects **tensors** with bilinear or bicubic modes and it is
            ignored otherwise: on PIL images, antialiasing is always applied on
            bilinear or bicubic modes; on other modes (for PIL images and
            tensors), antialiasing makes no sense and this parameter is ignored.
            Possible values are:

            - &#96;&#96;True&#96;&#96;: will apply antialiasing for bilinear or bicubic modes.
              Other mode aren&#39;t affected. This is probably what you want to use.
            - &#96;&#96;False&#96;&#96;: will not apply antialiasing for tensors on any mode. PIL
              images are still antialiased on bilinear or bicubic modes, because
              PIL doesn&#39;t support no antialias.
            - &#96;&#96;None&#96;&#96;: equivalent to &#96;&#96;False&#96;&#96; for tensors and &#96;&#96;True&#96;&#96; for
              PIL images. This value exists for legacy reasons and you probably
              don&#39;t want to use it unless you really know what you are doing.

            The current default is &#96;&#96;None&#96;&#96; **but will change to** &#96;&#96;True&#96;&#96; **in
            v0.17** for the PIL and Tensor backends to be consistent.
    &quot;&quot;&quot;

    def __init__(self, size, interpolation&#x3D;InterpolationMode.BILINEAR, max_size&#x3D;None, antialias&#x3D;&quot;warn&quot;):
        super().__init__()
        _log_api_usage_once(self)
        if not isinstance(size, (int, Sequence)):
            raise TypeError(f&quot;Size should be int or sequence. Got &#123;type(size)&#125;&quot;)
        if isinstance(size, Sequence) and len(size) not in (1, 2):
            raise ValueError(&quot;If size is a sequence, it should have 1 or 2 values&quot;)
        self.size &#x3D; size
        self.max_size &#x3D; max_size

        if isinstance(interpolation, int):
            interpolation &#x3D; _interpolation_modes_from_int(interpolation)

        self.interpolation &#x3D; interpolation
        self.antialias &#x3D; antialias

    def forward(self, img):
        &quot;&quot;&quot;
        Args:
            img (PIL Image or Tensor): Image to be scaled.

        Returns:
            PIL Image or Tensor: Rescaled image.
        &quot;&quot;&quot;
        return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)

    def __repr__(self) -&gt; str:
        detail &#x3D; f&quot;(size&#x3D;&#123;self.size&#125;, interpolation&#x3D;&#123;self.interpolation.value&#125;, max_size&#x3D;&#123;self.max_size&#125;, antialias&#x3D;&#123;self.antialias&#125;)&quot;
        return f&quot;&#123;self.__class__.__name__&#125;&#123;detail&#125;&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
trans_size <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">520</span><span class="token punctuation">,</span><span class="token number">520</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
imgResize <span class="token operator">=</span> trans_size<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>imgResize<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        这样就好了！</p>
<p><img src="image-20230503193919990.png" alt="image-20230503193919990"></p>
<h2 id="Compose-组合变换"><a href="#Compose-组合变换" class="headerlink" title="Compose 组合变换"></a>Compose 组合变换</h2><pre class="line-numbers language-none"><code class="language-none">trans_resize_2 &#x3D; transforms.Resize(512)
trans_compose &#x3D; transforms.Compose([trans_resize_2, trans])
img_resize_2 &#x3D; trans_compose(img)
writer.add_image(&quot;Composer111&quot;, img_resize_2,2)
writer.close()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        我们这样把若干变换组合在一起一并完成！</p>
<h2 id="torchvision-学习"><a href="#torchvision-学习" class="headerlink" title="torchvision 学习"></a>torchvision 学习</h2><p>​        pytorch的很多API可以去pytorch.org </p>
<p>​        下面来看一个加载：</p>
<p><img src="image-20230511224505274.png" alt="image-20230511224505274"></p>
<pre class="line-numbers language-C++" data-language="C++"><code class="language-C++">import torchvision

train_set &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&quot;.&#x2F;dataset&quot;,train&#x3D;True,download&#x3D;True)
test_set &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&quot;.&#x2F;dataset&quot;,train&#x3D;False,download&#x3D;True)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        稍等片刻，就会下载好数据！</p>
<p>​        来测试一下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>test_set<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="image-20230511224848459.png" alt="image-20230511224848459"></p>
<p>​        开debug发现还是很多属性的！</p>
<p>​        这里有相关的read_me:</p>
<p>The CIFAR-10 and CIFAR-100 are labeled subsets of the <a target="_blank" rel="noopener" href="http://people.csail.mit.edu/torralba/tinyimages/">80 million tiny images</a> dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.</p>
<h2 id="The-CIFAR-10-dataset"><a href="#The-CIFAR-10-dataset" class="headerlink" title="The CIFAR-10 dataset"></a>The CIFAR-10 dataset</h2><p>​        CIFAR-10数据集由10个类别的60000张32x32彩色图像组成，每个类别有6000张图像。有50000个训练图像和10000个测试图像。</p>
<p>​        数据集分为五个训练批次和一个测试批次，每个批次有10000张图像。测试批次包含从每个类别中随机选择的1000幅图像。训练批包含按随机顺序排列的剩余图像，但一些训练批可能包含来自一个类的图像多于来自另一类的图像。在它们之间，训练批次正好包含每个类的5000个图像。</p>
<p>​        以下是数据集中的类，以及每个类的10张随机图像：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>airplane</th>
<th><img src="airplane1.png" alt="img"></th>
<th><img src="airplane2.png" alt="img"></th>
<th><img src="airplane3.png" alt="img"></th>
<th><img src="airplane4.png" alt="img"></th>
<th><img src="airplane5.png" alt="img"></th>
<th><img src="airplane6.png" alt="img"></th>
<th><img src="airplane7.png" alt="img"></th>
<th><img src="airplane8.png" alt="img"></th>
<th><img src="airplane9.png" alt="img"></th>
<th><img src="airplane10.png" alt="img"></th>
</tr>
</thead>
<tbody>
<tr>
<td>automobile</td>
<td><img src="automobile1.png" alt="img"></td>
<td><img src="automobile2.png" alt="img"></td>
<td><img src="automobile3.png" alt="img"></td>
<td><img src="automobile4.png" alt="img"></td>
<td><img src="automobile5.png" alt="img"></td>
<td><img src="automobile6.png" alt="img"></td>
<td><img src="automobile7.png" alt="img"></td>
<td><img src="automobile8.png" alt="img"></td>
<td><img src="automobile9.png" alt="img"></td>
<td><img src="automobile10.png" alt="img"></td>
</tr>
<tr>
<td>bird</td>
<td><img src="bird1.png" alt="img"></td>
<td><img src="bird2.png" alt="img"></td>
<td><img src="bird3.png" alt="img"></td>
<td><img src="bird4.png" alt="img"></td>
<td><img src="bird5.png" alt="img"></td>
<td><img src="bird6.png" alt="img"></td>
<td><img src="bird7.png" alt="img"></td>
<td><img src="bird8.png" alt="img"></td>
<td><img src="bird9.png" alt="img"></td>
<td><img src="bird10.png" alt="img"></td>
</tr>
<tr>
<td>cat</td>
<td><img src="cat1.png" alt="img"></td>
<td><img src="cat2.png" alt="img"></td>
<td><img src="cat3.png" alt="img"></td>
<td><img src="cat4.png" alt="img"></td>
<td><img src="cat5.png" alt="img"></td>
<td><img src="cat6.png" alt="img"></td>
<td><img src="cat7.png" alt="img"></td>
<td><img src="cat8.png" alt="img"></td>
<td><img src="cat9.png" alt="img"></td>
<td><img src="cat10.png" alt="img"></td>
</tr>
<tr>
<td>deer</td>
<td><img src="deer1.png" alt="img"></td>
<td><img src="deer2.png" alt="img"></td>
<td><img src="deer3.png" alt="img"></td>
<td><img src="deer4.png" alt="img"></td>
<td><img src="deer5.png" alt="img"></td>
<td><img src="deer6.png" alt="img"></td>
<td><img src="deer7.png" alt="img"></td>
<td><img src="deer8.png" alt="img"></td>
<td><img src="deer9.png" alt="img"></td>
<td><img src="deer10.png" alt="img"></td>
</tr>
<tr>
<td>dog</td>
<td><img src="dog1.png" alt="img"></td>
<td><img src="dog2.png" alt="img"></td>
<td><img src="dog3.png" alt="img"></td>
<td><img src="dog4.png" alt="img"></td>
<td><img src="dog5.png" alt="img"></td>
<td><img src="dog6.png" alt="img"></td>
<td><img src="dog7.png" alt="img"></td>
<td><img src="dog8.png" alt="img"></td>
<td><img src="dog9.png" alt="img"></td>
<td><img src="dog10.png" alt="img"></td>
</tr>
<tr>
<td>frog</td>
<td><img src="frog1.png" alt="img"></td>
<td><img src="frog2.png" alt="img"></td>
<td><img src="frog3.png" alt="img"></td>
<td><img src="frog4.png" alt="img"></td>
<td><img src="frog5.png" alt="img"></td>
<td><img src="frog6.png" alt="img"></td>
<td><img src="frog7.png" alt="img"></td>
<td><img src="frog8.png" alt="img"></td>
<td><img src="frog9.png" alt="img"></td>
<td><img src="frog10.png" alt="img"></td>
</tr>
<tr>
<td>horse</td>
<td><img src="horse1.png" alt="img"></td>
<td><img src="horse2.png" alt="img"></td>
<td><img src="horse3.png" alt="img"></td>
<td><img src="horse4.png" alt="img"></td>
<td><img src="horse5.png" alt="img"></td>
<td><img src="horse6.png" alt="img"></td>
<td><img src="horse7.png" alt="img"></td>
<td><img src="horse8.png" alt="img"></td>
<td><img src="horse9.png" alt="img"></td>
<td><img src="horse10.png" alt="img"></td>
</tr>
<tr>
<td>ship</td>
<td><img src="ship1.png" alt="img"></td>
<td><img src="ship2.png" alt="img"></td>
<td><img src="ship3.png" alt="img"></td>
<td><img src="ship4.png" alt="img"></td>
<td><img src="ship5.png" alt="img"></td>
<td><img src="ship6.png" alt="img"></td>
<td><img src="ship7.png" alt="img"></td>
<td><img src="ship8.png" alt="img"></td>
<td><img src="ship9.png" alt="img"></td>
<td><img src="ship10.png" alt="img"></td>
</tr>
<tr>
<td>truck</td>
<td><img src="truck1.png" alt="img"></td>
<td><img src="truck2.png" alt="img"></td>
<td><img src="truck3.png" alt="img"></td>
<td><img src="truck4.png" alt="img"></td>
<td><img src="truck5.png" alt="img"></td>
<td><img src="truck6.png" alt="img"></td>
<td><img src="truck7.png" alt="img"></td>
<td><img src="truck8.png" alt="img"></td>
<td><img src="truck9.png" alt="img"></td>
<td><img src="truck10.png" alt="img"></td>
</tr>
</tbody>
</table>
</div>
<p>​        这些类是完全互斥的。汽车和卡车之间没有重叠。“汽车”包括轿车、SUV之类的东西。“卡车”只包括大卡车。两者都不包括皮卡。</p>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>如果您要使用此数据集，请引用本页底部的技术报告。</p>
<p>|版本|大小|md5sum|</p>
<p>| —————————————————————————————— | ——— | ———————————————— |</p>
<p>|[CIFAR-10 python版本](<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz）|163">http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz）|163</a> MB | c58f30108f718f92721af3b95e74349a|</p>
<p>|[CIFAR-10 Matlab版本](<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar-10-matlab.tar.gz）|175">http://www.cs.toronto.edu/~kriz/cifar-10-matlab.tar.gz）|175</a> MB |70270af85842c9e89bb428ec9976c926|</p>
<p>|[CIFAR-10二进制版本（适用于C程序）](<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz）|162">http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz）|162</a> MB | c32a1d4ab5d03f1284b67883e8d87530|</p>
<h2 id="基线结果"><a href="#基线结果" class="headerlink" title="基线结果"></a>基线结果</h2><p>你可以在这个数据集上找到一些基线可复制的结果<a target="_blank" rel="noopener" href="http://code.google.com/p/cuda-convnet/">在cuda convnet的项目页面上</a>. 这些结果是用卷积神经网络获得的。简单地说，在没有数据扩充的情况下，它们的测试误差为18%，在有数据扩充的条件下为11%。此外，<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~jasper/）有一篇[新论文](http://hips.seas.harvard.edu/content/practical-bayesian-optimization-machine-learning-algorithms">Jasper Snoek</a>其中，他使用贝叶斯超参数优化来找到权重衰减和其他超参数的良好设置，这使他能够使用获得18%的网络架构获得15%的测试错误率（没有数据扩充）。</p>
<h2 id="其他结果"><a href="#其他结果" class="headerlink" title="其他结果"></a>其他结果</h2><p>​        <a target="_blank" rel="noopener" href="http://rodrigob.github.com/">罗德里戈·贝南森</a>好心地在他的网站上收集了CIFAR-10/100和其他数据集的结果；<a target="_blank" rel="noopener" href="http://rodrigob.github.com/are_we_there_yet/build/classification_datasets_results.html">点击此处</a>查看。</p>
<p>​        数据集布局</p>
<p>​        Python/Matlab版本</p>
<p>​        我（这里指作者）将描述数据集的Python版本的布局。Matlab版本的布局是相同的。</p>
<p>​        档案包含文件data_batch_1，data_batch_2。。。，data_batch_5以及test_batch。这些文件中的每一个都是用[cPickle]生成的Python“pickle”对象(<a target="_blank" rel="noopener" href="http://www.python.org/doc/2.5/lib/module-cPickle.html">http://www.python.org/doc/2.5/lib/module-cPickle.html</a>). 下面是一个python2例程，它将打开这样一个文件并返回一个字典：</p>
<pre class="line-numbers language-none"><code class="language-none">def unpickle（文件）：

导入cPickle

打开（文件，&#39;rb&#39;）为fo：

dict&#x3D;cPickle.load（fo）

返回dict
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>还有一个蟒蛇3版本：</p>
<pre class="line-numbers language-none"><code class="language-none">def unpickle（文件）：

进口泡菜

打开（文件，&#39;rb&#39;）为fo：

dict&#x3D;pickle.load（fo，编码&#x3D;“字节”）

返回dict
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        以这种方式加载的每个批处理文件都包含一个字典，其中包含以下元素：</p>
<p>​        -<strong>数据</strong>—一个10000x3072<a target="_blank" rel="noopener" href="http://numpy.scipy.org/">数字</a>uint8s的数组。阵列的每一行存储一个32x32颜色的图像。前1024个条目包含红色通道值，接下来的1024个条目为绿色，最后的1024个为蓝色。图像按行主顺序存储，因此阵列的前32个条目是图像第一行的红色通道值。</p>
<p>​        -<strong>标签</strong>—包含0-9范围内的10000个数字的列表。索引<em>i</em>处的数字表示数组<strong>数据</strong>中第<em>i</em>个图像的标签。</p>
<p>​        数据集包含另一个名为batches.meta的文件。它也包含一个Python字典对象。它包含以下条目：</p>
<p>​        -<strong>label_names</strong>——一个10元素列表，为上述<strong>标签</strong>数组中的数字标签提供有意义的名称。例如，label_names[0]=“飞机”、label_names[1]=“汽车”等。</p>
<h2 id="二进制版本"><a href="#二进制版本" class="headerlink" title="二进制版本"></a>二进制版本</h2><p>二进制版本包含文件data_batch_1.bin、data_batch_2.bin、…、data_back_5.bin以及test_batch.bin。这些文件的格式如下：</p>
<pre class="line-numbers language-none"><code class="language-none">&lt;1 x标签&gt;&lt;3072 x像素&gt;

...

&lt;1 x标签&gt;&lt;3072 x像素&gt;
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>换句话说，第一个字节是第一个图像的标签，它是0-9范围内的数字。接下来的3072个字节是图像的像素值。第一个1024字节是红色通道值，接下来的1024字节是绿色，最后的1024字节为蓝色。这些值按行主顺序存储，因此前32个字节是图像第一行的红色通道值。</p>
<p>每个文件包含10000个这样的3073字节的图像“行”，尽管没有<strong>任何行的分隔符</strong>。因此，每个文件的长度应该恰好为30730000字节。</p>
<p>还有另一个文件，名为batches.meta.txt。这是一个ASCII文件，它将0-9范围内的数字标签映射到有意义的类名。它只是10个类名的列表，每行一个。第<em>i</em>行的类名对应于数字标签<em>i</em>。</p>
<p>这个数据集和CIFAR-10一样，只是它有100个类，每个类包含600个图像。每节课有500个训练图像和100个测试图像。CIFAR-100中的100个类被分组为20个超类。每个图像都带有一个“精细”标签（它所属的类）和一个“粗略”标签（其所属的超类）。</p>
<p>以下是CIFAR-100中的类列表：</p>
<p>|超类|类|</p>
<p>| ——————————————— | ——————————————————————————- |</p>
<p>|水生哺乳动物|海狸、海豚、水獭、海豹、鲸鱼|</p>
<p>|鱼类|水族馆鱼类、比目鱼、鳐鱼、鲨鱼、鳟鱼|</p>
<p>|花|兰花、罂粟、玫瑰、向日葵、郁金香|</p>
<p>|食品容器|瓶子、碗、罐头、杯子、盘子|</p>
<p>|水果和蔬菜|苹果、蘑菇、橙子、梨、甜椒|</p>
<p>|家用电器|时钟、电脑键盘、灯、电话、电视|</p>
<p>|家用家具|床、椅子、沙发、桌子、衣柜|</p>
<p>|昆虫|蜜蜂、甲虫、蝴蝶、毛毛虫、蟑螂|</p>
<p>|大型食肉动物|熊、豹、狮子、老虎、狼|</p>
<p>|大型人造户外物品|桥梁、城堡、房屋、道路、摩天大楼|</p>
<p>|大型自然户外场景|云、森林、山脉、平原、海洋|</p>
<p>|大型杂食动物和草食动物|骆驼、牛、黑猩猩、大象、袋鼠|</p>
<p>|中型哺乳动物|狐狸、豪猪、负鼠、浣熊、臭鼬|</p>
<p>|非昆虫无脊椎动物|螃蟹、龙虾、蜗牛、蜘蛛、蠕虫|</p>
<p>|人|婴儿，男孩，女孩，男人，女人|</p>
<p>|爬行动物|鳄鱼、恐龙、蜥蜴、蛇、乌龟|</p>
<p>|小型哺乳动物|仓鼠、老鼠、兔子、鼩鼩、松鼠|</p>
<p>|树木|枫树、橡树、棕榈树、松树、柳树|</p>
<p>|车辆1|自行车、公共汽车、摩托车、皮卡、火车|</p>
<p>|车辆2|割草机、火箭、有轨电车、坦克、拖拉机|</p>
<p>是的，我知道蘑菇不是真正的水果或蔬菜，熊也不是真正的食肉动物。</p>
<h2 id="下载-1"><a href="#下载-1" class="headerlink" title="下载"></a>下载</h2><p>|版本|大小|md5sum|</p>
<p>| —————————————————————————————— | ——— | ———————————————— |</p>
<p>|[CIFAR-100 python版本](<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz）|161">http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz）|161</a> MB | eb9058c3a382ffc7106e4002c42a8d85|</p>
<p>|[CIFAR-100 Matlab版本](<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar-100-matlab.tar.gz）|175">http://www.cs.toronto.edu/~kriz/cifar-100-matlab.tar.gz）|175</a> MB |6a4bfa1dcd5c9453dda6bb54194911f4|</p>
<p>|[CIFAR-100二进制版本（适用于C程序）](<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar-100-二进制.tar.gz）|161">http://www.cs.toronto.edu/~kriz/cifar-100-二进制.tar.gz）|161</a> MB |03b5dce0913d631647c71ecec9e9cb8|</p>
<p>数据集布局</p>
<p>python/Matlab版本</p>
<p>python和Matlab版本在布局上与CIFAR-10相同，所以我不会在这里浪费空间来描述它们。</p>
<p>二进制版本</p>
<p>CIFAR-100的二进制版本与CIFAR-10的二进制版本一样，只是每个图像都有两个标签字节（粗略和精细）和3072个像素字节，所以二进制文件看起来是这样的：</p>
<pre class="line-numbers language-none"><code class="language-none">&lt;1 x粗略标签&gt;&lt;1 x精细标签&gt;&lt;3072 x像素&gt;

...

&lt;1 x粗略标签&gt;&lt;1 x精细标签&gt;&lt;3072 x像素&gt;
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        Sivan Sabato好心地提供了[这份文件](<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar_indexes），它将cifar-100图像映射到8000万微小图像数据集中的图像。Sivan写道：">http://www.cs.toronto.edu/~kriz/cifar_indexes），它将cifar-100图像映射到8000万微小图像数据集中的图像。Sivan写道：</a></p>
<pre class="line-numbers language-none"><code class="language-none">该文件有60000行，每行都包含一个指向微小数据库的索引，

其中微小数据库中的第一个图像被索引为“1”。“0”表示不是来自微小数据库的图像。

前50000行对应于训练集，后10000行对应

到测试集。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>​        本技术报告（第3章）更详细地描述了数据集以及收集数据时所遵循的方法。如果您打算使用此数据集，请引用它。</p>
<h2 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h2><p>​        dataLoader意如其名，就是（从dataset）加载数据集</p>
<p><img src="image-20230520131556354.png" alt="image-20230520131556354"></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token comment"># 测试集</span>
test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># 第一张样本</span>
img<span class="token punctuation">,</span>target <span class="token operator">=</span> test_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span>
<span class="token comment"># 可以看看样本</span>
<span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span>data
    <span class="token keyword">print</span><span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>targets<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        可以使用SummaryWriter 来展示之：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter
<span class="token comment"># 测试集</span>
test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># 第一张样本</span>
img<span class="token punctuation">,</span>target <span class="token operator">=</span> test_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span>

step <span class="token operator">=</span> <span class="token number">0</span>

writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"dataLoader"</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span>data
    <span class="token comment"># print(imgs.shape)</span>
    <span class="token comment"># print(targets)</span>
    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"test_data"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>
    step <span class="token operator">=</span> step <span class="token operator">+</span> <span class="token number">1</span>

writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        </p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">tensorboard <span class="token assign-left variable">logdir</span><span class="token operator">=</span><span class="token string">"dataLoader"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="image-20230520132604606.png" alt="image-20230520132604606"></p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>​        先扔一个<code>pytorch</code>的官网！<a target="_blank" rel="noopener" href="https://pytorch.org/docs">https://pytorch.org/docs</a>        </p>
<p>​        继续：</p>
<p>​        这是参数：作为图像处理常用的是Conv2d</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d"><code>nn.Conv1d</code></a></th>
<th>Applies a 1D convolution over an input signal composed of several input planes.</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d"><code>nn.Conv2d</code></a></td>
<td>Applies a 2D convolution over an input signal composed of several input planes.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d"><code>nn.Conv3d</code></a></td>
<td>Applies a 3D convolution over an input signal composed of several input planes.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html#torch.nn.ConvTranspose1d"><code>nn.ConvTranspose1d</code></a></td>
<td>Applies a 1D transposed convolution operator over an input image composed of several input planes.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d"><code>nn.ConvTranspose2d</code></a></td>
<td>Applies a 2D transposed convolution operator over an input image composed of several input planes.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html#torch.nn.ConvTranspose3d"><code>nn.ConvTranspose3d</code></a></td>
<td>Applies a 3D transposed convolution operator over an input image composed of several input planes.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.LazyConv1d.html#torch.nn.LazyConv1d"><code>nn.LazyConv1d</code></a></td>
<td>A <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d"><code>torch.nn.Conv1d</code></a> module with lazy initialization of the <code>in_channels</code> argument of the <code>Conv1d</code> that is inferred from the <code>input.size(1)</code>.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.LazyConv2d.html#torch.nn.LazyConv2d"><code>nn.LazyConv2d</code></a></td>
<td>A <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d"><code>torch.nn.Conv2d</code></a> module with lazy initialization of the <code>in_channels</code> argument of the <code>Conv2d</code> that is inferred from the <code>input.size(1)</code>.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.LazyConv3d.html#torch.nn.LazyConv3d"><code>nn.LazyConv3d</code></a></td>
<td>A <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d"><code>torch.nn.Conv3d</code></a> module with lazy initialization of the <code>in_channels</code> argument of the <code>Conv3d</code> that is inferred from the <code>input.size(1)</code>.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose1d.html#torch.nn.LazyConvTranspose1d"><code>nn.LazyConvTranspose1d</code></a></td>
<td>A <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html#torch.nn.ConvTranspose1d"><code>torch.nn.ConvTranspose1d</code></a> module with lazy initialization of the <code>in_channels</code> argument of the <code>ConvTranspose1d</code> that is inferred from the <code>input.size(1)</code>.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose2d.html#torch.nn.LazyConvTranspose2d"><code>nn.LazyConvTranspose2d</code></a></td>
<td>A <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d"><code>torch.nn.ConvTranspose2d</code></a> module with lazy initialization of the <code>in_channels</code> argument of the <code>ConvTranspose2d</code> that is inferred from the <code>input.size(1)</code>.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose3d.html#torch.nn.LazyConvTranspose3d"><code>nn.LazyConvTranspose3d</code></a></td>
<td>A <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html#torch.nn.ConvTranspose3d"><code>torch.nn.ConvTranspose3d</code></a> module with lazy initialization of the <code>in_channels</code> argument of the <code>ConvTranspose3d</code> that is inferred from the <code>input.size(1)</code>.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold"><code>nn.Unfold</code></a></td>
<td>Extracts sliding local blocks from a batched input tensor.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Fold.html#torch.nn.Fold"><code>nn.Fold</code></a></td>
<td>Combines an array of sliding local blocks into a large containing tensor.</td>
</tr>
</tbody>
</table>
</div>
<p>​        点进去看看：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">CLASS 
<span class="token class-name">torch</span><span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> groups<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding_mode<span class="token operator">=</span><span class="token string">'zeros'</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​        Applies a 2D convolution over an input signal composed of several input planes.</p>
<p>In the simplest case, the output value of the layer with input size </p>
<script type="math/tex; mode=display">
(N,C_{in},H,W)</script><p>​        and output</p>
<script type="math/tex; mode=display">
(N,C_{out},H_{out},W_{out})</script><p>​         can be precisely described as:</p>
<script type="math/tex; mode=display">
out(N_i,C_{outj}) = bias(C_{outj})+\sum_{k=0}^{C_{in}-1}weight(C_{out},k)*input(N_i,k)</script><p>​        where ⋆ is the valid 2D <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> operator, <em>N</em> is a batch size, C<em> denotes a number of channels, </em>H<em> is a height of input planes in pixels, and </em>W* is width in pixels.</p>
<p>​        This module supports <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere">TensorFloat32</a>.</p>
<p>​        On certain ROCm devices, when using float16 inputs this module will use <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/numerical_accuracy.html#fp16-on-mi200">different precision</a> for backward.</p>
<ul>
<li><p><code>stride</code> controls the stride for the cross-correlation, a single number or a tuple.</p>
</li>
<li><p><code>padding</code> controls the amount of padding applied to the input. It can be either a string {‘valid’, ‘same’} or an int / a tuple of ints giving the amount of implicit padding applied on both sides.</p>
</li>
<li><p><code>dilation</code> controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this <a target="_blank" rel="noopener" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code>dilation</code> does.</p>
</li>
<li><p><code>groups</code> controls the connections between inputs and outputs. <code>in_channels</code> and <code>out_channels</code> must both be divisible by <code>groups</code>. For example,</p>
<blockquote>
<ul>
<li>At groups=1, all inputs are convolved to all outputs.</li>
<li>At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels and producing half the output channels, and both subsequently concatenated.</li>
<li>At groups= <code>in_channels</code>, each input channel is convolved with its own set of filters (of size $\frac{in_channels}{out_channels}$)</li>
</ul>
</blockquote>
</li>
</ul>
<p>​        The parameters <code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>dilation</code> can either be:</p>
<blockquote>
<ul>
<li>a single <code>int</code> – in which case the same value is used for the height and width dimension</li>
<li>a <code>tuple</code> of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension</li>
</ul>
</blockquote>
<p>​        When groups == in_channels and out_channels == K * in_channels, where K is a positive integer, this operation is also known as a “depthwise convolution”.</p>
<p>​        In other words, for an input of size $(N,C_{in},L_{in})$, a depthwise convolution with a depthwise multiplier<em>K</em> can be performed with the arguments ($C_{in}=C_{in},C_{out}=C_{in}×K,…,groups=C_{in}$.)</p>
<p>​        In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting </p>
<pre class="line-numbers language-none"><code class="language-none">torch.backends.cudnn.deterministic &#x3D; True. <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​        See <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/randomness.html">Reproducibility</a> for more information.</p>
<p>​        <code>padding=&#39;valid&#39;</code> is the same as no padding. <code>padding=&#39;same&#39;</code> pads the input so the output has the shape as the input. However, this mode doesn’t support any stride values other than 1.</p>
<p>​        This module supports complex data types i.e. <code>complex32, complex64, complex128</code>.</p>
<p>Parameters:</p>
<ul>
<li><strong>in_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels in the input image</li>
<li><strong>out_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels produced by the convolution</li>
<li><strong>kernel_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a>) – Size of the convolving kernel</li>
<li><strong>stride</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Stride of the convolution. Default: 1</li>
<li><strong>padding</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – Padding added to all four sides of the input. Default: 0</li>
<li><strong>padding_mode</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – <code>&#39;zeros&#39;</code>, <code>&#39;reflect&#39;</code>, <code>&#39;replicate&#39;</code> or <code>&#39;circular&#39;</code>. Default: <code>&#39;zeros&#39;</code></li>
<li><strong>dilation</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Spacing between kernel elements. Default: 1</li>
<li><strong>groups</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</li>
<li><strong>bias</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – If <code>True</code>, adds a learnable bias to the output. Default: <code>True</code></li>
</ul>
<h2 id="what-is-Convolution-arithmetic-from-read-ME"><a href="#what-is-Convolution-arithmetic-from-read-ME" class="headerlink" title="what is Convolution arithmetic(from read ME)"></a>what is Convolution arithmetic(from read ME)</h2><p>​        A technical report on convolution arithmetic in the context of deep learning.</p>
<p>​        The code and the images of this tutorial are free to use as regulated by the<br>licence and subject to proper attribution:</p>
<ul>
<li>[1] Vincent Dumoulin, Francesco Visin - <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1603.07285">A guide to convolution arithmetic<br>for deep learning</a><br>(<a target="_blank" rel="noopener" href="https://gist.github.com/fvisin/165ca9935392fa9600a6c94664a01214">BibTeX</a>)</li>
</ul>
<h2 id="Convolution-animations"><a href="#Convolution-animations" class="headerlink" title="Convolution animations"></a>Convolution animations</h2><p>_N.B.: Blue maps are inputs, and cyan maps are outputs._</p>
<table style="width:100%; table-layout:fixed;">
  <tr>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif"></td>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/arbitrary_padding_no_strides.gif"></td>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/same_padding_no_strides.gif"></td>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/full_padding_no_strides.gif"></td>
  </tr>
  <tr>
    <td>No padding, no strides</td>
    <td>Arbitrary padding, no strides</td>
    <td>Half padding, no strides</td>
    <td>Full padding, no strides</td>
  </tr>
  <tr>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_strides.gif"></td>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides.gif"></td>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides_odd.gif"></td>
    <td></td>
  </tr>
  <tr>
    <td>No padding, strides</td>
    <td>Padding, strides</td>
    <td>Padding, strides (odd)</td>
    <td></td>
  </tr>
</table>



<h2 id="Transposed-convolution-animations"><a href="#Transposed-convolution-animations" class="headerlink" title="Transposed convolution animations"></a>Transposed convolution animations</h2><p>_N.B.: Blue maps are inputs, and cyan maps are outputs._</p>
<table style="width:100%; table-layout:fixed;">
  <tr>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides_transposed.gif"></td>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/arbitrary_padding_no_strides_transposed.gif"></td>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/same_padding_no_strides_transposed.gif"></td>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/full_padding_no_strides_transposed.gif"></td>
  </tr>
  <tr>
    <td>No padding, no strides, transposed</td>
    <td>Arbitrary padding, no strides, transposed</td>
    <td>Half padding, no strides, transposed</td>
    <td>Full padding, no strides, transposed</td>
  </tr>
  <tr>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_strides_transposed.gif"></td>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides_transposed.gif"></td>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides_odd_transposed.gif"></td>
    <td></td>
  </tr>
  <tr>
    <td>No padding, strides, transposed</td>
    <td>Padding, strides, transposed</td>
    <td>Padding, strides, transposed (odd)</td>
    <td></td>
  </tr>
</table>



<h2 id="Dilated-convolution-animations"><a href="#Dilated-convolution-animations" class="headerlink" title="Dilated convolution animations"></a>Dilated convolution animations</h2><p>_N.B.: Blue maps are inputs, and cyan maps are outputs._</p>
<table style="width:25%"; table-layout:fixed;>
  <tr>
    <td><img width="150px" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/dilation.gif"></td>
  </tr>
  <tr>
    <td>No padding, no stride, dilation</td>
  </tr>
</table>



<h2 id="Generating-the-Makefile"><a href="#Generating-the-Makefile" class="headerlink" title="Generating the Makefile"></a>Generating the Makefile</h2><p>From the repository’s root directory:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ ./bin/generate_makefile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="Generating-the-animations"><a href="#Generating-the-animations" class="headerlink" title="Generating the animations"></a>Generating the animations</h2><p>From the repository’s root directory:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">make</span> all_animations<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>The animations will be output to the <code>gif</code> directory. Individual animation steps<br>will be output in PDF format to the <code>pdf</code> directory and in PNG format to the<br><code>png</code> directory.</p>
<h2 id="Compiling-the-document"><a href="#Compiling-the-document" class="headerlink" title="Compiling the document"></a>Compiling the document</h2><p>From the repository’s root directory:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">make</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="image-20230528203415187.png" alt="image-20230528203415187"></p>
<p>​        其实就是这样，我们3 x 3的扫过图像，并且对之求和输出到新单元，我们发现他会做九次。，故得到了一个 3 x 3的表。</p>
<p><img src="image-20230528203830290.png" alt="image-20230528203830290"></p>
<p>​        这样就可以升维了，从而提取信息特征。</p>
<p><img src="image-20230528213941244.png" alt="image-20230528213941244"></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"../data"</span><span class="token punctuation">,</span>train <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                                       transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        download<span class="token operator">=</span><span class="token boolean">True</span>
                                       <span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">cc</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>cc<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

c <span class="token operator">=</span> cc<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
    imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span>data
    output <span class="token operator">=</span> c<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​        我们把它输出到tensorboard里去：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter

dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"../data"</span><span class="token punctuation">,</span>train <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                                       transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        download<span class="token operator">=</span><span class="token boolean">True</span>
                                       <span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">cc</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>cc<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

c <span class="token operator">=</span> cc<span class="token punctuation">(</span><span class="token punctuation">)</span>

writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"../logs"</span><span class="token punctuation">)</span>
step <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
    imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span>data
    output <span class="token operator">=</span> c<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>output<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span> output<span class="token punctuation">,</span> step<span class="token punctuation">)</span>
    step <span class="token operator">=</span> step <span class="token operator">+</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">(</span>yolofacev5<span class="token punctuation">)</span> pythonProject<span class="token operator"><span class="token file-descriptor important">1</span>></span> <span class="token builtin class-name">cd</span> <span class="token punctuation">..</span>
<span class="token punctuation">(</span>yolofacev5<span class="token punctuation">)</span> pythonProject<span class="token operator"><span class="token file-descriptor important">1</span>></span> tensorboard <span class="token parameter variable">--logdir</span><span class="token operator">=</span>logs      <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><img src="image-20230528214836000.png" alt="image-20230528214836000"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/Charliechen114514">Charlie Chen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://charliechen114514.github.io/2023/06/06/Learn-Pytorch-1/">http://charliechen114514.github.io/2023/06/06/Learn-Pytorch-1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">全体目光向我看齐，我宣布个事！是我Charliechen写的这篇文章！(?)</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Pytorch/">Pytorch</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post_share"><div class="social-share" data-image="/img/passagepage.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/06/06/Learn-Windows-API-Semester-I/" title="Learn_Windows_API-Semester-I"><img class="cover" src="/img/passagepage.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Learn_Windows_API-Semester-I</div></div></a></div><div class="next-post pull-right"><a href="/2023/06/06/CPP-ExtensiveReadingNotes-2-MoreEffectiveCPP/" title="CPP_ExtensiveReadingNotes-2-MoreEffectiveCPP"><img class="cover" src="/img/passagepage.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">CPP_ExtensiveReadingNotes-2-MoreEffectiveCPP</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/04/13/Pandas-in-Python/" title="Pandas in Python"><img class="cover" src="/img/passagepage.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-13</div><div class="title">Pandas in Python</div></div></a></div><div><a href="/2023/06/06/Opencv-learning-Python-1/" title="Opencv_learning_Python(1)"><img class="cover" src="/img/passagepage.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-06</div><div class="title">Opencv_learning_Python(1)</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/webicon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Charlie Chen</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">50</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">25</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Charliechen114514"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Charliechen114514" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=725610365&amp;site=qq&amp;menu=yes" target="_blank" title="QQ"><i class="fab fa-qq"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">合并了大部分博客，并且优化了目录和标签！部分老博客删除，数据结构部分将会用Algorithm_in_C为大纲重写，可以期待一下（）</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Pytorch%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">Pytorch学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.1.</span> <span class="toc-text">学习加载数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TensorBoard%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-number">1.2.</span> <span class="toc-text">TensorBoard的基本使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E9%AA%8C%E6%9D%A5%E4%BA%86"><span class="toc-number">1.2.1.</span> <span class="toc-text">经验来了</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84transformer"><span class="toc-number">1.3.</span> <span class="toc-text">常见的transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#PIL-Image%E5%BA%93%E8%AF%BB%E5%85%A5%E5%9B%BE%E7%89%87"><span class="toc-number">1.3.1.</span> <span class="toc-text">PIL-Image库读入图片</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%8F%E6%8F%92%E6%9B%B2%EF%BC%9A-call-%E7%9A%84%E7%94%A8%E6%B3%95"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">小插曲： __call__的用法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%A7%E7%BB%AD%EF%BC%9A"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">继续：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#To-PILImage"><span class="toc-number">1.3.2.</span> <span class="toc-text">To PILImage</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Normalize%E6%96%B9%E6%B3%95%E7%B1%BB"><span class="toc-number">1.3.3.</span> <span class="toc-text">Normalize方法类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Resize"><span class="toc-number">1.3.4.</span> <span class="toc-text">Resize</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Compose-%E7%BB%84%E5%90%88%E5%8F%98%E6%8D%A2"><span class="toc-number">1.4.</span> <span class="toc-text">Compose 组合变换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#torchvision-%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.5.</span> <span class="toc-text">torchvision 学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-CIFAR-10-dataset"><span class="toc-number">1.6.</span> <span class="toc-text">The CIFAR-10 dataset</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD"><span class="toc-number">1.7.</span> <span class="toc-text">下载</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E7%BA%BF%E7%BB%93%E6%9E%9C"><span class="toc-number">1.8.</span> <span class="toc-text">基线结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E7%BB%93%E6%9E%9C"><span class="toc-number">1.9.</span> <span class="toc-text">其他结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%89%88%E6%9C%AC"><span class="toc-number">1.10.</span> <span class="toc-text">二进制版本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD-1"><span class="toc-number">1.11.</span> <span class="toc-text">下载</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">1.12.</span> <span class="toc-text">参考</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DataLoader"><span class="toc-number">1.13.</span> <span class="toc-text">DataLoader</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.14.</span> <span class="toc-text">神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">1.14.1.</span> <span class="toc-text">卷积层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#what-is-Convolution-arithmetic-from-read-ME"><span class="toc-number">1.15.</span> <span class="toc-text">what is Convolution arithmetic(from read ME)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Convolution-animations"><span class="toc-number">1.16.</span> <span class="toc-text">Convolution animations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Transposed-convolution-animations"><span class="toc-number">1.17.</span> <span class="toc-text">Transposed convolution animations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dilated-convolution-animations"><span class="toc-number">1.18.</span> <span class="toc-text">Dilated convolution animations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Generating-the-Makefile"><span class="toc-number">1.19.</span> <span class="toc-text">Generating the Makefile</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Generating-the-animations"><span class="toc-number">1.20.</span> <span class="toc-text">Generating the animations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Compiling-the-document"><span class="toc-number">1.21.</span> <span class="toc-text">Compiling the document</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/01/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E5%BF%B5%E9%80%9F%E9%80%9A%EF%BC%88%E5%9F%BA%E4%BA%8E%E8%B0%A2%E5%B8%8C%E4%BB%81%E7%89%88%E6%9C%AC%EF%BC%89/" title="计算机网络概念速通（基于谢希仁版本）"><img src="/img/passagepage.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机网络概念速通（基于谢希仁版本）"/></a><div class="content"><a class="title" href="/2024/01/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E5%BF%B5%E9%80%9F%E9%80%9A%EF%BC%88%E5%9F%BA%E4%BA%8E%E8%B0%A2%E5%B8%8C%E4%BB%81%E7%89%88%E6%9C%AC%EF%BC%89/" title="计算机网络概念速通（基于谢希仁版本）">计算机网络概念速通（基于谢希仁版本）</a><time datetime="2024-01-24T03:45:11.000Z" title="发表于 2024-01-24 11:45:11">2024-01-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/01/22/%E9%87%8D%E6%96%B0%E5%AD%A6%E4%B9%A0Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" title="重新学习Linux操作系统"><img src="/img/passagepage.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="重新学习Linux操作系统"/></a><div class="content"><a class="title" href="/2024/01/22/%E9%87%8D%E6%96%B0%E5%AD%A6%E4%B9%A0Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" title="重新学习Linux操作系统">重新学习Linux操作系统</a><time datetime="2024-01-22T04:24:05.000Z" title="发表于 2024-01-22 12:24:05">2024-01-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/01/20/%E5%BA%93%E8%AE%BE%E8%AE%A1%EF%BC%9A%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84Logger%E5%BA%93/" title="库设计：一个简单的Logger库"><img src="/img/passagepage.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="库设计：一个简单的Logger库"/></a><div class="content"><a class="title" href="/2024/01/20/%E5%BA%93%E8%AE%BE%E8%AE%A1%EF%BC%9A%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84Logger%E5%BA%93/" title="库设计：一个简单的Logger库">库设计：一个简单的Logger库</a><time datetime="2024-01-20T06:40:11.000Z" title="发表于 2024-01-20 14:40:11">2024-01-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/01/19/EffectiveModernCpp/" title="EffectiveModernCpp"><img src="/img/passagepage.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="EffectiveModernCpp"/></a><div class="content"><a class="title" href="/2024/01/19/EffectiveModernCpp/" title="EffectiveModernCpp">EffectiveModernCpp</a><time datetime="2024-01-19T12:39:07.000Z" title="发表于 2024-01-19 20:39:07">2024-01-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/01/19/Linux%E6%BC%AB%E6%B8%B8%E5%90%88%E9%9B%86/" title="Linux漫游合集"><img src="/img/passagepage.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux漫游合集"/></a><div class="content"><a class="title" href="/2024/01/19/Linux%E6%BC%AB%E6%B8%B8%E5%90%88%E9%9B%86/" title="Linux漫游合集">Linux漫游合集</a><time datetime="2024-01-19T11:55:46.000Z" title="发表于 2024-01-19 19:55:46">2024-01-19</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Charlie Chen</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="哼啊啊啊啊啊啊啊啊啊啊啊啊,人民万岁！,兄啊，别点力" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>