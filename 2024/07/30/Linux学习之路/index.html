<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>Linux学习之路 | Hello World!</title><meta name="author" content="Charlie Chen"><meta name="copyright" content="Charlie Chen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Linux Kernel Programming在我们开始之前…​    我们需要配置环境！这是一切的开始，但是在那之前，我们需要明确一下我们在这个系列将会做的事情！  在你的系统上建立一个可运行的 Linux 内核工作区（作为虚拟机或本地系统） 从源代码开始构建 Linux 内核（适用于 x86_64 和基于 ARM 的系统） 了解现代 Linux 内核模块（LKM）框架，并利用它编写内核模块">
<meta property="og:type" content="article">
<meta property="og:title" content="Linux学习之路">
<meta property="og:url" content="http://charliechen114514.github.io/2024/07/30/Linux%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/index.html">
<meta property="og:site_name" content="Hello World!">
<meta property="og:description" content="Linux Kernel Programming在我们开始之前…​    我们需要配置环境！这是一切的开始，但是在那之前，我们需要明确一下我们在这个系列将会做的事情！  在你的系统上建立一个可运行的 Linux 内核工作区（作为虚拟机或本地系统） 从源代码开始构建 Linux 内核（适用于 x86_64 和基于 ARM 的系统） 了解现代 Linux 内核模块（LKM）框架，并利用它编写内核模块">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://charliechen114514.github.io/img/passagepage.png">
<meta property="article:published_time" content="2024-07-30T02:02:02.000Z">
<meta property="article:modified_time" content="2024-07-30T02:03:43.268Z">
<meta property="article:author" content="Charlie Chen">
<meta property="article:tag" content="C&#x2F;C++">
<meta property="article:tag" content="Linux">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://charliechen114514.github.io/img/passagepage.png"><link rel="shortcut icon" href="/img/webicon.png"><link rel="canonical" href="http://charliechen114514.github.io/2024/07/30/Linux%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Linux学习之路',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-07-30 10:03:43'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = url => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      link.onload = () => resolve()
      link.onerror = () => reject()
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/webicon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">72</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 大爹们</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/passagepage.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Hello World!"><span class="site-name">Hello World!</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 大爹们</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Linux学习之路</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-07-30T02:02:02.000Z" title="发表于 2024-07-30 10:02:02">2024-07-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-07-30T02:03:43.268Z" title="更新于 2024-07-30 10:03:43">2024-07-30</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">205.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>687分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Linux学习之路"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Linux-Kernel-Programming"><a href="#Linux-Kernel-Programming" class="headerlink" title="Linux Kernel Programming"></a><code>Linux Kernel Programming</code></h1><h2 id="在我们开始之前…"><a href="#在我们开始之前…" class="headerlink" title="在我们开始之前…"></a>在我们开始之前…</h2><p>​    我们需要配置环境！这是一切的开始，但是在那之前，我们需要明确一下我们在这个系列将会做的事情！</p>
<ul>
<li>在你的系统上建立一个可运行的 Linux 内核工作区（作为虚拟机或本地系统）</li>
<li>从源代码开始构建 Linux 内核（适用于 x86_64 和基于 ARM 的系统）</li>
<li>了解现代 Linux 内核模块（LKM）框架，并利用它编写内核<br>模块</li>
<li>编写内核模块（和一些用户空间程序），执行各种任务（例如遍历所有存活的进程/线程，显示用户和内核地址空间的详细信息，动态管理内核内存（以各种方式分配和释放内存），以及启动内核内存不足杀手，同时通过 代码示例）。</li>
<li>了解并发（并行）硬件和软件系统工作中固有的复杂性 和软件系统（如 Linux）工作时固有的复杂性，并了解何时以及如何通过各种强大的技术同步内核代码 通过各种强大的锁定和无锁定技术来同步你的内核代码。</li>
</ul>
<h4 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h4><ol>
<li>配置好Ubuntu虚拟机</li>
</ol>
<h4 id="选择-Linux-发行版和内核"><a href="#选择-Linux-发行版和内核" class="headerlink" title="选择 Linux 发行版和内核"></a><strong>选择 Linux 发行版和内核</strong></h4><p>​    我们实践的关键是要安装一个最新的、支持良好的 Linux 发行版，以及一个最新的长期 Linux 内核。在软件方面，<strong>长期稳定</strong>（<strong>LTS</strong>）版本可以帮助你免受持续维护和升级的影响，并保证你的环境安全；负责维护 LTS 版本的组织或人员会对产品进行维护，并应用关键和必要的安全和漏洞修复，通常会持续很长时间。有关 LTS Linux 内核的情况将在下文中提及。</p>
<p>简而言之，在这次实践中，我们将选择以下内容：</p>
<ul>
<li><p>Linux 发行版（或发行版） Ubuntu 22.04 LTS（Jammy Jellyfish）；免费安全和维护更新保证至 2027 年 4 月。EOL 为 2032 年 4 月。</p>
</li>
<li><p>Linux 内核 最新的<strong>LTS</strong> Linux 内核版本（截至本文撰写之时）为<strong>6.1.y</strong>；<strong>生命周期结束日期</strong>（<strong>EOL</strong>）为 2026 年 12 月（内核版本命名法在第 2 章<em>“从源代码构建 6.x Linux 内核—第 1 部分</em>“中有详细解释）。</p>
</li>
<li><p>虚拟机管理程序： VMware</p>
</li>
</ul>
<p>​    我们的理由很简单：所有这些都是<strong>开源软件</strong>（<strong>OSS</strong>），截至本文撰写之时，其截止日期都足够长，可以确保它们在很长一段时间内都能继续得到支持并保持活力。关于Linux内核版本、术语的确切含义以及实际构建自定义内核的问题，将在接下来的两章中深入介绍；别紧张，我们会讲到的。当然，在本机系统上运行Linux有一定的性能优势。当然，在原生系统上运行 Linux 有一定的性能优势，但在这次实践中，我们不会假设你有一个专用的备用原生 Linux 系统，所以我们会选择在虚拟机上运行 Linux；这样做也更安全，有助于避免令人不快的数据丢失或其他意外情况。事实上，当在内核级别工作时，系统突然崩溃（以及由此产生的数据丢失风险）实际上是司空见惯的事情。对于虚拟机管理程序，我建议使用 Oracle VirtualBox 7.x（或最新的稳定版本）或其他虚拟化软件，如 VMware Workstation。</p>
<p>​    自己选择好自己上心的虚拟机运行程序之后，我们可以继续了。</p>
<h4 id="下面，是软件安装时间"><a href="#下面，是软件安装时间" class="headerlink" title="下面，是软件安装时间"></a>下面，是软件安装时间</h4><p>​    当使用典型的 Linux 桌面发行版（例如任何最新的 Ubuntu、Debian、CentOS 或 Fedora Linux 系统）时，默认安装的软件包可能包含系统程序员所需的最小集：本机工具链，其中包括 GCC 编译器以及标头和 make 实用程序/软件包。 什么是工具链和本机工具链？ 要开发软件，我们（显然）需要一个编译器（它将我们的源代码编译为汇编代码和机器代码，以便可以在机器上执行）。 我们通常使用古老的 GCC 编译器（尽管 <em>Clang</em> 变得非常流行！）。 但等等，这只是表面层次的观点；不仅仅是编译器——深入研究，还需要许多其他工具。它们包括 make 实用程序、GCC 编译器、标准 (GNU) C 库 (glibc)、binutils 包（链接器和汇编器）、bison 和 flex 解析器/词法分析器、GDB 调试器和 GNU autotools 套件。所有这些工具共同构成了我们所说的 <strong>工具链</strong>，这是开发所必需的。此外，在典型的 Linux 发行版上默认安装的工具链称为<em>本机工具链</em>（它从该系统上为同一系统类型的源代码构建软件）。另一方面，我们也有在主机系统上构建软件但旨在在另一个（外部）CPU 架构上运行的工具链（例如在 x86_64 上为 ARM32 构建）；这些被称为 <em>跨工具链</em>（我们将在本书后面介绍它们）。</p>
<p>​    是的，我们还需要安装一些重要的开发包，这里给出一种参考：</p>
<blockquote>
<p>写内核需要的</p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">sudo apt install -y bison build-essential flex libncurses5-dev libelf-dev libssl-dev tar util-linux xz-utils<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>干其他事情我们需要的：</p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">sudo apt install -y \
 bc bpfcc-tools bsdextrautils \
 clang cppcheck cscope curl exuberant-ctags \
 fakeroot flawfinder \
 gnome-system-monitor gnuplot hwloc indent \
 libnuma-dev linux-headers-$(uname -r) linux-tools-$(uname -r) \
 man-db net-tools numactl openjdk-22-jdk openssh-server \
 perf-tools-unstable psmisc python3-distutils \
 rt-tests smem sparse stress sysfsutils \
 tldr-py trace-cmd tree tuna virt-what<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="安装-QEMU-和交叉工具链"><a href="#安装-QEMU-和交叉工具链" class="headerlink" title="安装 QEMU 和交叉工具链"></a>安装 QEMU 和交叉工具链</h4><p>​    在 ARM 机器上尝试的一种方法是实际在基于 ARM[64] 的物理 SBC 上进行；例如，Raspberry Pi 是一个非常受欢迎的选择。在这种情况下，典型的开发工作流程是首先在 x86_64 主机系统上构建 ARM 代码。但要做到这一点，我们需要安装一个交叉工具链 - 一组工具，允许您在一个主机 CPU 上构建软件，以便它在不同的（外部）目标 CPU 上执行。x86_64 主机为 ARM 目标构建程序是一种非常常见的情况，实际上也是我们这里的用例。安装交叉编译器的详细信息稍后会介绍。 通常，尝试的另一种方法是模拟 ARM/Linux 系统 - 这减轻了对硬件的需求！为此，我们建议使用出色的 QEMU（快速模拟器） 项目！</p>
<pre class="line-numbers language-none"><code class="language-none">sudo apt install qemu-system-arm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    如果您打算编写一个在特定主机系统上编译但必须在另一个（外部）目标系统上执行的 C（或 C++）程序，那么您需要使用所谓的交叉编译器或交叉工具链对其进行编译。例如，在我们的用例中，我们希望在 x86_64 主机上工作（开发代码）。主机甚至可以是 x86_64 客户系统（这很好），但代码必须在 AArch32（ARM32）目标上运行。 我们现在不会进一步深入探讨安装特定交叉工具链的细节，因为我们实际上需要它 - 并在后面的章节中深入解释它。另一件有趣的事情是：您可以使用预构建的（Docker）容器作为多个目标的交叉编译环境；它有助于确保项目中的所有团队都使用相同的交叉编译环境。</p>
<p>​    这里先不介绍，用的时候再说！</p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>​    在开始之前，我们需要明白的是：任何一个现代的Linux系统都有三个部分：</p>
<ol>
<li><strong>一个bootloader</strong></li>
<li><strong>OS内核</strong></li>
<li><strong>根文件系统</strong></li>
</ol>
<p>当然，还有两个可选的（但是我自己玩玩的时候发现总是少不了的！）</p>
<ol>
<li>Linux设备树：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/unclemac/p/12783391.html">Linux dts 设备树详解(一) 基础知识 - 小麦大叔 - 博客园 (cnblogs.com)</a></li>
<li>initramfs和initrd文件</li>
</ol>
<h4 id="内核构建的准备工作（Preliminaries-for-the-kernel-build）"><a href="#内核构建的准备工作（Preliminaries-for-the-kernel-build）" class="headerlink" title="内核构建的准备工作（Preliminaries for the kernel build）"></a>内核构建的准备工作（<strong>Preliminaries for the kernel build</strong>）</h4><p>​    我们必须先理解对一些事情</p>
<p>​    首先，Linux 内核及其姊妹项目是完全去中心化的——它是一个虚拟的在线开源社区！我们最接近 Linux 的“办公室”是：Linux 内核（以及几十个相关项目）的管理权掌握在 Linux 基金会 (<a target="_blank" rel="noopener" href="https://linuxfoundation.org/">https://linuxfoundation.org/</a>) 的手中；此外，它还管理 Linux 内核组织，这是一个向公众免费分发 Linux 内核的私人基金会 (<a target="_blank" rel="noopener" href="https://www.kernel.org/nonprofit.html)。">https://www.kernel.org/nonprofit.html)。</a></p>
<p>​    本节将讨论的一些关键点包括：</p>
<ol>
<li>内核版本或版本号命名法</li>
<li>典型的内核开发工作流程</li>
<li>存储库中不同类型的内核源代码树的存在</li>
</ol>
<h4 id="理解内核版本或版本号命名法"><a href="#理解内核版本或版本号命名法" class="headerlink" title="理解内核版本或版本号命名法"></a>理解内核版本或版本号命名法</h4><p>​    咋看自己的内核版本呢？</p>
<pre class="line-numbers language-none"><code class="language-none">uname -r<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;Desktop$ uname -r
6.5.0-41-generic<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    格式是：<code>w.x[.y][-z]</code></p>
<p>​    w是主版本号，这里我们的主版本是6</p>
<p>​    x是次版本号，显然这里是5</p>
<p>​    我们还有补丁版本！这里是0</p>
<p>​    对于下一个是根据发行版相异的，在这里Ubuntu自己家的补丁版本是41-generic</p>
<h4 id="典型的内核开发工作流程"><a href="#典型的内核开发工作流程" class="headerlink" title="典型的内核开发工作流程"></a>典型的内核开发工作流程</h4><p>​    一个常见的误解，尤其是在 Linux 内核刚诞生的时期，<strong>是它以一种临时的方式开发出来的。这完全不是事实！内核开发过程已经发展成为一个运转良好的系统，拥有一个详尽记录的过程，以及对内核贡献者应该知道什么才能很好地使用它的期望。</strong><br>​    为了让我们了解一个典型的开发周期，我们假设我们已经将最新的主流 Linux Git 内核树克隆到我们的系统上。<br>​    如前所述，在撰写本文时，6.1 内核是一个长期稳定 (LTS) 版本，预计 EOL 日期距离现在最远（2026 年 12 月），因此我们将在后面的材料中使用它。那么，它是如何产生的呢？显然，它是从早期的候选版本 (rc) 内核和之前的稳定内核版本演变而来的，在这种情况下，将是 v6.1-rc’n’ 内核和之前的稳定 v6.0 内核。让我们通过两种方式查看这种演变：通过命令行和通过内核的 GitHub 页面以图形方式查看</p>
<h3 id="构建内核"><a href="#构建内核" class="headerlink" title="构建内核"></a>构建内核</h3><p>​    为方便快捷，以下是从源代码构建 Linux 内核所需的主要关键步骤。由于每个步骤的解释都非常详细，您可以参考此摘要以了解整体情况。步骤如下：</p>
<ol>
<li>通过以下任一选项获取 Linux 内核源代码树：将特定内核源代码树下载为压缩文件克隆（内核）Git 树</li>
<li>将内核源代码树提取到主目录中的某个位置（如果您通过克隆 Git 树获取内核，请跳过此步骤）。</li>
<li>配置：获取内核配置的起点（方法各不相同）。然后对其进行编辑，选择新内核所需的内核支持选项。建议使用make menuconfig。</li>
<li>使用 make [-j’n’] all 构建内核映像、可加载模块和任何需的设备树 Blob（DTB）。这将构建压缩的内核映像 (<code>arch/&lt;arch&gt;/boot/[b|z|u]&#123;Ii&#125;mage</code>)、未压缩的内核映像 – vmlinux、System.map 文件、内核模块对象以及任何已配置的 DTB 文件。</li>
<li>使用 <code>sudo make [INSTALL_MOD_PATH=&lt;prefix-dir&gt;]modules_install</code> 安装刚刚构建的内核模块（在 x86 上）。此步骤默认将内核模块安装在 /lib/modules/$(uname -r)/ 下（可利用INSTALL_MOD_PATH 环境变量来更改此设置）。</li>
<li>引导加载程序 (x86)：设置 GRUB 引导加载程序和initramfs（之前称为 initrd），映像：<code>sudo make[INSTALL_PATH=&lt;/new/boot/dir&gt;] install</code>这将在 /boot 下创建并安装 initramfs 或 initrd 映像（可利用INSTALL_PATH 环境变量来更改此设置）。它更新引导加载程序配置文件以启动新内核（第一个条目）。</li>
<li>自定义 GRUB 引导加载程序菜单（可选）。本章是此内核构建主题的两章中的第一章，将介绍步骤 1 至3，并附带大量必需的背景材料。下一章将介绍其余步骤，即步骤 4 至7。因此，让我们从步骤 1 开始。</li>
</ol>
<h4 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h4><p>​    我们根据上面的陈述，找到<a target="_blank" rel="noopener" href="https://mirrors.edge.kernel.org/pub/linux/kernel/v6.x/">Index of /pub/linux/kernel/v6.x/</a></p>
<p>​    下载自己需要的内核</p>
<pre class="line-numbers language-none"><code class="language-none">wget https:&#x2F;&#x2F;mirrors.edge.kernel.org&#x2F;pub&#x2F;linux&#x2F;kernel&#x2F;v6.x&#x2F;linux-6.1.25.tar.xz<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    完事了之后记得解压。然后创建一个变量指向之。</p>
<pre class="line-numbers language-none"><code class="language-none">export path&#x2F;to&#x2F;your&#x2F;linux-source<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="./image-20240704071212273.png" alt="image-20240704071212273"></p>
<p><img src="./image-20240704071509360.png" alt="image-20240704071509360"></p>
<h4 id="导览我们的内核源码"><a href="#导览我们的内核源码" class="headerlink" title="导览我们的内核源码"></a>导览我们的内核源码</h4><pre class="line-numbers language-none"><code class="language-none">du -h .<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    我们可以看到内核源码的大小1.5G！内核的构建是依靠MakeFile来进行的，我们常谈到的这个Makefile说的总是是最顶层的那个Makefile。</p>
<pre class="line-numbers language-none"><code class="language-none">head Makefile
charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ head Makefile 
# SPDX-License-Identifier: GPL-2.0
VERSION &#x3D; 6
PATCHLEVEL &#x3D; 1
SUBLEVEL &#x3D; 25
EXTRAVERSION &#x3D;
NAME &#x3D; Hurr durr I&#39;ma ninja sloth
# TIPS:上面的这个NAME是一个笑话，虽然我几乎总是Get不到
# *DOCUMENTATION*
# To see a list of typical targets execute &quot;make help&quot;
# More info can be located in .&#x2F;README<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    还有其他一些文件</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>文件/目录</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>README</td>
<td>这里将会给出一些doc在哪里：显然在/Documentation下，可以查看README来获取开发者们自己写的Doc</td>
</tr>
<tr>
<td>COPYING</td>
<td>此文件详细说明了发布内核源代码的许可条款。绝大多数内核源文件都是根据众所周知的 GNU GPL v2（写为 GPL-2.0）许可证发布的。 现代趋势是使用易于 grep 的行业一致 SPDX 许可证标识符。</td>
</tr>
<tr>
<td>MAINTAINERS</td>
<td>FAQ！也就是说我有若干模块的疑问可以找谁</td>
</tr>
<tr>
<td>Makefile</td>
<td>我们的KBuild构建系统将会最终生成它！到时候我们实际上就是一发入魂make</td>
</tr>
<tr>
<td>kernel</td>
<td>核心的子系统！他包括了我们操作系统核心的几个概念的构建！比如进程管理，调度，中断，锁等内容！</td>
</tr>
<tr>
<td>mm</td>
<td>内存管理的部分</td>
</tr>
<tr>
<td>fs</td>
<td>文件系统</td>
</tr>
<tr>
<td>block</td>
<td>这里是抽象出来的块层：比如说页缓存，通用的块IO，IO调度等，就是在这里是实现的</td>
</tr>
<tr>
<td>net</td>
<td>Linux的网络栈就是在这里实现的</td>
</tr>
<tr>
<td>ipc</td>
<td>进程间通信</td>
</tr>
<tr>
<td>sound</td>
<td>声卡</td>
</tr>
<tr>
<td>virt</td>
<td>虚拟化部分的代码，这里，KVM就是在这里实现的</td>
</tr>
<tr>
<td>Documentation</td>
<td>文档</td>
</tr>
<tr>
<td>LICENSES</td>
<td>协议</td>
</tr>
<tr>
<td>arch</td>
<td>在这里，Linux完成了架构层次的抽象，是它可以跑在多个平台的重要关键</td>
</tr>
<tr>
<td>cert</td>
<td>这里生成支持的签命模块</td>
</tr>
<tr>
<td>crypto</td>
<td>在这儿涉及到哦加密的算法</td>
</tr>
<tr>
<td>drivers</td>
<td>驱动</td>
</tr>
<tr>
<td>includes</td>
<td>包含的是架构特定的代码的includes</td>
</tr>
<tr>
<td>init</td>
<td>主要说的是初始化内核部分的代码！在这里是我们的Main函数</td>
</tr>
<tr>
<td>io_uring</td>
<td>全新的IO框架</td>
</tr>
<tr>
<td>lib</td>
<td>在这儿实现了我们常用的lib的函数，比如说压缩，位图，数学计算，字符串，常见的算法等</td>
</tr>
<tr>
<td>rust</td>
<td>R U S T</td>
</tr>
<tr>
<td>samples</td>
<td>一些实例</td>
</tr>
<tr>
<td>scripts</td>
<td>这里是辅助内核构建和调试的一些脚本</td>
</tr>
<tr>
<td>security</td>
<td>LSM（Linux安全模块）和MAC框架</td>
</tr>
<tr>
<td>tools</td>
<td>各种用户模式工具的源代码都存放在这里，大部分是与内核“紧密耦合”的应用程序或脚本，因此需要在特定的内核代码库内。Perf（一种现代 CPU 分析工具）、eBPF 工具和一些跟踪工具就是很好的例子。</td>
</tr>
<tr>
<td>usr</td>
<td>生成initramfs的地方，他将会在内核初始化的时候执行用户层的一些事情</td>
</tr>
</tbody>
</table>
</div>
<h4 id="一些重点"><a href="#一些重点" class="headerlink" title="一些重点"></a>一些重点</h4><p><strong>README</strong>：此文件还提到了有关构建和运行内核的最低可接受软件版本的信息，请参阅文档：Documentation/process/changes.rst。有趣的是，内核提供了一个 Awk 脚本 (scripts/ver_linux)，该脚本打印其运行的系统上当前软件的版本，帮助您检查已安装的版本是否可接受。</p>
<p><strong>内核许可</strong>：不必纠结于法律细节（不用说，我不是律师），以下是该事情的实用本质。由于内核是在 GNU GPL-2.0 许可证下发布的（<strong>GNU GPL 是 GNU 通用</strong>公共许可证），因此任何直接使用内核代码库的项目都会自动属于此许可证。这是 GPL-2.0 的“衍生作品”属性。从法律上讲，这些项目或产品现在必须根据相同的许可条款发布其内核软件。从实际情况来看，实际情况要模糊得多；许多在 Linux 内核上运行的商业产品确实包含专有的用户和/或内核空间代码。它们通常通过重构内核（最常见的是设备驱动程序）以可加载内核模块 (LKM) 格式工作来实现这一点。可以在 <em>双重许可</em> 模式下发布内核模块 (LKM)。LKM 是 <em>第 4 章 </em>编写您的第一个内核模块 - 第 1 部分<em> 和 </em>第 5 章 <em>编写您的第一个内核模块 - 第 2 部分</em> 的主题，我们在那里介绍了一些有关内核模块许可的信息。有些人更喜欢专有许可证，设法在未根据 GPL-2.0 条款许可的内核模块中发布他们的内核代码；从技术上讲，这也许是可能的，但至少被认为是非常反社会的，甚至可能越界为非法。感兴趣的人可以在本章的 <em>进一步**阅读</em> 文档中找到有关许可的更多链接。</p>
<p><strong>维护者</strong>：只需查看内核源代码树根目录中的此文件！有趣的东西……为了说明它有多有用，让我们运行一个辅助 Perl 脚本：scripts/get_maintainer.pl。请注意，从学术上讲，它只能在 Git 树上运行。在这里，我们要求脚本通过 -f 开关指定文件或目录来显示内核 CPU 任务调度代码库的维护者：</p>
<p><strong>Linux arch (CPU) 端口</strong>：从 6.1 开始，Linux 操作系统已移植到所有这些处理器。大多数都有 MMU，您可以在 arch/ 文件夹下看到特定于 arch 的代码，每个目录代表一个特定的 CPU 体系结构：事实上，在交叉编译时，ARCH 环境变量设置为其中一个文件夹的名称，以便为该体系结构编译内核。例如，在为 AArch64 构建目标“foo”时，我们通常会执行类似 make ARCH=arm64 CROSS_COMPILE=&lt;…&gt; foo 的操作</p>
<p><strong>io_uring</strong>：毫不夸张地说，io_uring 和 <em>eBPF</em> 被认为是现代 Linux 系统提供的两个新的“神奇功能”（这里的 io_uring 文件夹是该功能的内核支持）！数据库/网络人员对 io_uring 着迷的原因很简单：性能。该框架在现实世界的高 I/O 情况下显著提高了磁盘和网络工作负载的性能。其共享（在用户和内核空间之间）环形缓冲区架构、零拷贝模式以及与典型的旧 AIO 框架相比使用更少的系统调用的能力（包括轮询模式操作）使其成为令人羡慕的功能。因此，为了让您的用户空间应用程序走上真正快速的 I/O 路径，请查看 io_uring。本章的 <em>进一步阅读</em> 部分包含有用的链接。</p>
<p>内核中的 <strong>Rust</strong>：是的，确实，关于 Rust 编程语言的基本支持已进入 Linux 内核（首先是 6.0）这一事实，人们大肆宣传。为什么？Rust 确实比我们古老的 C 语言具有众所周知的优势：<strong>内存安全</strong>。事实上，即使在今天，用 C/C++ 编写的代码（无论是操作系统/驱动程序还是用户空间应用程序）最大的编程相关安全问题之一，其根源都是内存安全问题（例如众所周知的 <strong>BoF</strong>（<strong>缓冲区溢出</strong>）缺陷）。当开发人员在其 C/C++ 代码中生成内存损坏缺陷（错误！）时，就会发生这些问题。这会导致软件中的漏洞，聪明的黑客总是在寻找和利用这些漏洞！话虽如此，至少到目前为止，Rust 在内核中的应用非常少——没有核心代码使用它。内核中当前的 Rust 支持是为了将来支持用 Rust 编写模块。（当然，这里有一些示例 Rust 代码：samples/rust/。）内核中 Rust 的使用肯定会随着时间的推移而增加……</p>
<h3 id="配置内核"><a href="#配置内核" class="headerlink" title="配置内核"></a>配置内核</h3><p>​    最为关键的一步！要构建内核，无论如何您都必须执行内核配置步骤。即使您觉得不需要对现有或默认配置进行任何更改，也必须至少将此步骤作为构建过程的一部分运行一次。否则，此处自动生成的某些标头将会丢失，并在以后引起问题。至少，应该执行 make old[def]config 步骤。这将设置内核配置为现有系统的配置，并仅针对任何新选项回答用户请求的配置选项。</p>
<h4 id="关于Kconfig和Kbuild的最快理解"><a href="#关于Kconfig和Kbuild的最快理解" class="headerlink" title="关于Kconfig和Kbuild的最快理解"></a>关于Kconfig和Kbuild的最快理解</h4><p>​    Linux 内核用于配置内核的基础架构称为 Kconfig 系统，而构建它则需要 Kbuild 基础架构。无需深入研究细节，Kconfig + Kbuild 系统通过将工作分离为逻辑流，将复杂的内核配置和构建过程联系在一起： </p>
<ul>
<li><p>Kconfig – 配置内核的基础架构；它由两个逻辑部分组成： </p>
<ul>
<li>Kconfig 语言：用于指定各种 Kconfig[.*] 文件中的语法，这些文件实际上指定了选择内核配置选项的“菜单”。 </li>
<li>Kconfig 解析器：智能解析 Kconfig[.*] 文件、找出依赖项和自动选择并生成菜单系统的工具。其中包括常用的 make menuconfig，它在内部调用 mconf 工具（代码位于 scripts/kconfig 下）。 </li>
</ul>
</li>
<li><p>Kbuild – 将源代码构建为内核二进制组件的支持基础架构。它主要使用递归 make 样式构建，源自 内核顶层 Makefile，然后依次递归解析嵌入在源代码子目录中的 数百个 Makefile 的内容</p>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>构建</th>
<th>简单说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kconfig: CONFIG_FOO</td>
<td>每一个可以配置的选项FOO使用CONFIG_FOO表达，一般而言有三个选项：<br>- y = yes :在构建中包含进入特性<br>- m=module: 以一个单独的kobject模块进入内核<br>n = no:不包含</td>
</tr>
<tr>
<td>Kconfig: Kconfig.*</td>
<td>这是定义 CONFIG_FOO 符号的地方。 Kconfig 语法指定其类型（布尔、三态、 [alpha]numeric 等）和依赖树。 此外，对于基于菜单的配置 UI（通过 make [menu\</td>
<td>g\</td>
<td>x]config实现的</td>
</tr>
<tr>
<td>Kbuild</td>
<td>Kbuild 系统使用递归 make Makefile 方法。内核源代码树根目录中的 Makefile 称为顶级 Makefile，通常每个子文件夹中都有一个 Makefile 来在那里构建源代码。 6.1 内核源代码总共有 2,700 多个 Makefile！</td>
</tr>
<tr>
<td>.config</td>
<td>最终，内核配置归结为这个文件；.config 是最终的内核配置文件。它以简单的 ASCII 文本文件的形式生成并存储在内核源代码树根文件夹中。请妥善保管，因为它是您产品的关键部分。请注意，配置文件名可以通过环境变量KCONFIG_CONFIG 覆盖</td>
</tr>
</tbody>
</table>
</div>
<p>​    现在我们已经了解了一些细节，下面是它们如何结合在一起并工作的简化版本：<br>​    首先，用户（您）使用 Kconfig 提供的某种菜单系统配置内核。<br>​    通过此菜单系统 UI 选择的内核配置指令被写入几个自动生成的标头和最终的 .config 文件中，使用CONFIG_FOO={y|m} 语法，或者，CONFIG_FOO 被简单地注释掉（暗示“根本不构建 FOO”）。接下来，Kbuild 每个组件的 Makefile（通过内核顶层 Makefile 调用）通常指定一个指令 FOO，如下所示：</p>
<pre class="line-numbers language-none"><code class="language-none">obj-$(CONFIG_FOO) +&#x3D; FOO.o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    FOO 组件可以是任何东西 - 核心内核功能、设备驱动程序、文件系统、调试指令等等。回想一下，CONFIG_FOO 的值可能是 y、m 或不存在；因此，构建要么将组件 FOO 构建到内核中（当其值为 y 时），要么将其构建为模块（当其值为 m时）！如果注释掉，它根本就不会被构建，很简单。实际上，在构建时，上述 Makefile 指令会针对给定的内核组件 FOO 展开为以下三个之一：</p>
<pre class="line-numbers language-none"><code class="language-none">obj-y +&#x3D; FOO.o # 将功能 FOO 构建到内核映像中
obj-m +&#x3D; FOO.o # 将功能 FOO 构建为离散内核 m
&lt;如果 CONFIG_FOO 为空&gt; # 不构建功能 FOO<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​    不用说，先尝尝味道：</p>
<pre class="line-numbers language-none"><code class="language-none">$ cat Kconfig
…
obj-y +&#x3D; init&#x2F;
obj-y +&#x3D; usr&#x2F;
obj-y +&#x3D; arch&#x2F;$(SRCARCH)&#x2F;
obj-y +&#x3D; $(ARCH_CORE)
obj-y +&#x3D; kernel&#x2F;
[ … ]
obj-$(CONFIG_BLOCK) +&#x3D; block&#x2F;
obj-$(CONFIG_IO_URING) +&#x3D; io_uring&#x2F;
obj-$(CONFIG_RUST) +&#x3D; rust&#x2F;
obj-y +&#x3D; $(ARCH_LIB)
[ … ]
obj-y +&#x3D; virt&#x2F;
obj-y +&#x3D; $(ARCH_DRIVERS)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>有趣！我们可以清楚地看到顶级 Makefile 将如何进入其他目录，其中大多数被设置为 obj-y；实际上，将其构建进去（在少数情况下，它会被参数化，根据用户选择选项的方式变为 obj-y 或 obj-m）。很好。现在让我们继续；关键是要获得一个有效的.config 文件。我们该怎么做？我们以迭代方式进行。我们从“默认”配置（下一节的主题）开始，然后小心翼翼地逐步完成自定义配置。</p>
<h4 id="先聊怎么获取默认的配置"><a href="#先聊怎么获取默认的配置" class="headerlink" title="先聊怎么获取默认的配置"></a>先聊怎么获取默认的配置</h4><p>​    那么，您如何决定最初的内核配置呢？存在几种技术；一些常见的技术如下：</p>
<ol>
<li>不指定任何内容；Kconfig 将引入默认内核配置（因为所有内核配置都有默认值）</li>
<li>使用现有发行版的内核配置</li>
<li>根据当前加载到内存中的内核模块构建自定义配置</li>
</ol>
<p>​    第一种方法的优点是简单。内核将处理细节，为您提供默认配置。缺点是默认配置可能非常大（在为基于 x86_64 的桌面或服务器类型系统构建 Linux 时就是这种情况）；默认情况下会打开大量选项，以防万一您需要它，这会使构建时间非常长，内核映像大小非常大。当然，通常情况下，您需要手动将内核配置为所需的设置。<br>​    这带来了一个问题，默认内核配置存储在哪里？如果未指定任何配置，Kconfig 系统将使用优先级列表回退方案来检索默认配置。优先级列表及其顺序（第一个优先级最高）如下：</p>
<ul>
<li>.config</li>
<li>/lib/modules/$(uname -r)/.config</li>
<li>/etc/kernel-config</li>
<li>/boot/config-$(uname -r)</li>
<li>ARCH_DEFCONFIG（如果已定义）</li>
<li>arch/${ARCH}/defconfig</li>
</ul>
<p>​    从列表中，您可以看到 Kconfig 系统首先检查内核源代码树根目录中是否存在 .config 文件；如果找到，它会从那里获取所有配置值。如果不存在，它接下来会查看路径 /lib/modules/$(uname -r)/.config。如果找到，则将使用该文件中找到的值作为默认值。如果没有找到，它会检查前面优先级列表中的下一个，依此类推……</p>
<h4 id="获得内核配置的良好起点"><a href="#获得内核配置的良好起点" class="headerlink" title="获得内核配置的良好起点"></a>获得内核配置的良好起点</h4><p>​    这给我们带来了一个非常重要的点：虽然玩内核配置作为学习练习是可以的，但对于生产系统来说，至关重要的是，您必须将自定义配置建立在经过验证的（已知、经过测试且有效的）内核配置上。</p>
<p>​    在这里，为了帮助您理解选择内核配置有效起点的细微差别，我们将看到三种获取典型内核配置起点的方法：</p>
<ol>
<li><p>首先，一种简单（但不是最优）的方法，您只需模拟现有发行版的内核配置。</p>
</li>
<li><p>接下来，一种更优化的方法，您可以根据现有系统的内存内核模块来配置内核。这是 localmodconfig 方法。</p>
</li>
<li><p>最后，介绍一下典型嵌入式 Linux 项目应遵循的方法。</p>
</li>
</ol>
<p>​    让我们更详细地研究一下这些方法。在配置您在前两个步骤中下载和提取的内核方面，现在不要做任何事情；阅读以下部分，然后在开始使用 localmodconfig 方法部分，我们将让您真正开始。</p>
<h4 id="使用分发配置作为起点的内核配置"><a href="#使用分发配置作为起点的内核配置" class="headerlink" title="使用分发配置作为起点的内核配置"></a>使用分发配置作为起点的内核配置</h4><p>​    使用此方法的典型目标系统是 x86_64 桌面或服务器Linux 系统。让我们将内核配置为所有默认值：</p>
<pre class="line-numbers language-none"><code class="language-none">make mrproper # 清空所有的config<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    下一步就是生成默认的配置！</p>
<pre class="line-numbers language-none"><code class="language-none">make defconfig<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ make defconfig
  HOSTCC  scripts&#x2F;basic&#x2F;fixdep
  HOSTCC  scripts&#x2F;kconfig&#x2F;conf.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;confdata.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;expr.o
  LEX     scripts&#x2F;kconfig&#x2F;lexer.lex.c
  YACC    scripts&#x2F;kconfig&#x2F;parser.tab.[ch]
  HOSTCC  scripts&#x2F;kconfig&#x2F;lexer.lex.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;menu.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;parser.tab.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;preprocess.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;symbol.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;util.o
  HOSTLD  scripts&#x2F;kconfig&#x2F;conf
*** Default configuration is based on &#39;x86_64_defconfig&#39;
#
# configuration written to .config
#<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    他会生成默认的.config文件！</p>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$  ls -l .config
-rw-rw-r-- 1 charlie charlie 136414  7月  4 08:13 .config<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h4 id="通过-localmodconfig-方法调整内核配置"><a href="#通过-localmodconfig-方法调整内核配置" class="headerlink" title="通过 localmodconfig 方法调整内核配置"></a>通过 localmodconfig 方法调整内核配置</h4><p>​    使用此方法的典型目标系统是（通常为 x86_64）桌面或服务器 Linux 系统。 第二种方法比前一种方法更优化 - 当目标是从基于现有运行系统的内核配置开始时，这种方法很适合使用，因此（通常）与桌面或服务器 Linux 系统上的典型默认配置相比相对紧凑。 在这里，我们通过简单地将 lsmod 的输出重定向到临时文件，然后将该文件提供给构建，为 Kconfig 系统提供当前在系统上运行的内核模块的快照。这可以通过以下方式实现：</p>
<pre class="line-numbers language-none"><code class="language-none">lsmod &gt; &#x2F;tmp&#x2F;lsmod.now
cd $&#123;LKP_KSRC&#125;
make LSMOD&#x3D;&#x2F;tmp&#x2F;lsmod.now localmodconfig<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​    lsmod是列出当前系统中所有可以使用的模块文件</p>
<h4 id="使用make-help查看"><a href="#使用make-help查看" class="headerlink" title="使用make help查看"></a>使用make help查看</h4><pre class="line-numbers language-none"><code class="language-none">Cleaning targets:
  clean		  - Remove most generated files but keep the config and
                    enough build support to build external modules
  mrproper	  - Remove all generated files + config + various backup files
  distclean	  - mrproper + remove editor backup and patch files

Configuration targets:
  config	  - Update current config utilising a line-oriented program
  nconfig         - Update current config utilising a ncurses menu based program
  menuconfig	  - Update current config utilising a menu based program
  xconfig	  - Update current config utilising a Qt based front-end
  gconfig	  - Update current config utilising a GTK+ based front-end
  oldconfig	  - Update current config utilising a provided .config as base
  localmodconfig  - Update current config disabling modules not loaded
                    except those preserved by LMC_KEEP environment variable
  localyesconfig  - Update current config converting local mods to core
                    except those preserved by LMC_KEEP environment variable
  defconfig	  - New config with default from ARCH supplied defconfig
  savedefconfig   - Save current config as .&#x2F;defconfig (minimal config)
  allnoconfig	  - New config where all options are answered with no
  allyesconfig	  - New config where all options are accepted with yes
  allmodconfig	  - New config selecting modules when possible
  alldefconfig    - New config with all symbols set to default
  randconfig	  - New config with random answer to all options
  yes2modconfig	  - Change answers from yes to mod if possible
  mod2yesconfig	  - Change answers from mod to yes if possible
  mod2noconfig	  - Change answers from mod to no if possible
  listnewconfig   - List new options
  helpnewconfig   - List new options and help text
  olddefconfig	  - Same as oldconfig but sets new symbols to their
                    default value without prompting
  tinyconfig	  - Configure the tiniest possible kernel
  testconfig	  - Run Kconfig unit tests (requires python3 and pytest)

Other generic targets:
  all		  - Build all targets marked with [*]
* vmlinux	  - Build the bare kernel
* modules	  - Build all modules
  modules_install - Install all modules to INSTALL_MOD_PATH (default: &#x2F;)
  dir&#x2F;            - Build all files in dir and below
  dir&#x2F;file.[ois]  - Build specified target only
  dir&#x2F;file.ll     - Build the LLVM assembly file
                    (requires compiler support for LLVM assembly generation)
  dir&#x2F;file.lst    - Build specified mixed source&#x2F;assembly target only
                    (requires a recent binutils and recent build (System.map))
  dir&#x2F;file.ko     - Build module including final link
  modules_prepare - Set up for building external modules
  tags&#x2F;TAGS	  - Generate tags file for editors
  cscope	  - Generate cscope index
  gtags           - Generate GNU GLOBAL index
  kernelrelease	  - Output the release version string (use with make -s)
  kernelversion	  - Output the version stored in Makefile (use with make -s)
  image_name	  - Output the image name (use with make -s)
  headers_install - Install sanitised kernel headers to INSTALL_HDR_PATH
                    (default: .&#x2F;usr)

Static analysers:
  checkstack      - Generate a list of stack hogs
  versioncheck    - Sanity check on version.h usage
  includecheck    - Check for duplicate included header files
  export_report   - List the usages of all exported symbols
  headerdep       - Detect inclusion cycles in headers
  coccicheck      - Check with Coccinelle
  clang-analyzer  - Check with clang static analyzer
  clang-tidy      - Check with clang-tidy

Tools:
  nsdeps          - Generate missing symbol namespace dependencies

Kernel selftest:
  kselftest         - Build and run kernel selftest
                      Build, install, and boot kernel before
                      running kselftest on it
                      Run as root for full coverage
  kselftest-all     - Build kernel selftest
  kselftest-install - Build and install kernel selftest
  kselftest-clean   - Remove all generated kselftest files
  kselftest-merge   - Merge all the config dependencies of
		      kselftest to existing .config.

Rust targets:
  rustavailable   - Checks whether the Rust toolchain is
		    available and, if not, explains why.
  rustfmt	  - Reformat all the Rust code in the kernel
  rustfmtcheck	  - Checks if all the Rust code in the kernel
		    is formatted, printing a diff otherwise.
  rustdoc	  - Generate Rust documentation
		    (requires kernel .config)
  rusttest        - Runs the Rust tests
                    (requires kernel .config; downloads external repos)
  rust-analyzer	  - Generate rust-project.json rust-analyzer support file
		    (requires kernel .config)
  dir&#x2F;file.[os]   - Build specified target only
  dir&#x2F;file.rsi    - Build macro expanded source, similar to C preprocessing.
                    Run with RUSTFMT&#x3D;n to skip reformatting if needed.
                    The output is not intended to be compilable.
  dir&#x2F;file.ll     - Build the LLVM assembly file

Userspace tools targets:
  use &quot;make tools&#x2F;help&quot;
  or  &quot;cd tools; make help&quot;

Kernel packaging:
  rpm-pkg             - Build both source and binary RPM kernel packages
  binrpm-pkg          - Build only the binary kernel RPM package
  deb-pkg             - Build both source and binary deb kernel packages
  bindeb-pkg          - Build only the binary kernel deb package
  snap-pkg            - Build only the binary kernel snap package
                        (will connect to external hosts)
  dir-pkg             - Build the kernel as a plain directory structure
  tar-pkg             - Build the kernel as an uncompressed tarball
  targz-pkg           - Build the kernel as a gzip compressed tarball
  tarbz2-pkg          - Build the kernel as a bzip2 compressed tarball
  tarxz-pkg           - Build the kernel as a xz compressed tarball
  tarzst-pkg          - Build the kernel as a zstd compressed tarball
  perf-tar-src-pkg    - Build perf-6.1.25.tar source tarball
  perf-targz-src-pkg  - Build perf-6.1.25.tar.gz source tarball
  perf-tarbz2-src-pkg - Build perf-6.1.25.tar.bz2 source tarball
  perf-tarxz-src-pkg  - Build perf-6.1.25.tar.xz source tarball
  perf-tarzst-src-pkg - Build perf-6.1.25.tar.zst source tarball

Documentation targets:
 Linux kernel internal documentation in different formats from ReST:
  htmldocs        - HTML
  latexdocs       - LaTeX
  pdfdocs         - PDF
  epubdocs        - EPUB
  xmldocs         - XML
  linkcheckdocs   - check for broken external links
                    (will connect to external hosts)
  refcheckdocs    - check for references to non-existing files under
                    Documentation
  cleandocs       - clean all generated files

  make SPHINXDIRS&#x3D;&quot;s1 s2&quot; [target] Generate only docs of folder s1, s2
  valid values for SPHINXDIRS are: PCI RCU accounting admin-guide arc arm arm64 block bpf cdrom core-api cpu-freq crypto dev-tools devicetree doc-guide driver-api fault-injection fb filesystems firmware-guide fpga gpu hid hwmon i2c ia64 iio infiniband input isdn kbuild kernel-hacking leds livepatch locking loongarch m68k maintainer mhi mips misc-devices mm netlabel networking nios2 openrisc parisc pcmcia peci power powerpc process riscv rust s390 scheduler scsi security sh sound sparc spi staging target timers tools trace translations usb userspace-api virt w1 watchdog x86 xtensa

  make SPHINX_CONF&#x3D;&#123;conf-file&#125; [target] use *additional* sphinx-build
  configuration. This is e.g. useful to build with nit-picking config.

  make DOCS_THEME&#x3D;&#123;sphinx-theme&#125; selects a different Sphinx theme.

  make DOCS_CSS&#x3D;&#123;a .css file&#125; adds a DOCS_CSS override file for html&#x2F;epub output.

  Default location for the generated documents is Documentation&#x2F;output

Architecture specific targets (x86):
* bzImage		- Compressed kernel image (arch&#x2F;x86&#x2F;boot&#x2F;bzImage)
  install		- Install kernel using (your) ~&#x2F;bin&#x2F;installkernel or
			  (distribution) &#x2F;sbin&#x2F;installkernel or install to 
			  $(INSTALL_PATH) and run lilo

  fdimage		- Create 1.4MB boot floppy image (arch&#x2F;x86&#x2F;boot&#x2F;fdimage)
  fdimage144		- Create 1.4MB boot floppy image (arch&#x2F;x86&#x2F;boot&#x2F;fdimage)
  fdimage288		- Create 2.8MB boot floppy image (arch&#x2F;x86&#x2F;boot&#x2F;fdimage)
  hdimage		- Create a BIOS&#x2F;EFI hard disk image (arch&#x2F;x86&#x2F;boot&#x2F;hdimage)
  isoimage		- Create a boot CD-ROM image (arch&#x2F;x86&#x2F;boot&#x2F;image.iso)
			  bzdisk&#x2F;fdimage*&#x2F;hdimage&#x2F;isoimage also accept:
			  FDARGS&#x3D;&quot;...&quot;  arguments for the booted kernel
			  FDINITRD&#x3D;file initrd for the booted kernel

  kvm_guest.config	- Enable Kconfig items for running this kernel as a KVM guest
  xen.config		- Enable Kconfig items for running this kernel as a Xen guest
  x86_debug.config	- Enable tip tree debugging options for testing

  i386_defconfig              - Build for i386
  x86_64_defconfig            - Build for x86_64

  make V&#x3D;0|1 [targets] 0 &#x3D;&gt; quiet build (default), 1 &#x3D;&gt; verbose build
  make V&#x3D;2   [targets] 2 &#x3D;&gt; give reason for rebuild of target
  make O&#x3D;dir [targets] Locate all output files in &quot;dir&quot;, including .config
  make C&#x3D;1   [targets] Check re-compiled c source with $CHECK
                       (sparse by default)
  make C&#x3D;2   [targets] Force check of all c source with $CHECK
  make RECORDMCOUNT_WARN&#x3D;1 [targets] Warn about ignored mcount sections
  make W&#x3D;n   [targets] Enable extra build checks, n&#x3D;1,2,3 where
		1: warnings which may be relevant and do not occur too often
		2: warnings which occur quite often but may still be relevant
		3: more obscure warnings, can most likely be ignored
		e: warnings are being treated as errors
		Multiple levels can be combined with W&#x3D;12 or W&#x3D;123

Execute &quot;make&quot; or &quot;make all&quot; to build all targets marked with [*] 
For further info see the .&#x2F;README file<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="使用menuconfig进行配置"><a href="#使用menuconfig进行配置" class="headerlink" title="使用menuconfig进行配置"></a>使用menuconfig进行配置</h4><p>​    好的，太好了，我们现在有一个通过 localmodconfig Makefile 目标为我们生成的初始内核配置文件 (.config)，如上一节中详细所示，这是一个很好的起点。通常，我们现在进一步微调我们的内核配置。一种实现此目的的方法（实际上是推荐的方法）是通过 menuconfig Makefile 目标。此目标让 Kbuild 系统生成一个非常复杂的基于 C 的程序可执行文件 (scripts/kconfig/mconf)，它向最终用户呈现一个简洁的基于菜单的 UI。这是图 2.8 中的步骤 2。在下面的输出块中，当（在我们的内核源代码树的根目录中）我们第一次调用该命令时，Kbuild 系统会构建 mconf 可执行文件并调用它：</p>
<pre class="line-numbers language-none"><code class="language-none">make menuconfig
  UPD     scripts&#x2F;kconfig&#x2F;mconf-cfg
  HOSTCC  scripts&#x2F;kconfig&#x2F;mconf.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;lxdialog&#x2F;checklist.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;lxdialog&#x2F;inputbox.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;lxdialog&#x2F;menubox.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;lxdialog&#x2F;textbox.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;lxdialog&#x2F;util.o
  HOSTCC  scripts&#x2F;kconfig&#x2F;lxdialog&#x2F;yesno.o
  HOSTLD  scripts&#x2F;kconfig&#x2F;mconf
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="./image-20240704084007171.png" alt="image-20240704084007171"></p>
<p>​    接下来，Kconfig+Kbuild 开源框架通过其 UI 为用户提供线索。</p>
<p>​    您经常会看到菜单前面带有符号（如 [<em>]、&lt;&gt;、-</em>-、() 等）；这些符号及其含义如下： </p>
<ul>
<li><p>[.]：内核功能，布尔选项。它要么是 On，要么是 Off；显示的‘.’将被替换为 * 或空格： </p>
<ul>
<li>[*]：On，功能已编译并内置到内核映像中 (y) </li>
<li>[ ]：Off，根本没有构建 (n) </li>
</ul>
</li>
<li><p>&lt;.&gt;：可能处于三种状态之一的功能。这称为三态；。显示的将替换为 *、M 或空格)：</p>
<ul>
<li>&lt;*&gt;：开启，功能已在内核映像中编译和构建 (y) </li>
<li>\<M>：模块，功能已编译并构建为内核模块 (LKM) (m)</li>
<li>&lt; &gt;：关闭，根本不构建 (n) </li>
</ul>
</li>
<li><p>{.}：此配置选项存在依赖项；因此，需要将其构建或编译为模块 (m) 或内核映像 (y)。 </p>
</li>
<li>-*-：依赖项要求将此项目编译为 (y)。 </li>
<li>(…)：提示：需要字母数字输入。选中此选项时按 Enter 键，将出现提示框。 </li>
<li>&lt;菜单名称&gt; —-&gt;：随后出现子菜单。在此项目上按 Enter 键可导航至子菜单</li>
</ul>
<p>注意：最好不要尝试手动编辑 .config 文件。您可能不知道有几个相互依赖关系；请始终使用 Kbuild 菜单系统（我们建议使用 make menuconfig）来编辑它。话虽如此，还有一种非交互式方式可以通过脚本进行编辑。我们稍后会了解这一点。不过，使用 make menuconfig UI 确实是最好的方式</p>
<h4 id="在-menuconfig-UI-中搜索"><a href="#在-menuconfig-UI-中搜索" class="headerlink" title="在 menuconfig UI 中搜索"></a>在 menuconfig UI 中搜索</h4><p>​    如果在运行 make menuconfig 时，您正在寻找 特定的内核配置选项，但很难找到它，该怎么办？没问题：menuconfig UI 系统具有搜索配置参数 功能。就像著名的 vi 编辑器一样，按 /（正斜杠）键弹出搜索对话框，然后输入 您的搜索词，前面可以带或不带 CONFIG_，然后选择 &lt; Ok &gt; 按钮继续。 以下几张屏幕截图显示了搜索对话框和结果对话框。 例如，我们搜索了术语 vbox：</p>
<p><img src="./image-20240704085411861.png" alt="image-20240704085411861"></p>
<h4 id="查找配置中的差异"><a href="#查找配置中的差异" class="headerlink" title="查找配置中的差异"></a>查找配置中的差异</h4><p>在要写入 .config 内核配置文件时，Kconfig系统会检查它是否已经存在，如果存在，它会使用名称 .config.old 进行备份。了解这一点后，我们始终可以区分两者，以查看我们刚刚进行的更改。但是，使用典型的 diff 实用程序执行此操作会使差异很难解释。内核提供了一种更好的方法，即专门用于执行此操作的基于控制台的脚本。内核源代码树中的scripts/diffconfig 脚本对此很有用。将 —help 参数传递给它以查看使用屏幕。让我们尝试一下</p>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ scripts&#x2F;diffconfig .config .config.old
 IKCONFIG y -&gt; m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h4 id="使用内核的配置脚本查看-编辑-内核配置"><a href="#使用内核的配置脚本查看-编辑-内核配置" class="headerlink" title="使用内核的配置脚本查看/编辑 内核配置"></a>使用内核的配置脚本查看/编辑 内核配置</h4><p>​    有时，需要直接编辑或查询内核配置， 检查或修改给定的内核配置。我们已经学会了通过make menuconfig UI 来实现这一点。在这里，我们了解到也许有一种更简单、更重要的是非交互式且可编写脚本的方法来实现相同的目的 - 通过内核源中的 Bash 脚本：scripts/config。 在没有任何参数的情况下运行它将导致显示一个有用的帮助屏幕；请查看它。一个示例将有助于了解它的用法。 查找当前内核配置的能力非常有用，所以让我们确保这些内核配置已打开。仅针对此示例，让我们首先明确禁用相关内核配置，然后启用它们：</p>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ scripts&#x2F;config --disable IKCONFIG --disable IKCONFIG_PROC
charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ grep IKCONFIG .config
# CONFIG_IKCONFIG is not set
# CONFIG_IKCONFIG_PROC is not set
charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ scripts&#x2F;config --enable IKCONFIG --enable IKCONFIG_PROC
charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ grep IKCONFIG .config
CONFIG_IKCONFIG&#x3D;y
CONFIG_IKCONFIG_PROC&#x3D;y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="其他提示-–-内核配置"><a href="#其他提示-–-内核配置" class="headerlink" title="其他提示 – 内核配置"></a>其他提示 – 内核配置</h4><p>关于内核配置，下面是一些其他提示：</p>
<p>使用 VirtualBox 为虚拟机构建 x86 内核时（就像我们在这里一样），配置内核时，您可能会发现设置CONFIG_ISO9660_FS=y 很有用；它随后允许 VirtualBox 让客户机安装客户机附加虚拟 CD 并安装（非常有用！）客户机附加。通常，这些内容可以提高虚拟机的性能，并允许更好的图形、USB 功能、剪贴板和文件共享等。</p>
<p>​    在构建自定义内核时，我们有时想要编写/构建 eBPF程序（此处未介绍的高级主题）或类似的东西。为了这样做，需要一些内核标头。您可以通过设置内核配置 CONFIG_IKHEADERS=y（或设置为 m；从 5.2 开始）来明确确保这一点。这会导致 /sys/kernel/kheaders.tar.xz 文件可用，该文件可以在其他地方提取以提供标头。</p>
<ul>
<li>此外，谈到 eBPF，现代内核能够生成一些调试信息，称为 BPF 类型格式 (BTF)元数据。可以通过选择内核配置CONFIG_DEBUG_INFO_BTF=y 来启用此功能。这还需要安装 pahole 工具。有关 BTF 元数据的更多信息，请参阅此处的官方内核文档：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/next/bpf/btf.html。">https://www.kernel.org/doc/html/next/bpf/btf.html。</a></li>
<li>现在，当此选项打开时，另一个内核配置 –CONFIG_MODULE_ALLOW_BTF_MISMATCH – 在构建内核模块时变得相关。这是我们在以下两章中深入讨论的主题。如果启用了 CONFIG_DEBUG_INFO_BTF，最好将后一个配置设置为 Yes，否则，如果 BTF 元数据在加载时不匹配，则可能不允许加载模块。</li>
</ul>
<p>​    接下来，内核构建至少在理论上不会产生任何错误甚至警告。为确保这一点，要将警告视为错误，请设置 CONFIG_WERROR=y。<br>在现在熟悉的 make menuconfig UI 中，它位于常规设置 | 将警告编译为错误，默认情况下通常处于关闭状态。<br>这里有一个有趣的脚本：scripts/get_feat.pl；它的帮助屏幕显示了如何利用它来列出机器或给定架构的内核功能支持矩阵。例如，要查看 AArch64 的内核功能支持矩阵，请执行以下操作：</p>
<pre class="line-numbers language-none"><code class="language-none">scripts&#x2F;get_feat.pl --arch arm64 ls<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    接下来，Linux 内核驱动程序数据库 (LKDDb) 项目站点提供了一个非官方的“数据库”，其中包含所有可用的内核配置以及它们所支持的内核版本：<a target="_blank" rel="noopener" href="https://cateee.net/lkddb/web-lkddb/。">https://cateee.net/lkddb/web-lkddb/。</a><br>​    内核启动配置：在启动时，您始终可以通过强大的内核命令行参数覆盖某些内核功能。它们在此处有详尽的文档：<br><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/kernelparameters.html。虽然这非常有用，但有时我们需要传递更多参数作为键值对，本质上是">https://www.kernel.org/doc/html/latest/admin-guide/kernelparameters.html。虽然这非常有用，但有时我们需要传递更多参数作为键值对，本质上是</a> key=value 的形式，以扩展内核命令行。这可以通过填充一个名为启动配置的小型内核配置文件来完成。此启动配置功能取决于内核配置的 BOOT_CONFIG 是否为y。它位于常规设置菜单下，通常默认启用。它可以通过两种方式使用：将启动配置附加到 initrd 或initramfs 映像（我们将在下一章中介绍 initrd）或将启动配置嵌入到内核本身。对于后者，您需要创建启动配置文件，在内核配置中传递指令CONFIG_BOOT_CONFIG_EMBED_FILE=”x/y/z”，然后重建内核。请注意，内核命令行参数将优先于启动配置参数。在启动时，如果启用并使用，启动配置参数可通过 /proc/bootconfig 查看。<br>​    有关启动配置的详细信息位于官方内核文档中：<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/Documentation/admin-guide/bootconfig.rst。您肯定会遇到许多其他有用的内核配置设置和脚本，包括用于强化内核的设置和脚本；请密切关注。">https://elixir.bootlin.com/linux/v6.1.25/source/Documentation/admin-guide/bootconfig.rst。您肯定会遇到许多其他有用的内核配置设置和脚本，包括用于强化内核的设置和脚本；请密切关注。</a></p>
<p>好了！您现在已经完成了 Linux 内核构建的前三个步骤——相当不错。当然，我们将在下一章中完成内核构建过程的其余四个步骤。我们将以最后一节结束本章，介绍如何学习另一项有用的技能——如何自定义内核 UI 菜单。</p>
<h3 id="编译内核"><a href="#编译内核" class="headerlink" title="编译内核"></a>编译内核</h3><p>​    我们将继续构建内核，介绍构建内核的其余四个步骤。首先，当然，我们将构建内核（步骤 4）。然后，您将学习如何正确安装作为构建的一部分生成的内核模块（步骤 5）。接下来，我们将运行一个简单的命令来设置 GRUB（Grand Unified Bootloader）引导加载程序并生成 initramfs（或 initrd）映像（步骤 6）。我们还讨论了使用 initramfs 映像的动机及其生成方式。然后介绍一些有关配置 GRUB 引导加载程序（用于 x86）的详细信息（步骤 7）。 在本章结束时，我们将使用新的内核映像启动系统并验证它是否按预期构建。然后，我们将学习如何为外部架构（对于 AArch 32/64，所讨论的主板是著名的 Raspberry Pi）交叉编译 Linux 内核。 简而言之，本章将涵盖以下领域： </p>
<ul>
<li>步骤 4 – 构建内核映像和模块 </li>
<li>步骤 5 – 安装内核模块 </li>
<li>步骤 6 – 生成 initramfs 映像和引导加载程序设置，了解 initramfs 框架 </li>
<li>步骤 7 – 自定义 GRUB 引导加载程序 验证新内核的配置</li>
</ul>
<h4 id="步骤-4-–-构建内核映像和模块"><a href="#步骤-4-–-构建内核映像和模块" class="headerlink" title="步骤 4 – 构建内核映像和模块"></a>步骤 4 – 构建内核映像和模块</h4><p>​    很简单，当我们完成了.config文件的配置之后，直接干make all就行：</p>
<pre class="line-numbers language-none"><code class="language-none">Other generic targets:
  all		  - Build all targets marked with [*]
* vmlinux	  - Build the bare kernel
* modules	  - Build all modules
  modules_install - Install all modules to INSTALL_MOD_PATH (default: &#x2F;)
  dir&#x2F;            - Build all files in dir and below
  dir&#x2F;file.[ois]  - Build specified target only
  dir&#x2F;file.ll     - Build the LLVM assembly file
                    (requires compiler support for LLVM assembly generation)
  dir&#x2F;file.lst    - Build specified mixed source&#x2F;assembly target only
                    (requires a recent binutils and recent build (System.map))
  dir&#x2F;file.ko     - Build module including final link
  modules_prepare - Set up for building external modules
  tags&#x2F;TAGS	  - Generate tags file for editors
  cscope	  - Generate cscope index
  gtags           - Generate GNU GLOBAL index
  kernelrelease	  - Output the release version string (use with make -s)
  kernelversion	  - Output the version stored in Makefile (use with make -s)
  image_name	  - Output the image name (use with make -s)
  headers_install - Install sanitised kernel headers to INSTALL_HDR_PATH
                    (default: .&#x2F;usr)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    好的，那么需要注意的是：执行 make all 将使我们构建前面的三个目标（以 * 符号为前缀的目标）；它们是什么意思？<br>让我们看看：</p>
<ul>
<li>vmlinux 与未压缩的内核映像文件的名称匹配。模块目标意味着所有标记为 m（代表模块）的内核配置选项都将在内核源树中构建为内核模块（.ko 文件）（有关内核模块究竟是什么以及如何编写内核模块的详细信息是以下两章的主题）。</li>
<li>bzImage 是特定于体系结构的内核映像文件。在 x86[_64] 系统上，这是压缩内核映像的名称 - 引导加载程序实际上会将其加载到 RAM 中，在内存中解压缩并启动；实际上，它是（压缩的）内核映像文件。</li>
</ul>
<p>​    因此，常见问题解答：如果 bzImage 是我们用于引导和初始化系统的实际内核映像文件，那么 vmlinux 是做什么用的？请注意，vmlinux 是未压缩的内核映像文件。它可能很大（甚至非常大，因为存在调试版本期间生成的内核符号）。虽然我们从不通过 vmlinux 启动，但它仍然很重要 - 事实上是无价的。请保留它以用于内核调试目的</p>
<p>​    现在，有了 kbuild 系统（内核使用），只需运行 make 就等于 make all。 现代 Linux 内核代码库非常庞大。目前估计，最近的内核有大约 2500 万到 3000 万行源代码（SLOC）！因此，构建内核确实是一项非常耗费内存和 CPU 的工作。事实上，有些人将内核构建用作压力测试！（您还应该意识到，在特定的构建运行期间，并非所有代码行都会被编译）。现代 make 实用程序功能强大且具有多进程能力。我们可以要求它生成多个进程来并行处理构建的不同（不相关）部分，从而提高吞吐量并缩短构建时间。相关选项是 -jn，其中 n 是生成和并行运行的任务数量的上限。用于确定这一点的启发式方法（经验法则）如下：</p>
<pre class="line-numbers language-none"><code class="language-none">n &#x3D; $(procs) * factor<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ nproc
2
# 所以make -j4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>题外话：一般来说，如果构建失败，要检查什么？</p>
<ol>
<li>检查再检查，确保你做的所有事情都是正确的；责怪自己，而不是内核（社区/代码）！</li>
<li>是否安装了所有必需的和最新的软件包？例如，</li>
<li>如果内核配置有 CONFIG_DEBUG_INFO_BTF=y，则需要安装 pahole 1.16 或更高版本。</li>
<li>内核配置正常吗？</li>
<li>是硬件问题吗？内部编译器错误：分段错误等错误通常表明这一点；是否分配了足够的 RAM 和交换空间？</li>
<li>尝试在另一个 VM 上构建，或者最好在本机 Linux 系统上构建。</li>
<li>从头开始（或重新启动）；在内核源代码树的根目录中，执行 makemrproper（小心：它将清除所有内容，甚至删除任何 .config 文件），并小心执行所有步骤。</li>
<li>嘿，当其他一切都失败时，Google错误消息！</li>
</ol>
<p>​    构建应该可以顺利运行，不会出现任何错误或警告。有时，编译器会发出警告，但我们会毫不犹豫地忽略它们。如果您在此步骤中遇到编译器错误并因此导致构建失败，该怎么办？我们该如何礼貌地表达？哦，好吧，我们不能——这很可能是您的错，而不是内核社区的错。正如刚才提到的，请检查并重新检查每个步骤，如果其他方法都失败，请使用 make mrproper 命令从头开始重做！很多时候，构建内核失败意味着内核配置错误（随机选择的配置可能会发生冲突）、工具链版本过时或修补不正确等。（仅供参考，我们在内核构建的其他技巧部分介绍了更多非常具体的技巧）</p>
<pre class="line-numbers language-none"><code class="language-none">  BUILD   arch&#x2F;x86&#x2F;boot&#x2F;bzImage
Kernel: arch&#x2F;x86&#x2F;boot&#x2F;bzImage is ready  (#1)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>kbuild 系统生成了三个关键文件（其中有很多）。在内核源代码树的根目录中，我们现在将拥有以下文件：</p>
<ul>
<li>未压缩的内核映像文件 vmlinux（用于调试目的）</li>
<li>符号地址映射文件 System.map</li>
<li>压缩的可启动内核映像文件 bzImage（参见以下输出）</li>
</ul>
<p>让我们来看看！我们通过将 -h 选项传递给 ls，使输出（特别是文件大小）更易于阅读：</p>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$  ls -lh vmlinux System.map
-rw-rw-r-- 1 charlie charlie 4.8M  7月  4 10:16 System.map
-rwxrwxr-x 1 charlie charlie 699M  7月  4 10:16 vmlinux<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 可以简单的通过以下指令来查看自己编译的内核的版本以及生成的映像名称。</p>
<pre class="line-numbers language-none"><code class="language-none">harlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ make kernelrelease kernelversion image_name 
6.1.25
6.1.25
arch&#x2F;x86&#x2F;boot&#x2F;bzImage<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="步骤-5-–-安装内核模块"><a href="#步骤-5-–-安装内核模块" class="headerlink" title="步骤 5 – 安装内核模块"></a>步骤 5 – 安装内核模块</h4><p>​    在上一步中，所有标记为 m 的内核配置选项（实际上，所有内核模块、*.ko 文件）现在都已在源代码树中构建。正如您将了解到的，这还不够：现在必须将它们安装到系统上的已知位置。本节介绍这些细节。 在内核源代码中定位内核模块 正如您刚刚了解到的，上一步 - 构建内核映像和模块 - 导致生成压缩和未压缩的内核映像，以及所有内核模块（由我们的内核配置指定）。内核模块被标识为始终具有 .ko（代表内核对象）后缀的文件。这些模块非常有用；它们以模块化的方式为我们提供内核功能（我们可以决定将它们插入或拔出内核内存；以下两章将详细介绍该主题）。 现在，知道上一步也生成了所有内核模块文件，让我们在内核源代码树中找到它们。为此，我们使用 find 命令在内核源文件夹中找到它们：</p>
<pre class="line-numbers language-none"><code class="language-none">find .&#x2F; -name &quot;*.ko&quot;
.&#x2F;fs&#x2F;binfmt_misc.ko
.&#x2F;fs&#x2F;autofs&#x2F;autofs4.ko
.&#x2F;fs&#x2F;nls&#x2F;nls_iso8859-1.ko
.&#x2F;fs&#x2F;isofs&#x2F;isofs.ko
.&#x2F;arch&#x2F;x86&#x2F;kernel&#x2F;msr.ko
.&#x2F;arch&#x2F;x86&#x2F;crypto&#x2F;sha256-ssse3.ko
...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    但仅仅构建内核模块是不够的；为什么？它们需要安装到根文件系统中众所周知的位置，以便在启动时，系统可以真正找到它们并将其加载到内核内存中。这就是为什么我们需要以下步骤，即模块安装（请参阅下面的获取内核模块安装部分）。它们安装的“根文件系统中众所周知的位置”是 /lib/modules/$(uname -r)/，其中 $(uname -r) 当然会生成内核版本号。</p>
<p>​    需要注意的几点： </p>
<ul>
<li>请注意，我们使用 sudo 以 root（超级用户）身份执行模块安装过程。这是必需的，因为默认安装位置（在 /lib/modules/ 下）仅 root 可写。modules_install 目标导致将内核模块复制到 /lib/modules/ 下的正确安装位置（前面的输出块中显示的工作为 INSTALL /lib/modules/6.1.25-lkp-kernel/&lt;…&gt;）。 </li>
<li>接下来，模块可能被“签名”。在配置了内核模块加密签名的系统上（CONFIG_MODULE_SIG：一个有用的安全功能，就像这里的情况一样），SIGN 步骤让内核“签名”模块。 </li>
</ul>
<p>​    简而言之，当配置选项 CONFIG_MODULE_SIG_FORCE 处于打开状态（默认情况下处于关闭状态）时，只有正确签名的模块才允许在运行时加载到内核内存中。 接下来，在复制所有模块（并可能签名）后，kbuild 系统将运行一个名为 depmod 的实用程序。它的工作本质上是解决内核模块之间的依赖关系并将它们（如果存在）编码到某些元文件中。</p>
<p>现在让我们看看模块安装步骤的结果：</p>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ ls &#x2F;lib&#x2F;modules
5.15.0-25-generic  6.1.25  6.5.0-41-generic
charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ cd &#x2F;lib&#x2F;modules&#x2F;6.1.25&#x2F;
charlie@charlie-ubuntu:&#x2F;lib&#x2F;modules&#x2F;6.1.25$ ls
build              modules.builtin            modules.dep      modules.softdep
kernel             modules.builtin.alias.bin  modules.dep.bin  modules.symbols
modules.alias      modules.builtin.bin        modules.devname  modules.symbols.bin
modules.alias.bin  modules.builtin.modinfo    modules.order    source
charlie@charlie-ubuntu:&#x2F;lib&#x2F;modules&#x2F;6.1.25$ cd kernel&#x2F;
charlie@charlie-ubuntu:&#x2F;lib&#x2F;modules&#x2F;6.1.25&#x2F;kernel$ ls
arch  crypto  drivers  fs  kernel  lib  net  sound<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在前面的输出中，我们可以看到，对于系统上安装的每个（Linux）内核，/lib/modules/ 下都会有一个文件夹，其名称是内核版本，正如预期的那样。让我们看看感兴趣的文件夹——我们的新内核（6.1.25-lkp-kernel）。在那里，在 kernel/ 子目录下——在各种目录中——存放着刚刚安装的内核模块：</p>
<h4 id="步骤-6-–-生成-initramfs-映像和引导加载程序设置，了解-initramfs-框架"><a href="#步骤-6-–-生成-initramfs-映像和引导加载程序设置，了解-initramfs-框架" class="headerlink" title="步骤 6 – 生成 initramfs 映像和引导加载程序设置，了解 initramfs 框架"></a>步骤 6 – 生成 initramfs 映像和引导加载程序设置，了解 initramfs 框架</h4><p>​    首先，请注意，本讨论主要针对 x86[_64] 架构，这也许是最常用的架构。尽管如此，这里学到的概念可以直接应用于其他架构（如 ARM），尽管确切的命令可能会有所不同。通常，与 x86 不同，至少对于基于 ARM 的 Linux，没有直接命令来生成 initramfs 映像；它必须手动完成。嵌入式构建器项目（如 Yocto 和 Buildroot）确实提供了自动化此操作的方法。对于典型的 x86 桌面或服务器内核构建过程，此步骤在内部分为两个不同的部分： 生成 initramfs（以前称为 initrd）映像 为新内核映像设置 GRUB 之所以将其封装在一个步骤中，是因为在 x86 架构上， 便利脚本执行这两项任务，使其看起来像一个步骤。</p>
<p>​    现在，让我们继续生成 initramfs（初始 RAM 文件系统的缩写）映像文件以及更新引导加载程序。顺便说一句，现在也可能是检查虚拟机（或进行备份）的好时机，这样，在最坏的情况下，即使根文件系统已损坏（不应该如此），您也有办法恢复到良好状态并继续工作。在 x86[_64] Ubuntu 上执行此操作只需一个简单的步骤即可轻松完成：</p>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;linux-6.1.25$ sudo make install
  INSTALL &#x2F;boot
run-parts: executing &#x2F;etc&#x2F;kernel&#x2F;postinst.d&#x2F;dkms 6.1.25 &#x2F;boot&#x2F;vmlinuz-6.1.25
 * dkms: running auto installation service for kernel 6.1.25                      [ OK ] 
run-parts: executing &#x2F;etc&#x2F;kernel&#x2F;postinst.d&#x2F;initramfs-tools 6.1.25 &#x2F;boot&#x2F;vmlinuz-6.1.25
update-initramfs: Generating &#x2F;boot&#x2F;initrd.img-6.1.25
run-parts: executing &#x2F;etc&#x2F;kernel&#x2F;postinst.d&#x2F;unattended-upgrades 6.1.25 &#x2F;boot&#x2F;vmlinuz-6.1.25
run-parts: executing &#x2F;etc&#x2F;kernel&#x2F;postinst.d&#x2F;update-notifier 6.1.25 &#x2F;boot&#x2F;vmlinuz-6.1.25
run-parts: executing &#x2F;etc&#x2F;kernel&#x2F;postinst.d&#x2F;xx-update-initrd-links 6.1.25 &#x2F;boot&#x2F;vmlinuz-6.1.25
I: &#x2F;boot&#x2F;initrd.img.old is now a symlink to initrd.img-6.5.0-41-generic
I: &#x2F;boot&#x2F;initrd.img is now a symlink to initrd.img-6.1.25
run-parts: executing &#x2F;etc&#x2F;kernel&#x2F;postinst.d&#x2F;zz-shim 6.1.25 &#x2F;boot&#x2F;vmlinuz-6.1.25
run-parts: executing &#x2F;etc&#x2F;kernel&#x2F;postinst.d&#x2F;zz-update-grub 6.1.25 &#x2F;boot&#x2F;vmlinuz-6.1.25
Sourcing file &#96;&#x2F;etc&#x2F;default&#x2F;grub&#39;
Sourcing file &#96;&#x2F;etc&#x2F;default&#x2F;grub.d&#x2F;init-select.cfg&#39;
Generating grub configuration file ...
Found linux image: &#x2F;boot&#x2F;vmlinuz-6.5.0-41-generic
Found initrd image: &#x2F;boot&#x2F;initrd.img-6.5.0-41-generic
Found linux image: &#x2F;boot&#x2F;vmlinuz-6.1.25
Found initrd image: &#x2F;boot&#x2F;initrd.img-6.1.25
Found linux image: &#x2F;boot&#x2F;vmlinuz-5.15.0-25-generic
Found initrd image: &#x2F;boot&#x2F;initrd.img-5.15.0-25-generic
Found memtest86+ image: &#x2F;boot&#x2F;memtest86+.elf
Found memtest86+ image: &#x2F;boot&#x2F;memtest86+.bin
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    我们再次在 make install 命令前加上了 sudo。很明显，这是因为我们需要 root 权限才能写入相关文件和文件夹；它们被写入 /boot 目录（可以设置为根文件系统的一部分或单独的分区）。<br>​    如果我们不想将输出工件（initamfs 映像和引导加载程序文件）保存在 /boot 中，该怎么办？您始终可以通过 INSTALL_PATH 环境变量覆盖目标目录；在为嵌入式系统构建 Linux 时通常就是这种情况。内核文档在此处提到了这一点：<a target="_blank" rel="noopener" href="https://docs.kernel.org/kbuild/kbuild.html#install-path。">https://docs.kernel.org/kbuild/kbuild.html#install-path。</a><br>​    就这样，我们完成了：一个全新的 6.1 内核，以及所有请求的内核模块和 initramfs 映像都已生成并安装，并且 GRUB 已更新以反映新内核和 initramfs 映像的存在。<br>​    剩下的就是重新启动系统，在启动时选择新的内核映像（从引导加载程序菜单屏幕），启动，登录，然后验证一切正常。<br>在此步骤中，我们生成了 initramfs 映像。问题是，当我们这样做时，kbuild 系统在后台执行了什么？请继续阅读以找出答案。</p>
<h4 id="在后台生成-initramfs-映像"><a href="#在后台生成-initramfs-映像" class="headerlink" title="在后台生成 initramfs 映像"></a>在后台生成 initramfs 映像</h4><p>​    当您在 x86 上运行 sudo make install 命令时，在后台，内核 Makefile 调用此脚本：scripts/install.sh。这是一个包装器脚本，它循环遍历所有可能存在或不存在的特定于架构的安装脚本，如果存在，则运行它们（使用适当的参数）。更准确地说，如果存在，这些是可能执行的特定于 arch 的脚本的位置（按此顺序）：</p>
<pre class="line-numbers language-none"><code class="language-none">$&#123;HOME&#125;&#x2F;bin&#x2F;$&#123;INSTALLKERNEL&#125;&#x2F;sbin&#x2F;$&#123;INSTALLKERNEL&#125;
$&#123;srctree&#125;&#x2F;arch&#x2F;$&#123;SRCARCH&#125;&#x2F;install.sh
$&#123;srctree&#125;&#x2F;arch&#x2F;$&#123;SRCARCH&#125;&#x2F;boot&#x2F;install.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​    再次，重点关注这里的 x86[_64]，arch/x86/boot/install.sh 脚本在内部，作为其工作的一部分，将以下文件复制到 /boot 文件夹中，<br>名称格式通常为 </p>
<pre class="line-numbers language-none"><code class="language-none">&lt;filename&gt;-$(uname -r)-kernel:
&#x2F;boot&#x2F;config-6.1.25-lkp-kernel
&#x2F;boot&#x2F;System.map-6.1.25-lkp-kernel
&#x2F;boot&#x2F;initrd.img-6.1.25-lkp-kernel
&#x2F;boot&#x2F;vmlinuz-6.1.25-lkp-kernel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    initramfs 映像也已构建。在 x86 Ubuntu Linux 上，名为update-initramfs 的 shell 脚本执行此任务（它本身是另一个名为 mkinitramfs 的脚本的便捷包装器，后者执行实际工作）。但映像究竟是如何构建的？简单地说，initramfs映像只不过是一个使用所谓的 newc格式构建的 cpio 文件。cpio 实用程序（copy-in、copy-out）是一个古老的实用程序，用于创建存档 - 一个简单的文件集合；tar 是 cpio 内部众所周知的用户。从给定目录（我们称之为my_initramfs）的内容构建 initramfs 映像的一种简单方法是执行以下操作：</p>
<pre class="line-numbers language-none"><code class="language-none">find my_initramfs&#x2F; | sudo cpio -o --format&#x3D;newc -R root:root | gzip -	<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>请注意，映像通常使用 gzip 进行压缩。<br>    一旦构建完成，initramfs 映像也会复制到 /boot 目录中，如前面的输出片段中所示为 /boot/initrd.img-6.1.25-lkp-kernel 文件。<br>    如果复制到 /boot 的文件已经存在，则将其备份为 <code>&lt;filename&gt;-$(uname -r).old</code>。名为 <code>vmlinuz-&lt;kernel-ver&gt;-kernel</code> 的文件是 arch/x86/boot/bzImage 文件的副本。换句话说，它是压缩的内核映像 - 引导加载程序将配置为加载到 RAM、解压缩并跳转到其入口点的映像文件，从而将控制权移交给内核！<br>    为什么它们有名称 vmlinux（回想一下，这是存储在内核源代码树根目录中的未压缩内核映像文件）和 vmlinuz？这是 Linux 操作系统乐于遵循的旧 Unix 惯例：在许多 Unix 版本中，内核称为 vmunix，因此 Linux 将其称为 vmlinux，压缩后的内核称为 vmlinuz；vmlinuz 中的 z 表示它默认使用 gzip 压缩。顺便说一句，使用 gzip 压缩现代内核已经过时了；现代 x86 上的默认设置是使用更高级（更快）的 ZSTD 压缩，尽管文件命名约定仍然存在。此外，位于 /boot/grub/grub.cfg 的 GRUB 配置文件已更新，以反映现在可以启动新内核的事实。再次强调，所有这些都是特定于体系结构的。前面的讨论涉及在 Ubuntu Linux x86_64 系统上构建内核。虽然概念上相似，但内核映像文件名、其位置，尤其是引导加载程序的细节在不同的架构甚至不同的发行版上有所不同。</p>
<p>​    如果您愿意，可以跳到第 7 步 - 自定义 GRUB 部分。如果您很好奇（我希望如此），请继续阅读。在下一节中，我们将更详细地描述 initramfs（以前称为 initrd）框架的工作原理和原因。</p>
<h4 id="了解-initramfs-框架"><a href="#了解-initramfs-框架" class="headerlink" title="了解 initramfs 框架"></a>了解 initramfs 框架</h4><p>还有一点谜团！这个 initramfs（初始 RAM 文件系统）或 initr 到底是什么</p>
<p>​    首先，使用此功能是一种选择 - 内核配置指令称为 CONFIG_BLK_DEV_INITRD。它设置为 y，因此默认情况下处于启用状态。</p>
<p>​    简而言之，对于事先不知道某些事情的系统，例如启动磁盘主机适配器或控制器类型（SCSI、RAID 等）、根文件系统的确切文件系统格式（是 ext2、ext4、btrfs、f2fs 还是其他？），或者对于那些始终将这些功能构建为内核模块的系统，我们需要 initramfs 功能。确切原因稍后就会清楚。此外，如前所述，initrd 现在被认为是一个较旧的术语。 如今，我们更经常使用 initramfs 一词来代替它。 但旧 initrd 和新 initramfs 之间究竟有什么区别？关键区别在于它们的生成方式。要使用当前目录内容构建（较旧的）initrd 映像，我们可以执行以下操作： </p>
<pre class="line-numbers language-none"><code class="language-none">find . | sudo cpio -R root:root | gzip -9 &gt; initrd.img<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> 而要使用当前目录内容构建（较新的）initramfs 映像， 我们可以这样做（使用 newc 格式）： </p>
<pre class="line-numbers language-none"><code class="language-none">find . | sudo cpio -o --format&#x3D;newc -R root:root | gzip -9 &gt; initramf <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    为什么使用 initramfs 框架？ <strong>initramfs 框架本质上是早期内核启动和用户模式之间的一种中间人。它允许我们在实际（真实）根文件系统挂载之前、内核完成系统初始化之前运行用户空间应用程序（或脚本）</strong>。这在许多情况下都很有用，其中一些在以下列表中详细介绍。这里的关键点是 initramfs 允许我们运行内核在启动时通常无法运行的用户模式应用程序。 实际上，除了各种用途之外，这个框架还允许我们做一些 有趣的事情，包括： 设置控制台字体。 自定义键盘布局设置。 在控制台设备上打印自定义欢迎消息。 接受密码（加密磁盘必需）。 根据需要加载内核模块。 如果出现故障，生成“救援”shell。 还有更多！ 想象一下，您正在构建和维护一个新的 Linux 发行版。现在，在安装时，发行版的最终用户 可能会决定使用 f2fs（快速闪存文件系统）文件系统来格式化他们的 SSD 磁盘。问题是，您无法提前确切知道最终用户将做出什么选择——它可能是任意数量的文件系统之一。因此，您决定预先构建并提供各种各样的内核模块，以满足几乎所有的可能性。好的，当安装完成并且用户的系统启动时，在这种情况下，内核将需要 f2fs.ko 内核模块来成功挂载 (f2fs) 根文件系统并继续执行。</p>
<h4 id="了解-x86-上启动过程的基础知识"><a href="#了解-x86-上启动过程的基础知识" class="headerlink" title="了解 x86 上启动过程的基础知识"></a>了解 x86 上启动过程的基础知识</h4><p>​    在以下列表中，我们简要概述了 x86[_64] 台式机（或笔记本电脑）、工作站或服务器上的典型启动过程：</p>
<p>​    首先，系统启动大致有两种方式。首先，传统方式（特定于 x86）是通过 BIOS（基本输入输出系统的缩写 - 本质上是 x86 上的固件）。在执行基本系统初始化和诊断（POST - 开机自检）后，它将第一个可启动磁盘的第一个扇区加载到 RAM 中并跳转到其入口点。这形成了通常称为第一阶段引导加载程序的东西，它非常小（通常只有 1 个扇区，512 字节）；它的主要工作是将第二阶段（更大的）引导加载程序代码（也存在于可启动磁盘上）加载到内存中并跳转到它。<br>​    现代、更强大的启动方式是通过<strong>较新的 UEFI（统一可扩展固件接口）标准</strong>：在许多现代系统上，UEFI 框架被用作一种更优越、更安全的系统启动方式。那么传统 BIOS 和较新的 UEFI 之间有什么区别呢？</p>
<p>  ​    简而言之：UEFI 是一个现代框架，不限于 x86（BIOS 仅适用于 x86）；例如，基于 ARM 的系统利用 UEFI 作为其著名的安全启动功能的一部分。</p>
<p>​    UEFI 更安全；它只允许“签名”的操作系统（它称之为“应用程序”）通过它启动（这有时会导致双启动问题）。UEFI 需要一个单独的特殊分区，称为 ESP（EFI 系统分区）；它包含一个包含初始化代码和数据的 .efi 文件，而 BIOS 则将其写入固件中（通常在 EEPROM 芯片中）。因此，更新 UEFI 非常简单。</p>
<p>​    UEFI 启动时间比传统 BIOS 更快。UEFI 允许您运行现代 32 位或 64 位代码，因此可以使用美观的 GUI 作为界面；BIOS 仅适用于 16 位代码。<br>  驱动器大小：BIOS 仅支持最大 2.2 TB 的磁盘，而 UEFI 可以支持最大 9 ZB（泽字节）大小的磁盘！</p>
<p>​    无论 UEFI/BIOS 如何，一旦内核映像加载到 RAM 中，第二阶段引导加载程序代码就会接管控制。它的主要工作是将实际（第三阶段）引导加载程序从文件系统加载到内存中并跳转到其入口点。在 x86 上，GRUB 通常是使用的引导加载程序（较旧的是 LILO（Linux 加载程序））。</p>
<p>​    GRUB 将通过压缩的内核映像文件 (<code>/boot/vmlinuz-&lt;kernel-ver&gt;</code>) 以及压缩的 initramfs 映像文件 (<code>/boot/initrd.img-&lt;kernel-ver&gt;</code>) 作为参数（通过其配置文件，我们将在后面的部分中看到）。引导加载程序将（简单地）执行以下操作：<br>执行低级硬件初始化。将这些映像加载到 RAM 中，在一定程度上解压缩内核映像。然后它将跳转到内核入口点。</p>
<p>​    Linux 内核现在完全控制了机器，将初始化硬件和软件环境。它通常不会对引导加载程序先前执行的工作做出任何假设。好吧，它确实依赖于 BIOS 或 UEFI 来设置诸如 PCI 寻址和中断线分配之类的东西，通过 ACPI 表（或者，在 ARM/PPC 上，通过设备树）。</p>
<p>​    完成大部分硬件和软件初始化后，如果它注意到 initramfs 功能已打开（CONFIG_BLK_DEV_INITRD=y），它将在 RAM 中定位（并根据需要解压缩）initramfs（initrd）映像（参见图 3.2）。然后，它将在 RAM 本身中将其作为临时根文件系统挂载在 RAM 磁盘内。</p>
<p>​    现在，我们在内存中设置了一个基本、最小和临时的根文件系统。因此，基于 initramfs 的启动脚本现在运行，执行将所需内核模块加载到 RAM 中的任务（实际上，加载根文件系统驱动程序，包括我们场景中的 f2fs.ko 内核模块；再次参见图 3.2）。</p>
<p>​    当 initramfs 运行时，它首先调用 /sbin/init（这可能是二进制可执行文件或脚本）；除了其他日常工作外，它还执行一项关键任务：pivot-root，<strong>卸载临时的initramfs根文件系统，释放其内存，并挂载真正的根文件系统。</strong>现在这是可能的，因为提供该文件系统支持的内核模块确实可用（在RAM中）。</p>
<p>​    一旦成功挂载（实际磁盘或基于闪存的）根文件系统，系统初始化就可以继续。内核继续，最终调用第一个用户空间进程（PID 1），通常是/sbin/init（使用较旧的SysV init框架时），或者，现在更有可能通过更强大的systemd init框架。</p>
<p>​    init框架现在继续初始化系统，按配置启动系统服务。</p>
<blockquote>
<p>需要注意以下几点：<br>在现代 Linux 系统上，传统的（读作：旧/遗留）SysV（读作 System Five）init 框架已基本被现代优化框架 systemd（系统守护进程）所取代。因此，在许多（如果不是大多数）现代 Linux 系统（包括嵌入式系统）上，传统的 /sbin/init 已被 systemd 取代（或者只是指向其可执行文件的符号链接）。systemd 框架被认为是更优越的，能够微调启动过程并优化启动时间，以及许多其他功能。在“进一步阅读”部分了解有关 systemd 的更多信息。<br>本书未详细介绍 initramfs 根文件系统本身的生成；官方内核文档确实涵盖了其中的一些内容 - 使用初始 RAM 磁盘（initrd）：<a target="_blank" rel="noopener" href="https://docs.kernel.org/admin-guide/initrd.html。">https://docs.kernel.org/admin-guide/initrd.html。</a></p>
</blockquote>
<h4 id="有关-initramfs-框架的更多信息"><a href="#有关-initramfs-框架的更多信息" class="headerlink" title="有关 initramfs 框架的更多信息"></a>有关 initramfs 框架的更多信息</h4><p>​    initramfs 框架的另一个帮助是启动磁盘已加密的计算机。    </p>
<p>​    您是否在带有未加密磁盘的笔记本电脑上工作？这不是一个好主意；如果您的设备丢失或被盗，黑客只需使用基于 Linux 的 USB 笔式驱动器启动它，即可轻松访问您的数据，然后通常可以访问其所有磁盘分区。您的登录凭据在这里没有帮助。现代发行版可以肯定且轻松地加密磁盘分区；这现在是安装的常规部分。除了基于卷的加密(由 LUKS、dm-crypt、eCryptfs 等提供），还有几种工具可以单独加密和解密文件。<br>​    假设一个具有加密文件系统的系统，在启动过程的早期，内核将必须向用户询问密码，如果正确，则继续解密和安装磁盘等。但是请考虑一下：在没有 C 运行时环境（包含库、加载程序（ld-linux…）、所需内核模块（可能用于加密支持）等的根文件系统）的情况下，我们如何运行请求密码的 C 程序可执行文件？请记住，内核本身尚未完成初始化；用户空间应用程序如何运行？同样，initramfs 框架通过在主内存中设置一个相当完整（虽然是临时的）的用户空间运行时环境来解决此问题，该环境具有所需的根文件系统，其中包含库、加载程序、内核模块、一些脚本等窥视 initramfs 映像<br>​    因此，我们刚刚说过，initramfs 映像是一个临时的但相当完整的映像，包含系统库、加载程序、最低限度所需的内核模块、一些脚本等等。我们可以验证这一点吗？</p>
<p>​    是的，我们确实可以！让我们窥视一下 initramfs 映像文件。Ubuntu 上的 lsinitramfs 脚本正是用于此目的（在 Fedora 上，等效脚本称为 lsinitrd）：</p>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~$ ls -lh &#x2F;boot&#x2F;initrd.img-6.1.25
-rw-r--r-- 1 root root 23M  7月  4 10:41 &#x2F;boot&#x2F;initrd.img-6.1.25<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~$ lsinitramfs &#x2F;boot&#x2F;initrd.img-6.1.25
.
kernel
kernel&#x2F;x86
kernel&#x2F;x86&#x2F;microcode
kernel&#x2F;x86&#x2F;microcode&#x2F;AuthenticAMD.bin
kernel
kernel&#x2F;x86
kernel&#x2F;x86&#x2F;microcode
kernel&#x2F;x86&#x2F;microcode&#x2F;.enuineIntel.align.0123456789abc
kernel&#x2F;x86&#x2F;microcode&#x2F;GenuineIntel.bin
...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="一些附录文章"><a href="#一些附录文章" class="headerlink" title="一些附录文章"></a>一些附录文章</h1><h1 id="如何在Linux上构建Raspberry-Pi虚拟环境"><a href="#如何在Linux上构建Raspberry-Pi虚拟环境" class="headerlink" title="如何在Linux上构建Raspberry Pi虚拟环境"></a>如何在Linux上构建Raspberry Pi虚拟环境</h1><p>​    下面我们来讲讲如何使用QEMU来仿照树莓派环境。这里首先先分成两大类。第一类是跑比较老的，安全性较低的老树莓派，主要指代的是22年4月份发布之前的版本，这个版本当中，树莓派镜像自己内部就配置了一份默认的账户密码。对于之后的版本则不配备这种默认的账号密码。因此，我们需要区分出两种装载模式。</p>
<p>​    为了省力，我们使用人家已经配置好了的</p>
<blockquote>
<p>github仓库：<a target="_blank" rel="noopener" href="https:*//github.com/dhruvvyas90/qemu-rpi-kernel.git*">qemu-rpi-kernel</a></p>
</blockquote>
<h2 id="前置环境需求"><a href="#前置环境需求" class="headerlink" title="前置环境需求"></a>前置环境需求</h2><pre class="line-numbers language-none"><code class="language-none">yay -S qemu-system-arm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="Older-Version"><a href="#Older-Version" class="headerlink" title="Older Version"></a>Older Version</h2><p>​    考虑旧的树莓派镜像，安装的方式如下</p>
<ol>
<li><p>克隆仓库<a target="_blank" rel="noopener" href="https:*//github.com/dhruvvyas90/qemu-rpi-kernel.git*">qemu-rpi-kernel</a>到一个位置，取出里头的：</p>
<pre class="line-numbers language-none"><code class="language-none">kernel-qemu-5.4.51-buster
versatile-pb-buster-5.4.51.dtb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>这两个文件到一个自己创建的目录文件夹下。我的是oldone</p>
</li>
<li><p>下载旧树莓派镜像</p>
<pre class="line-numbers language-none"><code class="language-none">https:&#x2F;&#x2F;downloads.raspberrypi.org&#x2F;raspios_lite_armhf&#x2F;images&#x2F;raspios_lite_armhf-2020-05-28&#x2F;2020-05-27-raspios-buster-lite-armhf.zip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>wget还是扔浏览器自己点击，看自己兴趣。下载结束解压到上面创建的oldone文件夹下</p>
</li>
<li><p>写一个简单的脚本</p>
<pre class="line-numbers language-none"><code class="language-none">qemu-system-arm \
  -M versatilepb \
  -cpu arm1176 \
  -m 256 \
  -drive &quot;file&#x3D;2020-05-27-raspios-buster-lite-armhf.img,
   if&#x3D;none,index&#x3D;0,media&#x3D;disk,format&#x3D;raw,id&#x3D;disk0&quot; 
  -device &quot;virtio-blk-pci,drive&#x3D;disk0,disable-modern&#x3D;on,disable-legacy&#x3D;off&quot; \
  -net &quot;user,hostfwd&#x3D;tcp::5022-:22&quot; \
  -dtb versatile-pb-buster-5.4.51.dtb \
  -kernel kernel-qemu-5.4.51-buster \
  -nographic \ # 提示，这个跟下面的console&#x3D;ttyAMA0搭配使用，想要图形化输出请自行删掉提到的两行
  -append &#39;root&#x3D;&#x2F;dev&#x2F;vda2 panic&#x3D;1 console&#x3D;ttyAMA0&#39; \
  -no-reboot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>我先说说这些参数都是什么意思。</p>
<blockquote>
<p>-M versatilepb:QEMU支持的板子里有这个，这个是我们树莓派的体系平台，选这个运行我们的树莓派仿真环境</p>
<p>-cpu arm1176: CPU型号选择arm1176</p>
<p>-m 256 内存大小是256MB，我看有Issue说最大就这个，不能再大了，有bug会，笔者这里尚未考证，不予评价</p>
<p>下面这一个长一些：实际上就是指定我们的镜像文件和索引格式：</p>
<blockquote>
<p><code>file=2020-05-27-raspios-buster-lite-armhf.img</code>：指定要使用的镜像文件。</p>
<p><code>if=none</code>：指定该驱动器不自动分配到任何接口。</p>
<p><code>index=0</code>：设置驱动器的索引为0。</p>
<p><code>media=disk</code>：指定媒体类型为磁盘。</p>
<p><code>format=raw</code>：指定镜像文件的格式为raw（原始格式）。</p>
<p><code>id=disk0</code>：为该驱动器指定一个唯一的ID（disk0）。</p>
</blockquote>
<p>下面的这个是指定输入输出：</p>
<blockquote>
<p><code>virtio-blk-pci</code>：指定设备模型为VirtIO块设备（通过PCI总线连接的VirtIO块设备）。VirtIO设备通常用于提高虚拟化性能。</p>
<p><code>drive=disk0</code>：将这个设备与之前定义的ID为<code>disk0</code>的驱动器关联起来。</p>
<p><code>disable-modern=on</code>：禁用现代（modern）VirtIO设备特性。这些特性通常提供更高的性能，但可能与某些旧的系统不兼容。</p>
<p><code>disable-legacy=off</code>：启用传统（legacy）VirtIO设备特性。这些特性通常用于兼容旧的系统。</p>
</blockquote>
<p>-net配置网络：<code>user</code>：使用用户模式网络栈。这是QEMU的一种网络配置方式，适合不需要复杂网络配置的场景。<code>hostfwd=tcp::5022-:22</code>：设置端口转发规则，将主机的TCP端口5022转发到虚拟机的TCP端口22。</p>
<p>-dtb：指定设备树，这里用配好的</p>
<p>-kernel是使用到的内核：kernel-qemu-5.4.51-buster</p>
<p>-no-reboot：虚拟机关机或崩溃时，阻止它自动重启（关了我们怎么看日志呢hhh）</p>
<p>-nographic:不启用图形化，这个看心情指定，注意的是这个跟console=ttyAMA0一起用</p>
<p>下面的—append说的是追加内核启动参数：</p>
<blockquote>
<p><code>root=/dev/vda2</code>：指定根文件系统所在的设备。这里假设根文件系统位于虚拟磁盘的第二个分区。</p>
<p><code>panic=1</code>：在内核遇到致命错误时，指定在1秒后自动重启。</p>
<p><code>console=ttyAMA0</code>：指定内核控制台输出到<code>ttyAMA0</code>，通常用于ARM架构的串口控制台。</p>
</blockquote>
</blockquote>
</li>
</ol>
<p>​    下面就可以启动了，我想要提到的是，由于这玩意内存就给256M，可以说启动相当的缓慢，因此，有点耐心，好几次笔者以为是配置挂了反复检查，直到吃饭回来才发现跑通的本来</p>
<p>​    总结一下，如果看官希望采用的是非图形化的输出，需要写入的脚本是：</p>
<pre class="line-numbers language-none"><code class="language-none">qemu-system-arm \
  -M versatilepb \
  -cpu arm1176 \
  -m 256 \
  -drive &quot;file&#x3D;2020-05-27-raspios-buster-lite-armhf.img,
   if&#x3D;none,index&#x3D;0,media&#x3D;disk,format&#x3D;raw,id&#x3D;disk0&quot; 
  -device &quot;virtio-blk-pci,drive&#x3D;disk0,disable-modern&#x3D;on,disable-legacy&#x3D;off&quot; \
  -net &quot;user,hostfwd&#x3D;tcp::5022-:22&quot; \
  -dtb versatile-pb-buster-5.4.51.dtb \
  -kernel kernel-qemu-5.4.51-buster \
  -nographic \
  -append &#39;root&#x3D;&#x2F;dev&#x2F;vda2 panic&#x3D;1 console&#x3D;ttyAMA0&#39; \
  -no-reboot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    下面只需要</p>
<pre class="line-numbers language-none"><code class="language-none">chmod 777 &lt;脚本名称&gt;.sh
.&#x2F;&lt;脚本名称&gt;.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    很快就会刷屏</p>
<blockquote>
<p>笔者建议使用非图形化的方式启动，日志更加丰富，而且可以实时看看进度。图形化的方式则会缺斤少两，导致一些长时间的加载被误认为是kernel挂了（我自己）</p>
</blockquote>
<p><img src="./image-20240729214054816.png" alt="image-20240729214054816"></p>
<p>​    这是结束时候的画面，默认的，旧版本下的账号密码是：登录用户名为pi，该账户默认密码是raspberry，之后想要改passwd更改就好。</p>
<p>​    如果想要以图形化的方式启动：</p>
<pre class="line-numbers language-none"><code class="language-none">qemu-system-arm \
  -M versatilepb \
  -cpu arm1176 \
  -m 256 \
  -drive &quot;file&#x3D;2020-05-27-raspios-buster-lite-armhf.img,
   if&#x3D;none,index&#x3D;0,media&#x3D;disk,format&#x3D;raw,id&#x3D;disk0&quot; 
  -device &quot;virtio-blk-pci,drive&#x3D;disk0,disable-modern&#x3D;on,disable-legacy&#x3D;off&quot; \
  -net &quot;user,hostfwd&#x3D;tcp::5022-:22&quot; \
  -dtb versatile-pb-buster-5.4.51.dtb \
  -kernel kernel-qemu-5.4.51-buster \
  -append &#39;root&#x3D;&#x2F;dev&#x2F;vda2 panic&#x3D;1&#39; \
  -no-reboot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="./pic1.png" alt="pic1"></p>
<p><img src="./pic2.png" alt="pic2"></p>
<h2 id="新版本启动"><a href="#新版本启动" class="headerlink" title="新版本启动"></a>新版本启动</h2><p>​    我们这一次玩一个新的，这一次我们尝试跑最新版本的树莓派镜像，有了旧版本的经验，事情垂手可得，但是这次我们要注意的是，我们必须先用非图形化的方式跑一次（可以不用吗，可以，但是我懒得改文件）</p>
<p>​    这是因为我们需要被引导设置账号密码，新版本的树莓派OS不再提供默认的账号密码了！剩下的都一样！这里不再赘述</p>
<h1 id="附录文章"><a href="#附录文章" class="headerlink" title="附录文章"></a>附录文章</h1><h2 id="Kbuild-and-Kconfig"><a href="#Kbuild-and-Kconfig" class="headerlink" title="Kbuild and Kconfig"></a>Kbuild and Kconfig</h2><p>The Linux kernel config/build system, also known as Kconfig/kbuild, has been around for a long time, ever since the Linux kernel code migrated to Git. As supporting infrastructure, however, it is seldom in the spotlight; even kernel developers who use it in their daily work never really think about it.</p>
<p>To explore how the Linux kernel is compiled, this article will dive into the Kconfig/kbuild internal process, explain how the .config file and the vmlinux/bzImage files are produced, and introduce a smart trick for dependency tracking.</p>
<h2 id="Kconfig"><a href="#Kconfig" class="headerlink" title="Kconfig"></a>Kconfig</h2><p>The first step in building a kernel is always configuration. Kconfig helps make the Linux kernel highly modular and customizable. Kconfig offers the user many config targets:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>config</th>
<th>Update current config utilizing a line-oriented program</th>
</tr>
</thead>
<tbody>
<tr>
<td>nconfig</td>
<td>Update current config utilizing a ncurses menu-based program</td>
</tr>
<tr>
<td>menuconfig</td>
<td>Update current config utilizing a menu-based program</td>
</tr>
<tr>
<td>xconfig</td>
<td>Update current config utilizing a Qt-based frontend</td>
</tr>
<tr>
<td>gconfig</td>
<td>Update current config utilizing a GTK+ based frontend</td>
</tr>
<tr>
<td>oldconfig</td>
<td>Update current config utilizing a provided .config as base</td>
</tr>
<tr>
<td>localmodconfig</td>
<td>Update current config disabling modules not loaded</td>
</tr>
<tr>
<td>localyesconfig</td>
<td>Update current config converting local mods to core</td>
</tr>
<tr>
<td>defconfig</td>
<td>New config with default from Arch-supplied defconfig</td>
</tr>
<tr>
<td>savedefconfig</td>
<td>Save current config as ./defconfig (minimal config)</td>
</tr>
<tr>
<td>allnoconfig</td>
<td>New config where all options are answered with ‘no’</td>
</tr>
<tr>
<td>allyesconfig</td>
<td>New config where all options are accepted with ‘yes’</td>
</tr>
<tr>
<td>allmodconfig</td>
<td>New config selecting modules when possible</td>
</tr>
<tr>
<td>alldefconfig</td>
<td>New config with all symbols set to default</td>
</tr>
<tr>
<td>randconfig</td>
<td>New config with a random answer to all options</td>
</tr>
<tr>
<td>listnewconfig</td>
<td>List new options</td>
</tr>
<tr>
<td>olddefconfig</td>
<td>Same as oldconfig but sets new symbols to their default value without prompting</td>
</tr>
<tr>
<td>kvmconfig</td>
<td>Enable additional options for KVM guest kernel support</td>
</tr>
<tr>
<td>xenconfig</td>
<td>Enable additional options for xen dom0 and guest kernel support</td>
</tr>
<tr>
<td>tinyconfig</td>
<td>Configure the tiniest possible kernel</td>
</tr>
</tbody>
</table>
</div>
<p>I think <strong>menuconfig</strong> is the most popular of these targets. The targets are processed by different host programs, which are provided by the kernel and built during kernel building. Some targets have a GUI (for the user’s convenience) while most don’t. Kconfig-related tools and source code reside mainly under <strong>scripts/kconfig/</strong> in the kernel source. As we can see from <strong>scripts/kconfig/Makefile</strong>, there are several host programs, including <strong>conf</strong>, <strong>mconf</strong>, and <strong>nconf</strong>. Except for <strong>conf</strong>, each of them is responsible for one of the GUI-based config targets, so, <strong>conf</strong> deals with most of them.</p>
<p>Logically, Kconfig’s infrastructure has two parts: one implements a <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/master/Documentation/kbuild/kconfig-language.txt">new language</a> to define the configuration items (see the Kconfig files under the kernel source), and the other parses the Kconfig language and deals with configuration actions.</p>
<p>Most of the config targets have roughly the same internal process (shown below):</p>
<p><img src="./kconfig_process.png" alt="Kconfig process"></p>
<p><a target="_blank" rel="noopener" href="https://opensource.com/article/18/10/kbuild-and-kconfig#">SKIP TO CONTENT</a></p>
<p>The Linux Terminal</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://opensource.com/life/17/10/top-terminal-emulators?intcmp=7016000000127cYAAQ">Top 7 terminal emulators for Linux</a></li>
<li><a target="_blank" rel="noopener" href="https://opensource.com/article/17/2/command-line-tools-data-analysis-linux?intcmp=7016000000127cYAAQ">10 command-line tools for data analysis in Linux</a></li>
<li><a target="_blank" rel="noopener" href="https://opensource.com/downloads/advanced-ssh-cheat-sheet?intcmp=7016000000127cYAAQ">Download Now: SSH cheat sheet</a></li>
<li><a target="_blank" rel="noopener" href="https://developers.redhat.com/cheat-sheets/advanced-linux-commands/?intcmp=7016000000127cYAAQ">Advanced Linux commands cheat sheet</a></li>
<li><a target="_blank" rel="noopener" href="https://opensource.com/tags/command-line?intcmp=7016000000127cYAAQ">Linux command line tutorials</a></li>
</ul>
<p>Note that all configuration items have a default value.</p>
<p>The first step reads the Kconfig file under source root to construct an initial configuration database; then it updates the initial database by reading an existing configuration file according to this priority:</p>
<blockquote>
<p>.config</p>
<p>/lib/modules/$(shell,uname -r)/.config</p>
<p>/etc/kernel-config</p>
<p>/boot/config-$(shell,uname -r)</p>
<p>ARCH_DEFCONFIG</p>
<p>arch/$(ARCH)/defconfig</p>
</blockquote>
<p>If you are doing GUI-based configuration via <strong>menuconfig</strong> or command-line-based configuration via <strong>oldconfig</strong>, the database is updated according to your customization. Finally, the configuration database is dumped into the .config file.</p>
<p>But the .config file is not the final fodder for kernel building; this is why the <strong>syncconfig</strong> target exists. <strong>syncconfig</strong> used to be a config target called <strong>silentoldconfig</strong>, but it doesn’t do what the old name says, so it was renamed. Also, because it is for internal use (not for users), it was dropped from the list.</p>
<p>Here is an illustration of what <strong>syncconfig</strong> does:</p>
<p><img src="./syncconfig.png" alt="Syncconfig"></p>
<p><strong>syncconfig</strong> takes .config as input and outputs many other files, which fall into three categories:</p>
<ul>
<li>auto.conf &amp; tristate.conf</li>
</ul>
<p>  are used for makefile text processing. For example, you may see statements like this in a component’s makefile: </p>
  <pre class="line-numbers language-text" data-language="text"><code class="language-text">obj-$(CONFIG_GENERIC_CALIBRATE_DELAY) += calibrate.o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ul>
<li><p><strong>autoconf.h</strong> is used in C-language source files.</p>
</li>
<li><p>Empty header files under <strong>include/config/</strong> are used for configuration-dependency tracking during kbuild, which is explained below.</p>
</li>
</ul>
<p>After configuration, we will know which files and code pieces are not compiled.</p>
<h2 id="kbuild"><a href="#kbuild" class="headerlink" title="kbuild"></a>kbuild</h2><p>Component-wise building, called <em>recursive make</em>, is a common way for GNU <code>make</code> to manage a large project. Kbuild is a good example of recursive make. By dividing source files into different modules/components, each component is managed by its own makefile. When you start building, a top makefile invokes each component’s makefile in the proper order, builds the components, and collects them into the final executive.</p>
<p>Kbuild refers to different kinds of makefiles:</p>
<ul>
<li><strong>Makefile</strong> is the top makefile located in source root.</li>
<li><strong>.config</strong> is the kernel configuration file.</li>
<li><strong>arch/$(ARCH)/Makefile</strong> is the arch makefile, which is the supplement to the top makefile.</li>
<li><strong>scripts/Makefile.*</strong> describes common rules for all kbuild makefiles.</li>
<li>Finally, there are about 500 <strong>kbuild makefiles</strong>.</li>
</ul>
<p>The top makefile includes the arch makefile, reads the .config file, descends into subdirectories, invokes <strong>make</strong> on each component’s makefile with the help of routines defined in <strong>scripts/Makefile.*</strong>, builds up each intermediate object, and links all the intermediate objects into vmlinux. Kernel document <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/master/Documentation/kbuild/makefiles.txt">Documentation/kbuild/makefiles.txt</a> describes all aspects of these makefiles.</p>
<p>As an example, let’s look at how vmlinux is produced on x86-64:</p>
<p><img src="./vmlinux_generation_process.png" alt="vmlinux overview"></p>
<p>All the <strong>.o</strong> files that go into vmlinux first go into their own <strong>built-in.a</strong>, which is indicated via variables <strong>KBUILD_VMLINUX_INIT</strong>, <strong>KBUILD_VMLINUX_MAIN</strong>, <strong>KBUILD_VMLINUX_LIBS</strong>, then are collected into the vmlinux file.</p>
<p>Take a look at how recursive make is implemented in the Linux kernel, with the help of simplified makefile code:</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text"># In top Makefile
vmlinux: scripts/link-vmlinux.sh $(vmlinux-deps)
		+$(call if_changed,link-vmlinux)

# Variable assignments
vmlinux-deps := $(KBUILD_LDS) $(KBUILD_VMLINUX_INIT) $(KBUILD_VMLINUX_MAIN) $(KBUILD_VMLINUX_LIBS)

export KBUILD_VMLINUX_INIT := $(head-y) $(init-y)
export KBUILD_VMLINUX_MAIN := $(core-y) $(libs-y2) $(drivers-y) $(net-y) $(virt-y)
export KBUILD_VMLINUX_LIBS := $(libs-y1)
export KBUILD_LDS          := arch/$(SRCARCH)/kernel/vmlinux.lds

init-y          := init/
drivers-y       := drivers/ sound/ firmware/
net-y           := net/
libs-y          := lib/
core-y          := usr/
virt-y          := virt/

# Transform to corresponding built-in.a
init-y          := $(patsubst %/, %/built-in.a, $(init-y))
core-y          := $(patsubst %/, %/built-in.a, $(core-y))
drivers-y       := $(patsubst %/, %/built-in.a, $(drivers-y))
net-y           := $(patsubst %/, %/built-in.a, $(net-y))
libs-y1         := $(patsubst %/, %/lib.a, $(libs-y))
libs-y2         := $(patsubst %/, %/built-in.a, $(filter-out %.a, $(libs-y)))
virt-y          := $(patsubst %/, %/built-in.a, $(virt-y))

# Setup the dependency. vmlinux-deps are all intermediate objects, vmlinux-dirs
# are phony targets, so every time comes to this rule, the recipe of vmlinux-dirs
# will be executed. Refer "4.6 Phony Targets" of `info make`
$(sort $(vmlinux-deps)): $(vmlinux-dirs) ;

# Variable vmlinux-dirs is the directory part of each built-in.a
vmlinux-dirs    := $(patsubst %/,%,$(filter %/, $(init-y) $(init-m) \
                     $(core-y) $(core-m) $(drivers-y) $(drivers-m) \
                     $(net-y) $(net-m) $(libs-y) $(libs-m) $(virt-y)))

# The entry of recursive make
$(vmlinux-dirs):
		$(Q)$(MAKE) $(build)=$@ need-builtin=1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>The recursive make recipe is expanded, for example:</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">make -f scripts/Makefile.build obj=init need-builtin=1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>This means <strong>make</strong> will go into <strong>scripts/Makefile.build</strong> to continue the work of building each <strong>built-in.a</strong>. With the help of <strong>scripts/link-vmlinux.sh</strong>, the vmlinux file is finally under source root.</p>
<h3 id="Understanding-vmlinux-vs-bzImage"><a href="#Understanding-vmlinux-vs-bzImage" class="headerlink" title="Understanding vmlinux vs. bzImage"></a>Understanding vmlinux vs. bzImage</h3><p>Many Linux kernel developers may not be clear about the relationship between vmlinux and bzImage. For example, here is their relationship in x86-64:</p>
<p><img src="./vmlinux-bzimage.png" alt="vmlinux vs. bzImage"></p>
<p>The source root vmlinux is stripped, compressed, put into <strong>piggy.S</strong>, then linked with other peer objects into <strong>arch/x86/boot/compressed/vmlinux</strong>. Meanwhile, a file called setup.bin is produced under <strong>arch/x86/boot</strong>. There may be an optional third file that has relocation info, depending on the configuration of <strong>CONFIG_X86_NEED_RELOCS</strong>.</p>
<p>A host program called <strong>build</strong>, provided by the kernel, builds these two (or three) parts into the final bzImage file.</p>
<h3 id="Dependency-tracking"><a href="#Dependency-tracking" class="headerlink" title="Dependency tracking"></a>Dependency tracking</h3><p>Kbuild tracks three kinds of dependencies:</p>
<ol>
<li>All prerequisite files (both <strong>*.c</strong> and <strong>*.h</strong>)</li>
<li><strong>CONFIG_</strong> options used in all prerequisite files</li>
<li>Command-line dependencies used to compile the target</li>
</ol>
<p>The first one is easy to understand, but what about the second and third? Kernel developers often see code pieces like this:</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">#ifdef CONFIG_SMP
__boot_cpu_id = cpu;
#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>When <strong>CONFIG_SMP</strong> changes, this piece of code should be recompiled. The command line for compiling a source file also matters, because different command lines may result in different object files.</p>
<p>When a <strong>.c</strong> file uses a header file via a <strong>#include</strong> directive, you need write a rule like this:</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">main.o: defs.h
	recipe...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>When managing a large project, you need a lot of these kinds of rules; writing them all would be tedious and boring. Fortunately, most modern C compilers can write these rules for you by looking at the <strong>#include</strong> lines in the source file. For the GNU Compiler Collection (GCC), it is just a matter of adding a command-line parameter: <strong>-MD depfile</strong></p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text"># In scripts/Makefile.lib
c_flags        = -Wp,-MD,$(depfile) $(NOSTDINC_FLAGS) $(LINUXINCLUDE)     \
                 -include $(srctree)/include/linux/compiler_types.h       \
                 $(__c_flags) $(modkern_cflags)                           \
                 $(basename_flags) $(modname_flags)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>This would generate a <strong>.d</strong> file with content like:</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">init_task.o: init/init_task.c include/linux/kconfig.h \
 include/generated/autoconf.h include/linux/init_task.h \
 include/linux/rcupdate.h include/linux/types.h \
 ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>Then the host program <strong><a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/master/scripts/basic/fixdep.c">fixdep</a></strong> takes care of the other two dependencies by taking the <strong>depfile</strong> and command line as input, then outputting a <strong>.<target>.cmd</strong> file in makefile syntax, which records the command line and all the prerequisites (including the configuration) for a target. It looks like this:</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text"># The command line used to compile the target
cmd_init/init_task.o := gcc -Wp,-MD,init/.init_task.o.d  -nostdinc ...
...
# The dependency files
deps_init/init_task.o := \
$(wildcard include/config/posix/timers.h) \
$(wildcard include/config/arch/task/struct/on/stack.h) \
$(wildcard include/config/thread/info/in/task.h) \
...
  include/uapi/linux/types.h \
  arch/x86/include/uapi/asm/types.h \
  include/uapi/asm-generic/types.h \
  ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>A <strong>.<target>.cmd</strong> file will be included during recursive make, providing all the dependency info and helping to decide whether to rebuild a target or not.</p>
<p>The secret behind this is that <strong>fixdep</strong> will parse the <strong>depfile</strong> (<strong>.d</strong> file), then parse all the dependency files inside, search the text for all the <strong>CONFIG_</strong> strings, convert them to the corresponding empty header file, and add them to the target’s prerequisites. Every time the configuration changes, the corresponding empty header file will be updated, too, so kbuild can detect that change and rebuild the target that depends on it. Because the command line is also recorded, it is easy to compare the last and current compiling parameters.</p>
<h2 id="Looking-ahead"><a href="#Looking-ahead" class="headerlink" title="Looking ahead"></a>Looking ahead</h2><p>Kconfig/kbuild remained the same for a long time until the new maintainer, Masahiro Yamada, joined in early 2017, and now kbuild is under active development again. Don’t be surprised if you soon see something different from what’s in this article. </p>
<h2 id="编写我们的模块"><a href="#编写我们的模块" class="headerlink" title="编写我们的模块"></a>编写我们的模块</h2><h3 id="在展开之前，先说说…"><a href="#在展开之前，先说说…" class="headerlink" title="在展开之前，先说说…"></a>在展开之前，先说说…</h3><h4 id="用户空间和内核空间"><a href="#用户空间和内核空间" class="headerlink" title="用户空间和内核空间"></a>用户空间和内核空间</h4><p>​    现代微处理器支持至少两个特权级别的代码执行。作为一个现实世界的例子，Intel/AMD x86[-64] 系列支持四个特权级别（他们称之为环级别），AArch32（ARM-32）微处理器系列支持多达七种模式（ARM 称之为执行模式；六种是特权模式，一种是非特权模式），AArch64（ARM-64/ARMv8）微处理器系列支持四个异常级别（EL0 到 EL3，其中 EL0 最低，EL3 最高）。这里的关键点是，为了平台的安全性和稳定性，在这些处理器上运行的所有现代操作系统都将使用（至少）两个特权级别（或模式）执行，从而将虚拟地址空间 (VAS) 分成两个明确区分的（虚拟）地址空间</p>
<p>​    用户空间：用于在非特权用户模式下运行的应用程序。所有应用程序（进程和线程）都将在此空间中以该特权执行。因此，现在，您可能正在使用浏览器、编辑器、PDF 阅读器、终端、电子邮件客户端等。它们都是应用程序（最终是进程和线程）；</p>
<p>​    内核空间：用于在特权模式（内核模式）下运行的内核（及其所有组件）。这是操作系统及其内部内容的域（如驱动程序、网络、I/O 等，包括内核模块）。它们都以操作系统特权运行；实际上，它们可以做任何它们喜欢的事情！请注意，此特权级别是硬件功能，与是否以 root 身份运行不同（这是纯软件工件）；在许多情况下， 以内核权限运行可以被视为以 root 身份有效运行。 下图显示了此基本架构：</p>
<p><img src="./image-20240705054236841.png" alt="image-20240705054236841"></p>
<h4 id="库和系统调用API"><a href="#库和系统调用API" class="headerlink" title="库和系统调用API"></a>库和系统调用API</h4><p>​    用户空间应用程序通常依赖应用程序编程接口 (API) 来执行其工作。库本质上是 API 的集合或存档，允许您使用标准化、编写良好且经过充分测试的接口（并利用常见的好处：不必重新发明轮子、可移植性、标准化等）。</p>
<p>​    Linux 系统有几个库：企业级系统上甚至有数百个库也并不罕见。其中，所有用户模式 Linux 应用程序（可执行文件）都“自动链接”到一个重要的、始终使用的库中：glibc - GNU 标准 C 库，您将会了解到。但是，库仅在用户模式下可用；内核不使用这些用户模式库</p>
<p>​    库 API 的示例包括众所周知的 printf(3)、scanf(3)、strcmp(3)、malloc(3) 和 free(3)。</p>
<p>​    现在，一个关键点：如果用户和内核是独立的地址空间并且具有不同的权限级别，那么用户进程（正如我们刚刚了解到的，仅限于用户空间）</p>
<p>​    如何访问内核？简短的回答是： 通过系统调用。</p>
<p>​    系统调用是一种特殊的 API，因为它是用户空间进程（或线程）访问内核的唯一合法（同步）方式。换句话说，系统调用是进入内核空间的唯一合法入口点。 它们（系统调用）具有从非特权用户模式切换到特权内核模式的内置能力，系统调用的示例包括 fork(2)、execve(2)、open(2)、read(2)、write(2)、socket(2)、 accept(2)、chmod(2) 等等</p>
<p>​    可以自己查看（）</p>
<blockquote>
<p>APIs: <a target="_blank" rel="noopener" href="https://linux.die.net/man/3/">Section 3: library functions - Linux man pages (die.net)</a></p>
<p>System Call: <a target="_blank" rel="noopener" href="https://linux.die.net/man/2/">Section 2: system calls - Linux man pages (die.net)</a></p>
</blockquote>
<p>​    这里要强调的一点是，用户应用程序（进程和线程）和内核只能通过系统调用进行通信 </p>
<h4 id="内核空间组件"><a href="#内核空间组件" class="headerlink" title="内核空间组件"></a>内核空间组件</h4><p>​    当然，本书完全关注内核空间。当今的 Linux 内核是一个相当庞大和复杂的庞然大物。在内部，它由几个主要子系统和几个组件组成。对内核子系统和组件进行广泛列举可得出以下列表：</p>
<ul>
<li>核心内核：此代码处理任何现代操作系统的典型核心工作，包括（用户和内核）进程和线程创建/销毁、CPU 调度、同步原语、信号、计时器、中断处理、命名空间、cgroup、模块支持、加密等。</li>
<li>内存管理 (MM)：处理所有与内存相关的工作，包括内核和进程虚拟地址空间 (VAS) 的设置和维护。</li>
<li>VFS（用于文件系统支持）：虚拟文件系统交换机 (VFS) 是 Linux 内核中实现的实际文件系统的抽象层（例如，ext[2|4]、vfat、ntfs、msdos、iso9660、f2fS、u fS 等等）。</li>
<li>块 I/O：实现实际文件 I/O 的代码路径，从文件系统一直到块设备驱动程序以及其间的所有内容都包含在这里。</li>
<li>网络协议栈：Linux 以其精确、符合 RFC 要求、高质量地实现模型所有层上的知名（和不太知名）网络协议而闻名，其中 TCP/IP 可能是最著名的。</li>
<li>进程间通信 (IPC) 支持：IPC 机制的实现在这里完成；Linux 支持消息队列、共享内存、信号量（旧的 SysV 和新的 POSIX）和其他 IPC 机制。</li>
<li>声音支持：实现音频的所有代码都在这里，从固件到驱动程序和编解码器。</li>
<li>虚拟化支持：Linux 已在大型和小型云提供商中变得非常受欢迎，一个重要原因是其高质量、低占用空间的虚拟化引擎，基于内核的虚拟机 (KVM)。</li>
</ul>
<p>所有这些构成了主要的内核子系统；此外，我们还有这些：</p>
<ul>
<li>特定于架构（即特定于 CPU）的代码</li>
<li>内核初始化</li>
<li>安全框架</li>
<li>许多类型的设备驱动程序</li>
</ul>
<p>​    Linux的架构设计走的是宏内核：</p>
<p><img src="./image-20240705055043637.png" alt="image-20240705055043637"></p>
<p>​    您应该知道的另一个事实是，这些地址空间当然是虚拟地址空间，而不是物理地址空间。内核将在页面粒度级别将虚拟页面映射到物理页面框架，利用硬件块（例如内存管理单元 (MMU) 和处理器）以及转换后备缓冲区 (TLB) 缓存来提高效率。它通过使用主内核分页表将内核虚拟页面映射到物理框架 (RAM) 来实现这一点，并且对于每个处于活动状态的用户空间进程，它通过每个进程的单独分页表将进程（用户）的虚拟页面映射到物理页面框架。</p>
<h4 id="步入主角：LKM（Linux-Kernel-Modules）"><a href="#步入主角：LKM（Linux-Kernel-Modules）" class="headerlink" title="步入主角：LKM（Linux Kernel Modules）"></a>步入主角：LKM（Linux Kernel Modules）</h4><p>​    内核模块是一种提供内核级功能的方法，无需在内核源代码树和静态内核映像中工作。 想象一下您必须向 Linux 内核添加支持功能的场景——可能是新的设备驱动程序，以便使用某个硬件外围芯片、新文件系统或新的 I/O 调度程序。实现此目的的一种方法是显而易见的：使用新代码更新内核源代码树，然后对其进行配置、构建、测试和部署。 虽然这看起来很简单，但工作量很大——我们编写的代码的每一个更改，无论多么小，都需要我们重建内核映像，然后重新启动系统以进行测试。一定有一种更干净、更简单的方法；事实上，确实有——LKM 框架！ </p>
<h4 id="LKM-框架"><a href="#LKM-框架" class="headerlink" title="LKM 框架"></a>LKM 框架</h4><p>​    LKM 框架是一种编译内核代码的方法，通常在内核源代码树之外，通常称为“树外”代码，在有限的意义上使其独立于内核，然后将生成的“模块对象”插入或插入内核内存、内核 VAS，让它运行并执行其工作，然后从内核内存中删除（或拔出）。（请注意，LKM 框架也可用于生成树内内核模块，就像我们在构建内核时所做的那样。这里，我们重点介绍树外模块）。 内核模块的源代码通常由一个或多个 C 源文件、头文件和一个 Makefile 组成，并（当然是通过 make）构建到内核模块中。内核模块本身只是一个二进制对象文件，而不是二进制可执行文件。</p>
<p>​    在 Linux 2.4 及更早版本中，内核模块的文件名带有 .o 后缀；在现代 2.6 Linux 及更高版本中，它改为使用 .ko （内核对象）后缀。构建后，您可以在运行时将此 .ko 文件（内核 模块）插入到实时内核中，从而有效地使其成为内核的一部分。</p>
<p><img src="./image-20240705055447874.png" alt="image-20240705055447874"></p>
<p>​    我想你已经留意到了：内核模块是内核代码，是要在内核态运行的。（换而言之没写好是真的会挂的）</p>
<p>​    这样，您（内核（或驱动程序）开发人员）就不必每次都重新配置、重建和重新启动系统。您所要做的就是编辑内核模块的代码、重建它、从内存中删除旧副本（如果存在），然后插入新版本。这可以节省时间并提高生产力</p>
<p>​    内核模块具有优势的另一个原因是它们适合动态产品配置。例如，内核模块可以设计为以不同的价格点提供不同的功能；为嵌入式产品生成最终映像的脚本可以根据客户愿意支付的价格安装一组给定的内核模块。</p>
<p>​    通过允许我们将实时代码插入（然后从）内核内存中删除，我们可以实现内核功能。这种随意插入和拔出内核功能的能力让我们意识到，Linux 内核并不是纯粹的整体式，它也是模块化的。</p>
<h4 id="干！写我们的第一个模块"><a href="#干！写我们的第一个模块" class="headerlink" title="干！写我们的第一个模块"></a>干！写我们的第一个模块</h4><p>​    P话不多说，干！</p>
<p>​    在我们确保我们的linux-header下好之后，我们就可以开始行动了：</p>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;module&#x2F;ch4$ ls
charlie.c  Makefile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<blockquote>
<p>charlie.c</p>
</blockquote>
<pre class="line-numbers language-C" data-language="C"><code class="language-C">#include &lt;linux&#x2F;module.h&gt;
#include &lt;linux&#x2F;init.h&gt;

MODULE_AUTHOR(&quot;Charlie&quot;);
MODULE_DESCRIPTION(&quot;Our first module&quot;);
MODULE_LICENSE(&quot;GPL&quot;);
MODULE_VERSION(&quot;0.1&quot;);

static int __init Charliechen_init(void)
&#123;
	pr_info(&quot;Sup!\n&quot;);
	return 0;
&#125;

static void __exit Charliechen_exit(void)
&#123;
	pr_info(&quot;Goodbye!\n&quot;);
&#125;


module_init(Charliechen_init);
module_exit(Charliechen_exit);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    方便起见，写一个Makefile。</p>
<pre class="line-numbers language-none"><code class="language-none">obj-m :&#x3D; charlie.o
kver :&#x3D; $(shell uname -r)
kdir :&#x3D; &#x2F;lib&#x2F;modules&#x2F;$(kver)&#x2F;build&#x2F;
work_dir :&#x3D; $(shell pwd)

all:
	make -C $(kdir) M&#x3D;$(work_dir)

clean:
	make -C $(kdir) M&#x3D;$(work_dir) clean<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<blockquote>
<p><code>make -C</code> 的作用是改变目录后再执行 <code>make</code> 命令。具体来说，<code>make -C &lt;directory&gt;</code> 命令会进入指定的 <code>&lt;directory&gt;</code> 目录，然后在那个目录中运行 <code>make</code>。这对于在不同目录中的不同 Makefile 之间进行编译时非常有用。</p>
</blockquote>
<pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;kernel&#x2F;module&#x2F;ch4$ make
make -C &#x2F;lib&#x2F;modules&#x2F;6.5.0-41-generic&#x2F;build&#x2F; M&#x3D;&#x2F;home&#x2F;charlie&#x2F;kernel&#x2F;module&#x2F;ch4
make[1]: Entering directory &#39;&#x2F;usr&#x2F;src&#x2F;linux-headers-6.5.0-41-generic&#39;
warning: the compiler differs from the one used to build the kernel
  The kernel was built by: x86_64-linux-gnu-gcc-12 (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0
  You are using:           gcc-12 (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0
  CC [M]  &#x2F;home&#x2F;charlie&#x2F;kernel&#x2F;module&#x2F;ch4&#x2F;charlie.o
  MODPOST &#x2F;home&#x2F;charlie&#x2F;kernel&#x2F;module&#x2F;ch4&#x2F;Module.symvers
  CC [M]  &#x2F;home&#x2F;charlie&#x2F;kernel&#x2F;module&#x2F;ch4&#x2F;charlie.mod.o
  LD [M]  &#x2F;home&#x2F;charlie&#x2F;kernel&#x2F;module&#x2F;ch4&#x2F;charlie.ko
  BTF [M] &#x2F;home&#x2F;charlie&#x2F;kernel&#x2F;module&#x2F;ch4&#x2F;charlie.ko
Skipping BTF generation for &#x2F;home&#x2F;charlie&#x2F;kernel&#x2F;module&#x2F;ch4&#x2F;charlie.ko due to unavailability of vmlinux
make[1]: Leaving directory &#39;&#x2F;usr&#x2F;src&#x2F;linux-headers-6.5.0-41-generic&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    下面我们就可以开始尝试了：</p>
<pre class="line-numbers language-none"><code class="language-none">insmod: 将模块插入内核
lsmod: 枚举模块
rmmod: 移除内核<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><img src="./image-20240705061836861.png" alt="image-20240705061836861"></p>
<h4 id="一步步看："><a href="#一步步看：" class="headerlink" title="一步步看："></a>一步步看：</h4><h5 id="模块的宏"><a href="#模块的宏" class="headerlink" title="模块的宏"></a>模块的宏</h5><p>我们有几个模块宏，形式为 MODULE_FOO();（俗称“模块内容”）。大多数都非常直观：</p>
<ul>
<li>MODULE_AUTHOR()：指定内核模块的作者</li>
<li>MODULE_DESCRIPTION()：简要描述此 LKM 的功能或目的</li>
<li>MODULE_LICENSE()：指定发布此内核模块的许可证</li>
<li>MODULE_VERSION()：指定内核模块的（本地）版本字符串</li>
</ul>
<p>在没有源代码的情况下，如何将此信息传达给最终用户（或客户）？modinfo 实用程序正是这样做的！这些宏及其信息可能看起来微不足道，但它们在项目和产品中很重要。例如，供应商依靠此信息通过对所有已安装的内核模块的 modinfo 输出使用 grep 来建立代码所运行的（开源）许可证。 （这些是基本的模块宏；接下来我们将介绍更多宏。）</p>
<h5 id="入口点和出口点"><a href="#入口点和出口点" class="headerlink" title="入口点和出口点"></a>入口点和出口点</h5><p>​    永远不要忘记，内核模块毕竟是使用内核特权运行的内核代码。它不是应用程序，因此其入口点不是我们熟悉的 main() 函数（我们非常熟悉和喜欢）。当然，这引出了一个问题：内核模块的入口点和出口点是什么？请注意，在我们简单的内核模块的底部，有以下几行：</p>
<pre class="line-numbers language-none"><code class="language-none">module_init(helloworld_lkm_init);
module_exit(helloworld_lkm_exit);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><code>module_&#123;init|exit&#125;()</code> 代码是分别指定入口点和出口点的宏。每个宏的参数都是函数指针。使用现代 C 编译器，我们只需指定函数的名称即可。因此，在我们的代码中，以下内容适用：</p>
<p>Charliechen_init() 函数是入口点。 Charliechen_exit() 函数是退出点。</p>
<p>您几乎可以将这些入口点和出口点视为内核模块的构造函数/析构函数对。从技术上讲，情况当然并非如此，因为这不是面向对象的 C++ 代码，而是纯 C。尽管如此，但也许这是一个有用的类比。</p>
<h5 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h5><p>请注意，init 和 exit 函数的签名如下：</p>
<pre class="line-numbers language-none"><code class="language-none">static int __init &lt;modulename&gt;_init(void);
static void __exit &lt;modulename&gt;_exit(void);_<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    作为良好的编码实践，我们使用函数的命名格式为 <code>&lt;modulename&gt;_&#123;init|exit&#125;()</code>，其中 <code>&lt;modulename&gt;</code> 替换为内核模块的名称。您将意识到，这种命名约定仅仅是——从技术上讲，它只是一种不必要的约定，但它是直观的，因此很有帮助（请记住，我们人类必须编写代码供人类阅读和理解，而不是机器）。显然，这两个例程都没有接收任何参数。<br>用静态限定符标记这两个函数意味着它们是这个内核模块的私有函数。这就是我们想要的。</p>
<p>​    现在让我们继续讨论内核模块的 init 函数返回值所遵循的重要约定。</p>
<h5 id="0-E-返回约定"><a href="#0-E-返回约定" class="headerlink" title="0/-E 返回约定"></a>0/-E 返回约定</h5><p>​    内核模块的 init 函数返回一个整数，即 int 类型的值；这是一个关键方面。Linux 内核已经发展出一种风格或约定，如果你愿意的话，关于从它返回值（意味着从内核空间，模块驻留和运行的地方，到用户空间进程）。<br>​    要返回一个值，LKM 框架遵循俗称的 0/-E 约定：</p>
<blockquote>
<p>成功时，返回整数值 0。<br>失败时，返回您希望将用户空间全局未初始化整数 errno 设置为的值的负数</p>
</blockquote>
<p>​    指针怎么办？答案是用Linux预定义好的ERR_PTR，这里的地址是指向非法地址的。</p>
<h5 id="init-and-exit"><a href="#init-and-exit" class="headerlink" title="__init and __exit"></a>__init and __exit</h5><p>​    一个令人烦恼的遗留问题：我们在前面的函数签名中看到的 <strong>init 和 </strong>exit 宏到底是什么？它们只是指定内存优化链接器属性。<strong>init 宏为代码定义了一个 init.text 部分。同样，任何使用 </strong>initdata 属性声明的数据都会进入 init.data 部分。这里的重点是 init 函数中的代码和数据在初始化期间只使用一次。一旦调用它，它就不会再被调用；因此，一旦调用，这些 init 部分中的所有代码和数据都会被释放（通过 free_initmem()）。__exit 宏的处理方式类似，当然，这只对内核模块有意义。一旦调用清理函数，所有内存都会被释放。如果代码是静态内核映像的一部分（或者如果模块支持被禁用），则此宏将不起作用。</p>
<h3 id="了解内核日志记录和-printk"><a href="#了解内核日志记录和-printk" class="headerlink" title="了解内核日志记录和 printk"></a>了解内核日志记录和 printk</h3><p>​    关于通过 printk 内核 API 记录内核消息，还有很多内容需要介绍。本节将深入探讨一些细节。对于像您这样的新手内核/驱动程序开发人员来说，清楚地了解这些主题非常重要。<br>​    我们在前面的“快速了解内核 printk()”部分中看到了使用内核 printk API 功能的要点（如果您愿意，可以再看一遍）。在这里，我们将进一步探讨 printk() API 的使用。让我们开始吧！</p>
<h4 id="使用内核内存环形缓冲区"><a href="#使用内核内存环形缓冲区" class="headerlink" title="使用内核内存环形缓冲区"></a>使用内核内存环形缓冲区</h4><p>​    内核日志缓冲区只是内核虚拟地址空间内的内存缓冲区，printk 输出保存（记录）在其中。更技术性地说，它是全局 __log_buf[] 变量</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; kernel&#x2F;printk&#x2F;printk.c
#define __LOG_BUF_LEN (1 &lt;&lt; CONFIG_LOG_BUF_SHIFT)
#define LOG_BUF_LEN_MAX (u32)(1 &lt;&lt; 31)
 static char __log_buf[__LOG_BUF_LEN] __aligned(LOG_ALIGN);
static char *log_buf &#x3D; __log_buf;
static u32 log_buf_len &#x3D; __LOG_BUF_LEN;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    无论内核日志缓冲区的大小如何，处理 printk API 时都会出现两个问题： 其消息被记录在易失性存储器 (RAM) 中；如果系统以任何方式崩溃或断电，我们将丢失宝贵的内核日志（通常会严重限制甚至消除我们调试内核问题的能力）。 默认情况下，日志缓冲区不是很大，通常只有 256 KB（和/或系统上每个 CPU 可能为 4 到 8 KB）；因此，很明显，大量的打印将压垮环形缓冲区，使其回绕，从而丢失信息。</p>
<h4 id="内核日志记录与systemd的journalctl"><a href="#内核日志记录与systemd的journalctl" class="headerlink" title="内核日志记录与systemd的journalctl"></a>内核日志记录与systemd的journalctl</h4><p>​    正如用户空间应用程序使用日志一样，内核也使用日志；该功能称为内核日志记录，除了资源最受限的系统外，所有系统都需要该功能。解决前面提到的将内核日志记录到小型易失性内存缓冲区的问题的一个明显方法是将每个内核 printk 写入（实际上是附加）二级存储中的文件。这正是大多数现代 Linux 发行版的设置方式。内核日志文件的位置因发行版而异：传统上，基于 Red Hat 的发行版写入 /var/log/messages 文件，而基于 Debian 的发行版写入 /var/log/syslog。</p>
<p>​    传统上，内核 printk 会挂接到用户空间系统记录器守护程序 (syslogd) 以执行文件日志记录，从而自动获得更复杂的功能的好处，例如日志轮换、压缩和归档。然而，在过去几年中，系统日志记录已完全被实用且功能强大的新系统初始化框架 systemd 所取代（它取代了旧的 SysV init 框架，或经常作为其补充）。事实上，systemd 现在甚至在嵌入式 Linux 设备上也经常使用。在 systemd 框架内，日志记录由名为 systemd-journal 的守护进程执行，journalctl 实用程序是它的用户界面。</p>
<h3 id="printk的日志属性"><a href="#printk的日志属性" class="headerlink" title="printk的日志属性"></a>printk的日志属性</h3><p>​    printk就具有一定的日志属性。一个启用了日志属性的printk是这样的：</p>
<pre class="line-numbers language-none"><code class="language-none">printk(KERN_INFO &quot;Hello, kernel!&quot;);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    KERN_INFO指示了我们的日志等级，他最终会投射到我们的日志输出，我们一般会使用dmesg和journctl等进行查看。</p>
<p>​    这里提供八个等级：</p>
<pre class="line-numbers language-none"><code class="language-none">#define KERN_SOH	&quot;\001&quot;		&#x2F;* ASCII Start Of Header *&#x2F;
#define KERN_SOH_ASCII	&#39;\001&#39;

#define KERN_EMERG	KERN_SOH &quot;0&quot;	&#x2F;* system is unusable *&#x2F;
#define KERN_ALERT	KERN_SOH &quot;1&quot;	&#x2F;* action must be taken immediately *&#x2F;
#define KERN_CRIT	KERN_SOH &quot;2&quot;	&#x2F;* critical conditions *&#x2F;
#define KERN_ERR	KERN_SOH &quot;3&quot;	&#x2F;* error conditions *&#x2F;
#define KERN_WARNING	KERN_SOH &quot;4&quot;	&#x2F;* warning conditions *&#x2F;
#define KERN_NOTICE	KERN_SOH &quot;5&quot;	&#x2F;* normal but significant condition *&#x2F;
#define KERN_INFO	KERN_SOH &quot;6&quot;	&#x2F;* informational *&#x2F;
#define KERN_DEBUG	KERN_SOH &quot;7&quot;	&#x2F;* debug-level messages *&#x2F;

#define KERN_DEFAULT	&quot;&quot;		&#x2F;* the default kernel loglevel *&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="简化的函数"><a href="#简化的函数" class="headerlink" title="简化的函数"></a>简化的函数</h4><p>​    有的时候写等级太麻烦，我们也有简化的API：<code>pr_&lt;foo&gt;</code>系列函数，</p>
<pre class="line-numbers language-none"><code class="language-none">pr_info(&quot;Hello, kernel debug world\n&quot;);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    这个是一个使用的例子。</p>
<pre class="line-numbers language-none"><code class="language-none">pr_emerg(): printk() at log level KERN_EMERG
pr_alert(: printk() at log level KERN_ALERT
pr_crit: printk() at log level KERN_CRIT
pr_err(): printk() at log level KERN_ERR
pr_warn(): printk() at log level KERN_WARNING
pr_notice(): printk() at log level KERN_NOTICE
pr_info(): printk() at log level KERN_INFO
pr_debug() or pr_devel(): printk() at log level KERN_DEBUG<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="./res1.png" alt="res1"></p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; 这个宏定义放在最上层，让编译的时候采取我们的格式定义
#define pr_fmt(fmt) &quot;%s:%s():%d: &quot; fmt, KBUILD_MODNAME, __func__, __LINE__
#include &lt;linux&#x2F;module.h&gt;
#include &lt;linux&#x2F;init.h&gt;
#include &lt;linux&#x2F;kernel.h&gt;
MODULE_AUTHOR(&quot;Charliechen&quot;);
MODULE_LICENSE(&quot;GPL&quot;);
#define PRT_STD_MSG &quot;Hello, debug_world @ log-level&quot; 
#define LEVEL_STR(LEVEL) #LEVEL

static int __init Charliechen_init(void)&#123;
    pr_emerg(PRT_STD_MSG &quot;KERN_EMERG&quot; &quot;[%d]\n&quot;, LOGLEVEL_EMERG);
    pr_alert(PRT_STD_MSG &quot;KERN_ALERT&quot; &quot;[%d]\n&quot;, LOGLEVEL_ALERT);
    pr_crit(PRT_STD_MSG &quot;KERN_CRIT&quot; &quot;[%d]\n&quot;, LOGLEVEL_CRIT);
    pr_err(PRT_STD_MSG &quot;KERN_ERR&quot; &quot;[%d]\n&quot;, LOGLEVEL_ERR);
    pr_warn(PRT_STD_MSG &quot;KERN_WARNING&quot; &quot;[%d]\n&quot;, LOGLEVEL_WARNING);
    pr_notice(PRT_STD_MSG &quot;KERN_NOTICE&quot; &quot;[%d]\n&quot;, LOGLEVEL_NOTICE);
    pr_info(PRT_STD_MSG &quot;KERN_INFO&quot; &quot;[%d]\n&quot;, LOGLEVEL_INFO);
    pr_debug(PRT_STD_MSG &quot;KERN_DEBUG&quot; &quot;[%d]\n&quot;, LOGLEVEL_DEBUG);
    pr_devel(&quot;Welp, this is special cause it debug via pr_devel [%d]\n&quot;, LOGLEVEL_DEBUG);
    return 0;
&#125;

static void __exit Charliechen_exit(void)&#123;
    pr_info(&quot;Goodbye! debug world!\n&quot;);
&#125;

module_init(Charliechen_init);
module_exit(Charliechen_exit);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    对比一下上图，你会发现我们的printk函数采纳了我们自定义的format。</p>
<p>​    值得注意的是：任何在紧急以上的日志等级都会立即显示在所有的控制台上。</p>
<h3 id="输出一般向何去？"><a href="#输出一般向何去？" class="headerlink" title="输出一般向何去？"></a>输出一般向何去？</h3><div class="table-container">
<table>
<thead>
<tr>
<th>printk函数组向。。。</th>
<th>何时</th>
<th>其他</th>
</tr>
</thead>
<tbody>
<tr>
<td>向RAM缓冲区</td>
<td>总是</td>
<td>在<code>static char __log_buf[__LOG_BUF_LEN]</code>定义，其中他是一个环状的缓冲区，可以在编译内核的时候进行一定的配置。一般的是128KB</td>
</tr>
<tr>
<td>现代日志文件</td>
<td>对于大多数系统默认</td>
<td>systemd框架，journalctl的前端，而且持久化记忆</td>
</tr>
<tr>
<td>传统日志文件</td>
<td>对于大多数系统默认</td>
<td>syslogd, klogd，dmesg前端，而且持久化记忆</td>
</tr>
<tr>
<td>控制台设备</td>
<td>在日志等级小于4下</td>
<td>在/proc/sys/kernel/printk下控制</td>
</tr>
</tbody>
</table>
</div>
<p>​    对于最后一个，我们可以按照自己的意愿修改/proc/sys/kernel/printk里的内容：</p>
<pre class="line-numbers language-none"><code class="language-none">$ cat &#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;printk
1	4	1	4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    第一个数字是 1，代表日志级别，低于该级别的信息将显示在控制台中（以及记录到内核日志缓冲区和日志文件中）。在这种情况下，我们可以得出结论，所有日志级别小于 1  的 printks 都会出现在控制台上。当然，在 root 权限下，你可以随意更改</p>
<h3 id="一些tips"><a href="#一些tips" class="headerlink" title="一些tips"></a>一些tips</h3><p>以下是一些常用的 printk 格式规范，在编写可移植代码时应牢记<br>在编写可移植代码时要注意的几个常见打印格式指定符：</p>
<ul>
<li>对于 size_t 和 ssize_t 类型定义（分别表示有符号和无符号的 整数），分别使用 %zu 和 %zd 格式指定符。</li>
<li>打印内核空间中的地址（指针）时：非常重要：为了安全起见，使用 %pK（它将只输出散列值，有助于防止信息泄漏这一严重的安全隐患 防止信息泄露，这是一个严重的安全问题）。对实际指针使用 %px，以查看实际地址（不要在生产环境中这样做！）。使用 %pa 打印物理地址（必须通过引用传递）。</li>
<li>要以十六进制字符串的形式打印原始缓冲区，请使用 %<em>ph（其中 </em> 由字符数代替；对于少于 65 个字符的缓冲区，请使用该例程；对于字符数较多的缓冲区，请使用 print_hex_dump_bytes() 例程）。还可以使用其他方法（参见后面的内核文档链接）。</li>
<li>要打印 IPv4 地址，请使用 %pI4；要打印 IPv6 地址，请使用 %pI6（还有一些变体）。<br>关于 printk 格式说明的详尽列表，以及在什么情况下应使用什么格式（并附有示例！），是内核官方文档的一部分：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/printk-formats.txt。我建议您浏览一下！">https://www.kernel.org/doc/Documentation/printk-formats.txt。我建议您浏览一下！</a></li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;
How to get printk format specifiers right
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

:Author: Randy Dunlap &lt;rdunlap@infradead.org&gt;
:Author: Andrew Murray &lt;amurray@mpc-data.co.uk&gt;

Integer types
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	If variable is of Type,		use printk format specifier:
	------------------------------------------------------------
		int			%d or %x
		unsigned int		%u or %x
		long			%ld or %lx
		unsigned long		%lu or %lx
		long long		%lld or %llx
		unsigned long long	%llu or %llx
		size_t			%zu or %zx
		ssize_t			%zd or %zx
		s32			%d or %x
		u32			%u or %x
		s64			%lld or %llx
		u64			%llu or %llx

If &lt;type&gt; is dependent on a config option for its size (e.g., &#96;&#96;sector_t&#96;&#96;,
&#96;&#96;blkcnt_t&#96;&#96;) or is architecture-dependent for its size (e.g., &#96;&#96;tcflag_t&#96;&#96;),
use a format specifier of its largest possible type and explicitly cast to it.

Example::

	printk(&quot;test: sector number&#x2F;total blocks: %llu&#x2F;%llu\n&quot;,
		(unsigned long long)sector, (unsigned long long)blockcount);

Reminder: &#96;&#96;sizeof()&#96;&#96; result is of type &#96;&#96;size_t&#96;&#96;.

The kernel&#39;s printf does not support &#96;&#96;%n&#96;&#96;. For obvious reasons, floating
point formats (&#96;&#96;%e, %f, %g, %a&#96;&#96;) are also not recognized. Use of any
unsupported specifier or length qualifier results in a WARN and early
return from vsnprintf.

Raw pointer value SHOULD be printed with %p. The kernel supports
the following extended format specifiers for pointer types:

Pointer Types
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

Pointers printed without a specifier extension (i.e unadorned %p) are
hashed to give a unique identifier without leaking kernel addresses to user
space. On 64 bit machines the first 32 bits are zeroed. If you _really_
want the address see %px below.

::

	%p	abcdef12 or 00000000abcdef12

Symbols&#x2F;Function Pointers
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pF	versatile_init+0x0&#x2F;0x110
	%pf	versatile_init
	%pS	versatile_init+0x0&#x2F;0x110
	%pSR	versatile_init+0x9&#x2F;0x110
		(with __builtin_extract_return_addr() translation)
	%ps	versatile_init
	%pB	prev_fn_of_versatile_init+0x88&#x2F;0x88

The &#96;&#96;F&#96;&#96; and &#96;&#96;f&#96;&#96; specifiers are for printing function pointers,
for example, f-&gt;func, &amp;gettimeofday. They have the same result as
&#96;&#96;S&#96;&#96; and &#96;&#96;s&#96;&#96; specifiers. But they do an extra conversion on
ia64, ppc64 and parisc64 architectures where the function pointers
are actually function descriptors.

The &#96;&#96;S&#96;&#96; and &#96;&#96;s&#96;&#96; specifiers can be used for printing symbols
from direct addresses, for example, __builtin_return_address(0),
(void *)regs-&gt;ip. They result in the symbol name with (&#96;&#96;S&#96;&#96;) or
without (&#96;&#96;s&#96;&#96;) offsets. If KALLSYMS are disabled then the symbol
address is printed instead.

The &#96;&#96;B&#96;&#96; specifier results in the symbol name with offsets and should be
used when printing stack backtraces. The specifier takes into
consideration the effect of compiler optimisations which may occur
when tail-call&#96;&#96;s are used and marked with the noreturn GCC attribute.

Examples::

	printk(&quot;Going to call: %pF\n&quot;, gettimeofday);
	printk(&quot;Going to call: %pF\n&quot;, p-&gt;func);
	printk(&quot;%s: called from %pS\n&quot;, __func__, (void *)_RET_IP_);
	printk(&quot;%s: called from %pS\n&quot;, __func__,
				(void *)__builtin_return_address(0));
	printk(&quot;Faulted at %pS\n&quot;, (void *)regs-&gt;ip);
	printk(&quot; %s%pB\n&quot;, (reliable ? &quot;&quot; : &quot;? &quot;), (void *)*stack);

Kernel Pointers
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pK	01234567 or 0123456789abcdef

For printing kernel pointers which should be hidden from unprivileged
users. The behaviour of &#96;&#96;%pK&#96;&#96; depends on the &#96;&#96;kptr_restrict sysctl&#96;&#96; - see
Documentation&#x2F;sysctl&#x2F;kernel.txt for more details.

Unmodified Addresses
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%px	01234567 or 0123456789abcdef

For printing pointers when you _really_ want to print the address. Please
consider whether or not you are leaking sensitive information about the
Kernel layout in memory before printing pointers with %px. %px is
functionally equivalent to %lx. %px is preferred to %lx because it is more
uniquely grep&#39;able. If, in the future, we need to modify the way the Kernel
handles printing pointers it will be nice to be able to find the call
sites.

Struct Resources
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pr	[mem 0x60000000-0x6fffffff flags 0x2200] or
		[mem 0x0000000060000000-0x000000006fffffff flags 0x2200]
	%pR	[mem 0x60000000-0x6fffffff pref] or
		[mem 0x0000000060000000-0x000000006fffffff pref]

For printing struct resources. The &#96;&#96;R&#96;&#96; and &#96;&#96;r&#96;&#96; specifiers result in a
printed resource with (&#96;&#96;R&#96;&#96;) or without (&#96;&#96;r&#96;&#96;) a decoded flags member.
Passed by reference.

Physical addresses types &#96;&#96;phys_addr_t&#96;&#96;
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pa[p]	0x01234567 or 0x0123456789abcdef

For printing a &#96;&#96;phys_addr_t&#96;&#96; type (and its derivatives, such as
&#96;&#96;resource_size_t&#96;&#96;) which can vary based on build options, regardless of
the width of the CPU data path. Passed by reference.

DMA addresses types &#96;&#96;dma_addr_t&#96;&#96;
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pad	0x01234567 or 0x0123456789abcdef

For printing a &#96;&#96;dma_addr_t&#96;&#96; type which can vary based on build options,
regardless of the width of the CPU data path. Passed by reference.

Raw buffer as an escaped string
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%*pE[achnops]

For printing raw buffer as an escaped string. For the following buffer::

		1b 62 20 5c 43 07 22 90 0d 5d

few examples show how the conversion would be done (the result string
without surrounding quotes)::

		%*pE		&quot;\eb \C\a&quot;\220\r]&quot;
		%*pEhp		&quot;\x1bb \C\x07&quot;\x90\x0d]&quot;
		%*pEa		&quot;\e\142\040\\\103\a\042\220\r\135&quot;

The conversion rules are applied according to an optional combination
of flags (see :c:func:&#96;string_escape_mem&#96; kernel documentation for the
details):

	- &#96;&#96;a&#96;&#96; - ESCAPE_ANY
	- &#96;&#96;c&#96;&#96; - ESCAPE_SPECIAL
	- &#96;&#96;h&#96;&#96; - ESCAPE_HEX
	- &#96;&#96;n&#96;&#96; - ESCAPE_NULL
	- &#96;&#96;o&#96;&#96; - ESCAPE_OCTAL
	- &#96;&#96;p&#96;&#96; - ESCAPE_NP
	- &#96;&#96;s&#96;&#96; - ESCAPE_SPACE

By default ESCAPE_ANY_NP is used.

ESCAPE_ANY_NP is the sane choice for many cases, in particularly for
printing SSIDs.

If field width is omitted the 1 byte only will be escaped.

Raw buffer as a hex string
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%*ph	00 01 02  ...  3f
	%*phC	00:01:02: ... :3f
	%*phD	00-01-02- ... -3f
	%*phN	000102 ... 3f

For printing a small buffers (up to 64 bytes long) as a hex string with
certain separator. For the larger buffers consider to use
:c:func:&#96;print_hex_dump&#96;.

MAC&#x2F;FDDI addresses
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pM	00:01:02:03:04:05
	%pMR	05:04:03:02:01:00
	%pMF	00-01-02-03-04-05
	%pm	000102030405
	%pmR	050403020100

For printing 6-byte MAC&#x2F;FDDI addresses in hex notation. The &#96;&#96;M&#96;&#96; and &#96;&#96;m&#96;&#96;
specifiers result in a printed address with (&#96;&#96;M&#96;&#96;) or without (&#96;&#96;m&#96;&#96;) byte
separators. The default byte separator is the colon (&#96;&#96;:&#96;&#96;).

Where FDDI addresses are concerned the &#96;&#96;F&#96;&#96; specifier can be used after
the &#96;&#96;M&#96;&#96; specifier to use dash (&#96;&#96;-&#96;&#96;) separators instead of the default
separator.

For Bluetooth addresses the &#96;&#96;R&#96;&#96; specifier shall be used after the &#96;&#96;M&#96;&#96;
specifier to use reversed byte order suitable for visual interpretation
of Bluetooth addresses which are in the little endian order.

Passed by reference.

IPv4 addresses
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pI4	1.2.3.4
	%pi4	001.002.003.004
	%p[Ii]4[hnbl]

For printing IPv4 dot-separated decimal addresses. The &#96;&#96;I4&#96;&#96; and &#96;&#96;i4&#96;&#96;
specifiers result in a printed address with (&#96;&#96;i4&#96;&#96;) or without (&#96;&#96;I4&#96;&#96;)
leading zeros.

The additional &#96;&#96;h&#96;&#96;, &#96;&#96;n&#96;&#96;, &#96;&#96;b&#96;&#96;, and &#96;&#96;l&#96;&#96; specifiers are used to specify
host, network, big or little endian order addresses respectively. Where
no specifier is provided the default network&#x2F;big endian order is used.

Passed by reference.

IPv6 addresses
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pI6	0001:0002:0003:0004:0005:0006:0007:0008
	%pi6	00010002000300040005000600070008
	%pI6c	1:2:3:4:5:6:7:8

For printing IPv6 network-order 16-bit hex addresses. The &#96;&#96;I6&#96;&#96; and &#96;&#96;i6&#96;&#96;
specifiers result in a printed address with (&#96;&#96;I6&#96;&#96;) or without (&#96;&#96;i6&#96;&#96;)
colon-separators. Leading zeros are always used.

The additional &#96;&#96;c&#96;&#96; specifier can be used with the &#96;&#96;I&#96;&#96; specifier to
print a compressed IPv6 address as described by
http:&#x2F;&#x2F;tools.ietf.org&#x2F;html&#x2F;rfc5952

Passed by reference.

IPv4&#x2F;IPv6 addresses (generic, with port, flowinfo, scope)
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pIS	1.2.3.4		or 0001:0002:0003:0004:0005:0006:0007:0008
	%piS	001.002.003.004	or 00010002000300040005000600070008
	%pISc	1.2.3.4		or 1:2:3:4:5:6:7:8
	%pISpc	1.2.3.4:12345	or [1:2:3:4:5:6:7:8]:12345
	%p[Ii]S[pfschnbl]

For printing an IP address without the need to distinguish whether it&#96;&#96;s
of type AF_INET or AF_INET6, a pointer to a valid &#96;&#96;struct sockaddr&#96;&#96;,
specified through &#96;&#96;IS&#96;&#96; or &#96;&#96;iS&#96;&#96;, can be passed to this format specifier.

The additional &#96;&#96;p&#96;&#96;, &#96;&#96;f&#96;&#96;, and &#96;&#96;s&#96;&#96; specifiers are used to specify port
(IPv4, IPv6), flowinfo (IPv6) and scope (IPv6). Ports have a &#96;&#96;:&#96;&#96; prefix,
flowinfo a &#96;&#96;&#x2F;&#96;&#96; and scope a &#96;&#96;%&#96;&#96;, each followed by the actual value.

In case of an IPv6 address the compressed IPv6 address as described by
http:&#x2F;&#x2F;tools.ietf.org&#x2F;html&#x2F;rfc5952 is being used if the additional
specifier &#96;&#96;c&#96;&#96; is given. The IPv6 address is surrounded by &#96;&#96;[&#96;&#96;, &#96;&#96;]&#96;&#96; in
case of additional specifiers &#96;&#96;p&#96;&#96;, &#96;&#96;f&#96;&#96; or &#96;&#96;s&#96;&#96; as suggested by
https:&#x2F;&#x2F;tools.ietf.org&#x2F;html&#x2F;draft-ietf-6man-text-addr-representation-07

In case of IPv4 addresses, the additional &#96;&#96;h&#96;&#96;, &#96;&#96;n&#96;&#96;, &#96;&#96;b&#96;&#96;, and &#96;&#96;l&#96;&#96;
specifiers can be used as well and are ignored in case of an IPv6
address.

Passed by reference.

Further examples::

	%pISfc		1.2.3.4		or [1:2:3:4:5:6:7:8]&#x2F;123456789
	%pISsc		1.2.3.4		or [1:2:3:4:5:6:7:8]%1234567890
	%pISpfc		1.2.3.4:12345	or [1:2:3:4:5:6:7:8]:12345&#x2F;123456789

UUID&#x2F;GUID addresses
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pUb	00010203-0405-0607-0809-0a0b0c0d0e0f
	%pUB	00010203-0405-0607-0809-0A0B0C0D0E0F
	%pUl	03020100-0504-0706-0809-0a0b0c0e0e0f
	%pUL	03020100-0504-0706-0809-0A0B0C0E0E0F

For printing 16-byte UUID&#x2F;GUIDs addresses. The additional &#39;l&#39;, &#39;L&#39;,
&#39;b&#39; and &#39;B&#39; specifiers are used to specify a little endian order in
lower (&#39;l&#39;) or upper case (&#39;L&#39;) hex characters - and big endian order
in lower (&#39;b&#39;) or upper case (&#39;B&#39;) hex characters.

Where no additional specifiers are used the default big endian
order with lower case hex characters will be printed.

Passed by reference.

dentry names
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pd&#123;,2,3,4&#125;
	%pD&#123;,2,3,4&#125;

For printing dentry name; if we race with :c:func:&#96;d_move&#96;, the name might be
a mix of old and new ones, but it won&#39;t oops.  &#96;&#96;%pd&#96;&#96; dentry is a safer
equivalent of &#96;&#96;%s&#96;&#96; &#96;&#96;dentry-&gt;d_name.name&#96;&#96; we used to use, &#96;&#96;%pd&lt;n&gt;&#96;&#96; prints
&#96;&#96;n&#96;&#96; last components.  &#96;&#96;%pD&#96;&#96; does the same thing for struct file.

Passed by reference.

block_device names
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pg	sda, sda1 or loop0p1

For printing name of block_device pointers.

struct va_format
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pV

For printing struct va_format structures. These contain a format string
and va_list as follows::

	struct va_format &#123;
		const char *fmt;
		va_list *va;
	&#125;;

Implements a &quot;recursive vsnprintf&quot;.

Do not use this feature without some mechanism to verify the
correctness of the format string and va_list arguments.

Passed by reference.

kobjects
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pO

	Base specifier for kobject based structs. Must be followed with
	character for specific type of kobject as listed below:

	Device tree nodes:

	%pOF[fnpPcCF]

	For printing device tree nodes. The optional arguments are:
	    f device node full_name
	    n device node name
	    p device node phandle
	    P device node path spec (name + @unit)
	    F device node flags
	    c major compatible string
	    C full compatible string
	Without any arguments prints full_name (same as %pOFf)
	The separator when using multiple arguments is &#39;:&#39;

	Examples:

	%pOF	&#x2F;foo&#x2F;bar@0			- Node full name
	%pOFf	&#x2F;foo&#x2F;bar@0			- Same as above
	%pOFfp	&#x2F;foo&#x2F;bar@0:10			- Node full name + phandle
	%pOFfcF	&#x2F;foo&#x2F;bar@0:foo,device:--P-	- Node full name +
	                                          major compatible string +
						  node flags
							D - dynamic
							d - detached
							P - Populated
							B - Populated bus

	Passed by reference.


struct clk
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pC	pll1
	%pCn	pll1
	%pCr	1560000000

For printing struct clk structures. &#96;&#96;%pC&#96;&#96; and &#96;&#96;%pCn&#96;&#96; print the name
(Common Clock Framework) or address (legacy clock framework) of the
structure; &#96;&#96;%pCr&#96;&#96; prints the current clock rate.

Passed by reference.

bitmap and its derivatives such as cpumask and nodemask
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%*pb	0779
	%*pbl	0,3-6,8-10

For printing bitmap and its derivatives such as cpumask and nodemask,
&#96;&#96;%*pb&#96;&#96; output the bitmap with field width as the number of bits and &#96;&#96;%*pbl&#96;&#96;
output the bitmap as range list with field width as the number of bits.

Passed by reference.

Flags bitfields such as page flags, gfp_flags
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pGp	referenced|uptodate|lru|active|private
	%pGg	GFP_USER|GFP_DMA32|GFP_NOWARN
	%pGv	read|exec|mayread|maywrite|mayexec|denywrite

For printing flags bitfields as a collection of symbolic constants that
would construct the value. The type of flags is given by the third
character. Currently supported are [p]age flags, [v]ma_flags (both
expect &#96;&#96;unsigned long *&#96;&#96;) and [g]fp_flags (expects &#96;&#96;gfp_t *&#96;&#96;). The flag
names and print order depends on the particular	type.

Note that this format should not be used directly in :c:func:&#96;TP_printk()&#96; part
of a tracepoint. Instead, use the &#96;&#96;show_*_flags()&#96;&#96; functions from
&lt;trace&#x2F;events&#x2F;mmflags.h&gt;.

Passed by reference.

Network device features
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;

::

	%pNF	0x000000000000c000

For printing netdev_features_t.

Passed by reference.

If you add other &#96;&#96;%p&#96;&#96; extensions, please extend lib&#x2F;test_printf.c with
one or more test cases, if at all feasible.


Thank you for your cooperation and attention.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="向内核日志写入调试信息"><a href="#向内核日志写入调试信息" class="headerlink" title="向内核日志写入调试信息"></a>向内核日志写入调试信息</h3><p>​    再看看这两行代码：</p>
<pre class="line-numbers language-none"><code class="language-none">pr_debug(PRT_STD_MSG &quot;KERN_DEBUG&quot; &quot;[%d]\n&quot;, LOGLEVEL_DEBUG);
pr_devel(&quot;Welp, this is special cause it debug via pr_devel [%d]\n&quot;, LOGLEVEL_DEBUG);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    你可以留意到：嘿！为什么我的debug没有输出信息呢？答案是我们没有预定义一个debug符号，凡是没有预定义之，日志系统会选择保持它高雅的沉默（大嘘）</p>
<p>​    对于模块的开发者，需要避免使用pr_devel，对于生产环境而言他总不可见！</p>
<p>​    我们下面就来解决解决这两行的输出问题，为此，我们只需要预定义好符号</p>
<pre class="line-numbers language-none"><code class="language-none">obj-m:&#x3D; charlie.o
pwd:&#x3D; $(shell pwd)
ker-ver:&#x3D; $(shell uname -r)
KDIR:&#x3D; &#x2F;lib&#x2F;modules&#x2F;$(ker-ver)&#x2F;build
# 这里增加的是调试符号的信息
ccflags-y	+&#x3D; -DDEBUG -g -ggdb -gdwarf-4 -Og \
				-Wall -fno-omit-frame-pointer -fvar-tracking-assignments

all:
	make -C $(KDIR) M&#x3D;$(pwd) modules

clean:
	rm -rf *.o .* .cmd *.ko *.mod.c .tmp_versions *.order *.symvers *.mod<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">[Charliechen@ArchLinux module]$ sudo insmod charlie.ko &amp;&amp; lsmod | grep charlie 
[sudo] password for Charliechen: 
charlie                16384  0
[Charliechen@ArchLinux module]$ sudo dmesg | tail -8
[ 4697.043680] charlie:Charliechen_init():12: Hello, debug_world @ log-levelKERN_ALERT[1]
[ 4697.043682] charlie:Charliechen_init():13: Hello, debug_world @ log-levelKERN_CRIT[2]
[ 4697.043684] charlie:Charliechen_init():14: Hello, debug_world @ log-levelKERN_ERR[3]
[ 4697.043685] charlie:Charliechen_init():15: Hello, debug_world @ log-levelKERN_WARNING[4]
[ 4697.043687] charlie:Charliechen_init():16: Hello, debug_world @ log-levelKERN_NOTICE[5]
[ 4697.043688] charlie:Charliechen_init():17: Hello, debug_world @ log-levelKERN_INFO[6]
[ 4697.043690] charlie:Charliechen_init():18: Hello, debug_world @ log-levelKERN_DEBUG[7]
[ 4697.043692] charlie:Charliechen_init():19: Welp, this is special cause it debug via pr_devel [7]
[Charliechen@ArchLinux module]$ <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    这一次看到了！</p>
<blockquote>
<p><strong>为调试或生产构建内核模块</strong><br>内核模块的编译方式在很大程度上受 DEBUG_CFLAGS 变量值的影响。该变量主要在内核的顶级 Makefile 中设置。在这里，它的值取决于内核配置 CONFIG_DEBUG_INFO。当它处于开启状态时（意味着调试内核），各种调试标志就会进入 DEBUG_CFLAGS，因此你的内核模块就会使用它们来编译。实际上，我在这里想强调的是，内核模块的 Makefile 中是否包含 -DDEBUG 字符串（就像我们在这里所做的）并不会对内核模块的编译方式产生太大影响。实际上，当你通过调试内核启动并编译内核模块时，它们会自动打开符号信息和各种内核调试选项。举个例子，当我在调试内核上创建这个内核模块时，printk_loglevels.ko 文件的大小是 221 KB，而在生产内核上创建时，文件大小降到了 8 KB 以下！(缺乏调试符号和信息、KASAN 仪器等因素造成了这一重大差异）。</p>
<blockquote>
<p>快速提示：使用 make V=1 来实际查看传递给编译器的所有选项会很有启发！</p>
</blockquote>
<p>此外，非常有用的一点是，你可以利用 readelf(1) 来确定嵌入二进制可执行和链接格式 (ELF) 文件中的 DWARF 格式调试信息。这对于准确找出二进制可执行文件或内核模块是用哪个编译器标志构建的特别有用。你可以这样做<br><code>readelf --debug-dump &lt;module_dbg.ko&gt; | grep producer</code><br>请注意，这种方法通常只在启用调试信息时有效；此外，在使用不同的目标架构（例如 ARM）时、 您需要运行该工具链的版本：${CROSS_COMPILE}readelf。<br>请参阅 “更多阅读 “部分，查看有关 GNU 调试器 (GDB) 的一系列文章的链接，这些文章详细描述了这一点（以及更多内容）。系列文章的第二部分）。</p>
</blockquote>
<p>​    在处理项目或产品时，您可能需要生成一些调试 printk。只要定义了 DEBUG 符号，pr_debug() 宏就能完成工作。但请想一想：要查询调试打印，你需要反复运行 dmesg。下面是一些在这种情况下可以做的事情的提示：</p>
<ol>
<li><p>使用 sudo dmesg -C 清除内核日志缓冲区（在 RAM 中）。或者，sudo dmesg -c 会先打印内容，然后清除环形缓冲区。这样，过期信息就不会堵塞系统，运行 dmesg 时也只会看到最新的信息。</p>
</li>
<li><p>使用 journalctl -f 对内核日志进行*监视（类似于在文件上使用 tail -f 的方式）。试试看！</p>
</li>
<li><p>**将控制台日志级别设置为 8，这样就能确保所有打印任务（日志级别 0 至 7）都显示在控制台设备上：</p>
</li>
</ol>
<pre class="line-numbers language-none"><code class="language-none">sudo sh -c &quot;echo\&quot;8 4 1 7\&quot; &gt; &#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;printk &quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    调试内核时，我经常在启动脚本中这样做。例如，在我的 Raspberry Pi 上，我的启动脚本包含以下一行：[ $(id -u) -eq 0 ] &amp;&amp; echo “8 4 1 7” &gt; /proc/sys/kernel/printk 这样，当以 root 身份运行时，这一行就会生效，所有 printk 实例都会直接显示在 minicom(1)（或其他）控制台上，就像 printf 输出一样。</p>
<h3 id="限制打印速度"><a href="#限制打印速度" class="headerlink" title="限制打印速度"></a><strong>限制打印速度</strong></h3><p>​    让我们假设一个合理的场景：你正在为某个芯片组或外围设备编写设备驱动程序… 通常情况下，特别是在开发过程中，有时为了在生产中调试，您当然会在驱动程序代码中穿插现在已经很熟悉的 dev_dbg()（或类似）宏。这种方法效果很好，直到包含调试打印的代码路径（非常）频繁地运行。会发生什么情况呢？很简单：</p>
<ul>
<li><p>内核环形（循环）缓冲区并不大（通常在 64 KB 到 256KB 之间，可在内核构建时配置）。一旦满了，它就会缠绕在一起。这可能会导致宝贵的调试打印丢失。</p>
</li>
<li><p>在大量代码路径（例如中断处理程序例程和定时器内）中进行调试（或其他）打印，会大大降低运行速度（尤其是在通过串行线路进行打印的嵌入式系统上），甚至会导致<em>livelock</em>情况（一种由于处理器忙于日志记录工作（控制台输出、帧缓冲区滚动、日志文件追加等）而导致系统反应迟钝的情况）。</p>
</li>
<li><p>同样的调试（或其他）打印信息重复出现无数次（例如，循环中的警告或调试信息）对任何人都没有帮助。</p>
</li>
<li><p>此外，要知道不仅仅是 printk（和类似的）API 会导致日志记录问题和故障；在大容量代码路径上使用 kprobes 或任何类型的事件跟踪也会导致同样的问题（我们将在下一章介绍 kprobes，在后一章介绍跟踪）：</p>
</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;dev&#x2F;kmsg buffer overrun, some messages lost.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="动态调试"><a href="#动态调试" class="headerlink" title="动态调试"></a>动态调试</h3><p>​    有的时候，我们正在生产环境，是不允许重新卸下服务部署调试模式的，所以现在我们尝试进行动态的调试。</p>
<h4 id="方法一：内插调试变量"><a href="#方法一：内插调试变量" class="headerlink" title="方法一：内插调试变量"></a>方法一：内插调试变量</h4><p>先说说module_param：主要区别就是用户可否在系统启动或模块装载时为参数指定相应值，在驱动程序里，参数的用法如同全局变量。</p>
<p>如果我们不使用module_param：如只定一个全局变量:</p>
<pre class="line-numbers language-none"><code class="language-none">#define MY_MAJOR 0x09
static int global_val_test &#x3D; MY_MAJOR;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>那么编译模块后,insmod加载模块时不能传参数进去,如:</p>
<pre class="line-numbers language-none"><code class="language-none"># insmod first_hello.ko global_val_test&#x3D;5
insmod: ERROR: could not insert module first_hello.ko: Invalid parameters<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>同时,insmod模块后,对应module目录下的对应模块下不会生成parameter子目录,更不会生成参数文件.</p>
<p>使用module_param后,参考如下:</p>
<pre class="line-numbers language-none"><code class="language-none">#define MY_MAJOR 0x09
static int global_val_test &#x3D; MY_MAJOR;
module_param(global_val_test, int, 0644);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>再编译模块后,再insmod加载模块时就可以传参数进去了,如:</p>
<pre class="line-numbers language-none"><code class="language-none">[root@bogon hello_world]# insmod first_hello.ko global_val_test&#x3D;5
[root@bogon hello_world]# tail &#x2F;var&#x2F;log&#x2F;messages
May 26 14:20:08 localhost kernel: [63460.994397] global_val_test &#x3D; 5
May 26 14:20:08 localhost kernel: [63460.994409] hello world enter
May 26 14:20:08 localhost kernel: global_val_test &#x3D; 5
May 26 14:20:08 localhost kernel: hello world enter<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>同时,在模块目录下会生成parameter目录及参数文件,如下:</p>
<p>[root@bogon hello_world]# cat /sys/module/first_hello/<br>coresize     holders/     initsize     initstate    notes/       parameters/  refcnt       rhelversion  sections/    srcversion   taint        uevent       version<br>[root@bogon hello_world]# ls -alt /sys/module/first_hello/parameters/<br>total 0<br>-rw-r—r— 1 root root 16384 May 26 14:54 global_val_test</p>
<ol>
<li>module_param定义:<br>函数原型:</li>
</ol>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;**

module_param - typesafe helper for a module&#x2F;cmdline parameter

@name: the variable to alter, and exposed parameter name.

@type: the type of the parameter

@perm: visibility in sysfs.
*

@name becomes the module parameter, or (prefixed by KBUILD_MODNAME and a

&quot;.&quot;) the kernel commandline parameter.  Note that - is changed to _, so

the user can use &quot;foo-bar&#x3D;1&quot; even for variable &quot;foo_bar&quot;.
*

@perm is 0 if the the variable is not to appear in sysfs, or 0444

for world-readable, 0644 for root-writable, etc.  Note that if it

is writable, you may need to use kernel_param_lock() around

accesses (esp. charp, which can be kfreed when it changes).
*

The @type is simply pasted to refer to a param_ops_##type and a

param_check_##type: for convenience many standard types are provided but

you can create your own by defining those variables.
*

Standard types are:

byte, short, ushort, int, uint, long, ulong

charp: a character pointer

bool: a bool, values 0&#x2F;1, y&#x2F;n, Y&#x2F;N.

invbool: the above, only sense-reversed (N &#x3D; true).
*&#x2F;
#define module_param(name, type, perm)				\
module_param_named(name, name, type, perm)
&#x2F;**

module_param_named - typesafe helper for a renamed module&#x2F;cmdline parameter

@name: a valid C identifier which is the parameter name.

@value: the actual lvalue to alter.

@type: the type of the parameter

@perm: visibility in sysfs.
*

Usually it&#39;s a good idea to have variable names and user-exposed names the

same, but that&#39;s harder if the variable must be non-static or is inside a

structure.  This allows exposure under a different name.
*&#x2F;
#define module_param_named(name, value, type, perm)			   \
param_check_##type(name, &amp;(value));				   \
module_param_cb(name, &amp;param_ops_##type, &amp;value, perm);		   \
__MODULE_PARM_TYPE(name, #type)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>name既是用户看到的参数名，又是模块内接受参数的变量； </li>
<li><p>type指定参数类型.</p>
</li>
<li><p>perm指定了在sysfs中相应文件的访问权限。访问权限与linux文件爱你访问权限相同的方式管理，如0644，或使用stat.h中的宏如S_IRUGO表示。</p>
</li>
<li><p>0表示完全关闭在sysfs中相对应的项。</p>
</li>
</ul>
<p>​    这种一般方法确实可行，但缺点也很明显，尤其是与内核的动态调试工具相比：</p>
<ul>
<li><p>性能—你将需要某种条件语句（if、开关等）来检查是否每次都应发出调试打印。如果使用多级冗余，则需要进行更多检查。</p>
</li>
<li><p>使用内核的动态调试框架（将在下文中介绍），你将获得几个优势：</p>
</li>
</ul>
<p>​    调试信息的格式化和有用信息的前缀是功能集的一部分，学习曲线很平缓。</p>
<p>​    性能保持较高水平，在调试关闭（通常是生产中的默认设置）时几乎没有开销。这是通过内核采用的复杂动态代码修补技术实现的（ftrace 也是如此）。</p>
<p>​    它始终是主线内核的一部分（从很早以前的 2.6.30 内核开始），而不需要自制的解决方案，这些解决方案可能得到维护，也可能无法使用或运行。</p>
<p>​    因此，在本节的剩余部分，我们将重点学习如何使用和利用内核强大的<strong>动态调试</strong>框架，它从 2.6.30 内核开始就可用了。请继续阅读！</p>
<p>​    启用内核配置选项 CONFIG_DYNAMIC_DEBUG（动态调试）后，<strong>可以</strong>动态打开或关闭编译在内核映像和内核模块中的调试打印。具体做法是让内核始终编译所有 pr_debug() 和 dev_dbg() 调用。现在，真正强大的是，你不仅可以启用或禁用这些调试打印，还可以在不同层次的范围内启用或禁用：在给定源文件、内核模块、函数甚至行号的范围内。如果担心这个问题（也许是在严格受限的嵌入式 Linux 上），你可以设置内核配置 CONFIG_DYNAMIC_DEBUG_CORE。这将启用对动态 printks 的核心支持，但它只对编译时定义了 DYNAMIC_DEBUG_MODULE 符号的内核模块有效。因此，我们的模块 Makefile 总是定义了它。您可以将其注释掉…. 这是模块 Makefile 中的相关行：</p>
<pre class="line-numbers language-none"><code class="language-none">ccflags-y +&#x3D; -DDYNAMIC_DEBUG_MODULE<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    这样，所有动态调试的框架下的API都可以发挥作用了！</p>
<h3 id="指定打印调试信息的内容和方式"><a href="#指定打印调试信息的内容和方式" class="headerlink" title="指定打印调试信息的内容和方式"></a><strong>指定打印调试信息的内容和方式</strong></h3><p>​    与许多设施一样，对内核动态调试框架的控制—决定启用哪些调试信息以及在信息前添加哪些无关信息—是通过<strong>控制文件</strong>决定的。控制文件在哪里？这要看情况。如果在内核配置中启用了 debugfs 伪文件系统（通常是这样，CONFIG_DEBUG_FS=y），并且内核配置了 CONFIG_DEBUG_FS_ALLOW_ALL=y 和 CONFIG_DEBUG_FS_DISALLOW_MOUNT=n（通常是调试内核的情况），那么控制文件就在这里：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;sys&#x2F;kernel&#x2F;debug&#x2F;dynamic_debug&#x2F;control<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>但在许多生产环境中，出于安全考虑，debugfs 文件系统是存在的（功能性的），但通过 CONFIG_DEBUG_FS_DISALLOW_MOUNT=y 是不可见的（无法挂载）。</p>
<p>在这种情况下，debugfs API 可以正常工作，但文件系统没有被挂载（实际上，它是隐形的）。另外，也可以通过将内核配置 CONFIG_DEBUG_FS_ALLOW_NONE 设为 “y “来完全禁用 debugfs。在上述任何一种情况下，都应在伪 proc 文件系统（procfs）下使用一个相同但备用的动态调试控制文件：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;proc&#x2F;dynamic_debug&#x2F;control<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    与其他伪文件系统一样，debugfs 或 procfs 下的 <em>control</em> 文件也是一个伪文件；它只存在于 RAM 中。它由内核代码填充和操作。读取它的内容可以获得内核中所有调试 printk（和/或 print_hex_dump_*()）调用点的完整列表。因此，它的输出通常很大（在这里，我们使用的是自定义调试内核，因此可以使用 debugfs 位置作为控制文件）。</p>
<h3 id="在启动和模块初始化时激活调试打印"><a href="#在启动和模块初始化时激活调试打印" class="headerlink" title="在启动和模块初始化时激活调试打印"></a><strong>在启动和模块初始化时激活调试打印</strong></h3><p>必须认识到，内核初始化（启动）代码路径或内核模块初始化代码中的任何调试打印都不会自动启用*。</p>
<p>要启用它们，请执行以下操作：</p>
<ul>
<li><p>对于核心内核代码和任何内置内核模块，即在启动过程中激活调试打印，通过内核命令行参数 dyndbg=”QUERY “或 module.dyndbg=”QUERY”，其中 QUERY 是动态调试语法（如前所述）。例如，dyndng=”module myfoo<em> +pmft “将激活名为 myfoo</em> 的内核模块内的所有调试打印，显示方式由标志说明符 pmft 设置。</p>
</li>
<li><p>要在内核模块初始化时激活调试打印，即调用 modprobe myfoo 时（可能是由 systemd 调用），有几种方法，通过传递模块参数（举例说明）：</p>
</li>
</ul>
<p>通过 /etc/modprobe.d/*.conf（将其放入 /etc/modprobe.d/myfoo.conf 文件）： options myfoo dyndbg=+pmft</p>
<p>通过内核命令行： myfoo.dyndbg=”file myfoobar.c +pmf; func goforit +mpt”</p>
<p>通过 modprobe 本身的参数：modprobe myfoo dyndbg===pmft（这里的 = 而不是 + 会覆盖之前的任何设置！）有趣的是：dyndbg 是一个始终可用的内核模块参数，尽管你看不到它（甚至在 /sys/module/\<modname>/parameters）。你可以通过grepping动态调试控制文件或/proc/cmdline看到它（顺便提一下，关于向内核模块传递参数和自动加载内核模块的细节，我在早先的<em>Linux内核编程</em>一书中已有详述）。</p>
<p>关于动态调试的官方内核文档确实非常完整，请务必查看：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/dynamic-debug-howto.html#dynamic-debug。">https://www.kernel.org/doc/html/latest/admin-guide/dynamic-debug-howto.html#dynamic-debug。</a></p>
<pre class="line-numbers language-none"><code class="language-none">Dynamic debug¶
Introduction
Dynamic debug allows you to dynamically enable&#x2F;disable kernel debug-print code to obtain additional kernel information.

If &#x2F;proc&#x2F;dynamic_debug&#x2F;control exists, your kernel has dynamic debug. You’ll need root access (sudo su) to use this.

Dynamic debug provides:

a Catalog of all prdbgs in your kernel. cat &#x2F;proc&#x2F;dynamic_debug&#x2F;control to see them.

a Simple query&#x2F;command language to alter prdbgs by selecting on any combination of 0 or 1 of:

source filename

function name

line number (including ranges of line numbers)

module name

format string

class name (as known&#x2F;declared by each module)

Viewing Dynamic Debug Behaviour
You can view the currently configured behaviour in the prdbg catalog:

:#&gt; head -n7 &#x2F;proc&#x2F;dynamic_debug&#x2F;control
# filename:lineno [module]function flags format
init&#x2F;main.c:1179 [main]initcall_blacklist &#x3D;_ &quot;blacklisting initcall %s\012
init&#x2F;main.c:1218 [main]initcall_blacklisted &#x3D;_ &quot;initcall %s blacklisted\012&quot;
init&#x2F;main.c:1424 [main]run_init_process &#x3D;_ &quot;  with arguments:\012&quot;
init&#x2F;main.c:1426 [main]run_init_process &#x3D;_ &quot;    %s\012&quot;
init&#x2F;main.c:1427 [main]run_init_process &#x3D;_ &quot;  with environment:\012&quot;
init&#x2F;main.c:1429 [main]run_init_process &#x3D;_ &quot;    %s\012&quot;
The 3rd space-delimited column shows the current flags, preceded by a &#x3D; for easy use with grep&#x2F;cut. &#x3D;p shows enabled callsites.

Controlling dynamic debug Behaviour
The behaviour of prdbg sites are controlled by writing query&#x2F;commands to the control file. Example:

# grease the interface
:#&gt; alias ddcmd&#x3D;&#39;echo $* &gt; &#x2F;proc&#x2F;dynamic_debug&#x2F;control&#39;

:#&gt; ddcmd &#39;-p; module main func run* +p&#39;
:#&gt; grep &#x3D;p &#x2F;proc&#x2F;dynamic_debug&#x2F;control
init&#x2F;main.c:1424 [main]run_init_process &#x3D;p &quot;  with arguments:\012&quot;
init&#x2F;main.c:1426 [main]run_init_process &#x3D;p &quot;    %s\012&quot;
init&#x2F;main.c:1427 [main]run_init_process &#x3D;p &quot;  with environment:\012&quot;
init&#x2F;main.c:1429 [main]run_init_process &#x3D;p &quot;    %s\012&quot;
Error messages go to console&#x2F;syslog:

:#&gt; ddcmd mode foo +p
dyndbg: unknown keyword &quot;mode&quot;
dyndbg: query parse failed
bash: echo: write error: Invalid argument
If debugfs is also enabled and mounted, dynamic_debug&#x2F;control is also under the mount-dir, typically &#x2F;sys&#x2F;kernel&#x2F;debug&#x2F;.

Command Language Reference
At the basic lexical level, a command is a sequence of words separated by spaces or tabs. So these are all equivalent:

:#&gt; ddcmd file svcsock.c line 1603 +p
:#&gt; ddcmd &quot;file svcsock.c line 1603 +p&quot;
:#&gt; ddcmd &#39;  file   svcsock.c     line  1603 +p  &#39;
Command submissions are bounded by a write() system call. Multiple commands can be written together, separated by ; or \n:

:#&gt; ddcmd &quot;func pnpacpi_get_resources +p; func pnp_assign_mem +p&quot;
:#&gt; ddcmd &lt;&lt;&quot;EOC&quot;
func pnpacpi_get_resources +p
func pnp_assign_mem +p
EOC
:#&gt; cat query-batch-file &gt; &#x2F;proc&#x2F;dynamic_debug&#x2F;control
You can also use wildcards in each query term. The match rule supports * (matches zero or more characters) and ? (matches exactly one character). For example, you can match all usb drivers:

:#&gt; ddcmd file &quot;drivers&#x2F;usb&#x2F;*&quot; +p     # &quot;&quot; to suppress shell expansion
Syntactically, a command is pairs of keyword values, followed by a flags change or setting:

command ::&#x3D; match-spec* flags-spec
The match-spec’s select prdbgs from the catalog, upon which to apply the flags-spec, all constraints are ANDed together. An absent keyword is the same as keyword “*”.

A match specification is a keyword, which selects the attribute of the callsite to be compared, and a value to compare against. Possible keywords are::

match-spec ::&#x3D; &#39;func&#39; string |
               &#39;file&#39; string |
               &#39;module&#39; string |
               &#39;format&#39; string |
               &#39;class&#39; string |
               &#39;line&#39; line-range

line-range ::&#x3D; lineno |
               &#39;-&#39;lineno |
               lineno&#39;-&#39; |
               lineno&#39;-&#39;lineno

lineno ::&#x3D; unsigned-int
Note
line-range cannot contain space, e.g. “1-30” is valid range but “1 - 30” is not.

The meanings of each keyword are:

func
The given string is compared against the function name of each callsite. Example:

func svc_tcp_accept
func *recv*             # in rfcomm, bluetooth, ping, tcp
file
The given string is compared against either the src-root relative pathname, or the basename of the source file of each callsite. Examples:

file svcsock.c
file kernel&#x2F;freezer.c   # ie column 1 of control file
file drivers&#x2F;usb&#x2F;*      # all callsites under it
file inode.c:start_*    # parse :tail as a func (above)
file inode.c:1-100      # parse :tail as a line-range (above)
module
The given string is compared against the module name of each callsite. The module name is the string as seen in lsmod, i.e. without the directory or the .ko suffix and with - changed to _. Examples:

module sunrpc
module nfsd
module drm*     # both drm, drm_kms_helper
format
The given string is searched for in the dynamic debug format string. Note that the string does not need to match the entire format, only some part. Whitespace and other special characters can be escaped using C octal character escape \ooo notation, e.g. the space character is \040. Alternatively, the string can be enclosed in double quote characters (&quot;) or single quote characters (&#39;). Examples:

format svcrdma:         &#x2F;&#x2F; many of the NFS&#x2F;RDMA server pr_debugs
format readahead        &#x2F;&#x2F; some pr_debugs in the readahead cache
format nfsd:\040SETATTR &#x2F;&#x2F; one way to match a format with whitespace
format &quot;nfsd: SETATTR&quot;  &#x2F;&#x2F; a neater way to match a format with whitespace
format &#39;nfsd: SETATTR&#39;  &#x2F;&#x2F; yet another way to match a format with whitespace
class
The given class_name is validated against each module, which may have declared a list of known class_names. If the class_name is found for a module, callsite &amp; class matching and adjustment proceeds. Examples:

class DRM_UT_KMS        # a DRM.debug category
class JUNK              # silent non-match
&#x2F;&#x2F; class TLD_*          # NOTICE: no wildcard in class names
line
The given line number or range of line numbers is compared against the line number of each pr_debug() callsite. A single line number matches the callsite line number exactly. A range of line numbers matches any callsite between the first and last line number inclusive. An empty first number means the first line in the file, an empty last line number means the last line number in the file. Examples:

line 1603           &#x2F;&#x2F; exactly line 1603
line 1600-1605      &#x2F;&#x2F; the six lines from line 1600 to line 1605
line -1605          &#x2F;&#x2F; the 1605 lines from line 1 to line 1605
line 1600-          &#x2F;&#x2F; all lines from line 1600 to the end of the file
The flags specification comprises a change operation followed by one or more flag characters. The change operation is one of the characters:

-    remove the given flags
+    add the given flags
&#x3D;    set the flags to the given flags
The flags are:

p    enables the pr_debug() callsite.
_    enables no flags.

Decorator flags add to the message-prefix, in order:
t    Include thread ID, or &lt;intr&gt;
m    Include module name
f    Include the function name
s    Include the source file name
l    Include line number
For print_hex_dump_debug() and print_hex_dump_bytes(), only the p flag has meaning, other flags are ignored.

Note the regexp ^[-+&#x3D;][fslmpt_]+$ matches a flags specification. To clear all flags at once, use &#x3D;_ or -fslmpt.

Debug messages during Boot Process
To activate debug messages for core code and built-in modules during the boot process, even before userspace and debugfs exists, use dyndbg&#x3D;&quot;QUERY&quot; or module.dyndbg&#x3D;&quot;QUERY&quot;. QUERY follows the syntax described above, but must not exceed 1023 characters. Your bootloader may impose lower limits.

These dyndbg params are processed just after the ddebug tables are processed, as part of the early_initcall. Thus you can enable debug messages in all code run after this early_initcall via this boot parameter.

On an x86 system for example ACPI enablement is a subsys_initcall and:

dyndbg&#x3D;&quot;file ec.c +p&quot;
will show early Embedded Controller transactions during ACPI setup if your machine (typically a laptop) has an Embedded Controller. PCI (or other devices) initialization also is a hot candidate for using this boot parameter for debugging purposes.

If foo module is not built-in, foo.dyndbg will still be processed at boot time, without effect, but will be reprocessed when module is loaded later. Bare dyndbg&#x3D; is only processed at boot.

Debug Messages at Module Initialization Time
When modprobe foo is called, modprobe scans &#x2F;proc&#x2F;cmdline for foo.params, strips foo., and passes them to the kernel along with params given in modprobe args or &#x2F;etc&#x2F;modprobe.d&#x2F;*.conf files, in the following order:

parameters given via &#x2F;etc&#x2F;modprobe.d&#x2F;*.conf:

options foo dyndbg&#x3D;+pt
options foo dyndbg # defaults to +p
foo.dyndbg as given in boot args, foo. is stripped and passed:

foo.dyndbg&#x3D;&quot; func bar +p; func buz +mp&quot;
args to modprobe:

modprobe foo dyndbg&#x3D;&#x3D;pmf # override previous settings
These dyndbg queries are applied in order, with last having final say. This allows boot args to override or modify those from &#x2F;etc&#x2F;modprobe.d (sensible, since 1 is system wide, 2 is kernel or boot specific), and modprobe args to override both.

In the foo.dyndbg&#x3D;&quot;QUERY&quot; form, the query must exclude module foo. foo is extracted from the param-name, and applied to each query in QUERY, and only 1 match-spec of each type is allowed.

The dyndbg option is a “fake” module parameter, which means:

modules do not need to define it explicitly

every module gets it tacitly, whether they use pr_debug or not

it doesn’t appear in &#x2F;sys&#x2F;module&#x2F;$module&#x2F;parameters&#x2F; To see it, grep the control file, or inspect &#x2F;proc&#x2F;cmdline.

For CONFIG_DYNAMIC_DEBUG kernels, any settings given at boot-time (or enabled by -DDEBUG flag during compilation) can be disabled later via the debugfs interface if the debug messages are no longer needed:

echo &quot;module module_name -p&quot; &gt; &#x2F;proc&#x2F;dynamic_debug&#x2F;control
Examples
&#x2F;&#x2F; enable the message at line 1603 of file svcsock.c
:#&gt; ddcmd &#39;file svcsock.c line 1603 +p&#39;

&#x2F;&#x2F; enable all the messages in file svcsock.c
:#&gt; ddcmd &#39;file svcsock.c +p&#39;

&#x2F;&#x2F; enable all the messages in the NFS server module
:#&gt; ddcmd &#39;module nfsd +p&#39;

&#x2F;&#x2F; enable all 12 messages in the function svc_process()
:#&gt; ddcmd &#39;func svc_process +p&#39;

&#x2F;&#x2F; disable all 12 messages in the function svc_process()
:#&gt; ddcmd &#39;func svc_process -p&#39;

&#x2F;&#x2F; enable messages for NFS calls READ, READLINK, READDIR and READDIR+.
:#&gt; ddcmd &#39;format &quot;nfsd: READ&quot; +p&#39;

&#x2F;&#x2F; enable messages in files of which the paths include string &quot;usb&quot;
:#&gt; ddcmd &#39;file *usb* +p&#39;

&#x2F;&#x2F; enable all messages
:#&gt; ddcmd &#39;+p&#39;

&#x2F;&#x2F; add module, function to all enabled messages
:#&gt; ddcmd &#39;+mf&#39;

&#x2F;&#x2F; boot-args example, with newlines and comments for readability
Kernel command line: ...
  &#x2F;&#x2F; see what&#39;s going on in dyndbg&#x3D;value processing
  dynamic_debug.verbose&#x3D;3
  &#x2F;&#x2F; enable pr_debugs in the btrfs module (can be builtin or loadable)
  btrfs.dyndbg&#x3D;&quot;+p&quot;
  &#x2F;&#x2F; enable pr_debugs in all files under init&#x2F;
  &#x2F;&#x2F; and the function parse_one, #cmt is stripped
  dyndbg&#x3D;&quot;file init&#x2F;* +p #cmt ; func parse_one +p&quot;
  &#x2F;&#x2F; enable pr_debugs in 2 functions in a module loaded later
  pc87360.dyndbg&#x3D;&quot;func pc87360_init_device +p; func pc87360_find +p&quot;
Kernel Configuration
Dynamic Debug is enabled via kernel config items:

CONFIG_DYNAMIC_DEBUG&#x3D;y        # build catalog, enables CORE
CONFIG_DYNAMIC_DEBUG_CORE&#x3D;y   # enable mechanics only, skip catalog
If you do not want to enable dynamic debug globally (i.e. in some embedded system), you may set CONFIG_DYNAMIC_DEBUG_CORE as basic support of dynamic debug and add ccflags :&#x3D; -DDYNAMIC_DEBUG_MODULE into the Makefile of any modules which you’d like to dynamically debug later.

Kernel prdbg API
The following functions are cataloged and controllable when dynamic debug is enabled:

pr_debug()
dev_dbg()
print_hex_dump_debug()
print_hex_dump_bytes()
Otherwise, they are off by default; ccflags +&#x3D; -DDEBUG or #define DEBUG in a source file will enable them appropriately.

If CONFIG_DYNAMIC_DEBUG is not set, print_hex_dump_debug() is just a shortcut for print_hex_dump(KERN_DEBUG).

For print_hex_dump_debug()&#x2F;print_hex_dump_bytes(), format string is its prefix_str argument, if it is constant string; or hexdump in case prefix_str is built dynamically.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="控制台启动前的打印—早期的-printk"><a href="#控制台启动前的打印—早期的-printk" class="headerlink" title="控制台启动前的打印—早期的 printk"></a><strong>控制台启动前的打印—早期的 printk</strong></h3><p>printk 的输出当然可以发送到控制台设备上（我们在<em>了解 printk 输出的去向</em>部分已经介绍过这一点（见<em>表 3.1</em>））。默认情况下，在大多数系统中，所有日志级别为 3 级及以下（&lt;4 级）的 printk 消息都会被自动路由到控制台设备（实际上，所有日志级别为 emerg/alert/crit/err 的内核 printk 都会被路由到控制台设备）。</p>
<h4 id="控制台设备到底是什么？"><a href="#控制台设备到底是什么？" class="headerlink" title="控制台设备到底是什么？"></a>控制台设备到底是什么？</h4><p>​    在进一步了解之前，有必要先了解一下控制台设备到底是什么… 传统上，控制台设备是一个纯粹的内核功能，是超级用户在非图形环境中登录的初始终端窗口（/dev/console）。有趣的是，在 Linux 上，我们可以定义多个控制台—<strong>电传类型终端</strong>（<strong>tty</strong>）窗口（如 /dev/console）、文本模式 VGA、帧缓冲器，甚至是通过 USB 提供服务的串行端口（这在开发过程中的嵌入式系统中很常见）。</p>
<p>​    例如，当我们通过 USB 转 RS232 TTL UART（USB 转串口）电缆将 Raspberry Pi 连接到 x86_64 笔记本电脑时（请参阅本章的 “进一步阅读 “部分，了解关于这个非常有用的配件以及如何在 Raspberry Pi 上设置它的博客文章！），然后使用 minicom(1)（或 screen(1)）获取串口控制台，这就是显示为 tty 设备的设备 - 它就是串口：</p>
<pre class="line-numbers language-none"><code class="language-none">rpi # tty
&#x2F;dev&#x2F;ttyS0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>现在，问题出在哪里？让我们一探究竟！</p>
<p><strong>早期启动 - 问题和解决方案</strong></p>
<p>通过 printk，你可以向控制台（和内核日志）发送消息。是的，但请想一想：在启动过程的早期，当内核正在初始化时，控制台设备还没有准备好，没有初始化，因此无法使用。很明显，在启动初期发出的任何 printk，其输出都无法在 <em> 屏幕 </em> - 控制台上看到（尽管它可能记录在内核日志缓冲区中，但我们还没有 shell 来查找它</p>
<p>通常情况下（尤其是在嵌入式主板调试过程中），硬件怪异或故障会导致启动挂起、无休止地探测不存在或有故障的设备，甚至崩溃！令人沮丧的是，在没有控制台（printk）输出的情况下，这些问题很难调试（至少可以这么说！），而控制台（printk）输出如果可见，就能检测内核的启动过程，并非常清楚地显示问题发生在哪里（回顾一下内核命令行参数 debug 和 initcall_debug，在这种情况下非常有用—如果需要的话，可以回顾一下<em>内核启动时参数部分</em>）。 正如我们所知，必要是发明之母：内核社区为这个问题提出了一个可能的解决方案—所谓的<strong>早期 printk</strong>。有了它，内核 printk 仍然可以发送到控制台设备。怎么做到的？嗯，这是一个相当复杂的问题，而且与特定的设备有关，但广泛而典型的想法是，执行最基本的控制台初始化（该控制台设备称为 early_console），然后在循环中通过串行线路一个字符一个字符地<strong>比特撞击</strong>出要显示的字符串（典型的比特率范围在 9,600 至 115,200 bps 之间）。要使用该设施，需要做三件事：</p>
<ul>
<li><p>配置和构建内核以支持早期 printk（设置 CONFIG_EARLY_PRINTK=y），仅此一次。</p>
</li>
<li><p>使用适当的内核命令行参数 - earlyprintk=<code>&lt;value&gt;.</code> 启动目标内核。</p>
</li>
<li><p>发出早期 printk 的应用程序接口称为 early_printk()；语法与 printf()相同。</p>
</li>
</ul>
<p>让我们简单了解一下上述各点，首先是为早期 printk 配置内核。在 x86 系统上，你必须使用 CONFIG_EARLY_PRINTK=y 配置内核（位于 “内核黑客”|”x86 调试”|”早期 printk “菜单下）。也可以选择通过 USB 调试端口启用早期 printk。为内核调试选项进行内核配置（通过常用的 make menuconfig）的 UI（菜单系统）文件是 arch/x86/Kconfig.debug 文件。我们将在此展示其中的一个片段，即早期 printk 菜单选项所在的部分：</p>
<p><img src="./image-20240703095924545.png" alt="image-20240703095924545"></p>
<p>​    阅读此处显示的帮助屏幕确实很有帮助！正如上面所说，默认情况下不推荐使用该选项，因为输出格式不佳，可能会干扰正常日志记录。通常只有在调试早期启动问题时才会使用。(如果有兴趣，你可以在我早期的《Linux 内核<em>*编程</em>》一书中找到关于内核<em>Kconfig</em>语法和用法的详细信息）。</p>
<p>​    另一方面，在 ARM（AArch32）系统上，内核配置选项位于 “内核黑客”|”内核底层调试功能”（阅读帮助！）下，配置选项名为 CONFIG_DEBUG_LL。正如内核明确坚持的那样，让我们阅读帮助屏幕：</p>
<p><img src="./image-20240703095943161.png" alt="image-20240703095943161"></p>
<p>​    请注意其中的内容！此外，它后面的子菜单允许你配置底层调试端口（默认设置为 EmbeddedICE DCC 通道；如果你有可用的串行 UART，可以将其更改为串行 UART）。接下来，通过传递适当的内核命令行参数启用它—earlyprintk=<code>&lt;value&gt;</code>。官方内核文档显示了所有可能的传递方式（此处：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html）">https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html）</a></p>
<p>​    可以附加一个可选的 keep 参数，这意味着即使在 VGA 子系统（或真正的控制台）开始运行后，通过早期 printk 设施发送的 printk 信息也不会被禁用。一旦传递了 earlyprintk= 参数，内核就会开始使用它（基本上是将 printk 重定向到串行、VGA 或任何你通过该参数指定的控制台上）。要进行打印，只需调用 early_printk() API 即可。下面是内核代码库中的一个示例：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; kernel&#x2F;events&#x2F;core.c

 if (!irq_work_queue(&amp;perf_duration_work)) &#123;

 	early_printk(&quot;perf: interrupt took too long (%lld &gt; %lld), lowering &quot;&quot;kernel.perf_event_max_sample_rate 	to %d\n&quot;,__report_avg,__report_allowed,sysctl_perf_event_sample_rate);
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    上面介绍的主要是与操作系统无关的内容。举例来说，（仅）在 x86 系统上，你可以利用 USB 调试端口（如果你的系统有的话），方法如下。传递内核命令行参数 earlyprintk=dbgp。请注意，这需要（x86）主机系统上的 USB 调试端口和 NetChip USB2 调试端口密钥/电缆（连接到客户端或目标系统）。</p>
<h4 id="适用于内核模块的“更好”-Makefile-模板"><a href="#适用于内核模块的“更好”-Makefile-模板" class="headerlink" title="适用于内核模块的“更好” Makefile 模板"></a>适用于内核模块的“更好” Makefile 模板</h4><p>​    上一章介绍了用于从源代码生成内核模块、安装和清理内核模块的 Makefile。但是，正如我们在那里简要提到的，我现在将介绍我认为更优越的、所谓的“更好”的 Makefile，并解释它为什么更好。 最终，我们都必须编写更好、更安全的代码——无论是用户空间还是内核空间。好消息是，有几种工具可以帮助提高代码的稳健性和安全性，其中包括静态和动态分析器（因为在线章节“内核工作区设置”中已经提到了几种，我不会在这里重复它们）。 </p>
<p>​    我为内核模块设计了一个简单但有用的 Makefile“模板”，其中包括几个帮助您运行这些工具的目标。这些目标允许您非常轻松地执行有价值的检查和分析；否则您可能会忘记、忽略或永远推迟这些事情！</p>
<p>​    这些目标包括： </p>
<p>“通常”的目标 - 构建（全部）、安装和清理目标（考虑到“调试”设置，如果调试关闭，则剥离模块）。 内核编码风格生成和检查（通过缩进和内核的 checkpatch.pl 脚本）。</p>
<p> 内核静态分析目标（稀疏、gcc 和 flawfinder），其中提到了 Coccinelle。 几个虚拟内核动态分析目标指出您应该如何花时间配置和构建“调试”内核并使用它来捕获错误（通过 KASAN 和 LOCKDEP / CONFIG_PROVE_LOCKING；稍后将详细介绍） </p>
<p>一个简单的 tarxz-pkg 目标，将源文件打包并压缩到父目录中。这使您可以将压缩的 tar-xz 文件传输到任何其他 Linux 系统，然后在那里提取和构建 LKM。 您可以在 ch5/lkm_template 目录中找到代码（以及 README 文件）。为了帮助您了解其用途和功能并开始使用，下图仅显示了执行 <code>make &lt;tab&gt;&lt;tab&gt;</code> 并运行 <code>make help</code> 时代码生成的输出和输出屏幕截图：</p>
<p><img src="./image-20240708091704939.png" alt="image-20240708091704939"></p>
<p>如图 5.1 所示，我们输入 make，然后立即按两次 Tab 键，这样它就会显示所有可用的目标（您可能需要安装 Bash 完成包才能使此类功能正常工作；它通常安装在大多数发行版上）。请仔细研究并使用它！例如，运行 make sa（参见图 5.1 中的 sa 目标以及其他目标）将导致它在您的代码上运行所有静态分析 (sa) 目标。请注意以 FYI: KDIR=… 开头的行（突出显示）显示了 Makefile 对各种变量和“设置”的当前理解。我们在这里重现了它：</p>
<h4 id="配置一个调试内核"><a href="#配置一个调试内核" class="headerlink" title="配置一个调试内核"></a>配置一个调试内核</h4><p>​    在调试内核上运行代码可以帮助您发现难以发现的错误和问题。我强烈建议这样做，通常是在开发和测试期间！ 实际上，您应该有两个内核来运行和测试您的工作：精心配置的优化常规生产内核，以及一个调试内核，故意配置为启用许多内核调试选项（可能未优化，但目的是用它来捕获错误）。 在这里，我至少希望您配置自定义 6.1 内核，以便打开以下内核调试配置选项（即设置为 y；您会在 make menuconfig UI 中找到它们，并且您会在 Kernel Hacking 子菜单下找到它们中的大多数；以下列表与 Linux 6.1.25 有关）： </p>
<ul>
<li>CONFIG_DEBUG_KERNEL 和 CONFIG_DEBUG_INFO </li>
<li>CONFIG_DEBUG_MISC </li>
<li><p>通用内核调试工具： </p>
<ul>
<li>CONFIG_MAGIC_SYSRQ（神奇的 SysRq 热键功能） </li>
<li>CONFIG_DEBUG_FS（debugfs 伪文件系统） </li>
<li>CONFIG_KGDB（内核 GDB；可选，推荐） </li>
<li>CONFIG_UBSAN（未定义行为健全性检查器） </li>
<li>CONFIG_KCSAN（动态数据竞争检测器） </li>
</ul>
</li>
<li><p>内存调试： </p>
<ul>
<li>CONFIG_SLUB_DEBUG </li>
<li>CONFIG_DEBUG_MEMORY_INIT</li>
<li>CONFIG_KASAN：强大的内核地址清理器 (KASAN) 内存检查器 </li>
</ul>
</li>
<li><p>CONFIG_DEBUG_SHIRQ </p>
</li>
<li>CONFIG_SCHED_STACK_END_CHECK </li>
<li>CONFIG_DEBUG_PREEMPT </li>
<li><p>锁定调试： </p>
<ul>
<li>CONFIG_PROVE_LOCKING：非常强大的 lockdep 功能，可以捕获 锁定错误！这也会打开其他几个锁定调试配置， 在第 13 章“内核同步 - 第 2 部分”中进行了解释。 </li>
<li>CONFIG_LOCK_STAT</li>
<li>CONFIG_DEBUG_ATOMIC_SLEEP</li>
</ul>
</li>
<li><p>CONFIG_BUG_ON_DATA_CORRUPTION </p>
</li>
<li>CONFIG_STACKTRACE </li>
<li>CONFIG_DEBUG_BUGVERBOSE </li>
<li>CONFIG_FTRACE (ftrace：在其子菜单中，至少打开几个 “跟踪器”，包括“内核函数 [图形] 跟踪器”） </li>
<li>架构特定（在 x86 上显示在“x86 调试”下）： <ul>
<li>CONFIG_EARLY_PRINTK（架构特定） </li>
<li>CONFIG_DEBUG_BOOT_PARAMS </li>
<li>CONFIG_UNWINDER_FRAME_POINTER（选择 FRAME_POINTER 和 CONFIG_STA/CK_VALIDATION）</li>
</ul>
</li>
</ul>
<h4 id="设置系统以进行交叉编译"><a href="#设置系统以进行交叉编译" class="headerlink" title="设置系统以进行交叉编译"></a>设置系统以进行交叉编译</h4><p>交叉编译内核模块的先决条件非常明确：我们需要将目标系统的内核源代码树作为主机系统工作区的一部分安装，主机系统通常是 x86_64 桌面（例如，使用 Raspberry Pi 作为目标；请参阅此处的官方 Raspberry Pi 文档：<a target="_blank" rel="noopener" href="https://www.raspberrypi.org/documentation/linux/kernel/building.md）。">https://www.raspberrypi.org/documentation/linux/kernel/building.md）。</a></p>
<p>​    我们现在需要一个交叉工具链（主机到目标）。通常，主机系统是 x86_64，而这里，由于目标是 ARM-64，我们需要一个 x86_64 到 ARM64 的交叉工具链。再次，正如第 3 章“从源代码构建 6.x Linux 内核 - 第 2 部分”中明确提到的那样，在 Raspberry Pi 的内核构建部分中，您必须将 Raspberry Pi 特定的 x86_64-to-ARM 工具链作为主机系统工作区的一部分进行安装</p>
<p>​    好的，从现在开始，我将假设您已满足我们在第 3 章“从源代码构建 6.x Linux 内核 - 第 2 部分”中介绍的内容中的这些先决条件，即为 Raspberry Pi 构建内核部分：您已安装 Raspberry Pi 6.1.34 内核源代码树和 x86_64-to-ARM64 交叉工具链。因此，我还假设工具链前缀为 aarch64-linux-gnu；我们可以通过尝试调用 gcc 交叉编译器来快速检查工具链是否已安装并将其二进制文件添加到路径中：</p>
<pre class="line-numbers language-none"><code class="language-none">$ aarch64-linux-gnu-gcc -v<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="尝试-1-–-设置-ARCH-和-CROSS-COMPILE-环境变量"><a href="#尝试-1-–-设置-ARCH-和-CROSS-COMPILE-环境变量" class="headerlink" title="尝试 1 – 设置 ARCH 和 CROSS_COMPILE 环境变量"></a>尝试 1 – 设置 ARCH 和 CROSS_COMPILE 环境变量</h4><p>​    交叉编译内核模块非常简单（或者我们认为如此！）。</p>
<p>​    首先，确保 正确设置“特殊”ARCH 和 CROSS_COMPILE 环境变量。请按照以下步骤操作： </p>
<ol>
<li><p>让我们为 Raspberry Pi 目标重新构建我们刚刚讨论的 lkm_template 内核模块；这也具有使用所谓 “更好”的 Makefile 的优势。以下是构建方法： 为了在不破坏原始代码的情况下执行此操作，请首先创建一个名为 cross 的新文件夹，其中包含代码副本。 （顺便说一句，代码库已经设置好了，这里：ch5/cross。） </p>
<pre class="line-numbers language-none"><code class="language-none">cd &lt;book-dir&gt;&#x2F;ch5; mkdir cross ; 
cd cross 
cp ..&#x2F;lkm_template&#x2F;lkm_template.c ..&#x2F;lkm_template&#x2F;Makefile <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>这里，<code>&lt;book-dir&gt;</code>是本书 GitHub 源代码树的根目录。 </p>
</li>
<li><p>现在，运行以下命令（我们假设交叉编译器工具位于 此路径中）： make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- （顺便说一下，本书代码库有一个小的包装器脚本，ch5/cross/buildit， 它会执行几个有效性检查并为您运行此命令。）但它不能立即起作用（或者它可能起作用；请参阅以下材料）。我们得到编译失败，如下所示： </p>
<pre class="line-numbers language-none"><code class="language-none">$ make ARCH&#x3D;arm64 CROSS_COMPILE&#x3D;aarch64-linux-gnu- --- 正在构建：KDIR&#x3D;~&#x2F;arm64_prj&#x2F;kernel&#x2F;linux ARCH&#x3D;arm64 CROSS_COMPILE aarch64-linux-gnu-gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0 
make -C ~&#x2F;arm64_prj&#x2F;kernel&#x2F;linux M&#x3D;&#x2F;home&#x2F;c2kp&#x2F;Linux-Kernel-Programmin make[1]: *** &#x2F;home&#x2F;c2kp&#x2F;arm64_prj&#x2F;kernel&#x2F;linux: 没有这样的文件或目录 make: *** [Makefile:93: all] 错误 2 $ <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>（请注意，这一次，ARCH 和 CROSS_COMPILE 环境变量是如何正确定义的。）</p>
<p>​    为什么会失败？ 上述交叉编译尝试失败的原因在于，它<strong>试图使用（针对）当前主机系统的内核源代码树进行构建，而不是目标的内核源代码树。</strong>因此，我们需要修改 Makefile 以将其指向正确的内核源代码树，即目标的内核源代码树。这很容易做到。在下面的代码中，我们看到了（更正的）Makefile 代码的典型编写方式：</p>
</li>
</ol>
<p>​    仔细查看（新的和“更好的”，如上一节所述）Makefile，您将了解其工作原理：</p>
<ul>
<li>最重要的是，我们根据 ARCH 环境变量的值有条件地将 KDIR 变量设置为指向正确的内核源代码树（当然，我使用了 ARM-32 和 PowerPC 的内核源代码树的示例路径名作为示例；请将路径名替换为内核源代码树的实际路径）。</li>
<li>像往常一样，我们将 obj-m 设置为对象文件名。</li>
<li>您可以设置变量 ccflags-y（CFLAGS_EXTRA 被视为已弃用）以添加 DEBUG 符号（以便在我们的 LKM 中定义 DEBUG 符号，并且 pr_debug()/dev_dbg() 宏可以工作）。默认情况下，“调试”构建处于关闭状态。</li>
<li>@echo ‘&lt;…&gt;’ 行相当于 shell 的 echo 命令；它只是在构建时发出一些有用的信息（@ 前缀隐藏了 echo 语句本身，不显示）。</li>
<li>最后，我们有“通常的” Makefile 目标：all、install 和 clean。请注意，在调用 make 时，我们确保通过 -C 开关将目录更改为 KDIR 的值！</li>
<li>虽然前面的代码中没有显示，但这个“更好的” Makefile - 有重复的风险 - 有几个额外的有用目标。你一定要花时间探索和使用它们（如上一节所述；要开始，只需输入 make help，研究输出，然后尝试一下）。</li>
</ul>
<p>完成此操作后，让我们重试使用此版本的模块交叉编译，看看它进展如何。</p>
<h4 id="尝试-2-–-将-Makefile-指向目标的正确内核源代码树"><a href="#尝试-2-–-将-Makefile-指向目标的正确内核源代码树" class="headerlink" title="尝试 2 – 将 Makefile 指向目标的正确内核源代码树"></a>尝试 2 – 将 Makefile 指向目标的正确内核源代码树</h4><p>​    因此，现在，有了上一节中描述的增强和修复的 Makefile， 它应该可以工作了。在我们的新目录中，我们将尝试这个 - cross - 按照以下步骤操作： 1. 使用适合交叉编译的 make 命令尝试构建（第二次）：</p>
<pre class="line-numbers language-none"><code class="language-none">$ make ARCH&#x3D;arm CROSS_COMPILE&#x3D;arm-linux-gnueabihf-
[ ... ]
 CC [M] &#x2F;home&#x2F;c2kp&#x2F;Linux-Kernel-Programming_2E&#x2F;ch5&#x2F;cross&#x2F;lkm_te
 MODPOST &#x2F;home&#x2F;c2kp&#x2F;Linux-Kernel-Programming_2E&#x2F;ch5&#x2F;cross&#x2F;Module
ERROR: modpost: &quot;_printk&quot; [&#x2F;home&#x2F;c2kp&#x2F;Linux-Kernel-Programming_2E
make[2]: *** [scripts&#x2F;Makefile.modpost:126: &#x2F;home&#x2F;c2kp&#x2F;Linux-Kern
[ ... ]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    哎呀。这次我们遇到了 modpost 错误。在此模块构建阶段，MODPOST，构建系统必须能够访问和检查所有导出的内核符号。这些信息存储在文件 Module.symvers 中（位于内核源代码树的根目录中）。它通常在模块构建后立即生成（在内核构建过程中）。当此文件不存在时，我们可能会遇到此 modpost 失败（就像我们刚才所做的那样）。因此，为了一次性修复此问题，我只需清理我的（Raspberry Pi）内核源代码树（使用 make mrproper），然后重建它；Module.symvers 文件现在确实出现了，并且构建通过了：</p>
<p>​    当然，现实情况是，构建可能会因多种原因而失败，而不仅仅是这里看到的原因……在另一个例子中，它失败了，因为我们编译内核模块的目标内核源代码树仍处于“原始”状态。它的根目录中甚至可能没有 .config 文件（以及其他必需的标头），而它（至少）需要对其进行配置。要解决此问题，您必须以通常的方式配置和交叉编译内核，然后重试模块构建</p>
<h4 id="尝试-3-–-交叉编译我们的内核模块"><a href="#尝试-3-–-交叉编译我们的内核模块" class="headerlink" title="尝试 3 – 交叉编译我们的内核模块"></a>尝试 3 – 交叉编译我们的内核模块</h4><p>​    现在我们已经使用正确配置的 Raspberry Pi 内核源代码树生成了交叉编译的内核模块（在主机系统上，存在 Module.symvers 文件；请参阅尝试 2 – 将 Makefile 指向目标部分的正确内核源代码树），它应该可以在主板上运行（嘿，我们是乐观主义者）。 当然，实践出真知。因此，我们启动我们的 Raspberry Pi，将我们的交叉编译的内核模块目标文件 scp 到它，然后按如下方式（在 Raspberry Pi 上的 ssh 会话中）试用它（以下输出直接来自设备）：</p>
<p>​    显然，insmod 失败了！了解原因很重要。这是因为我们尝试加载模块的内核版本与模块编译的内核版本不匹配。登录到 Raspberry Pi 时，让我们打印出当前运行的 Raspberry Pi 内核版本，并使用 modinfo 实用程序打印出有关内核模块本身的详细信息：</p>
<p>从前面的输出可以清楚地看出，在 ARM64 Raspberry Pi 板上，我们运行的是 6.1.21-v8+ 内核。事实上，这是我在设备的 microSD 卡上安装默认 Raspberry Pi 操作系统时继承的内核（这是这里引入的故意场景，起初不使用我们之前为 Raspberry Pi 构建的 6.1 内核）。另一方面，内核模块显示它是针对 6.1.34-v8+ Linux 内核编译的（modinfo(8) 中的 vermagic 字符串显示了这一点）。显然，存在不匹配。那又怎么样？继续阅读，下一节将揭示这一点。</p>
<pre class="line-numbers language-none"><code class="language-none">rpi $ modinfo .&#x2F;lkm_template.ko 
filename: &#x2F;home&#x2F;pi&#x2F;lkp2e&#x2F;ch5&#x2F;cross&#x2F;.&#x2F;lkm_template.ko
version: 0.2
license: Dual MIT&#x2F;GPL
description: a simple LKM template; do refer to the (better) Makef
author: Kaiwan N Billimoria
srcversion: 606276CA0788B10170FC6D5
depends: 
name: lkm_template
vermagic: 6.1.34-v8+ SMP preempt mod_unload modversions aarch64
rpi $<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="检查-Linux-内核-ABI-兼容性问题"><a href="#检查-Linux-内核-ABI-兼容性问题" class="headerlink" title="检查 Linux 内核 ABI 兼容性问题"></a>检查 Linux 内核 ABI 兼容性问题</h4><p>​    Linux 内核有一条规则，是内核应用程序二进制接口 (ABI) 的一部分：只有当内核模块是针对它构建的时，它才会将内核模块插入内核内存中 - 精确的内核版本、构建标志，甚至内核配置选项都很重要！ 针对构建的内核是您在 Makefile 中指定其源位置的内核（我们之前通过 KDIR 变量指定了此位置）。 换句话说，内核模块与针对其构建的内核以外的内核不二进制兼容。例如，如果我们在 x86_64 Ubuntu 22.04 LTS 机器上构建内核模块，那么它只能在运行此精确环境（硬件、库和内核）的系统上运行！它无法在 Fedora 38 或 RHEL 8.x、Raspberry Pi 等上运行（加载），甚至无法在运行不同内核的 x86_64 Ubuntu 22.04 机器上运行。 现在，重要的是——再想想这个——这并不意味着内核模块完全不兼容且不可移植。不，它们在不同的架构之间是源兼容的（至少它们可以或应该这样编写）。因此，假设您有源代码，您始终可以在给定系统上重建内核模块，然后它将在该系统上运行。只是二进制映像（.ko 文件）与它所针对的内核以外的内核不兼容。（在某些版本的内核上，内核日志会说明这一点。）所以，现在很清楚了；这里，二进制模块和它所构建的内核以及我们试图运行（加载）它的内核之间存在不匹配，因此无法插入内核模块。 虽然我们在这里不使用这种方法，但有一种方法可以确保成功构建和部署第三方树外内核模块（如果它们的源代码可用），通过一个名为 DKMS（动态内核模块支持）的框架。以下是直接引用自它的内容： 动态内核模块支持 (DKMS) 是一个程序/框架，它能够生成 Linux 内核模块，其源代码通常位于内核源代码树之外。这个概念是让 DKMS 模块在安装新内核时自动重建。 请注意：关键短语是“…让 DKMS 模块在安装新内核时自动重建”，这证明了这一点：内核模块需要精确地针对它们将部署在其上的内核进行构建。作为 DKMS 使用的一个示例，Oracle VirtualBox 虚拟机管理程序（在 Linux 主机上运行时）使用 DKMS 自动构建并保持其内核模块的更新。 顺便说一句，如果您手边没有 Raspberry Pi 来尝试这些实验怎么办？不用担心，您可以使用其他基于 ARM 的主板甚至虚拟化！（仅供参考，第 1 章中提到的 SEALS 项目允许通过 QEMU 对 ARM-32、ARM-64 和 x86_64 PC 进行非常简单的虚拟化。）</p>
<h4 id="尝试-4-–-交叉编译我们的内核模块"><a href="#尝试-4-–-交叉编译我们的内核模块" class="headerlink" title="尝试 4 – 交叉编译我们的内核模块"></a>尝试 4 – 交叉编译我们的内核模块</h4><p>​    现在，我们已经了解了二进制兼容性问题，有几种可能的解决方案：</p>
<ul>
<li><p>我们必须使用产品所需的自定义内核配置、（交叉）构建和启动设备，并根据该内核源代码树构建所有内核模块。</p>
</li>
<li><p>使用 DKMS 方法。</p>
</li>
<li><p>或者，我们可以重建内核模块以匹配 Raspberry Pi 设备恰好正在运行的当前内核。</p>
</li>
</ul>
<p>​    现在，在典型的嵌入式 Linux 项目中，您几乎肯定会有一个针对目标设备的自定义配置内核，您必须使用它。产品的所有内核模块都将/必须针对它构建。因此，我们遵循第一种方法 - 我们必须使用我们自定义配置和构建的（6.1.34）内核启动设备，并且由于我们的内核模块是针对它构建的，因此它现在肯定可以工作。</p>
<p>​    我们在第 3 章“从源代码构建 6.x Linux 内核 - 第 2 部分”的“Raspberry Pi 内核构建”部分中介绍了 Raspberry Pi 的内核构建。如果需要，请参阅那里的详细信息。<br>​    好的，我必须假设您已经按照步骤（在第 3 章“从源代码构建 6.x Linux 内核 - 第 2 部分”的“Raspberry Pi 内核构建”部分中介绍）进行操作，并且现在已经为 Raspberry Pi 配置和构建了 6.x 内核。关于如何将我们的自定义内核映像、DTB 和模块文件复制到设备的 microSD 卡等的具体细节未涵盖；我建议您参考这里的官方 Raspberry Pi 文档：<br><a target="_blank" rel="noopener" href="https://www.raspberrypi.org/documentation/linux/kernel/building.md。">https://www.raspberrypi.org/documentation/linux/kernel/building.md。</a><br>​    尽管如此，我们将指出一种在设备上切换内核的便捷方法（这里，我假设该设备是运行 64 位内核的 Raspberry Pi 4B）：</p>
<ol>
<li>将您定制的 Image 内核二进制文件作为 kernel8.img 复制到设备的 microSD 卡的 /boot 分区中。（为了安全起见，首先确保将原始（默认）Raspberry Pi 内核映像保存为 kernel8.img.orig）。</li>
<li>将刚刚交叉编译的内核模块（上一节中为 ARM64 构建的 lkm_template.ko）从主机系统复制（scp）到 microSD 卡上（复制到 /home/pi 即可）。</li>
<li>[可选] 在 Raspberry Pi 板上，您可以按如下方式指定要启动的内核；在我们的例子中这不是必需的：引导加载程序将自动选择文件 kernel8.img 作为默认启动的内核。如果您想要指定不同的内核来启动，请在设备的 microSD 卡上编辑 /boot/config.txt 文件，通过 kernel=xxx 行将内核映像设置为启动。</li>
<li>保存并重新启动后，我们登录设备并重试我们的内核模块。</li>
</ol>
<h4 id="总结-cross-build-load-模块出了什么问题以及如何修复"><a href="#总结-cross-build-load-模块出了什么问题以及如何修复" class="headerlink" title="总结 cross-build/load 模块出了什么问题以及如何修复"></a>总结 cross-build/load 模块出了什么问题以及如何修复</h4><div class="table-container">
<table>
<thead>
<tr>
<th>尝试</th>
<th>问题</th>
<th>解决方案</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>模块构建失败，因为我们尝试根据当前主机 (x86_64) 系统的内核源代码树（或指定的无效路径）而不是目标的内核源代码树来构建目标内核模块。</td>
<td>修改模块 Makefile，将 KDIR 变量指向正确的内核源代码树，即目标系统的内核源代码树：KDIR ?=~/rpi_work/kernel_rpi/linux</td>
</tr>
<tr>
<td>2</td>
<td>模块构建在MODPOST 阶段失败（由于目标内核源树中缺少 Module.symvers 文件）。</td>
<td>意味着目标内核树尚未配置和/或构建；因此请这样做……然后会出现此文件，并且它会（交叉）构建模块</td>
</tr>
<tr>
<td>3</td>
<td>交叉编译模块无法加载到设备（Raspberry Pi）上，内核引用“无效模块格式”错误。</td>
<td>这是由于内核 ABI 规则：如果内核模块是针对它构建的，内核将只将内核模块插入内核内存。因此模块在系统之间没有二进制兼容性，但可以编写为源可移植的。</td>
</tr>
<tr>
<td>4</td>
<td>交叉编译模块无法加载到设备（Raspberry Pi）上，内核引用“无效模块格式”错误。</td>
<td>修复：我们使用自定义 6.1 内核启动设备，并针对同一内核交叉编译我们的模块（通过 KDIR Makefile 变量引用它），将二进制模块复制到目标的根文件系统上，然后对其进行 insmod。</td>
</tr>
</tbody>
</table>
</div>
<p>内核模块许可</p>
<p>​    众所周知，Linux 内核代码库本身是根据 GNU GPL v2（又名 GPL-2.0；GPL 代表通用公共许可证）许可的，就大多数人而言，这种许可将一直有效。如前所述，在第 4 章“编写您的第一个内核模块 - 第 1 部分”中，为您的内核代码颁发许可是必需的，也是很重要的。让我们将关于许可的简短讨论分为两部分：</p>
<p>第一部分，适用于内联内核代码（或主线内核）；</p>
<p>第二部分，适用于编写第三方树外内核模块（我们很多人都这样做）。</p>
<h4 id="内联内核代码的许可"><a href="#内联内核代码的许可" class="headerlink" title="内联内核代码的许可"></a>内联内核代码的许可</h4><p>我们从第一个部分开始，即内联内核代码。这里关于许可的一个关键点是：如果您打算直接使用 Linux 内核代码和/或将您的代码贡献到主线内核上游（我们将在下一节中对此进行更多介绍），则必须按照与 Linux 内核相同的许可证发布代码：GNU GPL-2.0。详细信息有据可查；</p>
<p>请参阅此处的官方说明：<a target="_blank" rel="noopener" href="https://docs.kernel.org/process/license￾rules.html#linux-kernel-licensing-rules。对于许可新手来说，大量的开源许可证及其注意事项无疑会令人困惑。请查看此网站以帮助消除迷雾：https://choosealicense.com/。此外，Bootlin">https://docs.kernel.org/process/license￾rules.html#linux-kernel-licensing-rules。对于许可新手来说，大量的开源许可证及其注意事项无疑会令人困惑。请查看此网站以帮助消除迷雾：https://choosealicense.com/。此外，Bootlin</a> 在其嵌入式 Linux 系统开发培训指南的“开源许可和合规性”部分中对开源许可的介绍也非常出色（<a target="_blank" rel="noopener" href="https://bootlin.com/doc/training/embedded-linux/embedded-linux-slides.pdf）。">https://bootlin.com/doc/training/embedded-linux/embedded-linux-slides.pdf）。</a></p>
<p>​    为了保持一致，最近的内核有一个规则：每个源文件的第一行必须是 SPDX（软件包数据交换）许可证标识符（有关详细信息，请参阅 <a target="_blank" rel="noopener" href="https://spdx.org/），这是一种简写和简洁的格式，用于表达代码发布的许可证。（当然，脚本需要第一行来指定解释器。）因此，内核中大多数">https://spdx.org/），这是一种简写和简洁的格式，用于表达代码发布的许可证。（当然，脚本需要第一行来指定解释器。）因此，内核中大多数</a> C 源文件的第一行都是关于 SPDX 许可证的注释：<br>// SPDX-License-Identifier: GPL-2.0</p>
<h4 id="树外内核模块的许可"><a href="#树外内核模块的许可" class="headerlink" title="树外内核模块的许可"></a>树外内核模块的许可</h4><p>对于树外内核模块，情况仍然有点“不稳定”，我们可以这么说。</p>
<p>​    无论如何，为了吸引内核社区并让他们提供帮助（这是一个巨大的优势），您应该或应该根据 GNU GPL-2.0 许可证发布代码（尽管双重许可当然是可能的和可接受的）。内核模块发布的许可证以两种方式指定：</p>
<ol>
<li>通过 SPDX-License-Identifier 标记作为第一个源代码行（中的注释）。这严格适用于源代码树中的模块，并不总是适用于树外模块。</li>
<li><ol>
<li>通过 MODULE_LICENSE() 宏。请注意官方内核文档明确指出的内容（<a target="_blank" rel="noopener" href="https://docs.kernel.org/process/license￾rules.html#id1）：“可加载内核模块还需要一个">https://docs.kernel.org/process/license￾rules.html#id1）：“可加载内核模块还需要一个</a> MODULE_LICENSE() 标记。此标记既不能替代正确的源代码许可证信息（SPDX-License-Identifier），也不能以任何方式与表达或确定模块源代码所依据的确切许可证相关。”此标签的唯一目的是提供足够的信息，说明模块是免费软件还是内核模块加载器和用户空间工具的专有软件。</li>
</ol>
</li>
</ol>
<p>以下注释摘自 include/linux/module.h 内核头文件，清楚地显示了哪些许可证“idents”是可接受的（请注意双重许可）。显然，内核社区强烈建议在 GPL-2.0（GPL v2）和/或其他类似许可证（如 BSD/MIT/MPL）下发布内核模块。如果您打算将代码贡献给内核主线上游，那么不用说，GPL-2.0 本身就是发布许可证：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; include&#x2F;linux&#x2F;module.h
[...]
&#x2F;*
 * The following license idents are currently accepted as indicating 
 * software modules
 *
 * &quot;GPL&quot; [GNU Public License v2 or later]
 * &quot;GPL v2&quot; [GNU Public License v2]
 * &quot;GPL and additional rights&quot; [GNU Public License v2 rights and more
 * &quot;Dual BSD&#x2F;GPL&quot; [GNU Public License v2
 * or BSD license choice]
 * &quot;Dual MIT&#x2F;GPL&quot; [GNU Public License v2
 * or MIT license choice]
 * &quot;Dual MPL&#x2F;GPL&quot; [GNU Public License v2
 * or Mozilla license choice]
 *
 * The following other idents are available
 *
 * &quot;Proprietary&quot; [Non free products]
 [ ... ]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    MODULE_LICENSE() 的使用在很大程度上是一种历史性的、失败的尝试，试图在 MODULE_LICENSE 字符串中传达更多信息。它现在的主要目的是能够检查和标记专有模块，从而限制它们使用 GPL 下导出的符号（我们将讨论这一点）。它还帮助社区、最终用户和模块供应商快速审查代码库是否是开源的。仅供参考，内核源代码树有一个 LICENSES/ 目录，您可以在该目录下找到有关相关许可证的详细信息；快速 ls 此文件夹会显示其中的子文件夹：</p>
<h4 id="为内核模块模拟“类似库”的功能"><a href="#为内核模块模拟“类似库”的功能" class="headerlink" title="为内核模块模拟“类似库”的功能"></a>为内核模块模拟“类似库”的功能</h4><p>​    用户模式和内核模式编程之间的主要区别之一是后者完全没有熟悉的“库”概念。库本质上是 API 的集合或存档，方便开发人员实现这些重要目标：不重新发明轮子、软件重用、模块化、可移植性等。但在 Linux 内核中，库（传统意义上的库）根本不存在。话虽如此，内核源代码树中的 lib/ 文件夹包含类似库的例程，其中一些例程内置于内核映像中，因此内核/模块开发人员可以在运行时使用。</p>
<p>好消息是，从广义上讲，有两种技术可以在内核空间中为内核模块实现“类似库”的功能：</p>
<ul>
<li>第一种技术是明确将多个源文件（包括所谓的“库”代码）“链接”到内核模块对象。</li>
<li>第二种技术称为模块堆叠。</li>
</ul>
<p>​    请继续阅读，我们将更详细地讨论这些技术。也许有点剧透，但知道这一点很有用，即前面的第一种方法通常优于第二种。不过，这确实取决于项目。请阅读以下部分中的详细信息；我们会在过程中列出一些优缺点。</p>
<h4 id="通过链接多个源文件执行库仿真"><a href="#通过链接多个源文件执行库仿真" class="headerlink" title="通过链接多个源文件执行库仿真"></a>通过链接多个源文件执行库仿真</h4><p>​    到目前为止，我们已经处理了非常简单的内核模块，这些模块只有一个C 源文件。那么（非常典型的）现实世界情况呢？单个内核模块有多个 C 源文件？所有源文件都必须编译，然后链接在一起作为单个 .ko 二进制对象。</p>
<p>例如，假设我们正在构建一个名为 projx 的内核模块项目。它由三个 C 源文件组成：prj1.c、prj2.c 和 prj3.c。我们希望最终的内核模块名为 projx.ko。 Makefile 是指定这些关系的地方，如下所示：</p>
<pre class="line-numbers language-none"><code class="language-none">obj-m :&#x3D; projx.o
projx-objs :&#x3D; prj1.o prj2.o prj3.o<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    在前面的代码中，请注意 projx 标签在 obj-m 指令之后的使用方式，以及在下一行中作为 -objs 指令的前缀的方式。当然，您可以使用任何标签代替 projx。我们前面的示例 Makefile 将让内核构建系统首先将三个单独的 C 源文件编译为单独的对象 (.o) 文件，然后将它们全部链接在一起以形成最终的二进制内核模块对象文件 projx.ko，正如我们所希望的那样。事实上，我们正是利用这种机制在我们书的源代码树中构建了一个小型的例程“库”（此“内核库”的源文件位于本书源代码树的根目录中：klib.h 和 klib.c）。当然，这个想法是其他内核模块可以通过链接到这里来使用这些函数！例如，在即将到来的第 8 章“模块作者的内核内存分配 - 第 1 部分”中，我们让 ch8/lowlevel_mem/lowlevel_mem.c<br>内核模块代码调用驻留在我们的库代码中的函数，其相对路径为：../../klib.c。通过将以下内容放入 lowlevel_mem 内核模块的 Makefile（前缀以粗体突出显示）来实现“链接到”我们所谓的库代码：</p>
<pre class="line-numbers language-none"><code class="language-none">FNAME_C :&#x3D; lowlevel_mem
[ … ]
PWD :&#x3D; $(shell pwd)
obj-m +&#x3D; $&#123;FNAME_C&#125;_lkm.o
lowlevel_mem_lkm-objs :&#x3D; $&#123;FNAME_C&#125;.o ..&#x2F;..&#x2F;klib.o<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    上面的最后一行指定要构建的源文件（到目标文件中）；它们是 lowlevel_mem.c 内核模块的代码和 ../../klib.c 库代码。然后，构建系统将两者链接到单个二进制内核模块 lowlevel_mem_lkm.ko，从而实现我们的目标。<br>​    接下来，让我们了解一些基本的东西——内核模块中函数和变量的范围。</p>
<h4 id="了解内核模块中的函数和变量作用域"><a href="#了解内核模块中的函数和变量作用域" class="headerlink" title="了解内核模块中的函数和变量作用域"></a>了解内核模块中的函数和变量作用域</h4><p>​    在深入研究之前，快速重新查看一些基础知识是个好主意。使用 C 编程时，您将了解以下内容：</p>
<ul>
<li>在函数内本地声明的变量显然是该函数的本地变量，并且仅在该函数内具有作用域（函数返回时局部变量“消失”，因此它们被称为“自动”。一个常见的错误是<br>尝试引用其作用域之外的局部或自动变量；这通常称为作用域后使用 (UAS) 或返回后使用 (UAR) 缺陷）。</li>
<li>以静态限定符为前缀的变量和函数仅在当前“单元”内具有作用域；实际上，它们在其中声明的文件中。这很好，因为它有助于减少命名空间污染。在函数内声明的静态数据变量在函数调用之间保留其值。</li>
</ul>
<p>​    在 2.6 Linux（即 &lt;= 2.4.x，现在已经过时了）之前，内核模块静态和全局变量以及所有函数在整个内核中都是自动可见的。回想起来，这显然不是一个好主意。</p>
<p>​    该决定从 2.5（以及 2.6 以后的现代 Linux）开始被推翻：所有内核模块变量（静态和全局数据）和函数默认作用域仅限于该内核模块，因此在其外部不可见。因此，</p>
<p>​    如果两个内核模块 lkmA 和 lkmB 有一个名为 maya 的全局（或静态）变量，则它对它们每个都是唯一的；没有冲突。要更改范围，LKM 框架提供了 EXPORT_SYMBOL() 宏。使用它，您可以将数据项或函数声明为作用域中的全局变量 - 实际上，</p>
<p>对任何其他内核模块都可见。<br>让我们举一个简单的例子。我们有一个名为 prj_core 的内核模块，它包含一个全局变量和一个函数：</p>
<pre class="line-numbers language-none"><code class="language-none">static int my_glob &#x3D; 5;
static long my_foo(int key)
&#123; [...]
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    虽然变量 my_glob 和函数 my_foo() 都可以在此内核模块内部使用，但它们在内核模块外部都无法看到。这是故意的。为了使它们在此内核模块外部可见，我们可以导出它们：</p>
<pre class="line-numbers language-none"><code class="language-none">int my_glob &#x3D; 5;
EXPORT_SYMBOL(my_glob);
long my_foo(int key)
&#123; [...]
&#125;
EXPORT_SYMBOL(my_foo);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    现在，它们都在此内核模块之外具有作用域（请注意，在前面的代码块中，static 关键字已被故意删除）。其他内核模块现在可以“看到”并使用它们。确切地说，这个想法主要体现在两个方面：</p>
<p>​    首先，内核通过 EXPORT_SYMBOL*() 宏导出经过深思熟虑的全局变量和函数子集，这些子集构成了内核功能以及其他子系统的一部分。现在，这些全局变量和函数是可见的，因此可以从内核模块中使用！我们很快就会看到一些示例用法。</p>
<p>​    这个想法还产生了一个非常重要的推论：树外内核模块只能访问内核中已明确导出的函数和变量。</p>
<p>​    其次，内核模块作者（通常是设备驱动程序）使用这个概念来导出某些数据和/或功能，以便其他内核模块（在更高的抽象级别）可以利用此设计并使用这些数据和/或功能 - 这个概念称为模块堆叠，我们将很快通过示例深入探讨它。例如，对于第一个用例，设备驱动程序作者可能想要处理（陷入）来自外围设备的硬件中断。一种常见的方法是通过 request_threaded_irq() API：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; kernel&#x2F;irq&#x2F;manage.c
int request_threaded_irq(unsigned int irq, irq_handler_t handler,
irq handler t thread fn nsigned long irqflags
const char *devname, void *dev_id)
&#123;
 struct irqaction *action;
[...]
 return retval;
&#125;
EXPORT_SYMBOL(request_threaded_irq);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    正是因为 request_threaded_irq() 函数是导出的，所以它才能在设备驱动程序中被调用，而设备驱动程序通常被写成内核模块（我们经常这样做，但不是树上的模块）。同样，模块开发人员通常需要一些“便利”例程 — 例如字符串处理例程。Linux 内核在 lib/string.c 中提供了几个常见字符串处理函数的实现（您希望它们存在）：str[n]casecmp()、str[n|l|s]cpy()、str[n|l]cat()、str[n]cmp()、<code>strchr[nul]()</code>、str[n|r]chr()、str[n]len() 等等。当然，这些都是通过 EXPORT_SYMBOL() 宏导出的，以便模块作者能够看到它们，从而可以使用它们。</p>
<p>​    另一方面，让我们看一下内核深处的核心 CFS（完全公平调度程序）CPU 调度代码的（微小）部分。在这里，pick_next_task_fair() 函数是当我们需要找到另一个任务进行上下文切换时由调度代码调用的函数：</p>
<p>​    由于前面的函数没有用任何 EXPORT_SYMBOL() 宏标记，因此它永远不能被内核模块调用。它仍然是私有的核心内核；这当然是一个经过深思熟虑的设计决定。 您还可以使用相同的宏将数据结构标记为导出。</p>
<p>​    另外，应该很明显，只有全局范围的数据（而不是局部变量）才能标记为导出。（仅供参考，如果您想了解 EXPORT_SYMBOL() 宏的工作原理，请参阅本章的“进一步阅读”部分。） </p>
<p>​    回想一下我们关于内核模块许可的简短讨论。Linux 内核有一个有趣的主张：还有一个名为 EXPORT_SYMBOL_GPL() 的宏。它就像它的表亲 EXPORT_SYMBOL() 宏一样，只是导出的函数或数据项只对在其 MODULE_LICENSE() 宏中包含单词 GPL 的内核模块可见！</p>
<p>​    要查看所有导出的符号，请导航到内核源代码树的根目录并发出 make export_report 命令。但请注意，这仅适用于已配置和构建的内核树。现在让我们看看实现类似库的内核功能的另一种关键方法：模块堆叠。 </p>
<h4 id="理解模块堆叠"><a href="#理解模块堆叠" class="headerlink" title="理解模块堆叠"></a>理解模块堆叠</h4><p>​    这里的第二个重要思想 - 模块堆叠 - 是我们现在将深入研究的内容。 模块堆叠是一个概念，它在某种程度上为内核模块作者提供了“类似库”的功能。在这里，我们通常以这样的方式构建我们的项目或产品设计，即我们有一个或多个“核心”内核模块，其工作是充当某种库。它将包括将导出到项目中其他内核模块（以及任何其他想要使用它们的人；上一节讨论了这一点）的数据结构和功能（函数/API）。 为了更好地理解这个概念，让我们看几个真实的例子。 首先，在我的主机系统（Ubuntu 22.04.3 LTS 原生 Linux 系统）上，我在 Oracle VirtualBox 7.0 虚拟机管理程序应用程序上运行了一个来宾 VM。好的， 在主机系统上执行快速 lsmod 并过滤字符串 vbox 会显示以下内容：</p>
<p>​    回想一下我们之前的讨论，在看到的四列中，第三列是使用计数。它在第一行中为 0，但在第三行中值为 3。不仅如此，vboxdrv 内核模块在其右侧（使用计数列之后）列出了两个内核模块。如果在第三列之后出现任何内核模块，则它们表示模块依赖关系；这样理解：右侧显示的内核模块依赖于左侧的内核模块。因此，在前面的示例中，vboxnetadp 和 vboxnetflt 内核模块依赖于 vboxdrv 内核模块。以何种方式依赖它？当然，它们调用函数（API）和/或使用驻留在 vboxdrv 核心内核模块中的数据结构！一般来说，第三列右侧显示的内核模块意味着它们正在调用一个或多个函数和/或使用左侧内核模块的数据结构（导致使用计数增加；这个使用计数是引用计数器的一个很好的例子（这里，它实际上是一个 32 位原子变量），我们将在上一章深入研究）。实际上，vboxdrv 内核模块类似于“库”（在有限的意义上，除了提供模块化功能外，没有与用户模式库相关的任何通常的用户空间内涵）。您可以看到，在这个快照中，它的使用计数是 3，依赖于它的内核模块堆叠在它之上——字面意思！（您可以在 lsmod 输出的前两行中看到它们。）另外，请注意 vboxnetflt 内核模块的使用计数为正（1），但其右侧没有显示内核模块；这仍然意味着此刻有某个东西正在使用它，通常是进程或线程。</p>
<h4 id="模拟“类库”功能-总结和结论"><a href="#模拟“类库”功能-总结和结论" class="headerlink" title="模拟“类库”功能 - 总结和结论"></a>模拟“类库”功能 - 总结和结论</h4><p>那么，让我们简要总结一下我们在内核模块空间中模拟类库功能时学到的要点。我们探索了两种技术：</p>
<ul>
<li>我们使用的第一种方法是将多个源文件链接在一起形成一个内核模块。</li>
<li>这与模块堆叠技术相反，在模块堆叠技术中，我们实际上构建了多个内核模块并将它们“堆叠”在一起。</li>
</ul>
<p>​    第一种技术不仅效果很好，而且还有以下优点：</p>
<ul>
<li>我们不必明确标记（通过 EXPORT_SYMBOL()）我们使用的每个函数和/或数据项为导出。</li>
</ul>
<p>这些函数和数据仅适用于它们实际链接到的内核模块（而不是任何其他模块）。这是一件好事！所有这些都是以稍微调整 Makefile 为代价的——非常值得。</p>
<p>“链接”（第一种）方法的一个缺点：当链接多个文件时，内核模块的大小可能会变得非常大。</p>
<p>至此，您学习了内核编程的一项强大功能 - 能够将多个源文件链接在一起以形成一个内核模块，和/或利用模块堆叠设计，这两者都允许您开发更复杂的内核项目。（在进入下一个主题领域之前，请先完成示例代码和建议的作业。）</p>
<p>现在，可以将参数传递给内核模块吗？以下部分将向您展示如何传递参数！</p>
<h4 id="将参数传递给内核模块"><a href="#将参数传递给内核模块" class="headerlink" title="将参数传递给内核模块"></a>将参数传递给内核模块</h4><p>一种常见的调试技术是检测您的代码；也就是说，在适当的位置插入打印，以便您可以跟踪代码所采用的路径。</p>
<h4 id="声明和使用模块参数"><a href="#声明和使用模块参数" class="headerlink" title="声明和使用模块参数"></a>声明和使用模块参数</h4><p>​    模块参数在模块插入（insmod/modprobe）时作为名称-值对传递给内核模块。</p>
<p>例如，假设我们有一个名为 mp_debug_level 的模块参数；然后，我们可以在 insmod 时传递它的值，如下所示：</p>
<pre class="line-numbers language-none"><code class="language-none">sudo insmod .&#x2F;modparams1.ko mp_debug_level&#x3D;2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    这里，mp 前缀代表模块参数。当然，不需要这样命名；这样命名很繁琐，但始终遵循这样的约定有助于使大型代码库的阅读更加直观。</p>
<p>​    这将非常强大。现在，最终用户可以决定他们希望以什么样的详细程度发出调试级别消息。我们可以轻松地将默认值设置为 0，这样模块默认不会发出任何调试消息。</p>
<p>​    您可能想知道它是如何工作的：内核模块没有 main() 函数，因此没有常规的 (argc、argv) 参数列表，那么您究竟如何传递参数呢？这只是一个链接器技巧……只需执行以下操作：<strong>将您想要的模块参数声明为全局（静态）变量，然后通过使用 module_param() 宏向构建系统指定将其视为模块参数。</strong></p>
<p>​    通过我们的第一个模块参数的演示内核模块，很容易看到这一点（与往常一样，可以在本书的 GitHub 存储库中找到完整的源代码和 Makefile）：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; ch5&#x2F;modparams&#x2F;modparams1&#x2F;modparams1.c
[ ... ]
&#x2F;* 模块参数 *&#x2F;
static int mp_debug_level;
module_param(mp_debug_level, int, 0660);
MODULE_PARM_DESC(mp_debug_level,
&quot;调试级别 [0-2]; 0 &#x3D;&gt; 无调试消息，2 &#x3D;&gt; 高详细程度&quot;);
static char *mp_strparam &#x3D; &quot;我的字符串参数&quot;;
module_param(mp_strparam, charp, 0660);
MODULE_PARM_DESC(mp_strparam, &quot;演示字符串参数&quot;);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">题外话：在上面的 static int mp_debug_level; 语句中，将其更改为 static int mp_debug_level &#x3D;0; 并没有什么坏处，因此明确将变量初始化为 0，对吗？嗯，没有：内核的 scripts&#x2F;checkpatch.pl 脚本输出显示，内核社区认为这不是一种好的编码风格；如果
您这样做，则会触发此“错误”：错误：不要将静态初始化为 0
#28：文件：modparams1.c:28：
+static int mp_debug_level &#x3D; 0;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>在前面的代码块中，我们已通过 module_param() 宏将两个变量声明为模块参数。module_param() 宏本身有三个参数：</p>
<ul>
<li>第一个参数：我们希望在代码中将其视为模块参数的变量。应使用 static 限定符声明。</li>
<li>第二个参数：其数据类型。</li>
<li>第三个参数：权限（实际上，它通过 sysfs 可见；稍后将对此进行解释）。</li>
</ul>
<p>​    接下来，MODULE_PARM_DESC() 宏允许我们“描述”参数代表的内容。想想看：这就是您如何告知内核模块（或驱动程序）的最终用户哪些参数实际上可用。查找是通过 modinfo(8) 实用程序执行的。此外，您可以使用 -p 选项开关专门打印模块参数信息，如下所示：</p>
<pre class="line-numbers language-none"><code class="language-none">$ cd &lt;booksrc&gt;&#x2F;ch5&#x2F;modparams&#x2F;modparams1 ; make
[ … ]
$ modinfo -p .&#x2F;modparams1.ko<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>parm: mp_debug_level:Debug level [0-2]; 0 =&gt; 无调试消息<br>parm: mp_strparam:A demo string 参数 (charp)<br>modinfo 输出显示可用的模块参数（如果有）。在这里，我们可以看到我们的 modparams1.ko 内核模块有两个参数：它们的名称、描述和数据类型（最后一个组件，在括号内；顺便说一下，charp 是“字符指针”，一个字符串）然后显示出来。好的，现在让我们快速运行一下我们的演示内核模块：</p>
<pre class="line-numbers language-none"><code class="language-none">$ sudo dmesg -C
$ sudo insmod .&#x2F;modparams1.ko
$ sudo dmesg
[630238.316261] modparams1:modparams1_init(): 已插入
[630238.316685] modparams1:modparams1_init(): 模块参数传递<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在这里，我们从 dmesg 输出中看到，由于我们没有明确传递任何内核模块参数，模块变量显然保留了它们的默认（原始）值。让我们重做一遍，这次将显式值传递给模块参数：</p>
<pre class="line-numbers language-none"><code class="language-none">sudo rmmod modparams1
sudo insmod .&#x2F;modparams1.ko mp_debug_level&#x3D;2 mp_strparam&#x3D;\&quot;Hello modp
sudo dmesg
[...]
[630359.270765] modparams1:modparams1_exit(): removed
[630373.572641] modparams1:modparams1_init(): inserted
[630373.573096] modparams1:modparams1_init(): module parameters passe<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    它按预期工作。是不是很有趣：（参数）变量现在已经在内核内存中被修改，并且使用了我们从用户空间传递的新值！</p>
<h4 id="内核不允许浮点数"><a href="#内核不允许浮点数" class="headerlink" title="内核不允许浮点数"></a>内核不允许浮点数</h4><p>​    几年前，一个年轻且相对缺乏经验的小伙子（我）在开发温度传感器设备驱动程序时，有过一次有趣的经历（尽管当时并不那么有趣）。他试图将以毫摄氏度为单位的温度值表示为精确到小数点后三位的“常规”摄氏度温度值，他做了类似以下的事情：</p>
<pre class="line-numbers language-none"><code class="language-none">int 温度；
double 温度_fp；
[... 处理…]
temperature_fp &#x3D; 温度 &#x2F; 1000.0；
printk(KERN_INFO &quot;温度为 %.3f 摄氏度\n&quot;,temperature_fp);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    从那以后一切都走下坡路了！值得尊敬的 LDD（Linux 设备驱动程序，由 Corbet、Rubini 和 Kroah￾Hartman 编写）一书指出了我的错误 - 内核空间不允许浮点 (FP) 算法！这是一个有意识的设计决定；保存处理器 (FP) 状态、打开 FP 单元、对其进行操作，然后关闭并恢复 FP 状态，这些在内核中执行的操作根本不值得。建议内核（或驱动程序）开发人员不要在内核空间中尝试执行 FP 工作。那么，您会问，如何进行（如我的示例）温度转换？很简单：将整数毫摄氏度值传递到用户空间并在那里执行 FP 工作！在很多情况下，在内核中执行某些类型的工作是完全错误的；用户空间是进行此类工作的正确场所（与每条规则一样，也有一些例外）。这包括执行浮点运算、文件 I/O（是的，不要尝试通过系统调用之类的代码路径在内核中执行文件读写）和运行应用程序，尽管内核确实提供了（相当令人惊讶但有时非常有用的）通过 UMH（用户模式帮助程序）API（如 call_usermodehelper() 等）执行这些操作的能力（谨慎使用！）等等。</p>
<h4 id="在内核中强制执行-FP"><a href="#在内核中强制执行-FP" class="headerlink" title="在内核中强制执行 FP"></a>在内核中强制执行 FP</h4><p>​    虽然我们说过内核空间不允许使用 FP，但确实存在一种强制内核执行浮点运算的方法：将浮点代码放在 kernel_fpu_begin() 和 kernel_fpu_end() 宏之间。在内核代码库中，有几处地方恰恰使用了这种技术（通常是一些涵盖加密/AES、CRC 等的代码路径）。<br>建议很明确：典型的模块（或驱动程序）开发人员应该只在内核中执行整数运算。然而，为了测试整个场景（永远记住，经验方法——实际尝试——是唯一现实的前进方式！），我们编写了一个简单的内核模块，尝试执行一些 FP 工作。代码的关键部分显示在这里：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; ch5&#x2F;fp_in_kernel&#x2F;fp_in_kernel.c
static double num &#x3D; 22.0, den &#x3D; 7.0, mypi;
static int __init fp_in_lkm_init(void)
&#123;
[...]
kernel_fpu_begin();
mypi &#x3D; num&#x2F;den;
kernel_fpu_end();
#if 1
pr_info(&quot;%s: PI &#x3D; %.4f &#x3D; %.4f\n&quot;, OURMODNAME, mypi, num&#x2F;den);
#endif
return 0; &#x2F;* 成功 *&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>它实际上有效，直到我们尝试通过 printk() 显示 FP 值！</p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="MakeFile"><a href="#MakeFile" class="headerlink" title="MakeFile"></a>MakeFile</h2><pre class="line-numbers language-none"><code class="language-none">https:&#x2F;&#x2F;github.com&#x2F;PacktPublishing&#x2F;Linux-Kernel-Programming_2E.git&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    这个Makefile在 ch5 / lkm_template下。</p>
<pre class="line-numbers language-none"><code class="language-none"># ***************************************************************# This program is part of the source code released for the book
#  &quot;Linux Kernel Programming&quot; 2E
#  (c) Author: Kaiwan N Billimoria
#  Publisher:  Packt
#  GitHub repository:
#  https:&#x2F;&#x2F;github.com&#x2F;PacktPublishing&#x2F;Linux-Kernel-Programming_2E
#
# From: Ch 5 : Writing Your First Kernel Module LKMs, Part 2
# ***************************************************************
# Brief Description:
# A &#39;better&#39; Makefile template for Linux LKMs (Loadable Kernel Modules); besides
# the &#39;usual&#39; targets (the build, install and clean), we incorporate targets to
# do useful (and indeed required) stuff like:
#  - adhering to kernel coding style (indent+checkpatch)
#  - several static analysis targets (via sparse, gcc, flawfinder, cppcheck)
#  - two _dummy_ dynamic analysis targets (KASAN, LOCKDEP); just to remind you!
#  - a packaging (.tar.xz) target and
#  - a help target.
#
# To get started, just type:
#  make help
#
# For details, please refer the book, Ch 5, section
# &#39;A &quot;better&quot; Makefile template for your kernel modules&#39;.
#
# AUTHOR : Kaiwan N Billimoria
# DESCRIPTION : A simple kernel module &#39;better&#39; Makefile template
# LICENSE : Dual MIT&#x2F;GPL
# VERSION : 0.2

#------------------------------------------------------------------
# IMPORTANT : Set FNAME_C to the kernel module name source filename (without .c).
# This enables you to use this Makefile as a template; just update this variable!
# As well, the MYDEBUG variable (see it below) can be set to &#39;y&#39; or &#39;n&#39; (no being
# the default)
FNAME_C :&#x3D; lkm_template
ifeq ($(FNAME_C),)
  $(error ERROR: you Must set the FNAME_C variable in the Makefile)
endif
#------------------------------------------------------------------

#--- To support cross-compiling for kernel modules
# For architecture (cpu) &#39;arch&#39;, invoke make as:
#  make ARCH&#x3D;&lt;arch&gt; CROSS_COMPILE&#x3D;&lt;cross-compiler-prefix&gt;
# F.e. to cross-compile for the AArch64:
#  make ARCH&#x3D;arm64 CROSS_COMPILE&#x3D;aarch64-linux-gnu-
#
# Alternately:
#  export ARCH&#x3D;&lt;arch&gt;
#  export CROSS_COMPILE&#x3D;&lt;cross-compiler-prefix&gt;
#  make
#
# The KDIR var is set to a sample path below; you&#39;re expected to update it on
# your box to the appropriate path to the kernel source tree for that arch.
ifeq ($(ARCH),arm)
  # *UPDATE* &#39;KDIR&#39; below to point to the ARM Linux kernel source tree on your box
  KDIR ?&#x3D; ~&#x2F;arm_prj&#x2F;kernel&#x2F;linux
else ifeq ($(ARCH),arm64)
  # *UPDATE* &#39;KDIR&#39; below to point to the ARM64 (AArch64) Linux kernel source
  # tree on your box
  KDIR ?&#x3D; ~&#x2F;arm64_prj&#x2F;kernel&#x2F;linux
else ifeq ($(ARCH),powerpc)
  # *UPDATE* &#39;KDIR&#39; below to point to the PPC64 Linux kernel source tree on your box
  KDIR ?&#x3D; ~&#x2F;ppc_prj&#x2F;kernel&#x2F;linux-5.4
else
  # &#39;KDIR&#39; is the Linux &#39;kernel headers&#39; package on your host system; this is
  # usually an x86_64, but could be anything, really (f.e. building directly
  # on a Raspberry Pi implies that it&#39;s the host)
  KDIR ?&#x3D; &#x2F;lib&#x2F;modules&#x2F;$(shell uname -r)&#x2F;build
endif
#---

# Compiler
CC     :&#x3D; $(CROSS_COMPILE)gcc-12
#CC    :&#x3D; clang
STRIP :&#x3D; $&#123;CROSS_COMPILE&#125;strip

PWD            :&#x3D; $(shell pwd)
obj-m          +&#x3D; $&#123;FNAME_C&#125;.o

#--- Debug or production mode?
# Set the MYDEBUG variable accordingly to y&#x2F;n resp. We keep it off (n) by default.
# (Actually, debug info is always going to be generated when you build the
# module on a debug kernel, where CONFIG_DEBUG_INFO is defined, making this
# setting of the ccflags-y (or the older EXTRA_CFLAGS) variable mostly redundant
# (besides the still useful -DDEBUG).
# This simply helps us influence the build on a production kernel, forcing
# generation of debug symbols, if so required. Also, realize that the DEBUG
# macro is turned on by many CONFIG_*DEBUG* options; hence, we use a different
# macro var name, MYDEBUG).
MYDEBUG :&#x3D; n
DBG_STRIP :&#x3D; y
ifeq ($&#123;MYDEBUG&#125;, y)
# https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;latest&#x2F;kbuild&#x2F;makefiles.html#compilation-flags
# EXTRA_CFLAGS deprecated; use ccflags-y
  ccflags-y   +&#x3D; -DDEBUG -g -ggdb -gdwarf-4 -Wall -fno-omit-frame-pointer -fvar-tracking-assignments
  DBG_STRIP :&#x3D; n
else
  ccflags-y   +&#x3D; -UDEBUG
endif
# We always keep the dynamic debug facility enabled; this allows us to turn
# dynamically turn on&#x2F;off debug printk&#39;s later... To disable it simply comment
# out the following line
ccflags-y   +&#x3D; -DDYNAMIC_DEBUG_MODULE
KMODDIR ?&#x3D; &#x2F;lib&#x2F;modules&#x2F;$(shell uname -r)

# Gain access to kernel configs
include $(KDIR)&#x2F;.config

# Strip the module? Note:
# a) Only strip debug symbols else it won&#39;t load correctly
# b) WARNING! Don&#39;t strip modules when using CONFIG_MODULE_SIG* crytographic security
ifdef CONFIG_MODULE_SIG
  DBG_STRIP :&#x3D; n
endif
ifdef CONFIG_MODULE_SIG_ALL
  DBG_STRIP :&#x3D; n
endif
ifdef CONFIG_MODULE_SIG_FORCE
  DBG_STRIP :&#x3D; n
endif


all:
	@echo
	@echo &#39;--- Building : KDIR&#x3D;$&#123;KDIR&#125; ARCH&#x3D;$&#123;ARCH&#125; CROSS_COMPILE&#x3D;$&#123;CROSS_COMPILE&#125; ccflags-y&#x3D;&quot;$&#123;ccflags-y&#125;&quot; MYDEBUG&#x3D;$&#123;MYDEBUG&#125; DBG_STRIP&#x3D;$&#123;DBG_STRIP&#125; ---&#39;
	@$&#123;CC&#125; --version|head -n1
	@echo
	make -C $(KDIR) M&#x3D;$(PWD) modules
	if [ &quot;$&#123;DBG_STRIP&#125;&quot; &#x3D; &quot;y&quot; ]; then \
	   $&#123;STRIP&#125; --strip-debug $&#123;FNAME_C&#125;.ko ; \
	fi
install:
	@echo
	@echo &quot;--- installing ---&quot;
	@echo &quot; [First, invoking the &#39;make&#39; ]&quot;
	make
	@echo
	@echo &quot; [Now for the &#39;sudo make install&#39; ]&quot;
	sudo make -C $(KDIR) M&#x3D;$(PWD) modules_install
	sudo depmod
	@echo &quot; [If !debug and !(module signing), stripping debug info from $&#123;KMODDIR&#125;&#x2F;extra&#x2F;$&#123;FNAME_C&#125;.ko]&quot;
	if [ &quot;$&#123;DBG_STRIP&#125;&quot; &#x3D; &quot;y&quot; ]; then \
           sudo $&#123;STRIP&#125; --strip-debug $&#123;KMODDIR&#125;&#x2F;extra&#x2F;$&#123;FNAME_C&#125;.ko ; \
	fi
nsdeps:
	@echo &quot;--- nsdeps (namespace dependencies resolution; for possibly importing ns&#39;s) ---&quot;
	make -C $(KDIR) M&#x3D;$(PWD) nsdeps
clean:
	@echo
	@echo &quot;--- cleaning ---&quot;
	@echo
	make -C $(KDIR) M&#x3D;$(PWD) clean
# from &#39;indent&#39;; comment out if you want the backup kept
	rm -f *~

# Any usermode programs to build? Insert the build target(s) below


#--------------- More (useful) targets! -------------------------------
INDENT :&#x3D; indent

# code-style : &quot;wrapper&quot; target over the following kernel code style targets
code-style:
	make indent
	make checkpatch

# indent- &quot;beautifies&quot; C code - to conform to the the Linux kernel
# coding style guidelines.
# Note! original source file(s) is overwritten, so we back it up.
indent:
ifeq (,$(shell which indent))
	$(error ERROR: install indent first)
endif
	@echo
	@echo &quot;--- applying kernel code style indentation with indent ---&quot;
	@echo
	mkdir bkp 2&gt; &#x2F;dev&#x2F;null; cp -f *.[chsS] bkp&#x2F;
	$&#123;INDENT&#125; -linux --line-length95 *.[chsS]
	  # add source files as required

# Detailed check on the source code styling &#x2F; etc
checkpatch:
	make clean
	@echo
	@echo &quot;--- kernel code style check with checkpatch.pl ---&quot;
	@echo
	$(KDIR)&#x2F;scripts&#x2F;checkpatch.pl --no-tree -f --max-line-length&#x3D;95 *.[ch]
	  # add source files as required

#--- Static Analysis
# sa : &quot;wrapper&quot; target over the following kernel static analyzer targets
sa:
	make sa_sparse
	make sa_gcc
	make sa_flawfinder
	make sa_cppcheck

# static analysis with sparse
sa_sparse:
ifeq (,$(shell which sparse))
	$(error ERROR: install sparse first)
endif
	make clean
	@echo
	@echo &quot;--- static analysis with sparse ---&quot;
	@echo
# If you feel it&#39;s too much, use C&#x3D;1 instead
# NOTE: deliberately IGNORING warnings from kernel headers!
	make -Wsparse-all C&#x3D;2 CHECK&#x3D;&quot;&#x2F;usr&#x2F;bin&#x2F;sparse --os&#x3D;linux --arch&#x3D;$(ARCH)&quot; -C $(KDIR) M&#x3D;$(PWD) modules 2&gt;&amp;1 |egrep -v &quot;^\.&#x2F;include&#x2F;.*\.h|^\.&#x2F;arch&#x2F;.*\.h&quot;

# static analysis with gcc
sa_gcc:
	make clean
	@echo
	@echo &quot;--- static analysis with gcc ---&quot;
	@echo
	make W&#x3D;1 -C $(KDIR) M&#x3D;$(PWD) modules

# static analysis with flawfinder
sa_flawfinder:
ifeq (,$(shell which flawfinder))
	$(error ERROR: install flawfinder first)
endif
	make clean
	@echo
	@echo &quot;--- static analysis with flawfinder ---&quot;
	@echo
	flawfinder *.[ch]

# static analysis with cppcheck
sa_cppcheck:
ifeq (,$(shell which cppcheck))
	$(error ERROR: install cppcheck first)
endif
	make clean
	@echo
	@echo &quot;--- static analysis with cppcheck ---&quot;
	@echo
	cppcheck -v --force --enable&#x3D;all -i .tmp_versions&#x2F; -i *.mod.c -i bkp&#x2F; --suppress&#x3D;missingIncludeSystem .

# Packaging: just generates a tar.xz of the source as of now
tarxz-pkg:
	rm -f ..&#x2F;$&#123;FNAME_C&#125;.tar.xz 2&gt;&#x2F;dev&#x2F;null
	make clean
	@echo
	@echo &quot;--- packaging ---&quot;
	@echo
	tar caf ..&#x2F;$&#123;FNAME_C&#125;.tar.xz *
	ls -l ..&#x2F;$&#123;FNAME_C&#125;.tar.xz
	@echo &#39;&#x3D;&#x3D;&#x3D; package created: ..&#x2F;$(FNAME_C).tar.xz &#x3D;&#x3D;&#x3D;&#39;
	@echo &#39;        TIP: When extracting, to extract into a directory with the same name as the tar file, do this:&#39;
	@echo &#39;              tar -xvf $&#123;FNAME_C&#125;.tar.xz --one-top-level&#39;

help:
	@echo &#39;&#x3D;&#x3D;&#x3D; Makefile Help : additional targets available &#x3D;&#x3D;&#x3D;&#39;
	@echo
	@echo &#39;TIP: Type make &lt;tab&gt;&lt;tab&gt; to show all valid targets&#39;
	@echo &#39;FYI: KDIR&#x3D;$&#123;KDIR&#125; ARCH&#x3D;$&#123;ARCH&#125; CROSS_COMPILE&#x3D;$&#123;CROSS_COMPILE&#125; ccflags-y&#x3D;&quot;$&#123;ccflags-y&#125;&quot; MYDEBUG&#x3D;$&#123;MYDEBUG&#125; DBG_STRIP&#x3D;$&#123;DBG_STRIP&#125;&#39;

	@echo
	@echo &#39;--- &#39;usual&#39; kernel LKM targets ---&#39;
	@echo &#39;typing &quot;make&quot; or &quot;all&quot; target : builds the kernel module object (the .ko)&#39;
	@echo &#39;install     : installs the kernel module(s) to INSTALL_MOD_PATH (default here: &#x2F;lib&#x2F;modules&#x2F;$(shell uname -r)&#x2F;).&#39;
	@echo &#39;            : Takes care of performing debug-only symbols stripping iff MYDEBUG&#x3D;n and not using module signature&#39;
	@echo &#39;nsdeps      : namespace dependencies resolution; for possibly importing namespaces&#39;
	@echo &#39;clean       : cleanup - remove all kernel objects, temp files&#x2F;dirs, etc&#39;

	@echo
	@echo &#39;--- kernel code style targets ---&#39;
	@echo &#39;code-style : &quot;wrapper&quot; target over the following kernel code style targets&#39;
	@echo &#39; indent     : run the $(INDENT) utility on source file(s) to indent them as per the kernel code style&#39;
	@echo &#39; checkpatch : run the kernel code style checker tool on source file(s)&#39;

	@echo
	@echo &#39;--- kernel static analyzer targets ---&#39;
	@echo &#39;sa         : &quot;wrapper&quot; target over the following kernel static analyzer targets&#39;
	@echo &#39; sa_sparse     : run the static analysis sparse tool on the source file(s)&#39;
	@echo &#39; sa_gcc        : run gcc with option -W1 (&quot;Generally useful warnings&quot;) on the source file(s)&#39;
	@echo &#39; sa_flawfinder : run the static analysis flawfinder tool on the source file(s)&#39;
	@echo &#39; sa_cppcheck   : run the static analysis cppcheck tool on the source file(s)&#39;
	@echo &#39;TIP: use Coccinelle as well: https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;v6.1&#x2F;dev-tools&#x2F;coccinelle.html&#39;

	@echo
	@echo &#39;--- kernel dynamic analysis targets ---&#39;
	@echo &#39;da_kasan   : DUMMY target: this is to remind you to run your code with the dynamic analysis KASAN tool enabled; requires configuring the kernel with CONFIG_KASAN On, rebuild and boot it&#39;
	@echo &#39;da_lockdep : DUMMY target: this is to remind you to run your code with the dynamic analysis LOCKDEP tool (for deep locking issues analysis) enabled; requires configuring the kernel with CONFIG_PROVE_LOCKING On, rebuild and boot it&#39;
	@echo &#39;TIP: Best to build a debug kernel with several kernel debug config options turned On, boot via it and run all your test cases&#39;

	@echo
	@echo &#39;--- misc targets ---&#39;
	@echo &#39;tarxz-pkg  : tar and compress the LKM source files as a tar.xz into the dir above; allows one to transfer and build the module on another system&#39;
	@echo &#39;        TIP: When extracting, to extract into a directory with the same name as the tar file, do this:&#39;
	@echo &#39;              tar -xvf $&#123;FNAME_C&#125;.tar.xz --one-top-level&#39;
	@echo &#39;help       : this help target&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="内核编程基础：线程和进程"><a href="#内核编程基础：线程和进程" class="headerlink" title="内核编程基础：线程和进程"></a>内核编程基础：线程和进程</h2><h4 id="理解进程和中断上下文"><a href="#理解进程和中断上下文" class="headerlink" title="理解进程和中断上下文"></a>理解进程和中断上下文</h4><p>​    在第 4 章“编写您的第一个内核模块 - 第 1 部分”中，我们介绍了一个简短的部分，题为“理解内核架构 - 第 1 部分”（如果您还没有阅读，我建议您在继续阅读之前先阅读一下）。我们现在将扩展此讨论。 首先，现代处理器以不同的特权级别执行代码。</p>
<p>​    例如，基于 x86 的处理器提供四个特权级别（或环），<strong>其中 Ring 0 是最高特权，Ring 3 是最低特权。同样，ARM-32（AArch32）有七种执行模式，其中六种是特权模式。 ARM64（AArch64）使用异常级别的概念（EL0 到 EL3，其中 EL0 是最低特权，EL3 是最高特权）。</strong>但实际上，关键点是：所有现代操作系统都只使用两个可用的 CPU 特权级别 - 一个特权级别和一个代码执行的非特权级别；我们分别将它们称为内核模式和用户模式。 了解大多数现代操作系统在设计上都是单片的也很重要。单片这个词的字面意思是一块大石头。我们稍后会讨论这如何应用于我们最喜欢的操作系统！ 现在，只需理解单片的含义：当进程或线程发出系统调用时，它会切换到（特权）内核模式，执行内核代码，并可能处理内核数据。是的，没有内核或内核线程代表它执行代码；发出系统调用的进程（或线程）切换到内核模式并自行执行内核代码。因此， 我们说内核代码在用户空间进程或线程的上下文中执行——我们将此执行上下文称为进程上下文。想想看， 内核的很大一部分正是以这种方式执行的，包括设备驱动程序的大部分代码。 （仅供参考，即使是处理器异常（如页面错误或系统调用）的处理以及 CPU 调度，也是在进程上下文中执行的）。</p>
<p>​    好吧，您可能会问，现在我明白了这一点，除了进程上下文之外，内核代码还能如何执行？还有另一种方式：当硬件中断（来自外围设备 - 键盘、网卡、磁盘等）触发时，CPU 的控制单元会保存当前上下文并立即重新引导 CPU 运行中断处理程序（中断服务例程 (ISR)）的代码。现在，此代码也在内核（特权）模式下运行 - 实际上，这是切换到内核模式的另一种异步方式（除非您已经在那里）！许多设备驱动程序的中断代码路径都是这样执行的；我们现在说以这种方式执行的内核/驱动程序代码是在中断上下文中执行的。 （再次提醒，仅供参考，一些现代驱动程序使用线程中断模型，其中大多数中断处理发生在内核线程上下文中，实际上是在进程上下文中）。</p>
<p>​    因此，任何和所有内核（或模块/驱动程序）代码都由以下两种上下文之一输入和执行：进程上下文：由于进程或线程发出系统调用或发生处理器异常（例如页面错误），内核代码被执行，并且内核数据被处理，因此进入内核空间；它通常是同步的。中断上下文：由于外围芯片断言硬件中断，内核（和/或驱动程序）代码被执行，并且内核数据被处理，因此进入内核空间；它是异步的。</p>
<p>​    图 6.1 显示了概念视图：用户模式进程和线程在非特权用户上下文中执行；用户模式线程可以通过发出系统调用切换到特权内核模式。该图还向我们展示了 Linux 中也存在纯内核线程；它们与用户模式线程非常相似，关键区别在于它们仅在内核空间中执行；它们甚至无法“看到”用户 VAS。通过系统调用（或处理器异常）同步切换到内核模式，任务现在在进程上下文中运行内核代码。（内核线程也在进程上下文中运行内核代码）。 然而，硬件中断是另一回事——它们抢占任何东西，包括内核代码，导致执行异步切换到内核特权（如果尚未处于其中）。它们执行的代码（通常是内核或设备驱动程序的中断处理程序）在所谓的中断上下文中运行。 图 6.1 显示了更多细节——中断上下文的上半部分和下半部分、内核线程和工作队列；</p>
<p><img src="./image-20240709083036733.png" alt="image-20240709083036733"></p>
<h4 id="了解进程虚拟地址空间-VAS-的基础知识"><a href="#了解进程虚拟地址空间-VAS-的基础知识" class="headerlink" title="了解进程虚拟地址空间 (VAS) 的基础知识"></a>了解进程虚拟地址空间 (VAS) 的基础知识</h4><p>​    虚拟内存的一个基本“规则”是：所有可能可寻址的内存都在一个盒子里；也就是说，它是沙盒化的。我们将这个“盒子”视为进程映像或进程 VAS。从盒子“外面”看是不可能的。</p>
<p>​    用户 VAS 被划分为称为段的同质内存区域，或者更技术性地说，称为映射（因为它们是通过 mmap() 系统调用在内部构建的）。图 6.2 显示了每个 Linux（用户空间）进程将具有的最小映射（段）：</p>
<p><img src="./image-20240709083145083.png" alt="image-20240709083145083"></p>
<p>​    让我们快速分析一下这些段或映射（从下往上）：</p>
<p>文本段：这是存储机器代码的地方；它是处理器核心的指令指针（或等效）寄存器指向的地方，而进程的线程执行代码时 - 静态/固定大小（模式：r-x）。<br>（请注意，文本段不是从虚拟地址 0x0 开始的；它比该地址高出一段距离。事实上，第一个虚拟页面 - 封装 NULL 地址（0x0）的页面 - 称为“空陷阱”页面。稍后将详细介绍空陷阱。）</p>
<p>数据段：紧挨着文本映射。这是存储全局和静态数据变量的地方（模式：rw-）。实际上，有三个不同的数据段：</p>
<p>初始化数据段：预初始化的全局/静态变量存储在此处 - 静态/固定大小。</p>
<p>未初始化的数据段：未初始化的全局/静态变量存储在此处（它们在运行时自动初始化为 0；此区域有时称为 bss）– 静态/固定大小。</p>
<p>堆段：用于内存分配和释放的标准 C 库 API（熟悉的 malloc() 例程系列）从此处获取内存。这也不完全正确。在现代 glibc 上，只有 malloc() 调用低于 MMAP_THRESHOLD 字节（默认为 128 KB）的内存才会从堆中获取内存。任何请求的更大大小都作为进程 VAS 中的单独映射分配（通过强大的 mmap() 系统调用），称为匿名（或 anon）映射。堆是一个动态段（它可以增大/缩小大小）。我们通俗地说，堆“向更高的虚拟地址增长”。堆上最后一个合法可引用的位置称为程序中断（可通过调用 sbrk(0) 检索）。</p>
<p>共享库（文本、数据）：进程动态链接到的所有共享库都映射（在运行时，通过加载器调用 mmap()）到进程 VAS 中 - 位于堆顶部和 main() 线程堆栈之间的某个位置（模式：r-x/rw-）。堆和堆栈之间的这个一般区域还保存任何其他线程的堆栈内存（除了 main() 的堆栈内存）、匿名内存和共享内存区域。</p>
<p>堆栈：使用后进先出 (LIFO) 语义的内存区域；堆栈用于实现高级语言的函数调用机制，实际上保存线程的执行上下文。堆栈（框架）包括参数传递、局部变量实例化（和销毁）和返回值传播的工作。它是一个动态段。在所有现代处理器（包括 x86 和 ARM 系列）上，堆栈都会向较低的虚拟地址“向下增长”（称为完全下降堆栈）。每次调用函数时，都会根据需要分配和初始化堆栈框架（或调用框架）；堆栈框架的精确布局非常依赖于 CPU（您必须参考相应的 CPU 应用程序二进制接口 (ABI) 文档 - 请参阅进一步阅读部分以获取参考资料）。处理器核心的堆栈指针 (SP) 寄存器（或等效寄存器）始终指向当前框架，即堆栈的顶部；随着堆栈向较低的（虚拟）地址增长，堆栈的顶部实际上是最低的（虚拟）地址！这不直观，但确实如此（模式：rw-）。 （仅供参考，当然还有更多内容；当调用函数时，堆栈框架实际上并没有被分配和初始化，那样会太慢。同样，当函数返回时，它们也不会被释放；随着你的进步，你会学到更多。）当然，你会明白进程必须包含至少一个执行线程（线程是进程内的执行路径）；</p>
<p>一个保证的线程当然是 main() 函数。在图 6.2 中，作为示例，我们展示了三个执行线程——main、thrd2 和 thrd3。此外，正如预期的那样，每个线程都共享进程 VAS 中的所有内容，除了堆栈；正如你所知，每个线程都有自己的私有堆栈。main 的堆栈显示在进程（用户）VAS 的最顶部； thrd2 和 thrd3 线程的堆栈，可以分配在库映射之间的任何位置，并且主堆栈通过此区域中的两个（蓝色）方块表示。</p>
<h4 id="组织进程、线程及其堆栈-用户和内核空间"><a href="#组织进程、线程及其堆栈-用户和内核空间" class="headerlink" title="组织进程、线程及其堆栈 - 用户和内核空间"></a>组织进程、线程及其堆栈 - 用户和内核空间</h4><p>​    传统的 UNIX 进程模型 - <strong>一切都是进程；如果不是进程，那就是文件</strong> - 有很多优点。经过五十多年的发展，它仍然是操作系统所遵循的模型，这一事实充分证明了这一点。当然，如今，线程被视为原子执行上下文；线程是进程内的执行路径。</p>
<p>​    线程共享所有进程资源，包括用户 VAS、打开的文件、信号配置、IPC 对象、凭据、分页表等，但堆栈除外。每个线程都有自己的私有堆栈区域（这完全说得通；如果不是，线程如何真正并行运行，因为堆栈保存着执行上下文）。</p>
<p>​    我们关注线程而不是进程的另一个原因在第 10 章“CPU 调度程序 - 第 1 部分”中得到了更清晰的说明。现在，我们只能这样说：线程，而不是进程，是内核可调度实体（又名 KSE）——它是被调度到 CPU 核心上运行的实体。这是 Linux 操作系统架构的一个关键方面的结果。在 Linux 上，每个线程（包括内核线程）都映射到称为任务结构的内核元数据结构。任务结构（也称为进程描述符）本质上是一个大型内核数据结构，内核将其用作每个线程的属性结构。对于每个活动线程，内核都会维护一个相应的任务结构（参见图 6.3，不用担心，我们将在接下来的章节中详细介绍任务结构）。下一个要掌握的关键点是，我们要求每个线程每个 CPU 支持的特权级别都有一个堆栈。在 Linux 等现代操作系统上，我们支持两种 CPU 特权级别 - 非特权用户模式（或用户空间）和特权内核模式（或内核空间）。因此，在 Linux 上，每个活动用户空间线程都有两个堆栈：</p>
<ul>
<li><p>用户空间堆栈：当线程执行用户模式代码路径时，此堆栈正在运行。</p>
</li>
<li><p>内核空间堆栈：当线程切换到内核模式（通过系统调用或处理器异常）并执行内核代码路径（在进程上下文中）时，此堆栈正在运行。</p>
</li>
</ul>
<p>  ​    当然，每条好规则都有一个例外：内核线程（简称 kthreads）是纯粹存在于内核中的线程，因此只能“查看”内核（虚拟）地址空间；它们无法“看到”用户空间。因此，这些 kthreads 只会执行内核空间代码路径，每个 kthread 只有一个堆栈 - 内核空间堆栈。</p>
<p>  ​    此外，这可能会让您想知道在处理硬件中断处理程序时使用什么堆栈；尽管依赖于架构，但内核通常为每个核心维护一个 IRQ 堆栈，仅用于此目的。</p>
<p>  ​    下面是一个简单示例，可帮助您明确这一关键点：当您执行经典的 K&amp;R C“Hello, world”进程时，内核会创建该进程；这会让内核设置并初始化几个对象 - 其中包括进程任务结构、其进程 VAS（包括用户模式堆栈）以及一个独特的内核模式堆栈。一旦运行，进程当然会首先在用户模式下执行 printf() API，从而利用用户空间堆栈（main()）。printf() 在设置完成后，发出 write() 系统调用！这会让我们的进程切换到内核模式，并实际将 Hello, world\n 字符串（通过内核中的 tty 层代码路径）写入 stdout 设备。由于它现在执行内核代码（在内核模式下），因此它会利用其内核空间堆栈。图 6.3 将地址空间分为两个部分 - 用户空间和内核空间。</p>
<p>  ​    在图表的上部 - 用户空间 - 您可以看到多个进程及其用户 VAS 的概念视图。在下部 - 内核空间（所有用户模式进程共享的大型单片空间） - 您可以看到对应于每个用户模式线程的内核元数据结构 struct task_struct（我们将在稍后详细介绍）和该线程的内核模式堆栈。<br>  此外，我们（在最底部）看到三个内核线程（标记为 kthrd1、kthrd2 和 kthrdn）；正如预期的那样，它们也有一个代表其内部（属性）的 task_struct 元数据结构和一个内核模式堆栈：</p>
<p>  <img src="./image-20240709083427425.png" alt="image-20240709083427425"></p>
<h4 id="运行一个小脚本来查看，活跃的进程和线程的数量"><a href="#运行一个小脚本来查看，活跃的进程和线程的数量" class="headerlink" title="运行一个小脚本来查看，活跃的进程和线程的数量"></a>运行一个小脚本来查看，活跃的进程和线程的数量</h4>  <pre class="line-numbers language-none"><code class="language-none">****************************************************************
# * Brief Description:
# * Counts the total number of processes, user and kernel threads currently
# * alive on the system.
# * For details, please refer the book, Ch 6.
# ****************************************************************
set -euo pipefail
echo &quot;System release info:&quot;
which lsb_release &gt;&#x2F;dev&#x2F;null &amp;&amp; lsb_release -a || true
[[ -f &#x2F;etc&#x2F;issue ]] &amp;&amp; cat &#x2F;etc&#x2F;issue
[[ -f &#x2F;etc&#x2F;os-release ]] &amp;&amp; cat &#x2F;etc&#x2F;os-release

total_prcs&#x3D;$(ps -A|wc -l)
printf &quot;\nTotal # of processes alive               &#x3D; %9d\n&quot; $&#123;total_prcs&#125;

# ps -LA shows all threads
total_thrds&#x3D;$(ps -LA|wc -l)
printf &quot;Total # of threads alive                 &#x3D; %9d\n&quot; $&#123;total_thrds&#125;

# ps aux shows all kernel threads names (col 11) in square brackets; count &#39;em
total_kthrds&#x3D;$(ps aux|awk &#39;&#123;print $11&#125;&#39;|grep &quot;^\[&quot;|wc -l)

printf &quot;Total # of kernel threads alive          &#x3D; %9d\n&quot; $&#123;total_kthrds&#125;
printf &quot;Thus, total # of user mode threads alive &#x3D; %9d\n&quot; $(($&#123;total_thrds&#125;-$&#123;total_kthrds&#125;))

exit 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
  <pre class="line-numbers language-none"><code class="language-none">System release info:
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 22.04.4 LTS
Release:	22.04
Codename:	jammy
Ubuntu 22.04.4 LTS \n \l

PRETTY_NAME&#x3D;&quot;Ubuntu 22.04.4 LTS&quot;
NAME&#x3D;&quot;Ubuntu&quot;
VERSION_ID&#x3D;&quot;22.04&quot;
VERSION&#x3D;&quot;22.04.4 LTS (Jammy Jellyfish)&quot;
VERSION_CODENAME&#x3D;jammy
ID&#x3D;ubuntu
ID_LIKE&#x3D;debian
HOME_URL&#x3D;&quot;https:&#x2F;&#x2F;www.ubuntu.com&#x2F;&quot;
SUPPORT_URL&#x3D;&quot;https:&#x2F;&#x2F;help.ubuntu.com&#x2F;&quot;
BUG_REPORT_URL&#x3D;&quot;https:&#x2F;&#x2F;bugs.launchpad.net&#x2F;ubuntu&#x2F;&quot;
PRIVACY_POLICY_URL&#x3D;&quot;https:&#x2F;&#x2F;www.ubuntu.com&#x2F;legal&#x2F;terms-and-policies&#x2F;privacy-policy&quot;
UBUNTU_CODENAME&#x3D;jammy

Total # of processes alive               &#x3D;       321
Total # of threads alive                 &#x3D;      1038
Total # of kernel threads alive          &#x3D;       174
Thus, total # of user mode threads alive &#x3D;       864<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="用户空间组织"><a href="#用户空间组织" class="headerlink" title="用户空间组织"></a>用户空间组织</h4><p>  ​    参考我们在上一节中运行的 countem.sh Bash 脚本，我们现在将其分解并讨论一些关键点，目前将我们自己限制在进程 VAS 的用户空间部分。请仔细阅读并理解这一点（我们在以下讨论中引用的数字是关于我们运行小脚本以查看活动进程和线程数部分中 countem.sh 脚本的示例运行）。为了更好地理解，我将图表的用户空间部分放在这里：</p>
<p>  <img src="./image-20240709090242097.png" alt="image-20240709090242097"></p>
<p>  ​    在这里（图 6.4），您可以看到三个单独的用户模式进程。每个进程至少有一个执行线（main() 线程）。在这里，我们展示了三个进程，P1、P2 和 Pn，它们分别有一个、三个和两个线程，包括 main()。在我们前面的示例运行（运行小脚本以查看活动进程和线程数部分中显示的脚本）countem.sh 脚本中，Pn 的 n=234。<br>  请注意，这些图表纯粹是概念性的。例如，实际上，PID 为 2 的进程通常是名为 kthreadd 的单线程内核线程。<br>  每个进程由多个段（技术上称为映射）组成。广义上讲，用户模式段（或映射）如下：</p>
<ul>
<li>文本：代码；r-x</li>
<li>数据段：rw-；由三个不同的映射组成 - 已初始化的数据段、未初始化的数据段（或 bss）和“向上增长”的堆</li>
<li>库映射：对于每个共享库的文本和数据，进程动态链接到：</li>
<li><p>向下增长的堆栈。</p>
<p>​    关于这些堆栈，我们从前面的示例运行中看到，系统上当前有 398 个用户模式线程处于活动状态。这意味着也有 398 个用户空间堆栈，因为每个活动用户模式线程都会有一个用户模式堆栈。关于这些用户空间线程堆栈，我们可以得出以下结论：main() 线程始终有一个用户空间堆栈，它将位于用户 VAS 的最顶部（高端）附近。如果进程是单线程的（只有一个 main() 线程），那么它将只有一个用户模式堆栈；图 6.4 中的 P1 进程显示了这种情况。另外，很重要的一点是：在 Linux 上，任何 foo() 系统调用通常都会成为内核中的 sys_foo() 函数。此外，通常但并非总是，这个 sys_foo() 函数是一个调用“真实”代码 do_[*]_foo() 的包装器。进一步的细节：在内核代码中，您可能会看到 SYSCALL_DEFINEn(foo, …) 类型的宏；该宏将成为 sys_foo() 例程。附加的数字 n 在 [0,6] 范围内；它是通过系统调用从用户空间传递给内核的参数数量。如果进程是多线程的，则每个线程（包括 main()）都有一个用户模式线程堆栈；图 6.4 中的进程 P2 和 Pn 说明了这种情况。堆栈是在调用 fork(2)（针对 main()）或 pthread_create()（针对进程内剩余线程）时分配的，这会导致此代码路径在内核（在 kernel/fork.c 中）的进程上下文中执行：sys_fork() —&gt;kernel_clone()<br>​    另外，仅供参考，Linux 上的 Pthreads 创建库 API pthread_create() 调用（非常特定于 Linux 的）clone() 系统调用（内核中的代码在此处：kernel/fork.c:sys_clone()）。此系统调用最终调用 kernel_clone()；传递的参数（特别是标志值）会告知内核如何创建自定义进程（换句话说，就是线程）！</p>
<p>​    用户空间堆栈当然是动态的；它们可以增大（也可以缩小）到堆栈大小资源限制 RLIMIT_STACK（通常为 8 MB - 您可以使用 prlimit 实用程序来查找）。</p>
<h4 id="内核空间组织"><a href="#内核空间组织" class="headerlink" title="内核空间组织"></a>内核空间组织</h4><p>​    我们继续讨论 countem.sh Bash 脚本（我们在运行一个小脚本来查看活动进程和线程的数量部分中运行过该脚本），现在我们将对其进行分解并讨论一些关键点，将我们自己限制在 VAS 的内核空间部分。请注意仔细阅读并理解这一点（同时阅读我们在前面运行的 countem.sh 脚本的示例中输出的数字）。为了更好地理解，我将图表的内核空间部分放在这里（图 6.5）</p>
<p><img src="./image-20240709090556679.png" alt="image-20240709090556679"></p>
<p>​    同样，从我们前面的示例运行中，您可以看到系统上当前有 398 个用户模式线程和 116 个内核线程处于活动状态。这总共产生了 514 个内核空间堆栈。怎么会这样？如前所述，每个用户模式线程都有两个堆栈 - 一个用户模式堆栈和一个内核模式堆栈。因此，我们将为每个用户模式线程提供 398 个内核模式堆栈，并为（纯）内核线程提供 116 个内核模式堆栈（回想一下，内核线程只有一个内核模式堆栈 - 它们根本无法“看到”用户空间），总共有 (398+116=) 514 个内核空间堆栈。让我们列出内核模式堆栈的一些特征：每个活动的用户模式线程（包括 main()）都会有一个内核模式堆栈。内核模式堆栈的大小是固定的（静态的），而且非常小。实际上，它们的大小在 32 位操作系统上为 2 页，在 64 位操作系统上为 4 页（页面大小通常为 4 KB）。</p>
<p>​    不要简单地假设页面大小始终为 4 KB - 在用户空间中，使用 getpagesize() 系统调用查询其值；在内核空间中，PAGE_SIZE 宏产生相同的值。</p>
<p>它们是在线程创建时分配的（通常归结为内核代码：kernel_clone() —&gt; copy_process() —&gt;<br>dup_task_struct()）。</p>
<p>再次，让我们明确这一点：每个用户模式线程都有两个堆栈 - 一个用户模式堆栈和一个内核模式堆栈。此规则的例外是内核线程；它们只有一个内核模式堆栈（因为它们没有用户映射，因此没有用户空间段）。在图 6.5 的下半部分，我们展示了三个内核线程 - kthrd1、kthrd2 和 kthrdn（在我们前面的示例运行中，kthrdn 的 n=116）。此外，每个内核线程都有一个任务结构和一个在创建时分配给它的内核模式堆栈。内核模式堆栈在大多数方面都与其用户模式堆栈相似 - 每次调用内核空间内的函数时，都会设置一个堆栈框架（框架布局特定于架构并构成 CPU ABI 文档的一部分；有关这些详细信息，请参阅进一步阅读部分）。CPU 有一个寄存器来跟踪堆栈的当前位置（通常称为堆栈指针 (SP)），堆栈向较低的虚拟地址“增长”。但是，与动态用户模式堆栈不同，内核模式堆栈的大小是固定的并且很小。对于内核/驱动程序开发人员来说，内核模式堆栈大小非常小（两页或四页），这有一个重要含义 - 执行堆栈密集型工作（例如使用大型局部变量或递归）时要非常小心，不要溢出内核堆栈。</p>
<p>​    存在一个内核可配置（CONFIG_FRAME_WARN）来警告您编译时内核堆栈使用率过高；</p>
<h4 id="总结内核中的线程、任务结构和堆栈"><a href="#总结内核中的线程、任务结构和堆栈" class="headerlink" title="总结内核中的线程、任务结构和堆栈"></a>总结内核中的线程、任务结构和堆栈</h4><p>​    好的，很好，现在让我们总结一下从前面的讨论和 countem.sh 脚本示例运行中获得的知识和发现（在运行小脚本以查看活动进程和线程的数量部分）：</p>
</li>
<li><p>任务结构：</p>
<ul>
<li>每个活动线程（用户或内核）在内核中都有一个相应的任务结构（struct task_struct）；这就是内核跟踪和管理它的方式。此外，所有线程的属性都存储在这里（您将在“了解和访问内核任务结构”部分中了解更多相关信息）</li>
<li>由于系统上总共有 514 个线程（用户和内核）处于活动状态，这意味着内核内存中总共有 514 个任务（元数据）结构（在代码中，它是 struct task_struct），其中我们可以说以下内容：</li>
<li>其中 398 个任务结构代表用户线程。</li>
<li>其余（514 - 398 =）116 个任务结构代表内核线程。</li>
</ul>
</li>
<li><p>堆栈：</p>
<ul>
<li>每个用户空间线程都有两个堆栈：<ul>
<li>用户模式堆栈（线程执行用户模式代码路径时使用）</li>
<li>内核模式堆栈（线程执行内核模式代码路径时使用）</li>
<li>此外，当硬件中断处理程序执行其代码路径时，还存在一个单独的每核 IRQ 堆栈供使用</li>
</ul>
</li>
<li>异常情况：内核线程只有一个堆栈，即内核模式堆栈</li>
<li>因此，对于我们的 ch6/countem.sh 脚本的示例运行，我们有：<ul>
<li>398 个用户空间堆栈（在用户空间中）。</li>
<li>以上，加上 398 个内核空间堆栈（在内核内存中）。</li>
<li>以上，加上 116 个内核空间堆栈（用于 116 个活动内核线程）。</li>
<li>总计为 398 + 398 + 116 = 912 个堆栈！ （在 64 位 Linux 上，每个内核模式堆栈有 4 页，假设页面大小为 4 KB，则堆栈内存占用了 4\*4096*912=14.25 MB 的 RAM）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>  ​    正如前面简要提到的，许多架构（包括 x86 和 ARM64）支持单独的每个 CPU 堆栈用于中断处理（称为 IRQ 堆栈）。当发生外部硬件中断时，CPU 的控制单元立即将控制权重新引导到最终的中断处理代码（可能在设备驱动程序内）。单独的每个 CPU 中断堆栈用于保存中断代码路径的堆栈帧；这有助于避免对被中断的进程/线程的现有（小）内核模式堆栈施加太大压力。IRQ 堆栈大小将与该体系结构的内核模式堆栈大小相同。（此外，像 x86_64 这样的体系结构支持更多类型的堆栈，但我们不会进一步深入研究）。<br>  好的，现在您已经了解了用户和内核空间在进程/线程及其堆栈方面的总体组织，让我们继续了解如何实际查看内核和用户空间堆栈的内容。除了对学习有用之外，这些知识还可以极大地帮助您进行调试。</p>
<h4 id="查看用户和内核堆栈"><a href="#查看用户和内核堆栈" class="headerlink" title="查看用户和内核堆栈"></a>查看用户和内核堆栈</h4><p>  ​    堆栈通常是调试会话的关键。堆栈保存了线程的当前执行上下文 - 它现在在哪个函数中执行代码，以及关键的是，它是如何到达这里的 - 这使我们能够推断历史记录（它在做什么以及发生了什么）。能够查看和解释线程的调用堆栈（又称调用链/调用跟踪/回溯）至关重要，这使我们能够了解我们究竟是如何到达这里的。所有这些宝贵的信息都驻留在堆栈中。但是，每个线程都有两个堆栈——用户空间和内核空间堆栈。我们如何查看它们的内容？在这里，我们将展示两种查看给定进程或线程的内核和用户模式堆栈的广泛方法，首先是通过传统方法，然后是较新的现代方法（通过 eBPF）。请继续阅读。查看堆栈的传统方法让我们首先学习使用我们称之为传统方法的方法查看给定进程或线程的内核和用户模式堆栈。让我们从内核模式堆栈开始。查看给定线程或进程的内核空间堆栈好消息；这很容易。 Linux 内核通过通常的机制使给定线程的内核堆栈可见，以将内核内部信息暴露给用户空间——强大而多功能的 proc 文件系统接口。只需读取伪文件 /proc/PID/stack 的内容即可。</p>
  <pre class="line-numbers language-none"><code class="language-none">charlie@charlie-ubuntu:~&#x2F;Linux-Kernel-Programming_2E&#x2F;ch6$ sudo cat &#x2F;proc&#x2F;1953&#x2F;stack
[&lt;0&gt;] do_wait+0x173&#x2F;0x320
[&lt;0&gt;] kernel_wait4+0xbd&#x2F;0x170
[&lt;0&gt;] __do_sys_wait4+0xad&#x2F;0xc0
[&lt;0&gt;] __x64_sys_wait4+0x1c&#x2F;0x30
[&lt;0&gt;] x64_sys_call+0x1e93&#x2F;0x20b0
[&lt;0&gt;] do_syscall_64+0x55&#x2F;0x90
[&lt;0&gt;] entry_SYSCALL_64_after_hwframe+0x73&#x2F;0xdd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>  ​    在前面的输出中，每一行代表堆栈上的一个调用框架（或堆栈框架）。为了帮助解读内核堆栈回溯，有必要了解以下几点：</p>
<p>  显示的名称是被调用函数的名称 - 例如，<br>  这里看到的第二个函数名为 do_syscall_64()（因为我们总是从下往上读取堆栈跟踪）。函数调用图的顺序是从下往上；因此输出应以自下而上的方式读取。因此，这里意味着<br>  （忽略最底部的第一个）调用图如下：<br>  do_syscall_64() —&gt; <strong>x64_sys_wait4() —&gt; </strong>do_sys_wait4() —&gt;kernel_wait4() —&gt; do_wait()。<br>  输出的每一行代表一个调用框架 - 实际上是调用链中的一个函数。如果调用框架以一个或多个 ? 为前缀，则表示调用框架是调用链中的一个函数。符号，这意味着内核无法可靠地解释此堆栈帧。忽略它，这是内核在说它很可能是一个无效的堆栈帧（遗留的一个小点）；内核回溯代码通常是正确的！（请注意，通常，堆栈内存的相同部分会被不断重用；这可能会留下与当前堆栈无关的先前调用堆栈的点。）</p>
<p>  ​    如前所述，在 Linux 上，任何 foo() 系统调用通常都会成为内核中的 sys_foo() 函数。此外，通常（但并非总是），sys_foo() 是一个调用“真实”代码 do_[*]_foo() 的包装器。</p>
<p>  现在，再看看前面的输出。应该很清楚：我们的 Bash进程目前正在内核中执行 do_wait() 函数；调用图清楚地向我们展示了它通过系统调用，即 wait4() 系统调用到达那里！这是完全正确的； shell 的工作方式是分叉一个子进程，然后通过 wait4(2) 系统调用等待其消亡。<br>  接下来，<code>&lt;func&gt;</code>+x/y 语法有什么用处—</p>
<p>  第一个数字（x，始终为十六进制）是从当前执行所在的函数开头的字节偏移量。<br>  第二个数字（y，同样为十六进制）是内核认为的这个函数的长度；它通常是正确的。</p>
<p>  因此，在这里，do_wait+0x184/0x340 意味着 do_wait() 函数正在从函数开头偏移 0x184（十进制 388）字节的位置执行其机器代码，并且函数的长度为 0x340（十进制 832）字节！ </p>
<p>  查看给定线程或进程的用户空间堆栈</p>
<p>  具有讽刺意味的是，在典型的 Linux 发行版上查看进程或线程的用户空间堆栈似乎更难（与查看内核模式堆栈相反，正如我们在上一节中看到的）。有一个实用程序可以做到这一点：<br>  gstack。实际上，它只是对脚本的简单包装，该脚本以批处理模式调用古老的 GDB 调试器，让 GDB 调用其回溯命令。</p>
<h4 id="eBPF-–-查看两个堆栈的现代方法"><a href="#eBPF-–-查看两个堆栈的现代方法" class="headerlink" title="eBPF – 查看两个堆栈的现代方法"></a>eBPF – 查看两个堆栈的现代方法</h4><p>  ​    现在 – 更令人兴奋！ – 让我们学习使用强大的现代方法的基础知识，利用（截至撰写本文时）称为扩展伯克利数据包过滤器 (eBPF) 的最新技术。我们确实在在线章节“内核工作区设置”中的“其他有用项目”部分中提到了 eBPF 项目。较旧的 BPF 已经存在很长时间了，并已用于网络数据包跟踪； eBPF 是一项相对较新的创新，仅在 4.x Linux 内核上可用（当然，这意味着您需要在 4.x 或更新的 Linux 系统上使用此方法）。</p>
<p>  ​    直接使用底层内核级 BPF 字节码技术（极其）困难；因此，好消息是该技术有几个易于使用的前端（工具和脚本）。在前端中，BPF 编译器集合 (BCC) 和 bpftrace 被认为非常有用。（可以在 <a target="_blank" rel="noopener" href="https://github.com/iovisor/bcc/blob/master/images/bcc_tracing_tools_2019.png">https://github.com/iovisor/bcc/blob/master/images/bcc_tracing_tools_2019.png</a> 找到显示当前 BCC 性能分析工具的图表；可以在 <a target="_blank" rel="noopener" href="http://www.brendangregg.com/ebpf.html#frontends">http://www.brendangregg.com/ebpf.html#frontends</a> 找到 eBPF 前端的列表。）</p>
<p>  ​    在这里，我们将使用名为 stackcount 的 BCC 工具进行快速演示（至少在 Ubuntu 上，这些 eBPF 工具以字符串 -bpfcc 为后缀，因此这个工具名为 stackcount-bpfcc）。另一个优点是，使用此工具可以同时查看内核和用户模式堆栈；无需单独的工具。</p>
<p>  您可以通过阅读此处的安装说明来为您的主机 Linux 发行版安装 BCC 工具：<br>  <a target="_blank" rel="noopener" href="https://github.com/iovisor/bcc/blob/master/INSTALL.md。在运行我们自定义的">https://github.com/iovisor/bcc/blob/master/INSTALL.md。在运行我们自定义的</a> 6.1 内核时，如何在我们的客户 Linux VM 上安装它们？您可以（不过，在早期的内核版本中，这可能会出现问题，需要运行发行版内核，例如 Ubuntu 或 Fedora 提供的内核）。</p>
<h4 id="理解和访问内核任务结构"><a href="#理解和访问内核任务结构" class="headerlink" title="理解和访问内核任务结构"></a>理解和访问内核任务结构</h4><p>  ​    正如您现在所了解的，每个用户和内核空间线程在 Linux 内核中都由包含其所有属性的元数据结构（任务结构）内部表示。任务结构在内核代码中表示如下：include/linux/sched.h:struct<br>  task_struct。</p>
<p>  ​    不幸的是，它经常被称为“进程描述符”，造成无尽的混乱！值得庆幸的是，短语任务结构要好得多；它代表一个可运行的任务——实际上是一个线程。</p>
<p>  因此，我们得到了：在 Linux 设计中，每个进程都由一个或多个线程组成，每个线程都映射到称为任务结构 (struct task_struct) 的内核元数据结构。</p>
<p>  ​    任务结构是线程的“根”元数据结构 - 它封装了操作系统为该线程所需的所有信息。这包括有关其内存（段/映射设置、分页表、使用信息等）、CPU 调度详细信息、当前打开的所有文件、其凭据、功能位掩码、计时器、锁、异步 I/O (AIO) 上下文、硬件上下文信息、信号配置、IPC 对象、资源限制、（可选）审计、安全和分析信息以及更多此类详细信息的概念表示。<br>  <img src="./image-20240709092348056.png" alt="image-20240709092348056"></p>
<h4 id="确定上下文"><a href="#确定上下文" class="headerlink" title="确定上下文"></a>确定上下文</h4><p>  正如您现在所知，内核代码在以下两种上下文之一中运行：</p>
<ul>
<li>进程（或任务）上下文</li>
<li><p>中断（原子）上下文</p>
<p>​    它们是互斥的 - 内核代码在任何给定时间点（我们很快会解释术语“原子”）在进程（有时是原子的）或中断上下文（始终是原子的）中运行。</p>
<p>​    为什么能够确定内核或驱动程序代码运行的上下文很重要？内核中的一条黄金法则是，您不能在任何类型的原子上下文中休眠（或阻塞）；这样做会导致内核错误。它会锁定系统，通常会导致内核崩溃。</p>
<p>​    为什么？好吧，首先要意识到休眠意味着上下文切换 - 在前一个任务进入休眠状态时切换 CPU 以运行另一个任务。因此，休眠意味着调用调度程序代码和随后的上下文切换（我们在第 10 章“CPU 调度程序 - 第 1 部分”和第 11 章“CPU 调度程序 - 第 2 部分”中详细介绍了这一点）。这确实是任何阻塞 API 的工作方式。但是，当在原子上下文中运行时 - 例如硬件中断（以及软件中断、softirq），或者当持有自旋锁时 - 必须在不阻塞、不休眠、不放弃 CPU 的情况下完成工作。这就是为什么使用“原子”这个词的原因；它意味着不间断地运行到完成。现在我们知道了这个规则 - 不要在原子上下文中休眠 - 问题出现了：我如何知道我的代码路径是否在原子上下文中运行？以下是您可以轻松确定内核/驱动程序代码当前正在执行的上下文的方法：#include <linux/preempt.h> if (in_task()) foo(); /<em> 在进程上下文中运行；通常可以安全休眠或 else bar(); /</em> 在原子上下文中运行；不安全休眠或阻塞 in_task() 宏返回布尔值；如果您的代码在进程（或任务）上下文中运行，则返回 True，通常可以安全地进入休眠状态；如果返回 False，则表示您处于某种原子上下文中（可能是中断上下文），因此永远无法安全地进入休眠状态。</p>
<p>​    您可能遇到过 in_interrupt() 宏的用法 - 如果它返回 True，则您的代码处于中断上下文中；如果返回 False，则不在中断上下文中。但是，对于现代代码，建议不要依赖此宏（因为禁用 Bottom Half (BH) 可能会干扰其工作）。因此，我们建议改用 in_task()。</p>
<p>​    不过请稍等！这可能会有点棘手：虽然 in_task() 返回 True 确实意味着您的代码处于进程上下文中，但这一事实本身并不能保证它当前是否是原子的，或者是否可以安全地进入休眠状态。例如，您可能在进程上下文中运行内核或驱动程序代码，但持有自旋锁（内核中使用的一种非常常见的锁）；在这里，锁定和解锁之间的代码 - 所谓的关键部分 - 必须以原子方式运行！这意味着尽管您的代码可能处于进程（或任务）上下文中，但如果它尝试发出任何可能阻塞（休眠）的 API，它仍会导致内核级错误！不用担心，锁定在本书的最后两章中详细介绍。）另外，请注意：（根据定义）当前宏的使用仅在进程上下文中运行时才被视为有效。</p>
<p>​    现在，您已经了解了有关任务结构的有用背景信息，如何通过当前宏访问它，以及找出内核或驱动程序代码当前正在运行的上下文。所以现在，让我们编写一些内核模块代码来检查一些内核任务结构！通过“current”使用任务结构在这里，我们将编写一个简单的内核模块来显示任务结构的几个成员。</p>
<p>​    此外，我希望您考虑一下：究竟是谁在运行此（或任何）内核模块（或内核）的初始化和清理代码路径？从我们了解到的情况来看，不是内核；如前所述，没有总体的“内核”进程……那么，谁在运行它？在 Linux 操作系统等单片内核中，答案应该很清楚：当用户空间进程（或线程）发出系统调用时，它会切换到内核模式并在进程上下文中运行内核（或模块）代码。所以，是的，它将是一个进程（或线程）。</p>
</li>
</ul>
<h3 id="内核内存管理内幕"><a href="#内核内存管理内幕" class="headerlink" title="内核内存管理内幕"></a>内核内存管理内幕</h3><h4 id="理解虚拟机分割"><a href="#理解虚拟机分割" class="headerlink" title="理解虚拟机分割"></a>理解虚拟机分割</h4><p>​    在本章中，我们将广泛地介绍 Linux 内核如何通过两种方式管理内存：</p>
<ul>
<li><p>基于虚拟内存的方法，其中内存被虚拟化（通常情况）</p>
</li>
<li><p>内核如何组织物理内存（RAM 页面）的视图</p>
</li>
</ul>
<p>​    首先，让我们从虚拟内存视图开始，然后在本章后面讨论物理内存组织。</p>
<p>​    正如我们在第 6 章“内核内部基本知识 - 进程和线程”中在“理解进程虚拟地址空间 (VAS) 的基础知识”部分中看到的那样，进程 VAS 的一个关键属性是它完全独立，是一个沙箱。你不能跳出框框看。在那一章的图 6.2 中，我们看到进程 VAS 的范围从虚拟地址 0x0 到我们简单称为“高地址”的范围。这个“高”地址的实际值是什么？它是 VAS 的最高范围，因此取决于用于寻址的位数；因此：</p>
<ul>
<li>在运行于 32 位处理器（或为 32 位编译）的 Linux 操作系统上，最高虚拟地址将为 2 ^ 32 = 4 GB。</li>
<li>在运行于（并为其编译）64 位处理器的 Linux 操作系统上，最高虚拟地址将为 2 ^ 64 = 16 EB。（EB 是 Exabyte 的缩写，即1,152,921,504,606,846,976 字节或 1,024 PB。显然，这是一个巨大的数量；16 EB 是 16 x 1018 的数字。）</li>
</ul>
<p>​    为简单起见，为了让数字易于管理，我们现在将重点放在 32 位地址空间上（我们当然也会介绍 64 位寻址）。因此，根据我们的讨论，在 32 位系统上，进程 VAS 的范围为 0 到 4 GB - 此区域由空白空间（未使用区域，称为稀疏区域或空洞）和有效内存区域组成，通常称为段（或更准确地说，映射）- 文本、数据、库和堆栈（所有这些内容已在第 6 章“内核内部基本知识 - 进程和线程”中详细介绍）。在我们理解虚拟内存的过程中，采用众所周知的 Hello, world K&amp;R C 程序并（在很大程度上）了解其在 Linux 系统上的内部工作原理很有用；这就是下一节要介绍的内容！</p>
<h4 id="从hello-c-发生了什么入手"><a href="#从hello-c-发生了什么入手" class="headerlink" title="从hello.c 发生了什么入手"></a>从hello.c 发生了什么入手</h4><pre class="line-numbers language-none"><code class="language-none">#include &lt;stdio.h&gt;
int main()
&#123;
	printf(&quot;Hello, World&quot;);
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    进程正在调用 printf() 函数。您编写了 printf() 的代码吗？<br>​    “不，当然没有，”您说，“它在标准 C 库中，通常是 Linux 上的 glibc (GNU libc)。是的，您是对的；但是等等，除非 printf() 的代码和数据（以及类似的所有其他库 API）实际上位于进程 VAS 中，否则我们如何访问它？（回想一下，您不能跳出框框！）为此，printf() 的代码（和数据）（实际上是整个 glibc 库）必须映射到进程框中——进程 VAS。它确实在进程 VAS 中映射，在库段中或映射中（如我们在第 6 章“内核内部要点 - 进程和线程”图 6.2 中看到的那样）。这种映射是如何发生的？</p>
<p>​    实际情况是，在应用程序启动时，作为 C 运行时环境设置的一部分，有一个小型的可执行和可链接格式 (ELF) 二进制文件（嵌入到您的 a.out 二进制可执行文件中），称为加载器 (ld.so 或 ld-linux.so)。它在执行初期就被赋予控制权。它检测所有必需的共享库，并通过打开它们并发出 mmap() 系统调用，将所有共享库（库文本（代码）、数据和任何其他必需的段）映射到进程 VAS 中。所以，现在，一旦库的代码和数据被映射到进程 VAS 中，进程就可以访问它，因此 - 等待它 - printf() API 可以成功调用！（我们在这里跳过了内存映射和链接的详细细节。）进一步验证这一点，ldd 脚本（以下输出来自 x86_64 系统）显示情况确实如此：</p>
<pre class="line-numbers language-none"><code class="language-none">ldd test
linux-vdso.so.1 (0x000075523d94d000)
libc.so.6 &#x3D;&gt; &#x2F;usr&#x2F;lib&#x2F;libc.so.6 (0x000075523d71c000)
&#x2F;lib64&#x2F;ld-linux-x86-64.so.2 &#x3D;&gt; &#x2F;usr&#x2F;lib64&#x2F;ld-linux-x86-64.so.2 (0x000075523d94f000)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>需要注意的几点：<br>    每个 Linux 进程（自动且默认）至少链接到两个对象：glibc 共享库和程序加载器（编译/链接期间不需要显式链接器切换）。加载程序的名称因架构而异。在这里，在我们的 x86_64 系统上，它是 ld-linux-x86-64.so.2。在前面的 ldd 输出中，右侧括号内的地址是映射位置的（用户空间）虚拟地址。例如，在前面的输出中，glibc 被映射到我们的进程 VAS 中的用户虚拟地址（UVA），等于 0x00007feb7b85b000。请注意，它依赖于运行时（当启用地址空间布局随机化 (ASLR) 语义时，它也会在每次运行时发生变化（ASLR 通常默认启用；详细信息见下文））。</p>
<p>出于安全原因（以及在 x86 以外的架构上），最好使用objdump 实用程序来查找此类详细信息。尝试对 Hello, world 二进制可执行文件执行 strace，您将看到大量 mmap() 系统调用，它们映射到 glibc（和其他）段中！</p>
<p>现在让我们更深入地研究我们简单的 Hello, world 应用程序。</p>
<h4 id="超越-printf-API"><a href="#超越-printf-API" class="headerlink" title="超越 printf() API"></a>超越 printf() API</h4><p>正如您所知道的，printf() API 执行其漂亮的格式化并调用write() 系统调用，它当然会将“Hello, world”字符串写入 stdout –这里，默认情况下，stdout 将是（伪）终端窗口或控制台设备。我们还知道，由于 write() 是一个系统调用，这意味着运行此代码的当前进程（或线程）——进程上下文——现在必须切换到内核模式并运行 write() 的内核代码（单片内核架构）！确实如此。但是请稍等一下：write() 的内核代码位于内核 VAS 中（请参阅第 6 章“内核内部要点 - 进程和线程”，图 6.1）。这里的要点是关键的：如果内核 VAS 不在盒子里，那么我们究竟该如何调用它？好吧，可以通过将用户和内核 VAS 放入两个单独的 4 GB 空间来实现，<br>但这种方法会导致非常慢的上下文切换（以及昂贵的转换后备缓冲区 (TLB) 刷新），所以根本无法做到这一点。</p>
<p>它的设计方式是这样的：用户和内核 VAS 都“生活”在同一个“盒子”中 - 可用的 VAS。具体怎么做？通过按照某个用户：内核 :: U：K 比率在用户和内核之间划分可用地址空间。这称为 VM拆分（比率 U:K 通常以兆字节、千兆字节、太字节甚至<br>拍字节表示）。在许多 ARM-32 (AArch32) 和 x86-32 系统上，默认 VM 拆分通常为 3:1<br>GB。下图（图 7.1）代表具有 3:1 VM 拆分（单位为 GB）的 32 位 Linux 进程；也就是说，共 4 GB 的进程 VAS 被拆分为 3GB 的用户空间和 1 GB 的内核空间。换句话说，拆分可以描述为U:K :: 3:1。</p>
<p><img src="./../七月笔记学习日志/7.10/image-20240710081725324.png" alt="image-20240710081725324"></p>
<h4 id="虚拟寻址和地址转换"><a href="#虚拟寻址和地址转换" class="headerlink" title="虚拟寻址和地址转换"></a>虚拟寻址和地址转换</h4><p>​    在深入研究这些细节之前，清楚地理解几个关键点非常重要。考虑一个 C 程序中的一小段典型代码片段：</p>
<pre class="line-numbers language-none"><code class="language-none">int i &#x3D; 5;
printf(&quot;i 的地址是 0x%x\n&quot;, &amp;i);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    在功能丰富的现代操作系统（如 Linux、Unix、Windows 或 Mac）上运行此程序时，</p>
<p>​    您看到的 printf() 发出的地址（几乎）始终是虚拟地址，而不是物理地址。此外，我们区分两种虚拟地址：</p>
<p>​    如果您在用户空间进程中运行此代码，您将看到的变量 i 的地址是用户虚拟地址，简称 UVA。如果您在内核或内核模块中运行此代码（当然，您将使用 printk()（或类似）API 代替 printf()），您将看到的变量 i 的地址是内核虚拟地址 (KVA)。</p>
<p>​    接下来，正如人们通常认为的那样，虚拟地址不是绝对值（从 0 开始的偏移量）；它是为 MMU（现代微处理器硅片内的内存管理单元）设计和解释的位掩码：</p>
<p>​    在 32 位 Linux 操作系统上，32 个可用位被分为所谓的页面全局目录 (PGD) 值、页表 (PT) 值和偏移量。这些成为物理内存的索引，MMU 通过这些索引可以访问当前进程上下文的内核页表，执行地址转换。我们不打算在这里介绍 MMU 级地址转换的深层细节。它也非常特定于架构。</p>
<p>​    正如可以预料的那样，在 64 位系统上，即使使用 48 位寻址，虚拟地址位掩码中也会有更多字段。好吧，如果这个 48 位寻址是 x86_64 处理器上的典型情况，那么 64 位虚拟地址中的位是如何布局的？未使用的 16 个 MSB 位会发生什么？下图回答了这个问题；它表示 x86_64 Linux 系统上 64 位虚拟地址（位掩码）的分解：</p>
<p><img src="./image-20240710081838701.png" alt="image-20240710081838701"></p>
<p>​    本质上，对于 48 位寻址，我们使用位 0 到 47（LSB 48 位）并忽略MSB（最高有效位）16 位，将其视为符号扩展。不过，未使用的 MSB 16 位的值（如下所示）会随所引用的地址空间而变化：</p>
<ul>
<li>在内核 VAS 中，MSB 16 位始终设置为 1。</li>
<li>在用户 VAS 中，MSB 16 位始终设置为 0。</li>
</ul>
<p>​    这是有用的信息！了解这一点后，只需查看（完整的 64 位）虚拟地址，您就可以立即判断它是 KVA 还是 UVA；因此，在 x86_64</p>
<p>Linux 系统上：</p>
<ul>
<li>KVA 的格式始终为 0xffff XXXX XXXX XXXX</li>
<li>UVA 的格式始终为 0x0000 XXXX XXXX XXXX</li>
</ul>
<p>需要注意的是：上述格式仅适用于将虚拟地址定义为 KVA 或 UVA 的处理器（实际上是 MMU）；x86 和 ARM 系列处理器（32 位和 64 位）都属于此类。这里，MSB（位 63）充当分页表的选择器；如果设置，则将内核分页表（位于 swapper_pg_dir）用作正在引用的内核虚拟地址；如果清除，则将进程分页表（进程分页表基址的物理地址位于 x86[_64] 上的 CR3 寄存器中，ARM[64] 上的 TTBR0（转换表基址寄存器 0）寄存器中）用作正在引用的用户虚拟地址（而 TTBR1 保存内核主 PGD – swapper_pg_dir 的基址）。</p>
<p>另一点：N 级分页是什么意思？重新看一下图 7.2；在到达偏移量之前，有四个“间接”级别——页面全局目录 (PGD)、页面上层目录 (PUD)、页面中间目录 (PMD) 和页表条目 (PTE)。这是分页模式的一个属性——间接级别的数量；这里是 4，因此，我们称之为 4 级分页（稍后，图 7.6 将向您展示各种 N 级分页值）。</p>
<h4 id="从虚拟地址到物理地址——非常简短的概述"><a href="#从虚拟地址到物理地址——非常简短的概述" class="headerlink" title="从虚拟地址到物理地址——非常简短的概述"></a>从虚拟地址到物理地址——非常简短的概述</h4><p>​    现在可以看到（我在这里重申），现实情况是虚拟地址不是绝对地址（从零开始的绝对偏移量，您可能错误地想象了）而是位掩码。事实上，内存管理是一个复杂的领域，其中的工作是共享的；让我们重申真正关键的要点：</p>
<p>​    每个活动进程都有一组分页表，将虚拟页面映射到物理页面（称为页框）；每当访问虚拟地址（用户或内核）时，分页表就会发挥作用。内核也有自己的分页表。操作系统创建和操作每个进程以及内核的分页表；工具链（编译器/链接器）生成虚拟地址。处理器 MMU 执行运行时地址转换，将给定的（用户或内核）虚拟地址转换为物理（RAM）地址。因此，再次，不深入细节，这里简要介绍通常称为硬件分页（此处为 x86）的总体过程（图 7.3 给出了总体流程的高级概述）：</p>
<ol>
<li>进程（或其中的线程）查找虚拟地址（UVA 或 KVA）——即，它对虚拟地址执行读/写/执行操作。（这是完全正常的、预期的行为；例如，读取或写入变量，或执行机器指令）。</li>
<li><p>为了让 CPU 在内存中的该位置执行工作，我们现在必须以某种方式将此虚拟地址转换为其对应的物理对应地址。不过，请稍等：由于硬件优化，此步骤可以绕过或更快地完成（步骤 3.1、3.2）；如果不能，则必须通过MMU“手动”转换（速度较慢；步骤 4）。</p>
</li>
<li><p>在进入 MMU 之前，一些硬件优化可以帮助我们加快速度，缩短“通常”较慢的路径：</p>
<ol>
<li>首先，正在处理的代码或数据可能已经驻留在CPU 缓存中（L1/L2/L3/…）；首先检查这一点。如果确实如此，我们就有一个缓存命中：代码/数据项在 CPU 缓存本身内进行处理，然后完成工作。如果没有，则说明 CPU 缓存未命中（从技术上讲，是 LLC（最后一级缓存）未命中（成本高昂））；因此，我们进入下一步。（我们将在第 13 章“内核同步 - 第 2 部分”中介绍更多有关 CPU 缓存和缓存一致性问题的内容；暂时忽略它。）</li>
<li>虚拟地址是否已转换？查找 CPU 的转换后备缓冲区 (TLB)。如果转换存在，则说明 TLB 命中；如果是，则说明 TLB 中缓存了物理地址：跳至步骤 5；如果没有，则说明 TLB 未命中（成本高昂）。（另外：不一定按此处显示的顺序完成；某些微架构使用物理缓存模型，其中 CPU 缓存位于 MMU 和 RAM 访问之间，实际上颠倒了上述两个步骤的顺序）。</li>
</ol>
</li>
<li>将虚拟地址发送到 MMU；它现在“遍历”进程的分页表（它通过保存其物理地址的系统寄存器知道进程（或内核）的基页表在物理 RAM 中的位置），并最终得到相应的页框和物理地址（图 7.4 描述了此步骤）。</li>
<li>物理地址（从前面的步骤之一获得）现在被搭载到 CPU 地址线上，然后开始工作。<br>请确保您仔细阅读并理解这一点。除步骤 4 之外，所有显示的步骤均由图 7.3 描述；步骤 4 - 通过 MMU 进行转换的步骤 - 由图 7.4 描述。请研究它们。</li>
</ol>
<p><img src="./../七月笔记学习日志/7.10/image-20240710082218611.png" alt="image-20240710082218611"></p>
<p><img src="./image-20240710082250348.png" alt="image-20240710082250348"></p>
<p>​    对于 MMU 地址转换图（图 7.4），请注意，这里我们使用了一个非常特定于架构的 x86_64 示例，该示例具有 4 级分页、4 KB 页面大小和 48 位寻址。传递虚拟地址时，MMU 能够将其视为位掩码；它查找基本物理地址 - 它位于 x86 上的控制寄存器 3 (CR3) 中（在 ARM 系列中，它是用户进程的 TTBR0 寄存器和内核分页表的 TTBR1） - 然后继续进行转换。（想想这个：当然，CR3 中的基址是物理地址，否则此步骤将变得无限递归！）简而言之，这就是 MMU 执行运行时地址转换所做的事情：它查找基本 CR3 地址，将虚拟地址的 PGD 部分中的 9 位值添加到它，然后查找该数量。这是指向下一个表的指针，它重复上一步，但这次使用的是来自 9 位 PUD 字段的值。这继续（通过 PMD）直到页表，在那里它引用实际的页表条目 (PTE)。它包含（除其他微架构特定位外）指向物理页框的指针；将 12 位偏移量添加到页框的基址可得出物理地址。</p>
<p>实际情况更加微妙；这里有几个关键点值得一提。</p>
<p>首先，至少在理论上，当虚拟地址传递给 MMU 时，它会“遍历”分页表，最终结果应该是物理地址；实际上，MMU 地址转换尝试可能会失败！一种情况很明显：提供的虚拟地址不正确（未映射的地址）：实际上，我们有一个错误，一个缺陷，导致 MMU 引发故障（操作系统故障处理程序将适当地处理它）。另一种情况是请求分页——虚拟地址合法但物理内存尚未分配（尚未分配）的情况，导致转换失败（导致 MMU 引发“良好”故障，系统分配页面框架）。我们在第 9 章“模块作者的内核内存分配 - 第 2 部分”的“请求分页和 OOM”部分中详细介绍了这一点；如果您愿意，可以浏览图 9.9，其中显示了还可能发生的情况……当然，我们将在那里介绍详细信息。其次，内核作为老板，实际上可以绕过使用 MMU 并在软件中自己执行地址转换。实际上，这很少做，因为当然会更慢。一个地方是执行 IO（读取或写入）时，通过 /proc/PID/maps 伪文件利用 mmap() 进入进程 VAS。通过\采用这种方法，可以写入标记为只读的内存！（offlinemark 在这篇博客文章中详细介绍了这一点：Linux 内部：/proc/self/mem 如何写入不可写内存，2021 年 5 月：<a target="_blank" rel="noopener" href="https://offlinemark.com/2021/05/12/an-obscure-quirk-of-proc/；请务必查看。）">https://offlinemark.com/2021/05/12/an-obscure-quirk-of-proc/；请务必查看。）</a></p>
<p>​    我们不会在本书中深入探讨有关硬件分页（以及各种硬件加速技术，例如转换后备缓冲区 (TLB)）的更多细节。这些主题已在本章的“进一步阅读”部分中提到的其他各种优秀书籍和参考网站中得到很好的介绍。</p>
<h4 id="64-位-Linux-系统上的-VM-拆分"><a href="#64-位-Linux-系统上的-VM-拆分" class="headerlink" title="64 位 Linux 系统上的 VM 拆分"></a>64 位 Linux 系统上的 VM 拆分</h4><p>​    首先，值得注意的是，在 64 位系统上，并非所有 64 位都用于寻址。具有（典型）4 KB<br>页面大小的 x86_64 的标准 Linux 操作系统配置使用 LSB（最低有效位）48 位进行寻址。为什么不使用完整的64 位？这实在是太多了！现有的任何计算机都无法接近完整的 2^64 = 18,446,744,073,709,551,616 字节的一半，这相当于 16 EB（16EB，即 16,384 PB）的 RAM！</p>
<p>​    您可能会想，“为什么我们要将这种虚拟寻址等同于 RAM？”。请继续阅读 - 在弄清楚这一点之前，需要涵盖更多材料。在检查内核 VAS 部分，您将完全理解这一点。如上所述，64 位系统上可用的 VAS 是令人难以置信的巨大。当 Linus 正在开发第一个 64 位 Linux 端口（DEC Alpha，第一个商用 64 位处理器）时，他可能必须决定如何在这个巨大的 VAS 中布局进程和内核段。即使在今天的 x86_64Linux 操作系统上，做出的决定或多或少仍然保留（概念上）。这个巨大的 64 位 VAS 分为用户模式的 VAS 和内核的单独 VAS，如下所示。这里，我们假设 48 位寻址，页面大小为 4 KB：</p>
<ul>
<li>128 TB 的进程 VAS 的所谓“规范下半部分”：用户 VAS –虚拟地址范围从 0x0 到 0x0000 7fff ffff ffff</li>
<li>128 TB 的进程 VAS 的所谓“规范上半部分”：内核 VAS虚拟地址范围从 0xffff 8000 0000 0000 到 0xffff ffff ffff ffff</li>
</ul>
<p>“规范”一词实际上意味着按照法律或按照惯例。这个 64 位 VM 在 x86_64 Linux 上拆分平台如下图可见：</p>
<p><img src="./../七月笔记学习日志/7.10/image-20240710082539314.png" alt="image-20240710082539314"></p>
<p>​    在上图中，您可以清楚地看到用户 VAS“锚定”在底部 128 TB，内核 VAS“锚定”在总共 16 EB VAS 的顶部 128 TB。那么中间未使用的区域（这里从 0x0000 8000 0000 0000 到 0xffff 7fff ffff ffff）呢？这只是一个空洞或稀疏区域；它也被称为非规范地址区域。有趣的是，正如图表告诉我们的那样，使用典型的 48 位寻址方案，大多数 VAS（99.998%）都未使用！这就是我们称 VAS 非常稀疏的原因。上图当然不是按比例绘制的！此外，请始终记住，这都是虚拟内存空间，而不是物理空间。<br>​    为了完善我们对 VM 分割的讨论，下图显示了一些针对不同 CPU 架构的常见用户：内核 VM 分割比率（同样，我们假设 MMU 页面大小为 4 KB，但最后一行除外，它使用 64 KB 大小的页面）：</p>
<p><img src="./../七月笔记学习日志/7.10/image-20240710082614569.png" alt="image-20240710082614569"></p>
<h4 id="关于-x86-64-Linux-寻址的说明"><a href="#关于-x86-64-Linux-寻址的说明" class="headerlink" title="关于 x86_64 Linux 寻址的说明"></a>关于 x86_64 Linux 寻址的说明</h4><p>以 x86_64 为例，2^47 为 128 TB；那么为什么地址位数是48（图 7.6 中 x86_64 的地址位数）而不是 47？当然，这是因为我们完全需要2*128 TB = 256 TB 的可用地址空间，128 TB 用于用户空间，另外 128 TB用于内核空间（2^48 = 256 TB）。</p>
<p>实际上，用于寻址的地址位数（图 7.6 中的第四列）决定了总使用虚拟内存的总体大小：用户 + 内核 –每个 VAS 通常获得总数的一半（例外往往是 32 位 x86 和 ARM-32，其中 VM 分割可以故意不相等）。我们用粗体（红色）突出显示第三行，因为它被认为是常见情况：在 x86_64（或 AMD64）架构上运行 Linux，使用用户：内核 :: 128 TB：128 TBVM 拆分。第四列 #Addr Bits 向我们展示了在 64 位处理器上，没有现实世界的处理器真正使用所有 64 位进行寻址。</p>
<p>在 x86_64 下，有两个 VM 拆分，如图 7.6（第 3 行和第 4 行）所示：</p>
<ul>
<li>第一个（图 7.6 中的第 3 行），128 TB：128 TB（4 级分页）是目前 Linux x86_64 系统（嵌入式系统、笔记本电脑、PC、工作站和服务器）上默认使用的 VM 拆分。它将物理地址空间限制为 64 TB（RAM）。</li>
<li>第二个（图 7.6 中的第 4 行），64 PB：64 PB，至少在撰写本文时，仍然是纯理论的；它支持 4.14 Linux 中所谓的 5 级分页。分配的 VAS（使用 57 位寻址，我们获得了令人难以置信的 128 PB VAS 和 4 PB 物理地址空间！）非常庞大，以至于据我们所知，在撰写本文时，还没有实际的计算机使用它。</li>
</ul>
<h4 id="关于-AArch64-Linux-寻址的说明"><a href="#关于-AArch64-Linux-寻址的说明" class="headerlink" title="关于 AArch64 Linux 寻址的说明"></a>关于 AArch64 Linux 寻址的说明</h4><p>​    请注意，在 Linux 上运行的 AArch64（ARM-64）架构的两行仅具有代表性。从事该产品的 BSP 供应商或平台团队可以使用不同的分割（图 7.6 后面的注释在此处提到了确切含义）。<br>此外，表格中的最后一行提到了下一代 (AArch64) ARMv8.2 处理器提供 LPA 扩展的事实。启用后，页面大小为 64 KB，地址空间可以扩展到每个用户和内核地址空间中的 52 位（因此总共 53 位），每个提供 (2^53) 4 PB 的 VAS 空间（以及 4 PB 的物理内存上限）。从 Linux 5.4 开始支持此功能。</p>
<blockquote>
<p>有关 AArch64 52 位寻址的更多详细信息，可在此处获取：<br>官方内核文档：AArch64 Linux 上的内存布局：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/v6.1/arm64/memory.html">https://www.kernel.org/doc/html/v6.1/arm64/memory.html</a><br>了解 Arm64 内核中的 52 位虚拟地址支持，B Sharma，2020 年 12 月：<a target="_blank" rel="noopener" href="https://opensource.com/article/20/12/52-bit-arm64-kernel">https://opensource.com/article/20/12/52-bit-arm64-kernel</a></p>
</blockquote>
<p>​    好的，继续；内核 VAS（又名内核段）中实际驻留着什么？所有内核代码、内核数据结构（包括任务结构、列表、</p>
<p>​    内核模式堆栈、分页表等）、设备驱动程序、内核模块等都在这里（如第 6 章“内核内部基本知识 – 进程和线程”中图 6.3 的下半部分所示；我们将在即将到来的“理解内核段”部分详细介绍这一点）。重要的是要意识到，作为 Linux 上的性能优化，内核内存始终是不可交换的；也就是说，内核内存永远不能被分页到交换分区。用户空间内存页面始终是分页的候选，除非被锁定（请参阅 mlock[all](2)系统调用）。<br>有了这些背景知识，您现在就可以很好地理解 Linux 操作系统上的完整进程 VAS<br>布局。继续阅读！</p>
<h4 id="理解进程-VAS-–-完整视图"><a href="#理解进程-VAS-–-完整视图" class="headerlink" title="理解进程 VAS – 完整视图"></a>理解进程 VAS – 完整视图</h4><p>​    再次参考图 7.1；它显示了单个 32 位进程的实际和完整进程 VAS 布局。当然，现实情况是系统上所有活跃的进程都有自己独特的用户模式 VAS，但共享相同的内核 VAS。下图试图从概念上传达这一点；它显示了典型 IA-32（或可能是 AArch32）系统的情况，具有 3:1（GB）的 VM 分割。在这里，每个进程的用户空间都是独一无二的，所有进程共享相同的内核 VAS：</p>
<p><img src="./image-20240710082821729.png" alt="image-20240710082821729"></p>
<p>​    请注意上图中虚拟地址空间如何反映 3:1 (GB) VM 分割。用户 VAS 从 0 扩展到 0xbfff ffff（0xc000 0000 是 3 GB 标记；这就是 PAGE_OFFSET 宏在此处设置的值），而内核 VAS 从 0xc0000000（3 GB）扩展到 0xffff ffff（4 GB）。</p>
<p>​    在本章后面，我们将介绍一个名为 procmap 的有用实用程序的用法。它将帮助您详细地可视化内核和用户的 VAS，类似于我们前面的图表所显示的方式。</p>
<p>需要注意的几点：</p>
<ul>
<li>对于图 7.7 中显示的示例，PAGE_OFFSET 内核宏的值为 0xc000 0000。</li>
<li>我们在此处显示的数字和数字并不是绝对的，也不是所有架构的约束力；它们往往非常特定于架构，许多高度供应商定制的 Linux 系统可能会更改它们（如图 7.6 所示）。</li>
<li>图 7.7 详细介绍了 32 位 Linux 操作系统上的 VM 布局。在 64 位 Linux 上，概念保持不变，只是数字（显著）发生了变化。如前面几节中详细显示的那样，x86_64（具有 48 位寻址和 4K 页）Linux 系统上的 VM 拆分为用户：内核 :: 128 TB：128 TB。</li>
</ul>
<p>​    现在，您已经了解了进程虚拟内存布局的基本原理，您会发现它对解密和在难以调试的情况下取得进展大有帮助。像往常一样，还有更多内容；接下来的部分介绍了用户空间和内核空间虚拟内存映射（内核 VAS），以及物理内存映射的一些介绍。继续，继续！</p>
<h4 id="检查进程-VAS"><a href="#检查进程-VAS" class="headerlink" title="检查进程 VAS"></a>检查进程 VAS</h4><p>​    我们已经介绍了每个进程的 VAS 的布局（段或映射）（请参阅第 6 章“内核内部要点 - 进程和线程”中的“了解进程虚拟地址空间 (VAS) 的基础知识”部分）。<br>我们了解到，进程 VAS 由各种映射或段组成；其中包括文本（代码）、数据段、库映射和至少一个堆栈。在这里，我们将大大扩展该讨论。<br>能够深入内核并查看各种运行时值对于像您这样的开发人员（以及应用程序用户、QA、系统管理员、DevOps 人员等）来说是一项重要技能。Linux 内核为我们提供了一个出色的界面来执行此操作——您猜对了，就是 proc 文件系统 (procfs)。</p>
<p>这个伪文件系统始终存在于 Linux 上（至少应该如此），并且默认安装在 /proc 下。 procfs 系统有两个主要任务：</p>
<ul>
<li>提供一组统一的（伪或虚拟）文件和目录，使您能够深入了解内核和硬件内部细节。</li>
<li>提供一组统一的 root 可写文件，允许 sysad（或 root 用户）修改关键内核参数。这些文件位于 /proc/sys/ 下，称为sysctl – 它们是 Linux 内核的调整旋钮。</li>
</ul>
<p>熟悉 proc 文件系统确实是必须的。我建议您查看它并阅读proc(5) 上的优秀手册页（通过在终端中输入 man 5 proc）。例如，只需执行 cat /proc/PID/status（其中 PID 当然是给定进程或线程的唯一进程标识符）即可从进程或线程的任务结构中获得大量有用的详细信息！</p>
<p>从概念上讲，与 procfs 类似的是 sysfs 文件系统，它安装在/sys 下（在其下是 debugfs，通常安装在 /sys/kernel/debug）。sysfs 是 &gt;= 2.6 Linux 的新设备和驱动程序模型的表示；它公开了系统上所有设备（及其驱动程序）的树，以及几个内核调整旋钮。所有这些都是伪文件系统；<br>也就是说，它们安装在 RAM 中（因此它们的内容是易失性的）。</p>
<h4 id="详细检查用户-VAS"><a href="#详细检查用户-VAS" class="headerlink" title="详细检查用户 VAS"></a>详细检查用户 VAS</h4><p>让我们从检查任何给定进程的用户 VAS 开始。通过 procfs 提供了用户 VAS 的非常详细的映射，特别是通过 /proc/PID/maps伪文件。让我们学习如何使用此接口来查看进程的用户空间<br>（虚拟）内存映射。我们将看到两种方法：</p>
<ul>
<li>直接通过 procfs 接口的 /proc/PID/maps 伪文件</li>
<li>使用一些有用的前端（使输出更易于理解）</li>
</ul>
<p>让我们从第一个开始。</p>
<h4 id="使用-procfs-直接查看进程内存映射"><a href="#使用-procfs-直接查看进程内存映射" class="headerlink" title="使用 procfs 直接查看进程内存映射"></a>使用 procfs 直接查看进程内存映射</h4><p>​    查找任何任意进程的内部进程详细信息确实需要 root 访问权限，而查找您拥有的进程的详细信息（包括调用者进程本身）则不需要。因此，作为一个简单的示例，我们将使用 self 关键字代替 PID 来查找调用进程的 VAS。以下屏幕截图显示了这一点（在 x86_64 Ubuntu 22.04 LTS 客户机上）：</p>
<pre class="line-numbers language-none"><code class="language-none">56848f1c1000-56848f1c3000 r--p 00000000 00:19 16119                      &#x2F;usr&#x2F;bin&#x2F;cat
56848f1c3000-56848f1c7000 r-xp 00002000 00:19 16119                      &#x2F;usr&#x2F;bin&#x2F;cat
56848f1c7000-56848f1c9000 r--p 00006000 00:19 16119                      &#x2F;usr&#x2F;bin&#x2F;cat
56848f1c9000-56848f1ca000 r--p 00007000 00:19 16119                      &#x2F;usr&#x2F;bin&#x2F;cat
56848f1ca000-56848f1cb000 rw-p 00008000 00:19 16119                      &#x2F;usr&#x2F;bin&#x2F;cat
5684a4d90000-5684a4db1000 rw-p 00000000 00:00 0                          [heap]
76e3ebc00000-76e3ec1f0000 r--p 00000000 00:19 54248                      &#x2F;usr&#x2F;lib&#x2F;locale&#x2F;locale-archive
76e3ec24a000-76e3ec28f000 rw-p 00000000 00:00 0 
76e3ec28f000-76e3ec2b3000 r--p 00000000 00:19 4061                       &#x2F;usr&#x2F;lib&#x2F;libc.so.6
76e3ec2b3000-76e3ec41f000 r-xp 00024000 00:19 4061                       &#x2F;usr&#x2F;lib&#x2F;libc.so.6
76e3ec41f000-76e3ec46d000 r--p 00190000 00:19 4061                       &#x2F;usr&#x2F;lib&#x2F;libc.so.6
76e3ec46d000-76e3ec471000 r--p 001dd000 00:19 4061                       &#x2F;usr&#x2F;lib&#x2F;libc.so.6
76e3ec471000-76e3ec473000 rw-p 001e1000 00:19 4061                       &#x2F;usr&#x2F;lib&#x2F;libc.so.6
76e3ec473000-76e3ec47d000 rw-p 00000000 00:00 0 
76e3ec4b7000-76e3ec4bb000 r--p 00000000 00:00 0                          [vvar]
76e3ec4bb000-76e3ec4bd000 r-xp 00000000 00:00 0                          [vdso]
76e3ec4bd000-76e3ec4be000 r--p 00000000 00:19 4052                       &#x2F;usr&#x2F;lib&#x2F;ld-linux-x86-64.so.2
76e3ec4be000-76e3ec4e5000 r-xp 00001000 00:19 4052                       &#x2F;usr&#x2F;lib&#x2F;ld-linux-x86-64.so.2
76e3ec4e5000-76e3ec4ef000 r--p 00028000 00:19 4052                       &#x2F;usr&#x2F;lib&#x2F;ld-linux-x86-64.so.2
76e3ec4ef000-76e3ec4f1000 r--p 00032000 00:19 4052                       &#x2F;usr&#x2F;lib&#x2F;ld-linux-x86-64.so.2
76e3ec4f1000-76e3ec4f3000 rw-p 00034000 00:19 4052                       &#x2F;usr&#x2F;lib&#x2F;ld-linux-x86-64.so.2
7ffca0560000-7ffca0581000 rw-p 00000000 00:00 0                          [stack]
ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0                  [vsyscall]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    在上面的屏幕截图中，您实际上可以看到 cat 进程的用户 VAS 的布局 - 该进程的用户 VAS 的真实内存映射！另外，请注意，前面的 procfs 输出按 UVA 升序排序。</p>
<blockquote>
<p>熟悉使用强大的 mmap(2) 系统调用将极大地帮助理解进一步的讨论。请（至少）浏览其手册页。</p>
</blockquote>
<h4 id="解释-proc-PID-maps-输出"><a href="#解释-proc-PID-maps-输出" class="headerlink" title="解释 /proc/PID/maps 输出"></a>解释 /proc/PID/maps 输出</h4><p>​    要解释图 7.8 的输出，请一次阅读一行。每一行代表所讨论进程的用户模式 VAS 的一个段或映射（在前面的例子中，它是 cat 进程的段或映射）。每一行由以下字段组成；</p>
<p>​    在这里，整行代表一个段，或者更准确地说，代表进程（用户）VAS 内的映射。</p>
<p>​    uva 是用户虚拟地址。每个映射的 start_uva 和 end_uva 显示为前两个字段（或列），并由连字符分隔。因此，映射（段）的长度很容易计算（end_uva￾start_uva 字节）。因此，在上一行中，start_uva 是 0x558822d66000，end_uva 是 0x558822d6a000，长度可以计算为 16 KB；但是这个段在进程中到底代表什么？请继续阅读…第三个字段 r-xp 是两条信息的组合：前三个字母代表段的模式（权限）（通常为 rwx 表示法）。下一个字母表示映射是私有映射 (p) 还是共享映射(s)。在内部，这是由 mmap() 系统调用的第四个参数flags 设置的；实际上，是 mmap() 系统调用在内部负责创建进程内的每个段或映射！因此，对于前面显示的示例段，第三个字段是值 r-xp，我们现在可以说它是一个文本（代码）段并且是一个私有映射（如预期的那样）。第四个字段 start-off（这里是值 0x2000）是从文件开头的起始偏移量，该文件的内容已映射到进程 VAS 中（对于看到的大小，为 16 KB）。显然，这个值只对文件映射有效。</p>
<p>​    您可以通过查看倒数第二个（第六个）字段 - 文件 inode 号来判断当前段是否是文件映射。对于非文件映射的映射（称为匿名映射），它始终为 0（例如，表示堆或堆栈段的映射）。在我们前面的示例行中，它是一个文件映射（/usr/bin/cat 的映射），并且从该文件开头的偏移量为 0x2000 字节（映射的长度，正如我们在上一段中计算的那样，为 16 KB）。<br>第五个字段（08:01）的形式为 mj:mn，其中 mj 是主编号，mn 是映像所在的（块）设备文件的次编号。与第四个字段一样，它仅对文件映射有效，否则它仅显示为 00:00；在我们前面的示例行中，由于它是一个文件映射，因此主编号和次编号（表示文件所在的存储介质的块设备的编号）分别为 8 和 1。</p>
<p>​    第六个字段 (7340181) 表示映像文件的 inode 编号 - 该文件的内容被映射到进程 VAS 中。inode 是 VFS（虚拟文件系统）的关键数据结构；它保存文件对象的所有元数据，除了其名称（位于目录（或点）文件中）之外的所有内容。同样，此值仅对文件映射有效，否则仅显示为 0。事实上，这是一种快速判断映射是文件映射还是匿名映射的方法！在我们前面的示例映射中，显然它是一个文件映射（/usr/bin/cat 的映射），inode 编号为 7340181。事实上，我们可以确认这一点：</p>
<pre class="line-numbers language-none"><code class="language-none">$ ls -i &#x2F;usr&#x2F;bin&#x2F;cat
7340181 &#x2F;usr&#x2F;bin&#x2F;cat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>第七个也是最后一个字段表示其内容被映射到用户 VAS 中的文件的路径名。在这里，当我们查看 cat 进程的内存映射时，路径名（文件映射段的路径名）恰好是 /usr/bin/cat。如果<br>映射代表一个文件，则文件的 inode 号（第六个字段）显示为正数；如果不是——意味着它是一个纯内存或匿名映射，没有后备存储——inode 号显示为 0，最后一个字段将为空。（当然，其他文件也可以显示：共享库、共享内存段等的文件。）</p>
<p>​    现在应该很明显了，但我们还是要指出这一点，因为它是一个关键点：所有前面看到的地址都是虚拟的，而不是物理的。此外，它们只属于用户空间，因此它们被称为 UVA，并且始终通过该进程的唯一分页表元数据进行访问（和转换）。此外，前面的屏幕截图是在 64 位 (x86_64) Linux 客户机上拍摄的。因此，在这里，我们看到 64 位虚拟地址。</p>
<p>​    虚拟地址在这里显示的方式不是完整的 64 位数字 - 例如，558822d66000 而不是 0000558822d66000。我希望您注意到这一点，因为它是 UVA，MSB 16 位为零！（当然，数字都是十六进制的。）</p>
<p>​    没错，虽然这涵盖了如何解释特定的段或映射（并且 [heap] 和 [stack] 行是不言自明的），但似乎有一些奇怪的（再次浏览图 7.8） - vvar、vdso 和 vsyscall 映射。让我们看看它们是什么意思。</p>
<p>vsyscall 页面</p>
<p>您是否注意到图 7.8 的输出中有些不寻常的东西？最后一行——所谓的 vsyscall 条目——映射了一个内核页面（现在，你知道我们如何判断：它的起始和结束虚拟地址的 MSB 16 位已设置）。在这里，我们只是提到这是一个（旧的）优化用于执行系统调用。它的工作原理是减轻切换到内核模式的一小部分系统调用的需要，而这些系统调用实际上并不需要。</p>
<p>​    目前，在 x86 上，这些系统调用包括 gettimeofday()、time() 和 getcpu() 系统调用。事实上，上面的 vvar 和 vdso（又名虚拟动态共享对象）映射是同一主题的（略）现代变体。如果您有兴趣了解更多信息，请查看本章的“进一步阅读”部分。</p>
<p>​    顺便说一句：名为 /proc/PID/map_files/ 的目录是另一个视图；它仅显示进程或线程内的文件映射。在这里，每个文件支持的内存映射（或段）都显示为其对应文件的符号链接。</p>
<p>​    因此，您现在已经学会了如何通过直接读取和解释具有指定 PID 的进程的 /proc/PID/maps（伪）文件的输出来检查和解释任何给定进程的“原始”用户空间内存映射。还有其他方便的前端可以这样做；我们现在将检查一些。</p>
<h4 id="查看进程内存映射的前端"><a href="#查看进程内存映射的前端" class="headerlink" title="查看进程内存映射的前端"></a>查看进程内存映射的前端</h4><p>​    除了通过 /proc/PID/maps 的原始或直接格式（我们在上一节中看到了如何解释）之外，还有一些包装器实用程序可以帮助我们更轻松地解释用户模式 VAS。其中包括附加的（原始）/proc/PID/smaps 伪文件、pmap 和 smem 实用程序以及我自己的实用程序（命名为 procmap）。</p>
<p>​    内核通过 proc 下的 /proc/PID/smaps 伪文件提供有关每个段或映射的详细信息。请尝试运行命令 cat /proc/self/smaps 亲自查看。您会注意到，对于每个段（映射），都提供了大量详细信息。proc(5) 的手册页有助于解释看到的许多字段。对于 pmap 和 smem 实用程序，我建议您参阅它们的手册页以了解详细信息。</p>
<h4 id="了解-VMA-基础知识"><a href="#了解-VMA-基础知识" class="headerlink" title="了解 VMA 基础知识"></a>了解 VMA 基础知识</h4><p>​    在 /proc/PID/maps 的输出中，输出的每一行都是从内核元数据结构（称为虚拟内存区域或 VMA）推断出来的。实际上，这非常简单：内核使用 VMA 数据结构在代码中抽象我们一直称为段或映射的内容。因此，对于用户 VAS 中的每个映射，都有一个由操作系统维护的 VMA 对象。请注意，只有用户空间映射才受内核元数据结构（称为 VMA）的管理；内核 VAS 本身没有 VMA。</p>
<p>​    那么，给定进程将有多少个 VMA？好吧，它等于其用户 VAS 中的映射（段）数量。在我运行的 helloworld 进程示例中，它报告了 15 个段或映射，这意味着内核内存中有 15 个 VMA 元数据对象 - 代表 15 个用户空间段或映射。</p>
<p>​    从编程的角度来说，内核通过以 current-&gt;mm-&gt;mmap 为根的任务结构维护 VMA“链”（出于效率原因，技术上是红黑树数据结构）。为什么指针称为 mmap？这是经过深思熟虑的：每次执行 mmap() 系统调用（即内存映射操作）时，内核都会在调用进程的 VAS 中生成一个映射（或“段”），从而生成一个代表它的 VMA 元数据对象。</p>
<p>​    VMA 元数据结构类似于一个涵盖映射的保护伞，包括内核执行各种内存管理所需的所有信息：处理页面错误（非常常见）、在 I/O 进入（或离开）内核页面缓存期间缓存文件内容，等等。</p>
<p>​    页面错误处理是一项非常重要的操作系统活动，其算法占用了内核 VMA 对象的很大一部分使用；不过，在本书中，我们不会深入探讨这些细节，因为这些细节对内核模块/驱动程序作者来说基本上是透明的。</p>
<p>​    现在应该更清楚 cat /proc/PID/maps 的底层工作原理：当用户空间执行 cat /proc/self/maps 时，cat 进程（最终）会发出 read() 系统调用；这会导致它切换到内核模式，并在内核中以内核权限运行 read() 系统调用代码。在这里，内核虚拟文件系统 (VFS) 开关将控制重定向到适当的 procfs 回调处理程序（从 5.6.0 开始，在最近的内核中，该函数在 proc_ops 结构中注册）。此代码遍历（循环）每个 VMA 元数据结构（对于正在运行的进程上下文：换句话说，对于当前进程，当然是我们的 cat 进程），将每个 VMA 对象的相关详细信息发送回用户空间。然后，cat 进程忠实地将通过 read 接收到的数据转储到 stdout，因此我们看到了它：进程的所有段或映射 - 实际上是用户模式 VAS 的内存映射！</p>
<p>​    太好了，我们现在结束本节；我们已经介绍了检查进程用户 VAS 的详细信息。这些知识不仅有助于理解用户模式 VAS 的精确布局，还有助于调试用户空间问题！现在，是时候了，让我们继续了解内存管理的另一个关键方面 - 内核 VAS 的详细布局！</p>
<h4 id="检查内核-VAS"><a href="#检查内核-VAS" class="headerlink" title="检查内核 VAS"></a>检查内核 VAS</h4><p>​    正如我们在上一章中讨论过的，如图 7.7 所示，了解所有进程都有自己独特的用户 VAS 但共享内核空间 - 我们称之为内核段或内核 VAS 至关重要。让我们从检查内核 VAS 的一些常见（与架构无关）区域开始本节。</p>
<p>​    内核 VAS 的内存布局非常依赖于架构（CPU）。尽管如此，所有架构都有一些共同点。以下基本图表表示用户 VAS 和内核 VAS（水平平铺格式），如在具有 3:1（GB）VM sp 的典型x86_32（或 IA-32）上所见</p>
<p><img src="./../七月笔记学习日志/7.10/image-20240710083728169.png" alt="image-20240710083728169"></p>
<p>​    让我们看一下进程 VAS 的每个区域（从左到右，如图 7.12 所示）： 用户模式 VAS：这是用户 VAS。</p>
<p>​    我们在上一章以及本章前面的部分中已经详细介绍了它；在这个特定的例子中，它占用 3 GB 的 VAS（其 UVA 范围从 0x0 到 0xbfff ffff）。 内核 VAS（或内核段）：在这个特定的例子中，我们有 1 GB 的内核 VAS（其 KVA 范围从 0xc000 0000 到 0xffff ffff）；现在让我们检查它的各个部分。 “lowmem”区域：这是操作系统将平台（系统）RAM 直接映射到内核 VAS 的区域。 （图 7.12 试图清楚地传达这一点。我们将在直接映射 RAM 和地址转换部分更详细地介绍这个关键主题。如果您觉得有帮助，可以先阅读该部分，然后返回此处）。现在先跳过一点，让我们了解内核 VAS 中平台 RAM 映射的基位置由名为 PAGE_OFFSET 的内核宏指定。这个宏的精确值非常依赖于架构；我们将把这个讨论留到后面的部分。现在，我们要求您相信在具有 3:1（GB）VM 分割的 x86_32 上，PAGE_OFFSET 的值为 0xc000 0000。显然，内核所谓的低内存区域的大小等于系统上的 RAM 量。 （至少内核看到的 RAM 数量是这样的；例如，启用 kdump 功能可以让操作系统很早就保留一些指定数量的 RAM。）组成该区域的虚拟地址称为内核逻辑地址，因为它们与物理对应地址有固定的偏移量。核心内核和设备驱动程序可以通过各种 API 从该区域分配（物理上连续的！）内存（它们包括页面分配器 API 和流行的 slab API - k{m|z}alloc()。请耐心等待，我们将在接下来的两章中详细介绍这些 API）。内核静态文本（代码）、数据和 BSS（未初始化数据）内存区域也位于此 lowmem 区域内。没错，在 lowmem 区域之后，还存在其他区域；虽然图 7.12 中没有明确显示（目前），但有几个关键区域： 内核 vmalloc 区域：这是内核 VAS 中完全虚拟的区域。核心内核和/或设备驱动程序代码可以使用 vmalloc()（及其相关函数）API 从该区域分配几乎连续的内存。同样，我们将在第 8 章“模块作者的内核内存分配 - 第 1 部分”和第 9 章“模块作者的内核内存分配 - 第 2 部分”中详细介绍这一点。 这也是所谓的 ioremap 空间。 </p>
<p>​    内核模块空间：内核 VAS 中留出一个区域用于存放 LKM 的静态文本和数据。执行 insmod（或 modprobe）时，生成的 [f]init_module() 系统调用的底层内核代码将从该区域分配内存（通常通过 vmalloc() API）并在那里加载内核模块的（静态）代码和数据。 上图（图 7.12）故意保持简单，甚至有点模糊，因为确切的内核虚拟内存布局非常依赖于架构。我们暂时不打算绘制详细的图表。相反，为了让这个讨论不那么迂腐，更实用、更有用，我们将在即将到来的一节中介绍一个内核模块，该模块查询并打印有关内核 VAS 布局的相关信息。只有这样，一旦我们获得了特定架构的内核 VAS 各个区域的实际值，我们才会提供一个详细的图表来描述这一点。从理论上讲（如图 7.10 所示），属于内核低内存区域的地址称为内核逻辑地址（它们与物理对应地址有固定的偏移量），而内核 VAS 其余部分的地址称为 KVA。虽然这里做出了这种区分，但请注意，出于所有实际目的，这是一个相当迂腐的区分：我们并没有真正区分彼此，并且通常只是将内核 VAS 内的所有地址称为 KVA。</p>
<p>​     在我们开始编写查询内核 VAS 的模块之前，还有其他几条信息需要介绍。让我们从一个特殊之处开始，这主要是由 32 位架构的限制引起的：</p>
<p>​    32 位系统上内核 VAS 的所谓高内存区域。 32 位系统上的高内存 记住我们之前简要讨论过的内核低内存区域，一个有趣的观察随之而来。在 32 位系统上，例如，VM 分割为 3:1（GB）（如图 7.12 所示），具有（例如）512 MB RAM 的系统会将此 RAM 直接映射到内核，从 PAGE_OFFSET（3 GB 或 KVA 0xc000 0000）开始，为 512 MB。这很清楚。但想想看：如果系统有更多的 RAM，比如 2 GB，会发生什么？现在，很明显，我们不能将整个 RAM 直接映射到内核低端区域。它根本放不下（因为在这个例子中，整个可用内核 VAS 只有 1 GB，而 RAM 是 2 GB）！因此，在 32 位 Linux 操作系统上，一定量的内存（在 IA-32 上通常为 896 MB）允许直接映射，因此落入 lowmem 区域。剩余的 RAM 被间接映射到另一个内存“区域”，称为 ZONE_HIGHMEM（我们将其视为高内存区域或区域，而不是 lowmem；有关内存区域的更多信息将在后面的区域部分中介绍）。更正确的是，由于内核现在发现不可能一次直接映射所有物理内存，因此它设置了一个（虚拟）区域，它可以在该区域设置和使用该 RAM 的临时虚拟映射（通常通过调用 kmap() 和 kunmap() API）。这就是所谓的高内存区域。不要对“高内存”这个短语感到困惑。它不一定位于内核 VAS 的“高”位置，也不是用来描述 PC 上 640 KB 以上内存的“高内存”术语。相反，high_memory 全局变量仅在 32 位上有效，表示内核低内存区域的上限。有关此内容的更多信息，请参阅后面的“描述内核 VAS 布局的宏和变量”一节。</p>
<p>​    然而，如今（尤其是 32 位系统使用越来越少），这些问题在 64 位 Linux 上完全消失了。想想看：例如，在运行 64 位 Linux 的 x86_64 上，内核 VAS 大小高达 128 TB（即 131,072 GB！）。据我所知，现有的任何单个系统（或节点）都没有这么多的 RAM。截至撰写本文时，NASA 的 Pleiades 超级计算机指定每个节点的最大 RAM 为 128 GB（参考：<a target="_blank" rel="noopener" href="https://www.nas.nasa.gov/hecc/resources/pleiades.html）。">https://www.nas.nasa.gov/hecc/resources/pleiades.html）。</a></p>
<p>​    接下来，当使用稀疏内存模型时（通常的情况；即将到来的物理内存模型简介部分将介绍这一点），物理地址中支持的最大位由宏 MAX_PHYSMEM_BITS 给出。在 x86_64 上，它通常为值 46，这意味着机器上支持的最大 RAM 量为 246 字节 - 即 64 TB。因此，所有平台 RAM 确实可以（轻松）直接映射到 128 TB 内核 VAS，并且对 ZONE_HIGHMEM（或等效的愚蠢解决方法）的需求就消失了。事实上，弃用 32 位系统上的这个高内存区域是大多数内核人员最终想要做的事情，但截至目前，它仍然存在，允许具有超过 1 GB RAM 的旧系统（通常是 ARM-32）继续在 Linux 上运行（有关更多信息，请参阅本文：高内存的终结？，LWN，2020 年 2 月：<a target="_blank" rel="noopener" href="https://lwn.net/Articles/813201/）。同样，官方内核文档提供了有关这个神秘的“高内存”区域（与">https://lwn.net/Articles/813201/）。同样，官方内核文档提供了有关这个神秘的“高内存”区域（与</a> 32 位相关）的详细信息；如果感兴趣，请看一下：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/vm/highmem.txt。">https://www.kernel.org/doc/Documentation/vm/highmem.txt。</a></p>
<p>​    好的，现在让我们解决我们一直想做的事情——编写一个内核模块（LKM）来深入研究有关内核 VAS 的一些细节。</p>
<h4 id="编写内核模块以显示有关内核-VAS-的信息"><a href="#编写内核模块以显示有关内核-VAS-的信息" class="headerlink" title="编写内核模块以显示有关内核 VAS 的信息"></a>编写内核模块以显示有关内核 VAS 的信息</h4><p>​    正如我们所了解的，内核 VAS 由各种区域组成。有些区域是所有体系结构所共有的（与架构无关）：它们包括 lowmem 区域（其中包含未压缩的内核映像 - 其代码和数据等），然后是内核模块区域、vmalloc/ioremap 区域等等。</p>
<p>​    这些区域在内核 VAS 中的确切位置以及可能存在哪些区域，与架构（CPU）密切相关。为了帮助理解和确定任何给定系统，让我们开发一个内核模块，以与架构相关的方式查询和打印有关内核 VAS 的各种详细信息（事实上，如果被要求，它还会打印一些有用的用户空间内存详细信息）。</p>
<p>​    现在，为了查询和打印此信息，您必须首先熟悉一些关键的内核宏和全局变量；我们将在下一节中介绍。</p>
<h4 id="描述内核-VAS-布局的宏和变量"><a href="#描述内核-VAS-布局的宏和变量" class="headerlink" title="描述内核 VAS 布局的宏和变量"></a>描述内核 VAS 布局的宏和变量</h4><p>​    要编写显示相关内核 VAS 信息的内核模块，我们需要知道如何准确询问内核有关这些详细信息。</p>
<p>​    在本节中，我们将简要介绍内核中表示内核 VAS 内存的几个关键宏和变量（在大多数架构上，按 KVA 降序排列）：</p>
<p>​    向量表是一种常见的操作系统数据结构 - 它是一个函数指针数组（也称为切换或跳转表）。它是特定于架构的：ARM-32 使用它来初始化其向量，以便在发生处理器异常或模式更改（例如中断、系统调用、页面错误、MMU 中止等）时，处理器知道要运行什么代码。宏  VECTORS_BASE如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>宏or变量</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>VECTORS_BASE</td>
<td>一般用在arm32平台上。他描述了KVA的向量表的那一页的地址</td>
</tr>
</tbody>
</table>
</div>
<p>​    修复映射区域是一系列编译时特殊或保留的虚拟地址；它们在启动时用于将必须有可用内存的所需内核元素修复到内核 VAS 中。典型示例包括初始内核页表的设置、早期 ioremap 和 vmalloc 区域等。同样，它是一个依赖于架构的区域，因此在不同的 CPU 上的使用方式不同：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>宏or变量</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>FIXADDR_START</td>
<td>KVA修复映射区域起始区域</td>
</tr>
</tbody>
</table>
</div>
<p>​    内核模块在加载时会分配内存（用于其静态文本和数据），内存位于内核 VAS 中的特定范围内。内核模块区域的精确位置因架构而异。事实上，在 AArch32 系统上，它位于用户 VAS 的正上方，而在 64 位系统上，它通常位于内核 VAS 的较高位置：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>内核模块</th>
<th>内存分配</th>
</tr>
</thead>
<tbody>
<tr>
<td>MODULES_VADDR</td>
<td>KVA模块起始位置</td>
</tr>
<tr>
<td>MODULES_END</td>
<td>KVA模块结束位置</td>
</tr>
</tbody>
</table>
</div>
<p>​    KASAN：现代内核（x86_64 为 4.0 及以上版本，AArch64 为 4.4 及 AArch32 为 5.11）采用强大的机制来检测和报告内存问题（错误）。它基于用户空间地址 SANitizer (ASAN) 代码库，因此称为内核地址 SANitizer (KASAN)。它的强大之处在于，通过一种称为编译时检测 (CTI) 的技术，能够检测内存缺陷（错误），例如越界 (OOB) 访问（包括缓冲区溢出/下溢）、释放后使用 (UAF) 和双重释放访问。然而，在 5.11 之前，它只能在 64 位 Linux 上运行，并且需要相当大的影子内存区域（其大小是内核 VAS 的八分之一，如果启用，我们会显示其范围；不过，在 5.11 中，Linus Walleij 为 ARM-32 引入了 KASAN 的优化版本）。</p>
<p>​    它是一个内核配置功能（CONFIG_KASAN），通常仅用于调试（寻找错误！）目的（在调试期间保持启用状态至关重要，并且</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>KASAN影子内存区域</th>
<th>可选</th>
</tr>
</thead>
<tbody>
<tr>
<td>KASAN_SHADOW_START</td>
<td>起始</td>
</tr>
<tr>
<td>KASAN_SHADOW_END</td>
<td>终末</td>
</tr>
</tbody>
</table>
</div>
<p>​    vmemmap 区域是内核 VAS 中的一个区域，在以下情况下使用：</p>
<ul>
<li>第一，物理内存模型是 sparsemem（通常是现代系统的默认模型）；</li>
<li>第二，将页框号 (PFN) 映射到其对应虚拟页面（通过 struct page 表示）所采用的方法是vmemmap：</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Vmemmap region</th>
<th>[可选]（仅当 CONFIG_ SPARSEMEM_VMEMMAP 已定义时）</th>
</tr>
</thead>
<tbody>
<tr>
<td>VMEMMAP_START</td>
<td>vmemmap 区域的起始 KVA</td>
</tr>
<tr>
<td>VMEMMAP_SIZE</td>
<td>内核 vmemmap 区域的大小；不过这个宏似乎只为 AArch64 定义…</td>
</tr>
</tbody>
</table>
</div>
<p>vmalloc 区域是内核区域，从中分配 vmalloc()(及其相关 API) 的内存；我们将在接下来的两章中详细介绍各种内存分配 API：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>vmalloc区域</th>
<th>通过 vmalloc() 及其相关 API 分配的内存</th>
</tr>
</thead>
<tbody>
<tr>
<td>VMALLOC_START</td>
<td>vmalloc 区域的起始 KVA</td>
</tr>
<tr>
<td>VMALLOC_END</td>
<td>vmalloc 区域的结束 KVA；大小为 VMALLOC_END - VMALLOC_START</td>
</tr>
</tbody>
</table>
</div>
<p>lowmem 区域 - 直接映射 RAM（即，以 1:1 :: 物理页框：内核逻辑/虚拟页为基础映射到内核 VAS 的 RAM）。它是 Linux 内核映射和管理（通常）所有 RAM 的区域。</p>
<p>此外，它通常在内核中设置为 ZONE_NORMAL（稍后我们将介绍区域）：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Lowmem region</th>
<th>直接映射内存区域</th>
</tr>
</thead>
<tbody>
<tr>
<td>PAGE_OFF_SET</td>
<td>lowmem 区域的起始 KVA；在某些架构上也表示内核 VAS/段的起始，并且（通常）是 32 位上的 VM 分割值。</td>
</tr>
<tr>
<td>high_memory</td>
<td>lowmem 区域的结束 KVA，直接映射内存的上限。实际上，此值减去 PAGE_OFFSET 就是系统上的（平台）RAM 数量（但请注意，这不一定适用于所有架构）；不要与 ZONE_HIGHMEM 混淆。</td>
</tr>
</tbody>
</table>
</div>
<p>​    highmem 区域或区域是可选区域。它可能存在于某些 32 位系统上（通常，其中存在的 RAM 量大于内核 VAS 本身的大小）。在这种情况下，它通常设置为 ZONE_HIGHMEM（我们稍后会介绍区域。此外，您可以参考前面标题为 32 位系统上的高内存的部分中有关此高内存区域的更多信息）：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>高内存区域（仅在 32 位上可能存在）</th>
<th>[可选] HIGHMEM 可能存在于某些 32 位系统上</th>
</tr>
</thead>
<tbody>
<tr>
<td>PKMAP_BASE</td>
<td>高内存区域的起始 KVA，运行到 LAST_PKMAP 页；表示所谓的高内存页面的内核映射（仅适用于 32 位）</td>
</tr>
</tbody>
</table>
</div>
<p>（未压缩的）内核映像本身 - 其代码、初始化和数据区域 - 始终存在，但它们是私有符号，因此内核模块无法使用。因此，我们甚至不会尝试在即将推出的内核模块的代码中打印它们：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>内核</th>
<th>未压缩的内核映像区域（未导出符号，因此内核模块不可用）</th>
</tr>
</thead>
<tbody>
<tr>
<td>_text，_etext</td>
<td>内核文本（代码）区域的起始和结束 KVA（分别）</td>
</tr>
<tr>
<td>__init_begin，<br/>__init_end</td>
<td>内核初始化部分的起始和结束 KVA（分别）区域</td>
</tr>
<tr>
<td>_sdata，_edata</td>
<td>内核静态数据区域的起始和结束 KVA（分别）</td>
</tr>
<tr>
<td>__bss_start</td>
<td>内核 BSS 的起始和结束 KVA（分别）</td>
</tr>
<tr>
<td>__bss_stop</td>
<td>（未初始化数据）区域</td>
</tr>
</tbody>
</table>
</div>
<p>​    用户 VAS：当然，最后一项是进程用户 VAS。它位于内核 VAS 之下（按降序虚拟地址排序），大小为 TASK_SIZE 字节。本章前面已详细讨论过（在检查进程 VAS 部分）：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>用户 VAS</th>
<th>用户虚拟地址空间 (VAS)</th>
</tr>
</thead>
<tbody>
<tr>
<td>大小为 TASK_SIZE 字节的用户模式 VAS</td>
<td>(之前已通过 procfs 和/或我们的 procmap 实用程序脚本详细检查过）；内核宏 TASK_SIZE 表示用户 VAS 的大小（以字节为单位）。</td>
</tr>
</tbody>
</table>
</div>
<p>​    好了，就是这样；我们已经看到了几个内核宏和变量，它们实际上描述了内核 VAS。继续查看内核模块的代码，您很快就会看到它的 init 方法调用了两个函数（很重要）： </p>
<ul>
<li>show_kernelvas_info()，它打印相关的内核 VAS 详细信息 </li>
<li>show_userspace_info()，它打印相关的用户 VAS 详细信息（它的执行是可选的，通过内核参数决定，默认情况下处于关闭状态）</li>
</ul>
<p>我们将首先描述内核 VAS 函数并查看其输出。此外，Makefile 的设置方式是链接到内核“库”代码 klib.c 的目标文件，并生成一个名为 show_kernel_vas.ko 的内核模块对象。</p>
<h4 id="通过-procmap-的内核-VAS"><a href="#通过-procmap-的内核-VAS" class="headerlink" title="通过 procmap 的内核 VAS"></a>通过 procmap 的内核 VAS</h4><p>​    好的，这很有趣：图 7.14 中详细显示的内存映射布局视图正是我们前面提到的 procmap 实用程序提供的；我们在 procmap 进程 VAS 可视化实用程序部分介绍了此实用程序的用法。正如承诺的那样，现在让我们看看运行 procmap 时内核 VAS 的屏幕截图（前面的部分显示了进程用户 VAS 的屏幕截图）。</p>
<p><img src="./../七月笔记学习日志/7.10/image-20240710102520253.png" alt="image-20240710102520253"></p>
<p>​    为了与当前的讨论保持同步，我们现在将展示 procmap 的屏幕截图，它在同一个 AArch32 Raspberry Pi Zero W 系统上提供内核 VAS 的“可视化”视图（我们可以指定 —only-kernel 开关以仅显示内核 VAS；但我们在这里不这样做）。由于我们必须在某些进程上运行 procmap，我们任意选择 systemd PID 1；我们还使用 —verbose 选项开关。<br>​    它失败了，因为构建 procmap 内核模块失败了；但为什么呢？我在项目的 README.md 文件中提到了这种可能性（<a target="_blank" rel="noopener" href="https://github.com/kaiwan/procmap/blob/master/README.md#procmap）：">https://github.com/kaiwan/procmap/blob/master/README.md#procmap）：</a></p>
<p>​    […] 要在目标系统上构建内核模块，您将需要它在这里，这是因为此内核的内核头文件包不可用，因此模块构建失败（如果您在板上安装了自定义内核，也会发生这种情况）。虽然您可以将整个 Raspberry Pi 内核源代码树复制到设备上并设置 /lib/module/<code>&lt;kver&gt;</code>/build 符号链接，但这并不是正确的做法。那么，什么是呢？当然是从主机交叉编译 Raspberry Pi 的 procmap 内核模块！我们在这里介绍了为 Raspberry Pi 交叉编译内核本身的详细信息：第 3 章，从源代码构建 6.x Linux 内核 - 第 2 部分，在 Raspberry Pi 的内核构建部分；讨论也适用于交叉编译内核模块。</p>
<blockquote>
<p>我想强调这一点：在运行（自定义）内核时，Raspberry Pi 上的 procmap 内核模块构建只会由于缺少 Raspberry Pi 提供的内核头文件包而失败。如果您乐于使用库存（默认）Raspberry Pi OS 内核（以前称为 Raspbian OS），内核头文件包肯定是可安装的（或已经安装），并且一切都会正常工作（该包名为 raspberrypi-kernel-headers）。类似地，在典型的 x86_64 Linux<br>发行版上，procmap.ko 内核模块会在运行时干净地构建和插入。请详细阅读 procmap 项目的 README.md 文件，尤其是标有“重要提示：在 x86_64 以外的系统上运行 procmap”的部分，以了解如何交叉编译procmap 内核模块的详细信息。</p>
</blockquote>
<p>​    在主机系统上成功交叉编译 procmap 内核模块后，将 procmap.ko 内核模块（可能通过 scp）复制到设备并将其放置在 &lt;…&gt;/procmap/procmap_kernel 目录下；现在您就可以开始了！</p>
<p>​    这里，作为示例，是 Raspberry Pi 设备上复制的（或构建的)内核模块：</p>
<pre class="line-numbers language-none"><code class="language-none">cd &lt;...&gt;&#x2F;procmap&#x2F;
$ ls -l procmap_kernel&#x2F;procmap.ko
-rw-r--r-- 1 pi pi 9100 Jan 22 17:32 procmap_kernel&#x2F;procmap.ko<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>您还可以在其上运行 modinfo 实用程序来验证它是否为 ARM 构建。在这里，我在主板上运行了 Raspberry Pi 操作系统。有了这个，让我们重试我们的 procmap 运行以显示内核 VAS 详细信息：</p>
<p><img src="./../七月笔记学习日志/7.10/image-20240710102639850.png" alt="image-20240710102639850"></p>
<h4 id="空陷阱页"><a href="#空陷阱页" class="headerlink" title="空陷阱页"></a>空陷阱页</h4><p>​    您是否注意到，在前面的图表（图 7.11 和图 7.14）中，在最左边（图 7.11，虽然非常小！），在用户空间的最开始处有一个页面，名为空陷阱页？它是什么？这很简单：虚拟页面 0 没有权限（在硬件 MMU/PTE 级别）。因此，任何访问此页面的操作，无论是 r、w 还是 x（读/写/执行），都会导致 MMU 引发所谓的处理器故障或异常。这将使处理器跳转到 OS 处理程序例程（故障处理程序）。它运行，杀死试图访问没有权限的内存区域的罪魁祸首进程！</p>
<p>​    这确实非常有趣：前面提到的 OS 处理程序在进程上下文中运行，猜猜 current 是什么：为什么，它是启动这个错误的 NULL 指针查找的进程（或线程）！ （还请注意，不仅仅是 NULL 或 0x0 地址会生成此错误；从 0 到 4095 的任何地址都会生成此错误。）在错误处理程序代码中，SIGSEGV 信号被传递给错误进程（当前进程），导致其死亡（通过段错误）。简而言之，这就是操作系统捕获经典 NULL 指针取消引用错误的方式。<br>查看内核文档中的内存布局</p>
<p>​    回到内核 VAS；显然，对于 64 位 VAS，内核 VAS 比 32 位大得多。正如我们之前所看到的，它在 x86_64 上通常为 128 TB。再次研究前面显示的 VM 拆分表（常见 VM 拆分部分中的图 7.6）；在那里，标有“VM Split …”的列当然是不同架构的 VM 拆分。您可以看到，在 64 位 Intel/AMD 和 AArch64 (ARM64) 上，这些数字比 32 位版本大得多。</p>
<h4 id="随机化内存布局-–-KASLR"><a href="#随机化内存布局-–-KASLR" class="headerlink" title="随机化内存布局 – KASLR"></a>随机化内存布局 – KASLR</h4><p>​    在信息安全圈中，众所周知，利用 proc 文件系统 (procfs) 和各种强大的“黑客”工具（听说过 Kali Linux 吗？），恶意用户提前知道进程 VAS 内各种函数和/或全局变量的精确位置（虚拟地址），可以设计攻击来利用并最终破坏给定系统。（为什么，即使知道给定内核中一个众所周知的函数或全局变量的精确位置也可能导致攻击媒介！）因此，为了确保安全，使攻击者几乎不可能（或至少很难）依赖“已知”虚拟地址，用户空间以及内核空间支持地址空间布局随机化 (ASLR) 和内核 ASLR (KASLR) 技术（通常发音为 Ass-ler/Kass-ler）。</p>
<p>​    这里的关键字是随机化：启用此功能后，它会以绝对数字的形式更改进程（和内核）内存布局部分的位置，因为它会将部分内存从给定的基地址偏移一个随机（页面对齐）的数量。我们到底在谈论哪些“内存部分”？关于用户空间映射（我们稍后会讨论 KASLR）、共享库的起始地址（它们的加载地址）、基于 mmap() 的分配（您会意识到，任何 malloc() 函数（/calloc()/realloc()）分配任何高于 MMAP_THRESHOLD（通常为 128 KB）的内存都会变成基于 mmap 的分配，而不是堆外的内存）、堆栈启动、堆和 vDSO 页面；所有这些都可以在进程运行（启动）时随机化。因此，攻击者不能依赖 glibc 函数（例如 system()）在任何给定进程中被映射到特定的固定 UVA（就像以前一样！）；不仅如此，每次进程运行时，位置都会发生变化！在 ASLR 之前，以及在 ASLR 不受支持或关闭的系统上，可以提前确定给定架构和软件版本的符号位置（procfs 加上 objdump、readelf、nm 等实用程序使这变得非常容易）。</p>
<p>​    关键是要意识到 [K]ASLR 只是一种统计保护。事实上，通常情况下，没有太多位可用于随机化，因此熵不是很好。这意味着即使在 64 位系统上，页面大小的偏移量也不会太多，从而可能导致实现被削弱（经验丰富的破解者会很高兴）。现在让我们简要介绍一下有关用户模式和内核模式 ASLR（后者称为 KASLR）的更多细节；以下各节分别介绍这些领域。</p>
<h4 id="使用-ASLR-进行用户内存随机化"><a href="#使用-ASLR-进行用户内存随机化" class="headerlink" title="使用 ASLR 进行用户内存随机化"></a>使用 ASLR 进行用户内存随机化</h4><p>​    用户模式 ASLR 通常就是术语 ASLR 的意思。启用它意味着此保护在每个进程的用户空间映射上都可用。实际上，启用 ASLR 意味着用户模式进程的绝对内存映射在每次运行时都会有所不同，并且同一程序的每个进程实例在绝对用户空间内存映射方面都会有所不同。</p>
<p>​    Linux 已经支持 ASLR 很长时间了（自 2005 年 2.6.12 以来）。内核在 procfs 中有一个可调的伪文件来查询和设置（以 root 身份）ASLR 状态；<br>它在这里：/proc/sys/kernel/randomize_va_space。<br>它可以有三个可能的值；下表显示了三个值及其含义：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>可调值</th>
<th>/proc/sys/kernel/randomize_va_space 中此值的解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>（用户模式）ASLR 已关闭，或者可以通过在启动时传递内核参数 norandmaps 来关闭。</td>
</tr>
<tr>
<td>1</td>
<td>（用户模式）ASLR 已打开：基于 mmap() 的分配、堆栈和 vDSO 页面是随机的。这也意味着共享库加载位置和共享内存段是随机的。</td>
</tr>
<tr>
<td>2</td>
<td>（用户模式）ASLR 已打开：所有前面的（值 1）加上堆位置都是随机的（自 2.6.25 起）；默认情况下，这是操作系统值。</td>
</tr>
</tbody>
</table>
</div>
<p>​    如前文 vsyscall 页面所述，vDSO 页面是一种系统调用优化，允许以较少的开销调用一些频繁发出的系统调用（gettimeofday() 就是一个典型调用）。如果感兴趣，您可以在此处的 vDSO(7) 手册页上查找更多详细信息：<a target="_blank" rel="noopener" href="https://man7.org/linux/manpages/man7/vdso.7.html。">https://man7.org/linux/manpages/man7/vdso.7.html。</a></p>
<p>​    可以通过将 norandmaps 参数传递给内核（通过引导加载程序）在启动时关闭用户模式 ASLR；为什么要这样做？在调试时这样做有时很有用…在生产中将其打开！</p>
<h4 id="使用-KASLR-进行内核内存布局随机化"><a href="#使用-KASLR-进行内核内存布局随机化" class="headerlink" title="使用 KASLR 进行内核内存布局随机化"></a>使用 KASLR 进行内核内存布局随机化</h4><p>​    类似于（用户）ASLR - 以及最近从 3.14 内核开始 - 甚至内核 VAS 也可以通过启用 KASLR 进行随机化（在一定程度上）。在这里，一些内核部分（lowmem、vmalloc 和 vmemmap 区域）的基址以及内核 VAS 内的模块代码将通过与 RAM 基址对齐的页面随机偏移量进行随机化。这对该会话一直有效 - 也就是说，直到电源循环或重新启动。</p>
<p>​    内核KASLR 的配置名为 CONFIG_RANDOMIZE_MEMORY。KASLR 似乎在 x86[_64] 和 AArch64 平台上受支持，但在 AArch32 上不受支持。</p>
<p>​    存在几个内核配置变量，使平台开发人员能够启用或禁用这些随机化选项。作为特定于 x86 的示例，以下内容直接引用自 Documentation/x86/x86_64/mm.txt<br>(<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/Documentation/x86/x86_64/mm.rst#L148)：">https://elixir.bootlin.com/linux/v6.1.25/source/Documentation/x86/x86_64/mm.rst#L148)：</a></p>
<p>​    配置完成后，KASLR 将默认保持开启状态；可以通过传递内核命令行参数（通过引导加载程序）来控制其在启动时的状态：通过传递 nokaslr 参数明确将其关闭通过传递 kaslr 参数明确将其打开从 5.13 内核开始，有一项新的安全功能可用：CONFIG_RANDOMIZE_KSTACK_OFFSET_DEFAULT。打开它会使内核模式堆栈偏移量在每次发出系统调用时随机化！（请查看编写得非常好的提交 #39218ff4c625dbf2，此处：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/commit/39218ff4c625dbf2e68224024fe0acaa60bcd51a）。提示：您可以从">https://github.com/torvalds/linux/commit/39218ff4c625dbf2e68224024fe0acaa60bcd51a）。提示：您可以从</a> <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux">https://github.com/torvalds/linux</a> 的搜索框中搜索给定的（缩写）提交编号。那么，你的 Linux 系统上 [K]ASLR 的当前设置是什么？我们可以更改它吗？当然可以（前提是我们有 root 访问权限）；下一节将向你展示如何通过 Bash 脚本进行更改</p>
<h4 id="了解物理内存组织"><a href="#了解物理内存组织" class="headerlink" title="了解物理内存组织"></a>了解物理内存组织</h4><p>现在我们已经详细研究了用户和内核 VAS 的虚拟内存视图，让我们转到 Linux 操作系统上的物理内存组织主题。</p>
<h4 id="物理-RAM-组织"><a href="#物理-RAM-组织" class="headerlink" title="物理 RAM 组织"></a>物理 RAM 组织</h4><p>​    Linux 内核在启动时将物理 RAM 组织和划分为由节点、区域和页框（页框是 RAM 的物理页面）组成的树状层次结构（参见图 7.22 和图 7.23）。请注意，在早期启动时还会通过物理内存模型进行进一步的组织，这是一个相关的讨论；我们将在物理内存模型简介部分对此进行一些说明。</p>
<p>​    节点分为区域，区域由页框组成。它本质上是一个树状层次结构，简单而概念性地描述为三级树状层次结构，如下所示：</p>
<ul>
<li>节点 ← 1 级</li>
<li>区域 ← 2 级</li>
<li>页面框架 ← 3 级</li>
</ul>
<p>​    节点是一种元数据结构，它抽象了物理 RAM 库；该 RAM 本身与一个或多个处理器 (CPU) 内核相关联。在硬件级别，微处理器连接到 RAM 控制器芯片；任何内存控制器芯片，以及任何 RAM，都可以通过互连从任何 CPU 内核访问。</p>
<p>​    现在，显然，能够访问物理上最接近线程正在分配或使用内存的内核的 RAM 将提高性能。支持所谓 NUMA 模型（其含义稍后解释）的硬件和操作系统利用了这个想法。</p>
<h4 id="节点和-NUMA"><a href="#节点和-NUMA" class="headerlink" title="节点和 NUMA"></a>节点和 NUMA</h4><p>​    本质上，节点是用于表示和抽象系统主板上的物理 RAM 模块及其相关控制器芯片组的数据结构。是的，我们在这里谈论的是通过软件元数据抽象的实际硬件。（请注意，在这种情况下使用的术语“节点”可能与用于表示网络上的单个硬件计算机时不同）。它始终与系统主板上的物理插槽（或处理器核心集合）相关联。存在两种类型的层次结构：<br>非统一内存访问 (NUMA) 系统：发生内核分配请求的特定 CPU 核心很重要（内存处理不统一），从而提高性能</p>
<p>​    统一内存访问 (UMA) 系统：发生内核分配请求的特定 CPU 核心无关紧要（内存处理统一）</p>
<p>​    真正的 NUMA 系统是那些硬件始终是多核的系统 - 意味着两个或更多个 CPU 核心，因此它也始终是对称多处理器 (SMP) - 并且必须有两个或更多个物理 RAM 组，每个 RAM 组都与一个 CPU（或多个 CPU）相关联。换句话说，NUMA 系统将始终具有两个或更多节点，而 UMA 系统将只有一个节点（仅供参考，抽象节点的数据结构称为 pg_data_t，在此处定义：include/linux/mmzone.h:pg_data_t 作为 typedef 结构）。</p>
<p>​    您可能想知道为什么会有这么复杂？好吧，这 – 还有什么 – 都与性能有关！NUMA 系统（它们通常是相当昂贵的服务器级机器和超级计算机）及其运行的操作系统（通常是 Linux/Unix/Windows Server）的设计方式是，当特定 CPU 核心上的进程（或线程）想要执行内核内存分配时，软件会保证它通过从最靠近核心的节点获取所需的内存（RAM）来高性能地完成此操作（因此得名 NUMA！）。 UMA 系统（典型的嵌入式系统、智能手机、笔记本电脑和台式机）没有这种好处，而且这些好处也不重要。如今，企业、数据中心级服务器和超级计算机系统可以拥有数百个处理器和 TB 甚至几 PB 的 RAM、一个节点，并且会有 2 个或更多节点。这些几乎总是被设计为 NUMA 系统。然而，根据 Linux 的设计方式——这是一个关键点——即使是普通的 UMA 系统也被内核视为 NUMA 系统（伪 NUMA）。这是为了不惜一切代价避免更改代码库，从而分叉 Linux（正如您所知，完全相同的 Linux 内核代码库用于为任何类型的 Linux 系统提供支持，从微型嵌入式系统到超级计算机）。它们（UMA 系统）将只有一个节点，因此这是一种快速检查系统是 NUMA 还是 UMA 的方法：如果有两个或更多节点并且它有多个 CPU 核心，则它是一个真正的 NUMA 系统；只有一个节点和/或只有一个 CPU 核心，它是一个“假 NUMA”或伪 NUMA 盒。您如何检查节点数？numactl 实用程序是一种方法（尝试执行 numactl —hardware）。还有其他方法可以检查（通过 procfs 本身）；稍等一下，我们会到达那里…（仅供参考，检查操作系统看到的 CPU 核心数量很容易；您可以使用 nproc、lscpu 和/或 cat /proc/cpuinfo）。因此，一种更简单的可视化方法：在 NUMA 盒上，一个或多个 CPU 核心与物理 RAM 的存储体（硬件模块）相关联；这称为节点，MUMA 系统将总是有两个或更多节点。因此，NUMA 系统也总是 SMP 系统，但 SMP 盒可能是 NUMA 或 UMA 系统。NUMA 服务器处理器的示例为了使这个讨论更实际一些，让我们简要地形象化一个实际服务器系统的微架构——运行 AMD Epyc/Ryzen/Threadripper（和较旧的 Bulldozer）CPU。它包含以下硬件（见图 7.22）：主板上的两个物理插槽（P#0 和 P#1）内总共有 32 个 CPU 内核（操作系统所见）。每个插槽由一组 8x2 CPU 内核组成（8x2，因为实际上有 8 个物理内核，每个内核都是超线程的；操作系统当然将每个超线程内核视为可用内核，因此每个插槽总共有 16 个 CPU 内核）。总共 32 GB 的 RAM 被分成四个物理组，每个组 8 GB。</p>
<p>​    显然，这里的系统是多核 (SMP) 的，并且有两个或更多 RAM 组，因此符合真正的 NUMA 系统的标准。因此，Linux NUMA 感知内存管理代码在启动时检测到此拓扑后，将设置四个 NUMA 节点来表示它。我们不会在这里深入研究处理器的各种（L1/L2/L3/等）缓存；</p>
<p>请参阅下图后面的提示框，以了解所有这些内容。此外，这样的系统被称为缓存一致性 NUMA (ccNUMA)，因为它们在硬件的帮助下保持缓存一致性；您将在第 13 章“内核同步 - 第 2 部分”的“了解 CPU 缓存基础知识、缓存效果和错误共享”部分中了解有关缓存和缓存一致性的更多信息。以下概念图显示了运行 Linux 操作系统的某些 AMD 服务器系统上形成的四个树状层次结构（每个节点一个）的近似值。图 7.22 概念性地显示了与不同 CPU 核心耦合的系统上每个物理 RAM 组的节点/区域/页框：</p>
<p><img src="./../七月笔记学习日志/7.10/image-20240710103535433.png" alt="image-20240710103535433"></p>
<h4 id="节点内的区域"><a href="#节点内的区域" class="headerlink" title="节点内的区域"></a>节点内的区域</h4><p>​    区域可以被认为是 Linux 消除和处理硬件怪癖的方式；这些怪癖往往在 x86 上激增，当然 Linux 就是在 x86 上“成长”的。它们还处理了一些软件难题（在现在大部分是传统的 32 位 x86 架构上查找 ZONE_HIGHMEM；我们在前面的 32 位系统上的高端内存部分讨论了这个概念）。</p>
<p>​    区域构成层次结构的第二层；它们始终属于某个节点（0、1、2、…）并由页框（RAM 的物理页面）组成。更技术性地说，节点内的每个区域都分配了一系列页框号 (PFN)：</p>
<p><img src="./../七月笔记学习日志/7.10/image-20240710103606333.png" alt="image-20240710103606333"></p>
<p>（题外话：有关 Linux 如何跟踪 PFN 的更多信息，请参阅物理内存模型简介部分。）<br>图 7.23 描绘了一个概念上的通用 Linux 系统，它有 N 个节点（编号从 0<br>到 N-1），每个节点由例如三个区域组成，每个区域由 RAM 的物理页面（页框）组成。每个节点的区域数量（和名称）由内核在启动时动态确定。您可以通过深入研究 procfs 来检查 Linux 系统上的这个物理内存层次结构。在下面的代码中，我们查看了具有 16 GB RAM 的本机 Linux x86_64 系统：</p>
<pre class="line-numbers language-none"><code class="language-none">$ cat &#x2F;proc&#x2F;buddyinfo
节点 0，区域 DMA 3 2 4 3 3 1 0 0 1 1 3
节点 0，区域 DMA32 31306 10918 1373 942 505 196 48 16 4 0 0
节点 0，区域 Normal 49135 7455 1917 535 237 89 19 3 0 0 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    最左边的一列显示整个系统中只有一个节点：节点 0。这告诉我们我们实际上是在 UMA 系统上，当然，Linux 操作系统会将其视为（伪/假）NUMA 系统。可以看出，这个单节点（节点 0）被分成三个区域，分别标记为 DMA、DMA32 和 Normal；当然，每个区域都由页框组成。现在，请忽略右侧的数字；我们将在下一章中了解它们的含义。另一种观察 Linux 如何在 UMA 系统上“伪造”NUMA 节点的方法是从内核日志中可见。我们在具有 16 GB RAM 的同一本机 x86_64 系统上运行以下命令。为了便于阅读，我用省略号替换了显示时间戳和主机名的前几列：</p>
<pre class="line-numbers language-none"><code class="language-none">$ journalctl -b -k --no-pager | grep -A7 &quot;NUMA&quot;
&lt;...&gt;: 未找到 NUMA 配置
&lt;...&gt;: 在 [mem 0x0000000000000000-0x00000004427fffff] 处伪造节点
&lt;...&gt;: NODE_DATA(0) 已分配 [mem 0x4427d5000-0x4427fffff]
&lt;...&gt;: 区域范围:
&lt;...&gt;: DMA [mem 0x000000000001000-0x000000000ffffff]
&lt;...&gt;: DMA32 [mem 0x0000000001000000-0x00000000ffffffff]
&lt;...&gt;: 正常 [mem 0x0000000100000000-0x00000004427fffff]
&lt;...&gt;: 设备为空
$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    我们可以清楚地看到，由于检测到系统不是 NUMA（因此是 UMA），因此内核伪造了一个 NUMA 节点。节点的范围是系统上的 RAM 总量（此处为 0x0-0x00000004427fffff，实际上是 16 GB）。我们还可以看到，在这个特定的系统上，内核实例化了三个区域 - DMA、DMA32 和 Normal - 来组织 RAM 的可用物理页框。这很好，并且与我们之前看到的 /proc/buddyinfo 输出相关。表示 Linux 上区域的数据结构在此处定义：include/linux/mmzone.h:struct zone。我们将在本书后面有机会访问它。现在，为了更好地理解 Linux 内核如何组织 RAM，让我们从最开始的地方开始——启动时。<br>直接映射 RAM 和地址转换</p>
<p>​    在启动时，Linux 内核将所有（可用）系统 RAM（又名平台 RAM）直接“映射”到内核 VAS（我们在检查内核 VAS 部分了解了这一点；如果您愿意，请再次参见图 7.12 和图 7.14）。因此，我们有以下内容：</p>
<ul>
<li>物理页框 0 映射到内核虚拟页 0。</li>
<li>物理页框 1 映射到内核虚拟页 1。</li>
<li>物理页框 2 映射到内核虚拟页 2，依此类推。</li>
</ul>
<p>​    因此，我们将其称为 1:1 或直接映射、身份映射 RAM 或线性地址。一个关键点是，所有这些内核虚拟页面都与其物理对应页面有固定的偏移量（并且，如前所述，这些内核地址被迂回地称为内核逻辑地址）。固定偏移量是 PAGE_OFFSET 值（这里我们假设它的值是 0xc000 0000）。</p>
<p>​    因此，请考虑这一点。在具有 3:1（GB）VM 分割的 32 位系统上，物理地址 0x0 等于内核逻辑地址 0xc000 0000（PAGE_OFFSET）。如前所述，（迂腐的）术语内核逻辑地址适用于与其物理对应地址有固定偏移量的内核地址。因此，直接映射 RAM 映射到内核逻辑地址。直接映射内存的这一区域通常称为内核 VAS 内的低内存（或简称为 lowmem）区域。</p>
<p>​    我们之前已经展示了一个几乎相同的图表，图 7.12。在下图中，为了强调刚才提到的要点，我们对其进行了轻微的修改，以实际显示 RAM 的前三个（物理）页框如何映射到前三个内核虚拟页（在内核 VAS 的 lowmem 区域中）：</p>
<p><img src="./../七月笔记学习日志/7.10/image-20240710103719828.png" alt="image-20240710103719828"></p>
<p>​    接下来，还有另一个需要注意的关键点：通过将所有物理 RAM 映射到自身，不要误以为内核正在为自己保留 RAM。事实并非如此；它只是映射所有可用 RAM，从而将其分配给任何需要它的人——核心内核代码、内核线程、设备驱动程序或用户空间应用程序。这是操作系统工作的一部分；毕竟，它是系统资源管理器。当然，毫无疑问，在启动时，一定比例的 RAM 将被静态内核代码、数据、内核页表等占用（分配）。此外，使用内核的 kdump 和/或连续内存分配器 (CMA) 功能可能需要在启动时为它们保留更大的指定 RAM 量。但通常情况下，您应该意识到内核本身直接使用的 RAM 量非常小。例如，在我的具有 1 GB RAM 的客户 VM 上，内核代码、数据和BSS 通常总共占用约 25 MB 的 RAM。所有内核内存大约为 100 MB，而用户空间内存使用量约为 550 MB！几乎总是用户空间占用内存。</p>
<blockquote>
<p>提示：尝试使用带有 —system -p 选项开关的 smem 实用程序来查看内存使用率摘要（也可以使用 —realmem= 开关传递系统上的实际 RAM 量）。</p>
</blockquote>
<p>回到正题：我们知道内核页表是在启动过程的早期设置的。</p>
<p>​    因此，在应用程序启动时，内核已映射所有 RAM 并可用，准备好分配！因此，我们明白，虽然内核直接将页面框架映射到其 VAS 中，但用户模式进程就没那么幸运了——它们只能通过操作系统在每个进程上设置的分页表（在进程创建时 - fork() - 时间）间接映射页面框架。同样有趣的是，通过强大的 mmap() 系统调用进行内存映射可以提供将文件或匿名页面“直接映射”到用户 VAS 的错觉（在后台，它都是页表操作）。需要注意的另外几点：</p>
<p>为了提高性能，分配的内核内存页面永远不能交换，即使它们没有被使用。有时，您可能会认为，用户空间内存页面通过操作系统在每个进程上设置的分页表映射到（物理）页面框架（假设页面是常驻的）是相当明显的。是的，但是内核内存页面呢？请明确这一点：所有内核页面也通过内核“主”分页表（名为<br>swapper_pg_dir）映射到页面框架。内核内存也是虚拟化的，就像用户空间内存一样。<br>在这方面，对于您，感兴趣的读者，请查看我在 Stack Overflow 上发起的问答：内核虚拟地址究竟是如何转换为物理 RAM 的？<br><a target="_blank" rel="noopener" href="http://stackoverflow.com/questions/36639607/how-exactly-do-kernel-virtual-addresses-gettranslated-to-physical-ram。">http://stackoverflow.com/questions/36639607/how-exactly-do-kernel-virtual-addresses-gettranslated-to-physical-ram。</a></p>
<p>Linux 内核中已经嵌入了几种内存优化技术（嗯，许多是配置选项）；其中包括透明大页面（THP）和对云/虚拟化工作负载至关重要的内核同页合并（KSM，又名内存重复数据删除）。我建议您参阅本章的进一步阅读部分以获取更多信息。</p>
<p>现在我们已经介绍了物理内存层次结构的前两个级别（节点和区域），让我们深入研究第三个也是最后一个级别的组织：页面框架！</p>
<h4 id="物理内存模型简介"><a href="#物理内存模型简介" class="headerlink" title="物理内存模型简介"></a>物理内存模型简介</h4><p>​    无论如何，物理内存都是宝贵的资源。此外，现代系统上的内存组织可以是复杂的层次结构，内存空间之间散布的大洞（或稀疏区域）非常常见（前面的部分对此进行了掩盖）。不仅如此，服务器类型系统上的每个 NUMA 节点都需要自己的一组内存管理元数据。硬件也变得更加苛刻 - 热插拔（和移除）内存组（和 CPU）的能力，在某些类型的持久存储设备中设置页面级映射的愿望，等等……因此，Linux 内核社区设计了抽象来更好地模拟和管理物理内存。这些抽象采用内存模型的形式；事实上，到目前为止，已经提出并实施了三种这样的模型：flatmem、discontigmem 和 sparsemem。但实际上，sparsemem 模型是得到广泛部署的模型，尤其是在具有大量 RAM 的现代 64 位系统中；discontigmem 模型已被弃用，而 flatmem 模型仍然坚持使用（为具有少量 RAM 的 32 位系统提供服务）。</p>
<p>​    在所有模型中，一个基本概念是能够跟踪系统上每个物理 RAM 页。跟踪这一点的元数据结构是 struct page（<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/include/li">https://elixir.bootlin.com/linux/v6.1.25/source/include/li</a><br>nux/mm_types.h#L73）；它通常被称为页面描述符。（使用页面结构跟踪每个 RAM 页？是的，这就是为什么它被保留下来的原因mall，只有 64 个字节；尽管如此，它确实会占用内存，尤其是在 RAM 量很大的情况下。）它包含有关其跟踪的页面的元数据 - 它正在用于什么（或者它当前是空闲的），以及各种标志值，包括映射。<br>回到内存模型。Linux 要求每个架构使用一个模型来管理其内存 - flatmem 或 sparsemem。早期启动中的 arch-specific 代码设置了这一点（例如，sparse_init() 设置了 sparsemem 模型）。每个内存模型都具有以下几个特征：</p>
<ul>
<li>由于物理 RAM 往往是连续的页面框架，可能被孔洞打破，因此模型通常在单元内实现一个或多个 struct page 数组；sparsemem 将单元称为部分。</li>
<li>每个物理 RAM 帧都由页框号 (PFN) 表示，实际上是指向 struct page 对象数组的索引。PFN 和 struct page 之间始终存在 1:1 映射。这种映射需要辅助函数在两者之间进行转换：辅助函数 page_to_pfn() 和 pfn_to_page() 将为每个模型进行最低限度的定义。</li>
</ul>
<p>让我们更深入地研究一下 sparsemem 内存模型。</p>
<h4 id="简要了解-sparsemem-vmemmap-内存模型"><a href="#简要了解-sparsemem-vmemmap-内存模型" class="headerlink" title="简要了解 sparsemem[-vmemmap] 内存模型"></a>简要了解 sparsemem[-vmemmap] 内存模型</h4><p>sparsemem 模型实际上是多功能的，也是实践中最常用的模型。它可以抽象和支持所需的现代功能，如内存组的热插拔、持久设备内存映射、内存的延迟初始化等。<br>该模型可以通过两种方式实现强制性辅助 API（page_to_pfn() 和 pfn_to_page()）：通过“经典稀疏”或“稀疏 vmemmap”方法。</p>
<p>​    当使用后者（常见方法）时，vmemmap 指针指向 struct page 对象数组的基数（更准确地说，它被设置为 (struct page*)VMEMMAP_START。为了更直观地了解，我建议您查看图表（并阅读文章）：<a target="_blank" rel="noopener" href="https://lwn.net/Articles/839737/。现在您将更好地理解">https://lwn.net/Articles/839737/。现在您将更好地理解</a> vmemmap 区域 - 描述的源自此指针的元数据 - 在前面的描述内核 VAS 布局的宏和变量部分中提到。由于 sparsemem-vmemmap 模型是当今 64 位 Linux 的首选模型，您经常会发现内核配置 CONFIG_SPARSEMEM_VMEMMAP=y, CONFIG_SPARSEMEM_VMEMMAP_ENABLE=y 在这样的系统上设置（现代 x86_64 总是使用sparsemem 模型和 AArch64 平台似乎也遵循此模型。仅供参考，AArch64 的通用 Android 通用内核映像 (GKI) 内核默认也启用了这些配置选项，表明它也使用此模型）。</p>
<p>​    需要为 sparsemem 模型定义两个宏：</p>
<ul>
<li>SECTION_SIZE_BITS：物理地址位数，用于覆盖（物理连续）部分中的最大内存量；每个内存部分的大小将为 2 的此幂。</li>
<li>MAX_PHYSMEM_BITS：物理地址中的最大位数；实际上，支持的最大 RAM 量。此值与 AArch64 上可配置的 CONFIG_ARM64_PA_BITS 内核相同。</li>
</ul>
<p>这些宏通常在 <code>arch/&lt;arch&gt;/include/asm/sparsemem.h</code>标头中定义。</p>
<h2 id="Kernel-Memory-Allocation"><a href="#Kernel-Memory-Allocation" class="headerlink" title="Kernel Memory Allocation"></a>Kernel Memory Allocation</h2><p>​    在本节中，我们将非常简要地总结您目前已经学到的内容。这旨在让您快速查找和回忆这些要点！</p>
<p>使用 slab 分配器（或 slab 缓存）API 分配和释放内核内存的优点如下：</p>
<ul>
<li>（非常）快（因为它使用预缓存的内存对象）。</li>
<li>保证分配物理上连续的内存块。</li>
<li>当创建缓存时指定 SLAB_HWCACHE_ALIGN 标志时，可以保证硬件（CPU）缓存行对齐的内存。这是 kmalloc()、kzalloc() 等的情况。</li>
<li>您可以为（频繁分配/释放的）对象创建自己的自定义 slab 缓存。 使用 slab 分配器（或 slab 缓存）API 的缺点如下： 一次可以分配的内存量有限；通常，通过 slab 接口直接分配的内存仅为 8 KB，或者在大多数当前平台上通过页面分配器间接分配的内存高达 4 MB（确切的上限取决于架构和系统页面大小；这些值适用于 x86[_64] 和 ARM 平台，页面大小为 4,096 字节，MAX_ORDER 值为 11）。</li>
<li>错误使用 k{m|z}alloc() API：请求过多的内存，或请求的内存大小刚好超过阈值（在第 8 章“模块作者的内核内存分配 - 第 1 部分”的 kmalloc API 的大小限制部分中详细讨论），肯定会导致内部碎片（浪费）。它实际上仅针对常见情况进行了优化 - 分配大小小于一页。</li>
</ul>
<p>现在，让我们继续讨论内核/驱动程序开发人员需要理解的另一个关键方面——仅提及：当内存分配/释放出现问题时，尤其是在 slab 层中，如何有效地进行调试。</p>
<p>调试内核内存问题——简要提及</p>
<p>不幸的是，内存损坏是导致错误的常见根本原因，能够调试它们是一项关键技能。好吧，不幸的是（并表示歉意），由于两个主要原因，我们没有在本书中介绍内核内存调试：</p>
<ol>
<li>这不是一本关于内核调试的书。</li>
<li>我最近（截至 5.10 LTS 内核）的 Linux 内核调试 (LKD) 一书中深入介绍了内核调试的主题，其中包括两章非常详细的关于调试内核内存问题的介绍。</li>
</ol>
<p>尽管如此，在这本书中，我认为我有责任至少提到调试内核内存问题时通常使用的各种工具和方法。您最好熟悉这里提到的强大的动态（运行时）分析框架/工具：</p>
<p>Sanitizer 工具集：</p>
<ul>
<li>KASAN（内核地址清理器）：适用于 x86_64和 AArch64，4.x 内核及以上版本</li>
<li>KMSAN（内核内存清理器）：内核等效于用户空间 MSAN（内存清理器）工具，可 以捕获致命的 UMR（未初始化内存读取）错误（最近，6.1 及以上版本）</li>
<li>UBSAN（未定义行为清理器）：捕获多种类型的 算术和内存相关 UB，包括 UMR 错误（4.5 及以上版本）</li>
<li>SLUB 调试技术： 依赖于 CONFIG_SLUB_DEBUG=y 并在启动时将各种标志传递给内核以启用不同类型的 SLUB 内存调试</li>
<li>（这些标志包括 F：健全性检查、Z：红色分区,P:投毒 , U:用户跟踪，等等……仅供参考，我们在第 8 章“模块作者的内核内存分配 - 第 1 部分”的“使用 alloc_traces 和自定义脚本的更多详细信息”部分中使用了 SLUB 调试及其标志。了解如何使用功能强大的 slabinfo 实用程序。 kmemleak（用于捕获内存泄漏，尽管 KASAN 似乎更胜一筹）。 eBPF 工具 memleak[-bpfcc] 可用于跟踪尚未释放的内核级分配。它功能强大 - 它甚至显示分配的内存量以及导致分配的调用跟踪！（尝试一下：sudo memleak-bpfcc -s 5）。嗯，到目前为止它还不是完全稳定的，你的里程可能会有所不同（YMMV）…</li>
<li>KFENCE：一种捕获内存错误的统计方法；必须运行 长时间，但开销足够低，甚至可以在 生产环境中运行！（事实上，如果编译的架构支持，并且启用了 SLAB 或 SLUB，则通常默认启用）。 kmemcheck（但请注意，kmemcheck 在 Linux4.15 中被删除）。</li>
</ul>
<p>还有更多（逐字引用 LKD 书中的内容）： 您可以使用以下方法间接捕获内核内存错误：</p>
<ul>
<li>静态分析工具：checkpatch.pl、sparse、smatch、Coccinelle、cppcheck、flawfinder 和 GCC</li>
<li>跟踪技术K[ret]probes 工具</li>
<li>事后分析工具（日志、Oops 分析、kdump/crash 和[K]GDB）</li>
</ul>
<p>好的。我将在下表中总结此信息，并详细说明您可以使用的工具。</p>
<p><img src="./image-20240712073341312.png" alt="image-20240712073341312"></p>
<h4 id="学习使用-vmalloc-系列-API"><a href="#学习使用-vmalloc-系列-API" class="headerlink" title="学习使用 vmalloc 系列 API"></a>学习使用 vmalloc 系列 API</h4><p>​    您可以从内核的 vmalloc 区域分配虚拟内存（当然是在内核空间中）——您可以将其视为内核中可分配虚拟内存页面的全局“池”——使用 vmalloc() API：</p>
<pre class="line-numbers language-none"><code class="language-none">#include &lt;linux&#x2F;vmalloc.h&gt;
void *vmalloc(unsigned long size);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<ul>
<li>关于 vmalloc 需要注意的一些要点： vmalloc() API 为调用者分配连续的虚拟内存。</li>
<li>无法保证分配的区域在物理上是连续的；它可能连续也可能不连续（分配越大，它在物理上连续的可能性越小）。</li>
<li>分配的虚拟页面的内容在理论上是随机的；在实践中，它似乎依赖于架构（至少 x86_64 似乎将内存区域清零）；当然（可能会有轻微的性能损失），建议您使用 vzalloc() 包装器 API（其签名与 vmalloc() 的签名相同）来确保内存归零。</li>
<li>vmalloc()（及其相关函数）API 只能从安全休眠（或非原子）进程上下文中调用（因为它可能会导致调用者休眠；因此，在进程上下文中调用它但同时持有自旋锁会违反此规则；不要这样做）。</li>
<li>成功时，v{m|z}alloc() 的返回值为内核虚拟地址（或 KVA）（在内核的 vmalloc 区域内），失败时为 NULL；虽然不太可能失败，但作为一名优秀的开发人员，检查失败情况是您的工作。</li>
</ul>
<p>​    刚刚分配的 vmalloc 内存区域的起始位置保证位于页面边界上（换句话说，分配始终是页面对齐的）。这告诉我们一些事情：v{m|z}alloc() API 旨在用于较大的内存分配，当分配的区域可能在物理上不连续时是可以接受的。</p>
<p>​    实际分配的内存（来自页面分配器）可能比请求的内存大（同样，它在内部分配了足够的页面来覆盖请求的大小）。 你会觉得这个 API 看起来与熟悉的用户空间 malloc() 非常相似。乍一看确实如此，只是当然，它是一个内核空间分配（同样，与 kmalloc() 系列一样，请记住，用户和内核分配 API 之间没有直接关联）。</p>
<p>​    既然如此，vmalloc() 对我们模块或驱动程序作者有什么帮助？当您需要一个比 slab API（即 k{m|z}alloc() 及其同类函数）所能提供的更大的、几乎连续的缓冲区时（回想一下，在 ARM 和 x86[_64] 上，单个分配通常为 4 MB），那么您应该使用 vmalloc()！</p>
<p>​    仅供参考，内核使用 vmalloc() 的原因有很多。其中一些原因如下：在将内核模块加载到内核时（在 kernel/module/main.c:load_module() 深处），为其（静态）内存分配空间。</p>
<p>​    如果定义了 CONFIG_VMAP_STACK（目前通常如此），则 vmalloc() 用于在线程诞生时分配内核模式堆栈（在 kernel/fork.c:alloc_thread_stack_node() 中）。</p>
<p>​    在内部，在为名为 ioremap()（及其同类函数）的操作提供服务时。     在 Linux 套接字过滤器 (bpf) 代码路径中，等等。     为了方便起见，内核提供了 vzalloc() 包装器 API（类似于kzalloc()）来分配和清零内存区域 - 毫无疑问，这是一种很好的编码实践，但可能会稍微损害时间关键的代码路径：</p>
<pre class="line-numbers language-none"><code class="language-none">void *vzalloc(unsigned long size);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>一旦您使用完分配的虚拟缓冲区，您当然必须释放它：</p>
<pre class="line-numbers language-none"><code class="language-none">void vfree(const void *addr);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    正如预期的那样，vfree() 的参数是 v{m|z}alloc() 的返回地址（甚至是这些调用的底层 __vmalloc() API）。将 NULL 传递给 vfree() 会导致它无害地返回。</p>
<p>关于用户模式内存分配和请求分页的简要说明</p>
<p>我们不会深入研究 vmalloc() 或用户空间 malloc() API 的内部工作原理，但我们仍将介绍一些关键点，像您这样的有能力的内核/驱动程序开发人员必须了解这些要点。</p>
<p>在用户空间应用程序中（在进程或线程内），假设我们这样做：</p>
<p>p = malloc(10000);</p>
<p>假设它成功了。人们普遍认为，现在，地址 p 以后有 10,000 字节的物理 RAM 可用。</p>
<p>猜猜怎么着：在 Linux 等现代操作系统上，这不一定是真的（至少不是立即的）！我们不会责怪您这样想；这只是现代操作系统的工作方式。</p>
<p>​    清楚地了解内存分配对于流行的用户空间 malloc() API 和朋友的实际工作方式非常有启发性——这一切都是通过请求分页进行的！意思是，这些 API 的成功返回对物理内存分配没有任何意义。当用户空间 malloc() 返回成功时，到目前为止真正发生的一切就是保留了一个虚拟内存区域；尚未实际分配任何物理内存！物理页面框架的实际分配仅在访问虚拟页面时（对于任何操作：读取、写入或执行）以页面为基础进行。但这在内部是如何发生的？答案：它只是通常的内存管理代码将虚拟地址转换为其对应的物理对应部分的一部分，即副作用（否则机器将如何工作？）。我们在第 7 章“内存管理内部原理 - 要点”的“从虚拟地址到物理地址”部分简要介绍了这个主题。因此，快速总结一下：每当内核（在进程或中断上下文中运行）或用户空间进程或线程访问虚拟地址时，该虚拟地址都会通过 CPU 发送到内存管理单元 (MMU) 并由其解释，内存管理单元是 CPU 核心上硅片的一部分。检查硬件优化：代码/数据是否已经在 CPU 内部 L1/L2/… 缓存中；如果是，则对其进行处理，任务就完成了。如果没有，我们是否有转换后备缓冲区 (TLB) 命中？如果是，则内存转换（虚拟到物理地址）已经可用；如果没有（我们有一个 TLB 未命中 - 代价高昂！），MMU 现在将遍历进程的分页表（位于内核内存中），有效地转换虚拟地址并从而获取物理地址。然后，它将转换缓存在 TLB 中，并将物理地址放在地址总线上，CPU 继续运行。</p>
<p>​    但是，请考虑一下：如果 MMU 无法将给定的虚拟地址转换为物理地址，该怎么办？这种情况可能由于多种原因而发生；其中一些原因如下：虚拟地址（尚未）具有到物理地址的映射。虚拟地址完全不正确（一个错误）。第一种情况实际上是我们的 malloc() 示例中将发生的情况 - 当线程以任何方式（读取/写入/执行）在新分配的虚拟页面中“接触”任何内存时，虚拟地址将发送到 MMU。现在，想想，MMU 无法将其转换为物理地址，因为自然没有映射，没有物理页面框架（尚未），只有虚拟页面。此时，MMU 基本上放弃了，因为它无法处理这种情况（毕竟它是硅，可怜的家伙）。相反，它将控制权移交给操作系统，调用其页面错误处理程序代码 - 在当前进程上下文中运行的异常或错误处理程序例程 - 换句话说，在当前上下文中。页面错误处理程序解决了这种情况；在我们的例子中，使用 malloc()，一旦它确定这确实是合法访问，它就会向页面分配器（或 BSA）请求单个物理页面框架（在顺序 0）并将其映射到虚拟页面（更新进程的分页表）。因此，我们现在可以看到虚拟页面实际上是在需要时才物理分配的，仅在访问时才分配，而不是在访问之前。这种物理内存分配方法称为按需分页（或惰性分配，所有现代操作系统基本上都做同样的事情）！此外，作为推论：如果用户空间进程或线程在内存区域上执行 malloc() 然后执行 memset()，则物理框架将在写入每个虚拟页面时分配！这也适用于 calloc() 之类的 API；因此，在实时系统中，我们更希望开发人员使用此类 API 在到达时间关键型代码路径之前预先在所需的内存帧中发生故障。</p>
<p>​    同样重要的是要意识到，这种按需分页（或惰性分配）操作系统技术不适用于通过页面（伙伴系统）、slab 分配器甚至 vmalloc 内存区域执行的内核内存分配。</p>
<p>​    因此，当通过内核 API 分配内核内存时，要明白实际的物理页面帧是立即分配的。（在 Linux 上，一切都非常快，因为回想一下，到那时系统启动后，伙伴系统分配器每个节点和每个区域的空闲列表已经将所有系统物理 RAM 映射到内核的 lowmem 区域，因此可以随意使用它。）vmalloc()（及其朋友）最终也使用页面分配器来满足内存分配请求；只是虚拟页面来自内核 VAS 内指定的“vmalloc 区域”。</p>
<p>​    您可以继续参考图 9.9，它很好地映射了所有这些；现在，请忽略 OOM 杀手的部分。我们当然会在后面的部分中介绍它。</p>
<p>​    回想一下我们在早期程序 ch8/lowlevel_mem 中所做的工作；在那里，我们使用 show_phy_pages() 库例程显示给定内存范围的虚拟地址、物理地址和页帧号 (PFN)，从而验证低级页面分配器例程确实分配了物理上连续的内存块。现在，您可能会想，为什么不在这个 ch9/vmalloc_demo 内核模块中调用这个相同的函数？如果分配的（虚拟）页面的 PFN 不连续，我们再次证明，它确实只是虚拟连续的。听起来很想尝试，但行不通！为什么？原因很简单，正如前面所述（第 8 章，模块作者的内核内存分配 - 第 1 部分），我们不应该尝试将除直接映射（身份映射/低内存区域）地址以外的任何地址从虚拟转换为物理地址 - 页面或 slab 分配器提供的地址。它只是不适用于 vmalloc 区域内的地址。</p>
<p>但是（正如我们所了解的），仍然需要了解的是，在底层，虽然 vmalloc 分配的内存不一定是物理连续的，但它确实是立即物理分配的（并且不像用户空间内存分配那样是按需分页的）。 下面是关于 vmalloc() 的更多要点和一些相关信息；</p>
<p>vmalloc() 的朋友</p>
<p>下面是一些与 vmalloc() 相关的 API，即 vmalloc() 的“朋友”，采用 FAQ 风格。这是 vmalloc（或模块区域）内存吗？要确定给定的 KVA（内核虚拟地址）是否由 vmalloc() 系列之一分配，可以使用快速辅助函数：</p>
<pre class="line-numbers language-none"><code class="language-none">mm&#x2F;vmalloc.c:bool is_vmalloc_addr(const void *x)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>当然，参数是需要检查的地址；如果是通过vmalloc()（或朋友）分配的，则返回 True，否则返回 False。在内部，它会检查传递的地址是否在内核的 vmalloc 区域内。（此例程已合并到 5.6 内核中。）相关说明中，内核提供了另一个辅助例程：</p>
<pre class="line-numbers language-none"><code class="language-none">mm&#x2F;vmalloc.c:int is_vmalloc_or_module_addr(const void *x)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>显然，如果传递的参数（内核虚拟地址）在内核模块区域或内核 vmalloc 区域内，则返回 True。如果两者都不是，则返回 False。</p>
<p><img src="./image-20240712073808788.png" alt="image-20240712073808788"></p>
<p><img src="./image-20240712073824434.png" alt="image-20240712073824434"></p>
<h4 id="内核中的内存分配-–何时使用哪些-API"><a href="#内核中的内存分配-–何时使用哪些-API" class="headerlink" title="内核中的内存分配 –何时使用哪些 API"></a>内核中的内存分配 –何时使用哪些 API</h4><p>​    我们目前所学内容的简要总结：内核用于内存分配（和释放）的底层引擎称为页面（或伙伴系统）分配器。最终，每个内存分配（和后续释放）都会经过这一层。但它也存在一些问题，最主要的是内部碎片或浪费（由于其最小粒度是一页或多页）。因此，我们在其上方分层了 slab 分配器（或 slab 缓存），提供对象缓存和页面片段缓存的功能（帮助缓解页面分配器的浪费问题）。此外，不要忘记您可以创建自己的自定义 slab 缓存。 此外，内核有一个 vmalloc 区域和 API，用于从其中分配大型虚拟内存带。 记住这些信息，让我们继续。要了解何时使用哪个 API，我们首先来看一下内核内存分配 API 集。</p>
<h4 id="可视化内核内存分配-API-集"><a href="#可视化内核内存分配-API-集" class="headerlink" title="可视化内核内存分配 API 集"></a>可视化内核内存分配 API 集</h4><p>以下概念图向我们展示了 Linux 内核的内存分配层以及其中的主要 API；请注意以下几点： 这里我们仅展示内核向模块/驱动程序作者公开的典型/常用 API（例外是最终在底层执行所有分配工作的 API：最底部的 __alloc_pages() API！参见图 9.4）。为简洁起见，我们没有展示相应的内存释放 API。以下是展示几个（向模块/驱动程序作者公开的）内核内存分配 API 的图表：</p>
<p><img src="./image-20240712074029919.png" alt="image-20240712074029919"></p>
<h4 id="选择适合内核内存分配的-API"><a href="#选择适合内核内存分配的-API" class="headerlink" title="选择适合内核内存分配的 API"></a>选择适合内核内存分配的 API</h4><p>面对如此众多的内存分配 API，我们如何选择何时使用哪个？虽然我们已经在本章以及上一章中讨论过这种情况，但我们将再次总结它，因为它非常重要。广义上讲，有两种看待它的方式——要使用的 API 取决于以下因素：</p>
<ul>
<li>所需内存量</li>
<li>所需内存类型</li>
</ul>
<p>我们将在本节中说明这两种情况。首先，要根据要分配的内存的类型、数量和连续性来决定使用哪个 API，请浏览以下流程图（从标签“从这里开始”的右上角开始）</p>
<p><img src="./image-20240712074213518.png" alt="image-20240712074213518"></p>
<p>当然，这并非微不足道；不仅如此，我还想提醒您回想一下我们在上一章中讨论过的详细讨论，</p>
<p>包括要使用的 GFP 标志（以及不要在原子上下文中休眠的规则）； 实际上，以下是关键点：</p>
<ul>
<li>在任何原子（“不能休眠”）上下文中，包括中断上下文，请确保仅使用 GFP_ATOMIC 标志。</li>
<li>否则，在进程上下文中，您可以决定是否使用GFP_ATOMIC 或 GFP_KERNEL 标志；当可以安全休眠时，请使用 GFP_KERNEL。</li>
<li>然后，如第 8 章“模块作者的内核内存分配 - 第 1 部分”中所述，在“使用 slab 分配器时的注意事项”部分中：</li>
<li>使用 k{m|z}alloc() API 和朋友时，请务必使用 ksize() 检查</li>
<li>实际分配的内存大小。更好的方法是，通过 /sys/kernel/slab/<slab-name>/slab_size伪文件检查分配的实际大小（正如我们在提取有关 slab 缓存的有用信息部分中了解到的那样）。</li>
</ul>
<p>接下来，要根据要分配的内存类型决定使用哪个 API， 请浏览下表：</p>
<p><img src="./image-20240712074338139.png" alt="image-20240712074338139"></p>
<p><img src="./image-20240712074343711.png" alt="image-20240712074343711"></p>
<p><img src="./image-20240712074349393.png" alt="image-20240712074349393"></p>
<h4 id="关于-DMA-和-CMA-的说明"><a href="#关于-DMA-和-CMA-的说明" class="headerlink" title="关于 DMA 和 CMA 的说明"></a>关于 DMA 和 CMA 的说明</h4><p>​    关于 DMA 的话题，虽然它的研究和使用超出了本书的范围，但我还是想提一下，Linux 有一套专门为 DMA 构建的 API，称为 DMA 引擎。执行 DMA 操作的驱动程序作者非常希望使用这些 API，而不是直接使用 slab 或页面分配器 API（如果这样做，确实会出现细微的硬件问题）。</p>
<p>​    此外，几年前，三星工程师成功地将一个补丁合并到主线内核中，称为连续内存分配器 (CMA)。</p>
<p>​    本质上，它允许分配大型、物理上连续的内存块（大小超过典型的 4 MB 限制！）。这是某些内存密集型设备上 DMA 所必需的（想在大屏幕平板电脑或电视上播放超高清质量的电影？）。很酷的是，CMA 代码透明地内置在 DMA 引擎和 DMA API 中。因此，像往常一样，执行 DMA 操作的驱动程序作者应该坚持使用 Linux DMA 引擎层。</p>
<p>​    另外，请注意，我们的讨论主要是针对典型的内核模块或设备驱动程序作者。在操作系统本身中，对单个页面的需求往往非常高（由于操作系统通过页面错误处理程序服务需求分页，用于处理所谓的轻微或“良好”错误）。因此，在底层，内存管理子系统往往会非常频繁地发出 __get_free_page<a href="typora://app/typemark/window.html">s</a> API。此外，为了满足页面缓存（和其他内部缓存）的内存需求，页面分配器起着重要作用。</p>
<p>​    好的，做得好；通过这一点，您（几乎！）完成了我们关于各种内核内存分配层和 API 的两章介绍，重点是模块/驱动程序作者！让我们用剩下的几个重要领域来结束这个大话题——Linux 内核的内存回收程序和（颇具争议的）OOM 杀手；请继续阅读！</p>
<h4 id="内存回收——内核的一项关键内务处理任务"><a href="#内存回收——内核的一项关键内务处理任务" class="headerlink" title="内存回收——内核的一项关键内务处理任务"></a>内存回收——内核的一项关键内务处理任务</h4><p>​    正如您所知道的，为了获得最佳性能，内核会尝试将内存页面的工作集保持在内存金字塔（或层次结构）中尽可能高的位置。</p>
<p>​    系统上所谓的内存金字塔（或内存层次结构）由（按顺序从最小但速度最快到最大但速度最慢）组成：CPU 寄存器、CPU 缓存（LI、L2、L3、…）、RAM 和交换（原始磁盘/闪存/SSD 分区）。在下面的讨论中，我们忽略了 CPU 寄存器，因为它们的大小很小。</p>
<p>​    在现代处理器中，当代码执行和数据被处理时，处理器使用其硬件缓存（L1、L2 等）将当前工作页面集保存在其多级 CPU 指令和数据缓存中。</p>
<p>​    但当然，CPU 缓存内存非常有限，因此很快就会耗尽，导致内存溢出到下一个层次——RAM。在现代系统上，甚至许多嵌入式系统，都有相当多的 RAM；但有时还是会用完。当发生这种情况时（简单来说），操作系统会将无法再容纳在 RAM 中的内存页面溢出到原始磁盘分区——交换中。因此，系统继续运行良好，尽管一旦（经常）使用交换，性能成本就会显著降低（当然，我们指的是用户空间页面可能被交换；如您所知，内核页面根本无法交换。同样，通常是用户空间占用了资源）。区域水印和 kswapd</p>
<p>​    Linux 内核为了确保 RAM 中始终有给定的最小可用内存页，不断执行后台页面回收工作 - 实际上，您可以将其视为例行管理。内核中的谁执行这项工作？ （嘿，我们所说的“回收”内存到底是什么意思？释放内存页，实际上是使其可供系统使用。）</p>
<p>​    kswapd 内核线程不断监视系统的内存使用情况，并在检测到内存不足时调用页面回收机制。</p>
<p>​    此页面回收工作是按节点：区域完成的。内核使用所谓的水印级别 - 最小、低和高 - 每个节点：区域以智能方式确定何时回收内存页。您可以随时查找 /proc/zoneinfo 以查看当前水印级别；请注意，水印级别的单位是页面</p>
<p>​    那么，如果内存压力确实增加了怎么办？内核的页面回收算法（即所谓的 PFA 或简称为“回收”）松散地（并且通常）编码以下步骤：</p>
<ul>
<li>如果低（区域水印）页面数 &lt; 空闲页面数 &lt; 高页面数（换句话说，如果空闲页面数介于高和低区域水印之间），内核将开始驱逐一些缓存并执行“温和”交换；这应该会释放足够的页面，使“空闲页面数”超过“高”，一切正常。 如果这不起作用，并且最小（区域水印）页面数 &lt; 空闲页面数 &lt; 低页面数（换句话说，如果空闲页面数介于低和最小区域水印之间），内核将继续驱逐缓存（在更大程度上）并执行积极交换；这应该会有所帮助…</li>
<li>如果没有，并且空闲页面数量继续下降，空闲页面数量 &lt; 最小（区域水印）页面数量（换句话说，如果空闲页面数量低于最小区域水印），内核现在会“报警”；它现在会努力通过执行以下操作来积极回收内存页面：</li>
<li>它会继续积极地驱逐（删除）缓存。</li>
<li>它继续执行积极的交换。</li>
<li>它拒绝该区域上的任何新内存请求。</li>
</ul>
<p>​    最近，一些与页面回收相关的新功能已经合并；我们现在将简要介绍它们。新的多代 LRU（MGLRU）列表功能。Linux 内核传统上通过典型的最近最少使用 (LRU) 算法来确定要回收（实际上驱逐）哪些页面；最近未访问的页面不太可能在不久的将来被需要，反之亦然。因此，传统上（但简化了），内核维护了一对 LRU 列表：活动和非活动 LRU 列表。这似乎是合理的，但经验表明，它并不总是能很好地工作，并且实际上可能会导致系统变慢！（例如，在许多情况下，顺序读取大文件是一种常见操作，因此刚刚读取的页面会进入活动列表。但如果您的应用程序不再需要这些页面；现在它非常不理想）。此外，在运行时使用反向映射（rmap）方法扫描匿名页面（那些没有文件支持的页面）（有关详细信息，请参阅此链接：<a target="_blank" rel="noopener" href="http://lastweek.io/notes/rmap/）的方式被认为是昂贵的。新的多代">http://lastweek.io/notes/rmap/）的方式被认为是昂贵的。新的多代</a> LRU（又名 MGLRU）功能最近才在 6.1 内核中合并，它具有以下基本特征：</p>
<p>​    现在，在活动页面和非活动页面之间存在大量 LRU 列表，以便在选择要回收的页面时提供更精细的粒度；每个列表称为一个代。</p>
<p>​    它们按页面年龄组织，从最年轻的代（第 0 代，当然包含最近使用的页面，即活动页面）到最老的代（第 N-1 代，包含 LRU 页面）。在回收时，老一代页面是明显的驱逐候选对象。</p>
<p>​    第 N 代（以及列表）的数量在内核代码中设置；基于 Android 的系统通常将该数字设置为 4，而高端云/企业服务器可能会使用更高的值。在默认代码库中，我们有（在include/linux/mmzone.h中）：/<em> MAX_NR_GENS 设置为 4，以便多代 LRU 可以在通过页表进行访问时确定活动/非活动 LRU 的类别数。[…] </em>/#define MIN_NR_GENS 2U#define MAX_NR_GENS 4U 它不使用昂贵的 rmap 方法来查找匿名页面；相反，它会扫描进程 PTE 本身，查找最近设置或清除的位标志（并且，作为优化，仅针对自上次扫描以来运行过的线程）。因此，它肯定更快。它使用更少的 CPU（“显示 kswapd 的 CPU 使用率降低了 51％”）。它使用更多的内存（“每个 memcg 和每个节点约 500 字节，每个进程内存开销约 50 字节”）。多代 LRU 本身是一个内核可配置功能 (CONFIG_LRU_GEN)；截至撰写本文时，它仍被视为可选功能，并未与内存管理子系统紧密结合（使用一对活动/非活动列表的传统代码仍然存在，但在激活 MGLRU 时未使用）。在我的 Ubuntu 22.04 LTS 发行版内核上，默认情况下未配置它。即使配置了，它也可能默认关闭，可以通过 debugfs 下的可调参数 (/sys/kernel/debug/lru_gen) 打开。（最近，运行基于 6.6 的发行版内核的 Fedora 39 和运行基于 6.5 的发行版内核的 Ubuntu 23.04 启用了 MGLRU。）配置后，各种 sysctl（或可调参数）出现在 /sys/kernel/mm/lru_gen 下，并在 debugfs 中出现几个。</p>
<h4 id="DAMON（数据访问监控功能）的简要介绍"><a href="#DAMON（数据访问监控功能）的简要介绍" class="headerlink" title="DAMON（数据访问监控功能）的简要介绍"></a>DAMON（数据访问监控功能）的简要介绍</h4><p>​    DAMON（数据访问监控器）的目的是捕获和分析用户空间进程的内存访问模式，帮助开发人员深入了解它们，从而能够对其进行优化。此功能已合并到 5.15 内核中。</p>
<p>​    DAMON 的内核组件本质上将目标进程划分为大小相等的区域，并监控这些区域的数据访问。它很聪明：如果某个区域看起来是热点，它会进一步划分。对每个区域的访问次数以直方图的形式提供。实际上，我们有一个生产者￾消费者架构：DAMON 内核组件是生产者（给定用户空间进程的数据访问模式）。</p>
<p>​    消费者可以是用户模式应用程序或内核本身；通过分析工作负载的数据访问模式，他们甚至可以请求更改内存区域（以优化访问！），通过调用众所周知的 madvise() 系统调用来实现。（为此，DAMON 设置了一种指定“方案”的方法；详细信息可以在官方内核文档中找到：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/v6.1/admin￾guide/mm/damon/usage.html#schemes-n。）为了处理">https://www.kernel.org/doc/html/v6.1/admin￾guide/mm/damon/usage.html#schemes-n。）为了处理</a> 64 位 Linux 上非常大的 VAS，DAMON 首先仅监控对文本、堆和堆栈段（或映射）的数据访问。现在，为了使其适合生产使用（这是目的），监控每个映射中的每个页面将非常昂贵。因此（有点像 KCSAN（内核并发 SANitizer）），它使用基于采样或统计的方法，在每个映射中选择一个随机页面并记录对它的访问，希望它们代表该区域的典型数据访问模式。它使用智能“放大”热点并进一步将其细分为更多区域，从而获得更好的采样。</p>
<p>要使用 DAMON，需要提供几个接口：</p>
<ul>
<li>通过名为 damo 的 DAMON 用户模式工具（<a target="_blank" rel="noopener" href="https://github.com/awslabs/damo）。">https://github.com/awslabs/damo）。</a></li>
<li>通过 sysfs（在 /sys/kernel/mm/damon/admin/ 下）；这些记录在此处：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/v6.1/admin-guide/mm/damon/usage.html#sysfs-interface。">https://www.kernel.org/doc/html/v6.1/admin-guide/mm/damon/usage.html#sysfs-interface。</a></li>
<li>通过 debugfs 接口；然而，这最初是使用的，现在已被视为弃用。改用 sysfs。</li>
<li>通过内核 API（适用于内核开发人员；</li>
<li><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/v6.1/mm/damon/api.html）。">https://www.kernel.org/doc/html/v6.1/mm/damon/api.html）。</a></li>
</ul>
<h4 id="保持活力-–-OOM-杀手"><a href="#保持活力-–-OOM-杀手" class="headerlink" title="保持活力 – OOM 杀手"></a>保持活力 – OOM 杀手</h4><p>​    现在我们已经介绍了有关内核内存管理的背景细节，特别是回收空闲内存，您已经可以很好地理解什么是内存不足 (OOM) 杀手内核组件，如何使用它，甚至如何故意调用它并在一定程度上控制它。</p>
<p>​    让我们重新回顾一个关键点，即内存（RAM 和交换）不足。</p>
<p>​    让我们扮演魔鬼代言人：如果 RAM 不足，所有这些内存回收工作（我们在上一节中刚刚介绍过）根本无济于事，并且内存压力不断增加，直到整个内存金字塔耗尽，内核分配甚至几页都会失败（或无限重试，坦率地说，这同样没用，甚至更糟）？换句话说，如果所有 CPU 缓存、RAM 和交换都（几乎完全）满了，该怎么办！？好吧，大多数系统在这个时候就死掉了（实际上，它们并没有真正死掉；它们只是变得非常慢，以至于在我们人类看来，它们永远挂起了）。     此外，要意识到在许多嵌入式系统上，没有交换分区（或文件），因此增加了内存完全耗尽的可能性！</p>
<p>​    然而，Linux 内核作为 Linux，在这些情况下往往会变得激进；它现在调用一个恰当地命名为 OOM 杀手的组件。</p>
<p>​    OOM 杀手的工作是识别并立即杀死占用内存的进程及其后代，方法是向它们发送致命的 SIGKILL 信号；因此，它最终可能会杀死一大堆进程。</p>
<p>​    直接引用内核文档：“OOM 杀手选择一个任务来牺牲，以保证整个系统的健康。选定的任务被杀死，是希望它退出后有足够的内存被释放以继续正常操作。” 您可能已经想到，它已经引起了不少争议。早期版本的 OOM 杀手（非常正确）受到了批评（有时，它会杀死错误的家伙！）。</p>
<p>​    就 OOM 杀手这样说道：“……‘相当’有争议是轻描淡写。大多数时候，人们看到 OOM 杀手，但不知道如何处理，尤其是在没有交换的嵌入式系统上。”</p>
<p>​    不过，还是有希望的；内核的最新版本使用了更高级的 OOM 杀手受害者 ID 启发式方法，效果确实更好。</p>
<p>​    您可以在这篇 LWN 文章（2015 年 12 月）中找到有关改进的 OOM 杀手工作（启动策略和 OOM 收割线程）的更多信息：实现更可预测和更可靠的内存不足处理，Jon Corbet：<a target="_blank" rel="noopener" href="https://lwn.net/Articles/668126/。">https://lwn.net/Articles/668126/。</a></p>
<h4 id="故意调用-OOM-杀手"><a href="#故意调用-OOM-杀手" class="headerlink" title="故意调用 OOM 杀手"></a>故意调用 OOM 杀手</h4><p>​    我们不想纠结于理论和内部实现，而是宁愿活得更久一点，测试我们的朋友 OOM 杀手，激怒内核，让它释放她！当然，要做到这一点，我们必须对系统施加巨大的内存压力。如果我们成功了，内核将非常乐意加入战斗，释放它的武器 - OOM 杀手，一旦被调用，它将识别并杀死某个进程（或多个进程）。</p>
<p>​    很明显，我强烈建议您在安全、独立的系统上尝试类似的东西，最好是测试 Linux VM（上面没有重要数据）。</p>
<p>​    通过 Magic SysRq 调用 OOM 杀手</p>
<p>​    内核提供了一个有趣的功能，称为 Magic SysRq：本质上，某些键盘组合键（或加速器）会导致回调某些内核代码。例如（假设已启用），在 x86[_64] 系统上按下 Alt-SysRq-b 组合键会导致冷重启！注意 - 不要随便输入任何内容；请阅读此处的相关文档： <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/sysrq.html">https://www.kernel.org/doc/html/latest/admin-guide/sysrq.html</a></p>
<p>​    让我们尝试一些有趣的东西；要查看 Magic SysRq 状态，我们在 x86_64 Ubuntu 22.04 Linux VM 上运行以下命令：$ cat /proc/sys/kernel/sysrq176这揭示了 Magic SysRq 位掩码的当前状态；如果为正数，则表明该功能已部分启用（本节开头提到的内核文档提供了详细信息）。为了能够通过 SysRq 功能调用 OOM 杀手，我们需要先完全启用它。为此，请运行以下命令：sudo sh -c “echo 1 &gt; /proc/sys/kernel/sysrq”现在我们可以使用 Magic SysRq 调用 OOM 杀手！小心！通过 Magic SysRq 或其他方式调用 OOM 杀手将导致某些进程（通常是重量级进程）无条件死亡！如何实现？以 root 身份运行以下命令：</p>
<pre class="line-numbers language-none"><code class="language-none">echo f &gt; &#x2F;proc&#x2F;sysrq-trigger<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    查看内核日志，看看是否发生了有趣的事情！</p>
<p>​    在即将到来的按需分页和 OOM 部分中，将详细介绍 OOM 杀手来袭时内核日志的详细解释；目前，我们只是在考虑如何调用它</p>
<h4 id="了解-OOM-分数"><a href="#了解-OOM-分数" class="headerlink" title="了解 OOM 分数"></a>了解 OOM 分数</h4><p>​    为了在关键时刻（当调用 OOM 杀手时）加快发现占用内存最多的进程，内核会为每个进程分配并维护一个 OOM 分数（您始终可以在 /proc/<pid>/oom_score 伪文件中查找该值）。 此外，OOM 分数有一个范围；从 0 到 1000：</p>
<ul>
<li>OOM 分数为 0 表示该进程未使用任何可用内存。</li>
<li>OOM 分数为 1000 表示该进程正在使用 100% 的可用内存。</li>
</ul>
<p>​    显然，OOM 分数最高的进程“获胜”。它的奖励是 - 它被选为被 OOM 杀手杀死的受害者（谈论冷幽默）。</p>
<p>​    不过，不要这么快：内核有启发式方法来保护重要任务。内置的启发式方法意味着 OOM 杀手不会选择任何 root 拥有的进程、任何内核线程或任何打开硬件设备的任务作为其受害者。如果我们想确保某个进程永远不会被 OOM 杀手杀死怎么办？这样做是完全有可能的，尽管它确实需要 root 访问权限。内核提供了一个可调的 /proc/<pid>/oom_score_adj，一个 OOM“调整”值（默认值为 0）。净 OOM 分数是 oom_score 值和调整值的总和：net_oom_score = oom_score + oom_score_adj</p>
<p>​    因此，将进程的 oom_score_adj 值设置为 1000 几乎可以保证它将被杀死，而将其设置为 -1000 则会产生完全相反的效果——它永远不会被选为受害者。 查询（甚至设置）进程的 OOM 分数及其</p>
<p>OOM 调整值的快速方法是通过 choom(1) 实用程序。例如，要查询 systemd 进程的 OOM 分数和 OOM 调整值，只需执行 choom -p 1。我们做了一件显而易见的事情 - 编写了一个脚本，一个对 choom 的简单包装 - 查询系统中当前活动的所有进程的 OOM 分数（可以在此处找到：ch9/query_process_oom.sh；请在您的机器上尝试一下）。快速提示：可以使用此命令行快速查看系统中 OOM 分数最高的（10）个进程（第三列是净 OOM 分数）：</p>
<pre class="line-numbers language-none"><code class="language-none">.&#x2F;query_process_oom.sh | sort -k3n | tail<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>关于 OOM 杀手和 cgroups 的总结</p>
<p>​    那么，现在我们已经介绍了 OOM 杀手，您觉得怎么样？我认为，一个合理的回应是：首先不要让触发 OOM 杀手的情况发生！当然，说起来容易做起来难，但应该小心谨慎；这样想很重要（不要因噎废食，对吧？）。正如 Andries Brouwer 的一句玩笑话（2004 年 9 月：<a target="_blank" rel="noopener" href="https://lwn.net/Articles/104185/）所说，OOM">https://lwn.net/Articles/104185/）所说，OOM</a> 杀手算法可能类似于在飞机燃料不足时将乘客赶出飞机。不过，一些生产环境在单个服务器系统设置方面有所不同；没有一条规则是最好的。在某些设置中，调用 OOM 杀手并杀死行为不端的应用程序比让无辜的小应用程序因无法获得内存而失败要好。这是很常见的情况：没有灵丹妙药。测试并找到适合您特定设置的最佳方法。 Cgroups 和内存带宽 - 注释</p>
<p>我们经常提到的是控制组 (cgroups)；不用担心，第 11 章“CPU 调度程序 - 第 2 部分”的“cgroups 简介”部分详细介绍了这一关键、强大且隐含的内核基础架构（这不仅仅是一个简介）。 Cgroups（现在在其 v2 实现中）允许根据需要应用资源约束，无论资源是 CPU、内存 (RAM)、IO、允许的最大 PID（进程/线程）数量，等等，通过所谓的资源控制器。内存资源控制器显然用于对 cgroup 中的一组进程施加约束，以限制它们的综合内存使用量。为了理解它，并利用它，我建议您做两件事：</p>
<ol>
<li><p>阅读第 11 章“CPU 调度程序 - 第 2 部分”中 cgroups 的内容，标题为“cgroups 简介”的部分。</p>
</li>
<li><p>同时，参考官方内核文档，特别是内存控制器；可在此处获取： <a target="_blank" rel="noopener" href="https://docs.kernel.org/admin-guide/cgroup￾v2.html#memory-interface-files。您将看到所有可能的">https://docs.kernel.org/admin-guide/cgroup￾v2.html#memory-interface-files。您将看到所有可能的</a> 内存控制器接口文件以及它们的确切含义。 此外，标题为“使用指南”的简短部分（<a target="_blank" rel="noopener" href="https://docs.kernel.org/admin-guide/cgroup￾v2.html#usage-guidelines）也很有用。">https://docs.kernel.org/admin-guide/cgroup￾v2.html#usage-guidelines）也很有用。</a> 接下来，由于我们稍后对 cgroups (v2) 的介绍有点偏向于限制 CPU 带宽的主题，我们将在这里快速提到一些有关内存控制器的要点：限制 cgroup 中进程的内存使用量与限制 CPU 使用量并不完全相同。想想这个：CPU 时间在真正意义上确实是无限的；内存不是。因此，我们可以设置不同类型的内存使用限制（通过 cgroup 的</p>
</li>
<li><p>s memory.min|low|high|max 伪文件；有关详细信息，请参阅刚刚提到的内核文档链接）。 4.19 内核引入了一个 cgroup 感知 OOM 终止组件的微型实现；这允许 – 引用 – “能够将 cgroup 作为单个单元终止，从而保证工作负载的完整性。”接口是 memory.oom.group 伪文件；当设置并且 cgroup 中的进程触发 OOM 终止程序时，它会终止该 cgroup 中的所有进程（或根本不终止）。 内部：内核包含一个 slab 内存控制器 (kmemcg)，它基本上复制了每个现有内存 cgroup (memcg) 的 slab 内存内部。这导致这些 memcgs 中的 slab 内存严重利用不足（因为它们不共享 slab 内存；每个都有自己的 slab），进而导致严重问题 – 实际上是严重的 slab 内存浪费。这导致从 5.9 Linux 开始创建了新的 slab 内存控制器（由 Roman Gushchin 等人创建）。</p>
<p>slab 内存节省范围从 35% 到 50%（在桌面和服务器级系统上）。</p>
<p>控制 cgroups 内存带宽分配的一种可能更简单的方法是通过 systemd 提供的接口进行控制。与内核内存 cgroup (memcg) 接口类似，它为给定 systemd 单元内的进程提供 MemoryMin、MemoryLow、MemoryHigh 和 MemoryMax 接口（全部设置为一个数量，以字节/KB/MB/GB/TB 为单位表示）。或者，您可以将内存指定为它们占总 RAM 的百分比。甚至交换内存使用量也可以通过 MemorySwapMax 和 MemoryZSwapMax 接口进行限制。</p>
<p>MemoryHigh 接口通常是建议指定的接口；引用其使用文档（来自此处的手册页： <a target="_blank" rel="noopener" href="https://man7.org/linux/manpages/man5/systemd.resource-control.5.html">https://man7.org/linux/manpages/man5/systemd.resource-control.5.html</a> “指定此单元中执行进程的内存使用限制。</p>
</li>
<li><p>如果不可避免，内存使用可能会超过限制，但在这种情况下，进程会严重减慢，内存会被大量占用。这是控制单元内存使用的主要机制。 MemoryMax 接口允许指定单元进程内存使用的不可协商的上限（或绝对）限制；如果内存使用量超过此阈值，则会调用 OOM 杀手。 设置基于 systemd 的 memcg 设置有几个注意事项；请务必仔细阅读文档。 至此，我们结束了本节，实际上也结束了本章</p>
</li>
</ol>
<h2 id="CPU调度程序–第1部分"><a href="#CPU调度程序–第1部分" class="headerlink" title="CPU调度程序–第1部分"></a>CPU调度程序–第1部分</h2><p>让我们快速浏览一下我们需要的基本背景信息了解Linux上的CPU调度。</p>
<p>请注意，在本书中，我们不打算涵盖材料Linux上有能力的（用户空间）系统程序员应该已经很清楚了: 这包括以下基础知识</p>
<p>进程（或线程）状态，关于真实状态的基本信息时间是，POSIX调度策略等等</p>
<h4 id="Linux上的KSE是什么？"><a href="#Linux上的KSE是什么？" class="headerlink" title="Linux上的KSE是什么？"></a>Linux上的KSE是什么？</h4><p>​    正如您在第6章“内核内部要素-进程和线程”中的“组织进程、线程及其堆栈-用户和内核空间”一节中所了解到的那样，系统上的每个（用户模式）活动线程都被赋予了一个任务结构（struct task_struct）以及一个用户模式和一个内核模式堆栈。正如我们所了解到的，内核线程确实有一个任务结构，但只有一个内核模式堆栈。</p>
<p>​    当然，每个操作系统都需要执行任务调度。现代操作系统——Linux/Unix/Windows/Mac——具有进程和读取的概念。现在，要问的关键问题是：当执行任务调度时，它作用于什么“对象”？换句话说，什么是内核可调度实体，KSE？在Linux上，KSE是一个线程，而不是一个进程（当然，每个进程至少包含一个线程）。因此，线程是执行调度的粒度级别。一个例子和一个图表（图10.1）将有助于解释这一点：如果我们有一个假设的情况，我们只有一个CPU核和三个用户空间进程（P1、P2和P3），分别由一个、两个和五个线程组成，再加上几个内核线程（比如三个），那么我们总共有（1+2+5+3），等于11个线程。</p>
<p><img src="./image-20240716094210563.png" alt="image-20240716094210563"></p>
<p>​    好吧，我要求你忽略房间里的大象。图10.1的顶部显示了cgroups内核框架的抽象、高度概念化的视图，该框架现在已深度嵌入内核的每个结构中。在这里，我要求你想象一下——根本不用担心“为什么/如何/谁/何时/…”的问题——如果你愿意的话，这个cgroups层在现代Linux中非常普遍，它肯定会对CPU调度产生影响。现在，只要意识到它的存在；细节–并尝试一下！–将在下一章中介绍。关于图10.1，除内核线程外，每个线程都有一个用户和内核堆栈以及一个任务结构（内核线程只有内核堆栈和任务结构；所有这些在第6章“内核内部要素——进程和线程”的“组织进程、线程及其堆栈——用户和内核空间”一节中都有详细解释）。</p>
<p>​    现在，如果这11个线程都处于可运行状态，也就是说，它们已经准备好运行，那么它们都会争夺单个处理器核心。（尽管它们不太可能同时运行，但为了讨论起见，让我们考虑一下）。关键是要明白，我们现在有11个线程在争夺CPU资源，而不是三个进程和三个内核线程。一个更现实的情况是，在11个活动线程中，可能有4个是可运行的，即它们在运行队列中并且想要运行，而其余7个线程处于各种其他状态（睡眠（在阻塞调用中）或停止（冻结））；剩下的七个人甚至都不是日程安排的候选人。</p>
<p>​    既然我们了解了KSE是一个线程，我们将（几乎）总是在调度的上下文中引用该线程。现在让我们继续讨论所谓的Linux进程状态机。Linux进程状态机在Linux操作系统上，每个进程或线程都运行在各种定义状态中，通过对这些定义状态进行编码，我们可以形成Linux操作系统中进程的状态机（orthread）（阅读本文时请参考图10.2）。由于我们现在了解到Linux操作系统上的KSE是一个线程而不是一个进程，因此我们将忽略使用“进程”一词的约定，而不是在描述在状态机的各种状态下循环的实体时使用“线程”一词。（如果比较舒服的话，你可以在下面的文本中用“process”代替“thread”。）Linux线程可以循环通过的状态如下（ps实用程序通过这里显示的字母对状态进行编码）：R：准备运行或正在运行（或“可运行”）睡眠：s：可中断睡眠D：不间断睡眠T：已停止（或暂停/冻结）Z：僵尸（或不存在）X：Dead当通过fork（）或clone（）系统调用或pthread_create（）API新建线程时，一旦OS确定线程已经完全诞生，它通过将线程进入可运行（R）状态。处于R状态的线程实际上正在CPU核心上运行，或者处于准备运行状态。我们需要理解的是，在这两种情况下，线程都在操作系统中的数据结构上排队，称为运行队列。Linux在系统上为每个CPUcore维护一个运行队列（实际上，现实情况更加微妙；我们很快就会达到这一点）。运行队列中的线程是给定CPU核上运行的有效候选线程；除非在操作系统运行队列中排队，否则任何线程都不可能运行。Linux没有明确区分就绪运行和实际运行状态；它只是将处于任一状态的线程标记为R。当然，正如我们在第6章“内核内部要素——进程和线程”中所了解到的，它是任务结构（unsignenight__state；）中的一个成员，被设置为适当的值来标记处于特定状态的线程。下图表示任何进程或读取的Linux状态机：</p>
<p><img src="./image-20240716163741228.png" alt="image-20240716163741228"></p>
<p>​    上图通过（红色）箭头显示了状态之间的转换。为了清楚起见，一些转换（例如，一个线程可以在休眠或停止时被终止）在上图中没有明确显示。（仅供参考，一个死亡但未被其父进程等待的进程最终会处于半死半活的状态，称为僵尸或失效进程；这本应是一个混乱的状态。防止僵尸永远留在系统上的规则是，每个fork（）都需要相应的wait*（）系统调用。（像往常一样，Linux有一个巧妙的技巧：杀死azombie的父级，僵尸也会“收获”（死亡）。）我们知道，每个活着的线程（用户和内核）都有自己的任务结构。因此，在代码级别，任务结构成员named__state（之前称为state）在所谓的“状态机”中保存任务的“状态”——线程。当它可运行时，它将被设置为值TASK_RUNNING（总体上由“R”表示，内部由图10.2中的Rrand Rcpu状态表示）。等待队列是一种数据结构，其中处于睡眠状态的任务被排队——也就是说，它们正在等待一个事件（实际上，它们在阻塞调用中到达这里）。Linux有两种休眠线程的可能性；线程可以处于：可中断睡眠：__state=TASK_Interruptible：它“睡眠”，等待某个事件；然而，任何传递给进程/线程的信号都会唤醒它并运行信号处理程序（如图10.2中的字母“S”所示）不间断睡眠：__state=TASK_Uninterruptible：它“睡眠”，等待某个事件；传递到进程/线程的任何/所有信号都不会对其产生影响（如图10.2中的字母“D”所示）。当它正在等待的事件发生时，操作系统将向其发出唤醒呼叫，使其再次可运行（从等待队列中退出并在运行队列中退出）。请注意，线程不会立即运行；它将变得可运行（图10.2中的Rr），并成为调度器的候选对象；很快，它将有机会在CPU（Rcpu）上实际运行。一个常见的误解是认为操作系统维护一个运行队列和一个等待队列。Linux内核为每个CPU维护一个运行队列。等待队列通常由设备驱动程序（以及内核）创建和使用；因此，它们可以有任意数量。</p>
<p>有了这些基础知识，让我们开始吧！</p>
<h4 id="POSIX调度策略"><a href="#POSIX调度策略" class="headerlink" title="POSIX调度策略"></a>POSIX调度策略</h4><p>​    认为调度策略一词大致相当于调度算法。重要的是要意识到Linux内核并没有一个实现CPU调度的策略；事实上，POSIX标准规定了兼容POSIX的操作系统必须遵守的至少三个调度策略（实际上是算法）。Linux超越了这三个，并通过称为调度类的强大设计实现了这三种以及更多（本章稍后的理解模块化调度类部分将介绍）。现在，让我们在下表中简要总结一下POSIX调度策略及其影响；不过，在此之前，关键是要理解，在任何给定时间点，每个活动线程（用户和内核空间）都与这些调度策略中的一个相关联（可以在运行时更改）。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>计划策略</th>
<th>关键点</th>
<th>优先级标尺</th>
</tr>
</thead>
<tbody>
<tr>
<td>SCHED_OTHER或SCHED_NORMALA</td>
<td>始终为默认值；具有此策略的线程是非实时的；它们在内部被实现为一个完全公平调度（CFS）类,此调度策略背后的动机是公平性（即“对所有可运行的线程公平，避免浪费任何CPU时间”）和整体吞吐量优先级）</td>
<td>此策略的线程的实时优先级为0）。非实时优先级称为nicevalue；它的范围从-20到+19（数字越低，意味着越优秀.基础（初始）值为0</td>
</tr>
<tr>
<td>SCHED_RR</td>
<td>此调度策略的动机是提供一个非常激进的（软）实时策略。属于此sched类的线程具有有限时间片（通常默认为100毫秒）。SCHED_RR线程将产生处理器IFF（当且仅当）：<br> 它在I/O上阻塞（进入休眠状态）。<br>它停止或死亡。<br>更高优先级的实时线程变得可运行（这将抢先一步）。<br>它的时间片到期了。</td>
<td>（软）实时：1到99（更高的数字意味着更高的优先级）</td>
</tr>
<tr>
<td>SCHED_FIFO</td>
<td>此调度策略背后的动机是提供一种（软）实时策略，该策略（与SCHED_RR相比，非常）激进。SCHED_FIFO线程将产生处理器IFF：它阻塞I/O（进入休眠状态）。它停止或死亡。一个优先级更高的实时线程变得可运行（这将抢占这个线程）。实际上，它有无限长的时间片</td>
<td>（与SCHED_RR相同）</td>
</tr>
<tr>
<td>SCHED_batch</td>
<td>此调度策略背后的动机是“适用于低优先级的非交互式批处理作业，优先权较少”。</td>
<td>NICE的值范围（-20到+19）</td>
</tr>
<tr>
<td>SCHED_IDLE</td>
<td>特殊情况：通常，PID0内核线程（传统上称为swapper；实际上，它是每CPU空闲线程）使用此策略。它始终保证是系统上优先级最低的线程，并且仅在没有其他线程需要CPU时运行。</td>
<td>是所有优先级中最低的</td>
</tr>
</tbody>
</table>
</div>
<p>重要的是要注意，当我们在前一个表中说实时时，我们指的是软（或充其量是硬）实时，而不是硬实时，就像在实时操作系统（RTOS）中一样。Linux是一个通用操作系统（GPOS），而不是RTOS。话虽如此，您可以通过应用外部补丁程序（称为RTL，由Linux基金会支持）将vanilla Linux转换为真正的硬实时RTOS；在下一章的“将主线Linux转换为RTOS”一节中，您将学习如何精确地做到这一点。仔细研究桌子；请注意，SCHED_FIFO线程实际上具有无限的时间片，因此可以在CPU内核上运行任意时间；当上述条件之一满足时，它会被抢占（从CPU上移除）。此外，</p>
<p>​    SCHED_FIFO和SCHED_RR之间的其他关键区别包括：</p>
<p>​    虽然SCHED_FIFO线程实际上具有无限的时间片，但SCHED_RR线程具有有限的时间片（可通过/proc/sys/kernel/sched_rr_timeslice_ms-sysctl；默认情况下为100ms）</p>
<p>​    具有相同优先级的SCHED_RR线程以轮询方式进行调度（从而允许其他SCHED_RR线程共享处理器）。对于SCHED_FIFO线程，情况并非如此——被抢占的线程将返回下一个要运行的任务（从而拒绝与处理器具有相同优先级的其他线程）。因此，在使用CSCHED_FIFO时，您应该避免将线程保持在相同的优先级（我们将在下一章的“在内核中设置策略和优先级——在内核线程上”一节中对此进行更多介绍）。在这一点上，重要的是要理解，在Linux等操作系统上，硬件（和软件）中断总是优于甚至会抢占（内核或用户空间）SCHED_FIFO线程！</p>
<p>​    对于我们在这里的讨论，我们暂时忽略中断。现在，让我们更详细地了解每个线程的优先级值。</p>
<h4 id="线程优先级"><a href="#线程优先级" class="headerlink" title="线程优先级"></a>线程优先级</h4><p>​    线程的优先级缩放很简单（以下是从低到高的优先级；参见图10.3）：非实时线程（SCHED_OTHER）的实时优先级为0；这确保了它们甚至无法与实时线程竞争；他们甚至不在同一个竞技场上！那么，在优先级方面，如何区分所有非实时线程呢？</p>
<p>​    很简单——他们使用一个名为nicevalue的（旧UNIX风格）优先级值，范围从-20到+19，-20是最高优先级，0是基数或默认值，+19是最低优先级。</p>
<p>​    启用后，传统的“好价值”概念并没有真正被使用（在“nice”下，cgroups被利用了）。更多信息请参阅进一步阅读部分。）实时线程（具有SCHED_FIFO或SCHED_RR策略）的区域时间优先级范围为1到99，1表示最小优先级，99表示最高优先级。这样想吧：在一个只有一个CPU的不可抢占的内核上，在不可破解的无限循环中旋转的SCHED_FIFO优先级99线程将有效地挂起机器！</p>
<p><img src="./image-20240716165835673.png" alt="image-20240716165835673"></p>
<p>​    调度策略是通过任务结构中的一个成员（调度类）（松散地）指定的。此外，线程策略和优先级（静态nice值和实时优先级）是任务结构的成员（如图10.1所示）。请注意，线程所属的调度类是独占的；一个线程在给定的时间点只能属于一个调度类（不用担心，我们稍后将在即将到来的CPU调度内部学习第2部分中详细介绍调度类）。此外，您应该意识到，在现代Linux内核上，还有其他调度类（stop-scched和deadline）在优先级上优于我们看到的FIFO/RR类（再次详细介绍如下）。</p>
<h4 id="可视化流程"><a href="#可视化流程" class="headerlink" title="可视化流程"></a>可视化流程</h4><p>​    多核系统导致进程——实际上是线程（包括用户空间和内核空间）——在不同的处理器上并发执行。这对于获得更高的吞吐量和性能非常有用，但当它们处理共享的可写数据时，也会出现同步问题（我们将在本书的最后两章深入探讨内核同步这一真正重要的主题）。因此，例如，在具有六个处理器内核的硬件平台上，我们可以期望进程（线程）在它们上并行执行；这不是什么新鲜事。然而，有没有一种方法可以真正看到哪些进程或线程在哪个CPU核上执行，也就是说，有一种方法来可视化一个进程或线程？事实证明，确实有几种方法可以做到这一点。在接下来的部分中，我们将介绍几种有趣的方法：使用gnome系统监视器GUI程序、perf以及其他可能性。</p>
<h4 id="使用gnome系统监视器GUI来可视化流程"><a href="#使用gnome系统监视器GUI来可视化流程" class="headerlink" title="使用gnome系统监视器GUI来可视化流程"></a>使用gnome系统监视器GUI来可视化流程</h4><p>​    gnome项目提供了一个极好的GUI来查看和监视系统活动，适用于笔记本电脑、台式机和服务器级系统（事实上，适用于任何强大到足以运行gnome GUI环境的系统）：gnome系统监视应用程序。为了快速测试使用它来查看几个CPU内核之间的工作流程，让我们首先同时运行几个进程。对于我们这里的简单测试用例，我们需要一个在CPU上连续执行的进程，即CPU绑定的进程。一个很好的候选者是名为yes的简单实用程序，它只是将字符y连续打印到stdout（试试看！）。那么，假设我们运行它三次，在后台。为了使这个实验有意义，我们想将每个进程仿射（绑定）到系统上的特定CPU核心。Thenproc命令显示内核数量；它们的编号从0开始。在我的x86_64 Fedora 38 VM:</p>
<pre class="line-numbers language-none"><code class="language-none">$nproc6<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    我有六个CPU内核（编号为0-5）。我们利用有用的任务集实用程序（它属于util-linux包，我们在第1章中指定了该包）。使用-c选项运行任务集允许ust指定命令要在哪个CPU核上运行；因此，如果我们</p>
<pre class="line-numbers language-none"><code class="language-none">taskset-c 2 yes&gt;&#x2F;dev&#x2F;null<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    它只在CPU核心#2上运行yes（我们将stdout重定向到null设备，这样我们就不必连续看到y）！因此，让我们快速构建一个测试用例：我们将运行三次yes实用程序（当然是在后台），每个流程实例都在不同的CPUcore上运行——例如，如下：</p>
<pre class="line-numbers language-none"><code class="language-none">taskset-c 1 yes &gt; &#x2F;dev&#x2F;null&amp;taskset-c 2 yes&gt;&#x2F;dev&#x2F;null &amp; taskset-c3 yes&gt;&#x2F;dev&#x2F;null &amp;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>（当然，您必须有一个至少有四个内核的系统来完成上述任务（因为内核编号从0开始）。）当它们还活着并正在运行时（就像检查一样），运行gnome系统监视器应用程序（我们假设您正在使用</p>
<h4 id="使用perf可视化flow"><a href="#使用perf可视化flow" class="headerlink" title="使用perf可视化flow"></a>使用perf可视化flow</h4><p>​    Linux及其庞大的开发人员和质量保证（QA）工具库，在perf中有一个非常强大的工具。简而言之，perf工具集是在Linux机器上执行CPU性能分析的方法之一。（除了一些提示外，我们在本书中没有详细介绍perf。）与古老的top（和较新的htop）实用程序一样，为了获得CPU消耗情况的“千英尺视图”（比top更详细），perf实用程序集非常出色。不过，请注意，对于一个应用程序来说，与它运行的内核完美结合是非常不寻常的。重要的是（至少在Ubuntu上），要获得性能，您需要安装<code>linux-tools-$（uname-r）</code>包。此外，与性能相关的分发包将不适用于我们构建的自定义6.1内核；因此，在使用perf时，我建议您使用标准（ordistro）内核之一启动来宾VM，安装<code>linux tools-$（uname-r）</code>包，然后尝试使用perf。（当然，您也可以从tools/perf/文件夹下的内核源代码树中手动构建perf。）</p>
<p>安装并运行perf后，您可以尝试以下与perf-top相关的命令（有关详细信息，请参阅手册页或教程）：</p>
<pre class="line-numbers language-none"><code class="language-none">sudo perf-topsudo perf-top--sort comm，dsosudo perf-top-r 90--sort pid，comm，dso，symbol<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    上述perf-top变体不仅帮助我们鸟瞰CPU的消耗情况，还帮助我们查看它们正在执行的代码路径，甚至允许我们放大每个任务以查看更多详细信息（传统工具通常不允许我们这样做）。顺便说一句，comm意味着命令/进程的名称，dso是dynamicshared对象的缩写。perf（1）的手册页提供了详细信息；使用manperf-<foo>符号（例如man-perf-top）来获取perftop的帮助。但回到我们的主要观点：使用perf的一种方法是清楚地了解哪些任务在哪个CPU核上运行；这是通过perf中的ched-map子命令完成的。不过，首先，您必须使用perf记录事件，这既可以在系统范围内完成，也可以在特定进程中完成。要记录事件，请运行以下命令：sudo perf sched record[command]在record关键字后面没有参数，它记录系统范围内的事件；传递参数使其仅记录该命令进程及其子进程的事件。使用SIGINT信号（^C）终止录制会话。这将生成一个名为perf.databy-default的二进制数据文件；我们很快就会看到如何直观地解释它。</p>
<h4 id="学习CPU调度内部——第2部分"><a href="#学习CPU调度内部——第2部分" class="headerlink" title="学习CPU调度内部——第2部分"></a>学习CPU调度内部——第2部分</h4><p>​    本节深入探讨了内核CPU调度内部，重点是现代设计的核心方面，模块化调度类。了解模块化调度类关键内核开发人员Ingo Molnar（和其他人一起）重新设计了内核调度程序的内部结构，引入了一种称为调度类的新方法（这可以追溯到2007年10月2.6.23内核的发布）。顺便说一句，调度器类中的class一词并不常见；许多Linux内核特性本质上，而且很自然地，都是以面向对象的方式设计的。当然，C语言不允许我们直接在代码中表达这一点（因此，大多数结构同时具有数据和函数指针成员，模拟一个类）。然而，设计通常是面向对象的（正如你在《LinuxKernel Programming–Part 2》一书中对驱动程序模型所清楚看到的那样）。有关这方面的更多详细信息，请参阅本章的进一步阅读部分。</p>
<p>​    核心调度代码中引入了一个抽象层，即函数kernel/sched/core.c:schedule（）。schedule（）中的这一层通常称为调度类，在设计上是模块化的。请注意，这里的“模块化”一词意味着调度器类可以从树内内核代码中添加或删除；它与可加载内核模块（LKM）框架无关。基本思想是：Linux内核（截至6.1，实际上是最新的6.7内核）包含五个调度类，每个调度类都与一个优先级相关联。当调用核心调度程序代码theschedule（）函数（它本身是__schedule（）的一个薄包装器）时，它会按照预定义的优先级顺序迭代每个类，询问每个类是否有一个准备运行的线程（具体如何，我们很快就会看到）。在有五个排课的情况下，可以保证其中一个会给出肯定的答案，并选择一个候选线程来运行下一个；一旦发生这种情况，核心调度代码上下文就会切换到该幸运线程（跳过任何剩余的调度类），工作就完成了。以下流程图封装了此设计：</p>
<p><img src="./image-20240717071538943.png" alt="image-20240717071538943"></p>
<p>​    您很警惕，在图10.9的最顶部发现了标记为S的连接器；这意味着什么？这是为了回答一个关键问题：“谁调用，什么时候调用核心调度程序函数schedule（）？”（这将在下一节“学习CPU调度内部-第3部分；放松-我们会到那里！”中详细回答！）从6.1 Linux内核（以及撰写本文时的最新6.7内核事实）开始，内核中有五个调度程序类，按优先级顺序列出，最高优先级显示在第一位：调度策略调度程序</p>
<p><img src="./image-20240717071815187.png" alt="image-20240717071815187"></p>
<p><img src="./image-20240717071824232.png" alt="image-20240717071824232"></p>
<p>​    因此，我们有五个模块式调度类——停止任务、截止日期、（软）实时（RT）、公平（CFS）和空闲——按优先级从高到低排列。抽象这些调度器类的数据结构structsched_class在一个单链表上串在一起，核心调度代码迭代该链表。（稍后我们将讨论sched_class结构是什么；暂时忽略它。）每个线程都与其唯一的任务结构（structtask_struct）相关联；在任务结构中（正如我们在第6章中看到的，您可以在此处查找：<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/include/linux/sched.h\#L737)，以下情况适用：成员struct">https://elixir.bootlin.com/linux/v6.1.25/source/include/linux/sched.h\#L737)，以下情况适用：成员struct</a> sched_class*持有指向线程所属模块化调度类的指针；它是独占的——在任何给定点，一个线程只能属于一个调度类（它将是表10.2第三列中提到的调度类之一）。默认情况下，它将指向CFS（fair_sched_class）。</p>
<p>​    策略成员指定线程所遵循的调度策略（它将是表10.2第一列中提到的策略之一）。它也是排他性的——一个线程在任何给定的时间点只能遵守一个调度策略（但可以更改）。线程优先级值；包含它们的成员是prio、staticprio、normal_prio和rtpriority。调度策略和优先级都是动态的，可以通过编程方式（或通过实用程序；您很快就会看到这一点）查询和设置。仅供参考，属于stop-scched类的线程很少；这是因为这是一个极端的优先级。当stopᦆsched线程获得处理器时，内核会关闭系统上所有其他内核上的执行（以及任何与锁定相关的、中断和其他一切）。因此，stop-scched类线程在所有中断和内核抢占都被掩盖的核心上执行，完全没有被抢占的机会。谁需要这种优先级和不可抢占性？一个例子是Ftrace内核跟踪子系统；另一个是实时内核补丁。此外，下一个优先级调度类——Deadline——适用于必须满足相关截止日期的实时任务（以经典的RTOS方式）。由于停止调度和截止日期线程倾向于分散，我们关注RT线程，并且主要是公平（CFS）线程；“公平类”线程通常是处于活动状态并正在运行的线程。</p>
<p>​    现在，这是一个关键点：内核为每个处理器核心和每个调度类维护一个运行队列！所以，如果我们有一个有六个CPU核的系统，那么我们将有6个核*5个调度类=30个运行队列！（有一个例外：在单处理器（UP）系统上，top sched类不存在。）运行队列是按类实现的；例如，以下是CFS的运行队列：struct CFS_rq(<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/kernel/sched/sched.h\#L550">https://elixir.bootlin.com/linux/v6.1.25/source/kernel/sched/sched.h\#L550</a>); 同样，对于RT类，它是structrt_rq，以此类推。下图试图呈现此信息：</p>
<p><img src="./image-20240717072045881.png" alt="image-20240717072045881"></p>
<p>​    请注意，在上图中，我显示运行队列的方式使它们看起来可能是数组。这根本不是目的；这是一个概念图。实际使用的运行队列数据结构取决于调度类（毕竟类代码实现了运行队列）。它可以是一个链表数组（与实时类一样），atree（实际上是一个红黑（rb）树）和fair类，等等。</p>
<h4 id="一个有助于理解调度类的概念性例子"><a href="#一个有助于理解调度类的概念性例子" class="headerlink" title="一个有助于理解调度类的概念性例子"></a>一个有助于理解调度类的概念性例子</h4><p>​    为了更好地理解调度程序类模型，我们将设计一个例子：假设在对称多处理器（SMP）或多核系统上，我们有100个线程（在用户和内核空间中）是活动的。其中，我们有几个竞争CPU；也就是说，它们处于readyᦙto run（Rr）状态，这意味着它们是可运行的，因此在runqueue数据结构上排队（见图10.2，状态机）。假设可运行线程分为以下各种调度类：一站式调度（SS）类线程、S1Two Deadline（DL）类线程，D1和D2两个实时（RT）类线程和RT1和RT2三个完全公平调度（CFS）（或公平）类线程以及F1、F2和F3一个空闲类线程I1。现在让我们想象一下，首先，线程F2在处理器核心上，愉快地执行代码。在某个时候，内核希望上下文切换到该CPU上的其他任务。（是什么触发了这一点？你很快就会看到。）在调度代码路径上，内核代码最终会进入核心调度代码kernel/sched/core.c：void schedule（void）内核例程（代码级细节稍后再说）。现在重要的是要理解的是，由schedule（）调用的pick_next_task（）例程会迭代调度器类的链表，询问每个类是否有候选程序要运行（再次参见图10.9）。它的代码路径（当然是概念上的）看起来像这样：1。核心调度程序代码（__schedule（））：“嘿，SS（stop-scched类），你有要运行的线程吗？”2。SS类代码：遍历其运行队列并找到可运行线程（S1）；它这样回答：“是的，我知道；这是S1线程。”。核心调度程序代码（<strong>scheduled（））：“好的，太好了；让我们将上下文切换到S1。”然后任务就完成了（至少在这个调度轮或纪元）。但是让我们稍微改变一下场景：如果该处理器的SSrunqueue上没有可运行的线程S1（或者它已经进入睡眠状态，或者停止运行，或者它正在运行另一个CPU的运行队列）？然后，SS会说“不”，然后会问下一个最重要的排课，截止日期（DL）。如果它有潜在的候选线程想要运行（在我们的例子中为D1和D2），它的类代码将运行其算法来识别D1或D2中的哪一个应该运行，将该线程任务结构指针返回给\</strong>s\chedules（），内核调度器将忠实地向其进行上下文切换。此过程对实时（RT）和公平（CFS）调度类继续进行。（一张图片胜过千言万语，对吧？见图10.11。）很可能（在典型的中等负载的Linux系统上），没有SS、DL或RT候选线程想要在CPU查询上运行，而且通常至少会有一个公平（CFS）线程想要运行。因此，竞争通常发生在公平（CFS）可运行线程之间；公平类实现（CFS）选择的线程将是上下文切换到的线程。如果真的没有要运行的线程（没有SS/DL/RT/CFS类线程要运行），则意味着系统当前处于空闲状态（懒惰的家伙）。现在，Idle类被询问是否要运行；它总是说是的！这是有道理的；毕竟，当没有其他人需要/想要在处理器上运行时，CPU空闲线程的任务就是在处理器上执行。因此，在这种情况下，内核会将上下文切换到空闲线程，通常标记为swapper/n，其中n是它正在执行的CPUnnumber（从0开始；是的，我知道你可能在想什么：为什么它被称为“swapper”？…这只是旧的Unixhistory回来困扰我们了——没有别的）。此外，请注意，swapper/n（CPU空闲）内核线程不会出现在ps列表中，即使它总是存在（回想一下我们在第6章“内核内部要素——进程和线程</p>
<p><img src="./image-20240717072452058.png" alt="image-20240717072452058"></p>
<p>核心调度程序代码（在pick_next_task（）中）究竟是如何询问调度类是否有任何要运行的线程的？我们已经看到了这一点，但我觉得为了清楚起见，值得重复以下代码片段（主要从__schedule（）和线程迁移代码路径调用）：</p>
<p><img src="./image-20240717072816817.png" alt="image-20240717072816817"></p>
<p>​    注意实际中的面向对象：出于所有实际目的，<code>class-&gt;pick_next_task(rq)</code>代码调用了调度类的一个方法<code>class-&gt;pick_next-task()</code>！返回值方便而有意地指向所选任务的任务结构，代码现在可以上下文切换到该结构。还可以看出，<code>pick_next_task()</code>返回NULL意味着当前类没有任何可调度的候选对象；因此，我们转到下一个类并询问它。循环将始终终止，因为如果没有其他情况，空闲类将始终返回一个非空的候选调度，即该核心的空闲线程。</p>
<h4 id="简介完全公平调度（CFS）类的工作原理"><a href="#简介完全公平调度（CFS）类的工作原理" class="headerlink" title="简介完全公平调度（CFS）类的工作原理"></a>简介完全公平调度（CFS）类的工作原理</h4><p>​    自2.6.23版本（早在2007年）以来，CFS一直是常规线程的实际内核CPUscheduling代码；默认情况下，Linux上的大多数线程都属于由CFS驱动的SCHED_OTHER策略。CFS算法背后的驱动因素是提供公平性和整体吞吐量。简而言之，它的实现是这样的：内核跟踪每个可运行的CFS（SCHED_OTHER/SCHED_NORMAL）线程的实际CPU运行时（以纳秒粒度）；运行时间最小的线程是最值得运行的线程，并将在下一个调度周期或纪元（“纪元”一词表示“某人或某事历史上某个时期的开始”）获得处理器。相反，持续敲击处理器的线程将积累大量的运行时间，因此将受到惩罚（这真的很因果报应）！我们将此讨论分为两部分：第一部分简要介绍了vruntime及其内部rb树运行队列的CFS概念，第二部分介绍了CFS动态时间片的工作原理。当然，让我们从第一部分开始。</p>
<h4 id="关于CFS-vruntime值及其运行队列的说明"><a href="#关于CFS-vruntime值及其运行队列的说明" class="headerlink" title="关于CFS vruntime值及其运行队列的说明"></a>关于CFS vruntime值及其运行队列的说明</h4><p>​    在不深入研究CFS实现内部太多细节的情况下，任务结构中嵌入了另一个数据结构struct sched_entity，其中包含一个名为vruntime（或虚拟运行时）的无符号64位值(<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/include/linux/sched.h\#L556">https://elixir.bootlin.com/linux/v6.1.25/source/include/linux/sched.h\#L556</a>). 简单来说，这是一个单调计数器，用于跟踪线程在处理器上累积（运行）的时间量（以纳秒为单位）。在实践中，在实现中，需要进行大量的代码级调整、检查和平衡。例如，内核通常会将vruntime值重置为0，从而触发另一个调度周期。此外，在/proc/sys/kernel/sched_*下有各种各样的不可选项（或sysctls），有助于更好地微调CPU调度器行为（其中一些在这里有记录：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin￾guide/sysctl/kernel.html）。CFS如何选择下一个要运行的任务封装在kernel/sched/fair.c:pick_next_task_fair（）函数中。理论上，CFS的工作方式本身就很简单：将所有可运行的任务（针对该CPU）排队到CFS运行队列上，这是一个rb树（一种自平衡的二元搜索树），这样在处理器上花费时间最少的任务就是树上最左的叶子节点，右边的后续（叶子）节点表示下一个要运行的任务，然后是下一个。实际上，从左到右扫描树可以给出未来任务执行的时间线。这是如何保证的？通过使用上述vruntime值作为将任务排队到rb树上的键！">https://www.kernel.org/doc/html/latest/admin￾guide/sysctl/kernel.html）。CFS如何选择下一个要运行的任务封装在kernel/sched/fair.c:pick_next_task_fair（）函数中。理论上，CFS的工作方式本身就很简单：将所有可运行的任务（针对该CPU）排队到CFS运行队列上，这是一个rb树（一种自平衡的二元搜索树），这样在处理器上花费时间最少的任务就是树上最左的叶子节点，右边的后续（叶子）节点表示下一个要运行的任务，然后是下一个。实际上，从左到右扫描树可以给出未来任务执行的时间线。这是如何保证的？通过使用上述vruntime值作为将任务排队到rb树上的键！</a></p>
<p>​    为什么它被称为vruntime，而不仅仅是运行时？这是因为vruntime成员的值不仅仅是线程在处理器上花费的时间；它更微妙：在计算这个非常重要的数字时，它考虑了线程的优先级——即nice值（毕竟，线程在CFS-rb树运行队列中的“位置”是基于这个vruntime量的）。因此，我们采取了以下措施：nicevalue越低（优先级越高），vruntime值越低，因此它更多地排在左边；nice值越高（优先级越低），runtime值就越大，因此它被更多地向右排队。（这种任务调度方法被广泛称为加权公平排队调度程序。）当核心调度程序需要调度时，它会问CFS“你有任何要运行的线程吗？”，CFS类代码（我们已经讨论过函数pick_next_task_fair（））会运行，只需选择树上最左侧的叶子节点，并返回指向嵌入其中的任务结构inter的指针。想想看——根据定义，它是具有最低vruntime值的任务，因此实际上是运行最少的任务！（遍历树是一种O（logn）时间复杂度的算法，但由于一些代码优化和对最左侧叶子节点的巧妙缓存，该实现有效地具有非常理想的O（1）时间复杂性。）当然，实际的代码比这里介绍的要复杂得多；它需要进行多次制衡。我们不会在这里深入探讨所有血腥的细节。我们建议有兴趣了解更多关于CFS的人参阅关于此主题的内核文档</p>
<h4 id="关于CFS调度周期和时间的说明"><a href="#关于CFS调度周期和时间的说明" class="headerlink" title="关于CFS调度周期和时间的说明"></a>关于CFS调度周期和时间的说明</h4><p>​    你注意到了吗？与传统的操作系统调度器不同，CFS的时间片是动态的！CPU上的任务（所谓的IO绑定任务）会自动累积较少的vruntime，从而向CFS-rb树的左侧迁移。对于CPU受限的任务，情况正好相反；它们（通过具有更大的vruntime值）向右移动，减少了快速获得CPU的机会。</p>
<p>​    在调度器上下文中，调度周期（有时被混淆为“调度延迟”）是指一个完整的调度周期（或纪元）运行的时间；在此时间段内，操作系统保证每个线程都有机会在CPU上运行。那是什么？默认值位于sysctl/sys/kernel/debug/sched/latency_ns中（Ubuntu 22.04上的典型默认值为24毫秒，Fedora38/39上的默认值为18毫秒）。此外，在运行时，它可以改变——它本身是动态的（稍后将详细介绍）——计算如下：调度周期长度=min_granularity_ns*nr_running；这里，nr_running是当前可运行的任务数（这是基于每个运行队列）。在最近的内核中，这些调度程序可调项可以在indebugfs中找到；让我们在x86_64 Ubuntu 22.04 LTS上查找一些值。</p>
<p>​    好的，以下是一些相关可调参数的含义：</p>
<ul>
<li>latency_ns：这是当前计算的“周期”值（innanoseconds（ns））；因此，这里的默认调度周期为24000000ns，即24ms，也就是说，每个线程都保证每24ms至少有一次机会运行！</li>
<li>min_granularity_ns：这是CFS-rb树上节点之间所需的最小“距离”；实际上，这是每个CFS线程运行时允许的最小时间（默认值：3ms）。</li>
</ul>
<p>在继续之前，有几点需要注意：</p>
<blockquote>
<p>默认值可以而且确实因系统（内核）而异！在我的x86_64Fedora 38虚拟机上，周期和最小粒度（最小时间片）分别为18毫秒和2.25毫秒。检查你的系统上有什么。</p>
<p>上述调度程序可调参数是在functionsched_init_debug（）中创建的（在系统初始化过程中调用：<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/kernel/sched/debug.c\#L299).想想看——当前可运行任务的数量（nr_running）直接影响周期（因此也影响时间片）。">https://elixir.bootlin.com/linux/v6.1.25/source/kernel/sched/debug.c\#L299).想想看——当前可运行任务的数量（nr_running）直接影响周期（因此也影响时间片）。</a></p>
</blockquote>
<p>因此，给出以下事实：调度周期长度=min_granularity_ns*nr_running（如我们所见）min_granuality_ns实际上是CFS（动态）时间策略值给定默认的min_granularity_ns值为3ms，周期（latency_ns）为24ms（就像我的Ubuntu 22.04（和23.10）盒子上的情况一样），为了了解这是如何工作的，我们提供了一组示例值的有效时间级别和调度周期的计算，如下表所示</p>
<p><img src="./image-20240717073306746.png" alt="image-20240717073306746"></p>
<p><img src="./image-20240717073322088.png" alt="image-20240717073322088"></p>
<p>​    基于可运行线程数量的有效CFS任务时间片计算有效时间片，并在第二列中显示；只要它的值在min_granularityns值（3ms）内，一切都很好。然而，可以看出，当可运行线程的数量变得非常大时，情况显然变得无法维持（表10.3的最后一行）；现在，调度器没有放弃，而是巧妙地、动态地调整调度周期，重新计算它！（好吧，这是一种说法；狡猾的内核是：“我答应过你每24毫秒至少有一次机会在CPU上吗？不，不，你错了；我的意思是每36毫秒有一次……”。）从技术上讲，所做的检查是这样的（伪代码）：effective_timeslice（ms）=latency_ns调度周期。）有关CFS和这些与调度程序相关的可调参数的更多信息，请查看进一步阅读部分。现在让我们继续讨论（简短的）主题，即查找由内核维护的任务调度统计信息（如果配置了）。</p>
<p>基于可运行线程数量的有效CFS任务时间片计算有效时间片，并在第二列中显示；只要它的值在min_granularityns值（3ms）内，一切都很好。然而，可以看出，当可运行线程的数量变得非常大时，情况显然变得无法维持（表10.3的最后一行）；现在，调度器没有放弃，而是巧妙地、动态地调整调度周期，重新计算它！（好吧，这是一种说法；狡猾的内核是：“我答应过你每24毫秒至少有一次机会在CPU上吗？不，不，你错了；我的意思是每36毫秒有一次……”。）从技术上讲，所做的检查是这样的（伪代码）：effective_timeslice（ms）=latency_ns调度周期。）有关CFS和这些与调度程序相关的可调参数的更多信息，请查看进一步阅读部分。现在让我们继续讨论（简短的）主题，即查找由内核维护的任务调度统计信息（如果配置了）。</p>
<p>​    调度统计数据您能在系统和流程粒度上看到调度的状态吗？事实上，当配置时（需要CONFIG_SCHEDSTATS=y），内核会在proc:/proc/schedstat下提供这些伪文件：系统范围的调度统计信息。这些已经存在了很长时间；它们显示每个CPU的调度统计数据（以及SMP上的域-CPU/微架构层次结构信息）。该信息包括调度程序（和thetry_to_wake_up（）函数）被调用的次数（在该CPU核心上），核心上任务运行/等待的所有时间的累积总和，以及该核心上的时隙数。</p>
<p>​    最好参考官方的内核文档：<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/Documentation/scheduler/sched-stats.rst./proc/PID/schedstat">https://elixir.bootlin.com/linux/v6.1.25/source/Documentation/scheduler/sched-stats.rst./proc/PID/schedstat</a></p>
<p>​    /proc/PID/sched：进程/线程级粒度：/proc/PDI/schedstat内容由三个空格分隔的数字组成，所有这些数字都与进程ID为PID的线程有关：在CPU上花费的时间（纳秒）在运行队列上等待的时间（毫微秒）在这个CPU上运行的时间片数/proc/PII/sched内容非常详细；它包括任务sched_entity结构的许多字段（显示为se.foo；这包括任务vruntime（以纳秒为单位）se.vruntime！），上下文切换统计、调度策略和优先级，以及一些NUMA统计。</p>
<p>​    查询给定线程的调度策略和优先级在本节中，您将学习如何通过命令行查询系统上任何给定线程的进度策略和优先级。（但是，通过编程方式查询和设置相同的内容呢？我们将讨论推迟到第11章“CPU调度器-第2部分”的查询和设置athread的调度策略和优先级部分。）我们了解到，在Linux上，线程是KSE；它是被调度并在处理器上运行的。此外，Linux有多种调度策略（或算法）可供选择。调度策略和优先级都是基于每个线程分配的，默认策略始终为SCHED_OTHER，默认实时优先级为0（换句话说，它是非实时线程；见表10.1）。在给定的Linux系统上，我们总是可以看到所有进程都是活动的（通过simpleps-a），或者，使用GNU ps，甚至可以看到每个线程都是活的（一种方法是使用ps-LA）。然而，这并没有揭示一个关键事实：这些任务在什么调度策略和优先级下运行。我们如何对此提出质疑？事实证明，这很简单：在shell上，chrt实用程序非常适合查询和设置给定进程的调度策略和/或优先级。发出带有-p选项开关的chrt并提供PID作为参数，使其显示调度策略以及所讨论任务的实时优先级；例如，让我们查询init进程（orsystemd）PID 1:</p>
<pre class="line-numbers language-none"><code class="language-none">pid 1&#39;s current scheduling policy: SCHED_OTHER 
pid 1&#39;s current scheduling priority: 0 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    需要注意的几件事：在我们的脚本中，通过使用GNU ps，调用ps-LA命令，我们能够捕获系统上所有活动的线程；显示它们的PID和TID。正如您在第6章“内核内部要素-进程和线程”中所了解到的，PID是内核TGID的用户空间等效值，TID是内核PID的用户空间等价值。因此，我们可以得出以下结论：如果PID和TID匹配，则该行中看到的线程（第三列有其名称）是进程的main（）线程。如果PID和TID匹配，并且PID只显示一次，则这是一个单线程进程。如果PID以不同的TID（第二列）重复（最左侧的列），则该进程是多线程的，而这些TID是该进程的子线程（更准确地说，工作线程）。我们的脚本通过在右侧缩进TID编号来显示这一点（在图10.12的截断屏幕截图中，您看不到它，因为稍后会发生这种情况）。</p>
<p>​    请注意，典型Linux机器（桌面、服务器甚至嵌入式）上的绝大多数线程往往是非实时的（属于策略SCHED_OTHER）。一些（软）实时线程（SCHED_FIFO/SCHED_RR）也可能出现。Deadline（DL）和Stop Sched（SS）线程确实很少见（当然，这样的事情往往是特定于项目的）。请注意前面输出中显示的关于实时线程的以下观察结果：我们的脚本通过在（第六）列中显示一个星号（标记为*RT）来突出显示任何实时线程（第四列为SCHED_FIFO或SCHED_RR的线程）。</p>
<p>​    此外，任何实时优先级为99（最大可能值）的软实时线程在同一列中都会有三个星号（这些往往是专门的内核线程）。当与调度策略进行布尔OR运算时，SCHED_RESET_ON_FORK标志具有禁止任何子项（viafork（））继承特权调度策略（安全措施）的效果。倒数第二列是线程的“nice”值（回想一下，范围是-20到+19，-20是最佳优先级，19是最差优先级，默认值为0）。请注意，nice值仅对具有调度策略SCHED_OTHER的线程（以及批处理和空闲线程）有效。最右边的列显示了CPU关联掩码（十六进制），也是每个线程的属性！这意味着您可以设置线程可能调度的CPU核心（我们将在下一章详细介绍这一方面）。例如，二进制中的掩码值0x3f为0011 1111，这意味着该线程可以在设置为1的任何内核上运行，因此在这里，可以在任何内核上（因为系统上总共有六个内核）运行。快速测试：CPU关联掩码值0x8意味着什么？更改线程的调度策略和/或优先级可以使用chrt执行；但是，您应该意识到，这是一个需要root权限的敏感操作（或者，现在，推荐的机制是通过能力模型，CAP_SYS_NICE是所需的能力位）。我们将让您检查脚本的代码（ch10/query_task_sched.sh）。此外，请注意，性能和shellscripting并没有真正结合在一起（所以不要对</p>
<p>表演在这里）。想想看，ashell脚本中发出的每个外部命令（我们这里有几个，比如awk、grep和cut）都涉及fork-exec等待语义和上下文切换。此外，这些都在循环中执行。</p>
<blockquote>
<p>tuna（8）程序是一个强大的基于GUI（或控制台模式）的系统监控、调整和配置文件管理工具，可用于查询和设置各种属性；这包括进程/线程级调度策略/优先级和CPU亲和性掩码，以及IRQ亲和性。这是一个设计良好的GUI；一定要看看！（安装tuna：<a target="_blank" rel="noopener" href="https://tuna.readthedocs.io/en/stable/installation.html).此外，schedtool实用程序与chrt有些相似，可用于查询和设置给定线程上的任何或所有任务调度参数；schedtool（8）的手册页介绍了它的用法。">https://tuna.readthedocs.io/en/stable/installation.html).此外，schedtool实用程序与chrt有些相似，可用于查询和设置给定线程上的任何或所有任务调度参数；schedtool（8）的手册页介绍了它的用法。</a></p>
</blockquote>
<p>​    您可能会想，具有SCHED_FIFO策略和99的区域时间优先级的（少数）线程是否总是占用系统的处理器？不，不是真的；现实情况是，这些线程通常大部分时间都处于休眠状态。当内核确实要求他们执行一些工作时，它会唤醒他们。现在，正是由于他们的实时策略和非常高的优先级，可以很好地保证他们或多或少会立即获得一个CPU内核，并按照需要执行（一旦工作完成，就会重新进入睡眠状态）。关键在于，当他们需要处理器时，他们会得到它（有点类似于RTOS，但没有RTOS提供的铁证如山的保证、低调度延迟和确定性）。</p>
<h4 id="学习CPU调度内部机制——第3部分"><a href="#学习CPU调度内部机制——第3部分" class="headerlink" title="学习CPU调度内部机制——第3部分"></a>学习CPU调度内部机制——第3部分</h4><p>​    让我们从探索抢占主题开始。抢占式内核请想象一下这种假设情况：您正在一个只有一个CPU内核的系统上运行。一个模拟时钟应用程序与aC程序a.out一起在GUI上运行，a.out的一行代码是（呻吟）while（1）；。那么，你怎么看：当1个进程无限期占用CPU时，CPU会占用CPU，从而导致GUI时钟应用程序停止运行（它的第二手盖会完全移动吗）？稍加思考（和实验）就会发现，尽管有淘气的CPU占用者应用程序，GUI clockapp确实一直在运行！这就是拥有操作系统级调度器的全部意义：它可以而且确实会抢占（踢出！）占用CPU的用户空间进程。（我们之前简要讨论了CFS算法；CFS会导致占用大量CPU的进程累积一个巨大的vruntime值，从而在其rbᦙ树运行队列上向右移动更多，从而惩罚处理器本身！）所有现代操作系统都支持这种类型的抢占——它被称为用户模式抢占。但现在考虑一下：如果你编写一个在单核系统上执行相同while（1）无限循环的内核模块呢？这就带来了一个问题：系统现在只会挂起。为什么？因为默认情况下，大多数操作系统内核都是不可抢占的；也就是说，他们不能先发制人！</p>
<p>​    除了这个微不足道的例子，现实世界中肯定存在这样的情况，即如果内核不可抢占，它可能会对（实时）线程调度产生负面影响。想想看：如果你的高优先级线程在运行队列中（因此是可运行的）并且需要紧急运行，但内核在内核（或内核模块/驱动程序）代码的不可抢占部分中处理了一些长循环，该怎么办？或者，硬件中断发生但无法提供服务，因为中断再次被掩盖在长时间运行的不可抢占的代码段中……锁定在这里起着重要作用（你将在最后两章中更详细地学习）；事实上，多年来，内核有一个臭名昭著的、非常粗粒度（和递归）的锁，绰号为大内核锁（BKL）；当被持有时，它会使内核在很长一段时间内保持不可抢占状态（中断被屏蔽），从而对性能和延迟响应造成严重破坏。它（终于！）在2.6.39内核中被完全删除了。因此，问题出现了：在需要时，内核可以抢占自己吗？好吧，你猜怎么着：多年来，Linux提供了一个构建时配置选项，使内核可抢占；它被称为CONFIG_PREEMPT。（实际上，这只是朝着降低延迟和改善内核和调度响应的长期目标的进化。这项工作的大部分来自早期和一些正在进行的努力：低延迟（LowLat）补丁、（旧的）RTLinux工作，特别是RTL（实时Linux）项目（Linux作为真正的RTOS运行！我们将在下一章介绍RTL的设置）。）一旦启用了CONFIG_PREEMPT内核配置选项，并且构建并启动了内核，我们就会在可抢占的内核上运行——在大多数情况下，操作系统都有能力抢占自己！</p>
<h4 id="动态可抢占内核特性"><a href="#动态可抢占内核特性" class="headerlink" title="动态可抢占内核特性"></a>动态可抢占内核特性</h4><p>​    从5.12内核开始，引入了一种新的动态可抢占核特性（CONFIG_PREEMPT_dynamic）。具有此功能可以让您绕过内核参数（当然是通过引导加载程序）在引导时调整内核的抢占行为（或模式）；它的名字叫repempt=。它可以设置的值如下（参见表10.4）：抢占=无：内核抢占行为与CONFIG_preempt_none相同。抢占=自愿：内核抢占的行为接近CONFIG_preempt_voluntary。</p>
<p>​    preempt=full[默认]：内核抢占行为与CONFIG_preempt相同。一个典型的预期用例是允许发行版发布一个内核二进制映像——使用CONFIG_PREEMPT构建，内置（几乎）完整的内核抢占——但能够允许最终用户在启动时修改内核抢占模式，从而允许用户选择是将其作为典型的服务器类系统（抢占=无）、桌面（抢占=自愿）还是启用完全抢占来运行。这样，发行版（或产品）就不必为不同的用例提供和维护不同的内核映像。内核配置名为config_PREEMPT_DYNAMIC；将其设置为y可启用该功能。（要在make menuconfig UI中执行此操作，请转到General Setup |启动时定义的抢占行为。这是一个布尔值；打开它，重新构建并重新启动，传递抢占=<value>参数。）仅供参考，uname-a以及/proc/version将显示此功能</p>
<p>​    好的，完成这项工作后，我们将回到内部方面的更多细节。让我们非常简要地总结一下我们在前几节中学到的一些关键点。您了解到核心内核调度代码被编排在void schedule（void）函数中，该函数是worker函数__schedule（）的一个薄包装器，它按优先级顺序迭代模块化调度器类，最终得到一个被（底层调度类的一个代码）选中的线程进行上下文切换。所有这些都很好；现在有几个关键问题是：谁确切地称之为“任务调度”核心代码路径，它到底什么时候运行？（正是图10.9最上面标有“S”的连接器所暗示的！）以下部分试图回答这些问题；加油，加油！谁运行调度程序代码？许多人不幸地持有一个关于调度工作原理的微妙但关键的误解：我们想象存在一种称为“调度器”的内核线程（或某种这样的实体），它定期运行和调度任务。这显然是错误的；在Linux等单片操作系统中，调度是由进程上下文本身执行的，即在内核模式下在CPU上运行的规则线程！事实上，调度代码总是由当前正在执行内核代码的进程上下文运行的——换句话说，由当前运行的（我们在第6章“内核内部要素——进程和线程”中，在“使用当前访问任务结构”一节中介绍了当前到底是什么）。这也可能是提醒您我们将称之为Linux内核黄金法则之一的合适时机：调度器绝不能在任何类型的原子上下文（包括中断上下文）中运行。</p>
<h4 id="schedule（）什么时候运行？"><a href="#schedule（）什么时候运行？" class="headerlink" title="schedule（）什么时候运行？"></a>schedule（）什么时候运行？</h4><p>​    操作系统调度器的工作是仲裁对处理器（CPU）资源的访问，在想要使用它的竞争实体（线程）之间共享它。但是，如果系统很忙，许多线程不断竞争、获取然后放弃处理器怎么办？更准确地说，我们真正要做的是：为了确保任务之间公平共享CPU资源，你必须确保图片中的警察，即调度器本身，在处理器上定期运行。听起来不错，但你究竟如何确保这一点？这里有一个（看似）合乎逻辑的方法：在启动时将操作系统挂接到定时器芯片的中断中，作为定时器中断触发时在中断处理程序例程中完成的“内务处理”的一部分，调用调度器！现在，（有点简单）与我们之前学到的相反，timeprinterrupt每秒“触发”CONFIG_HZ次。因此，如果我们在这里调用schedule（），它有机会每秒运行CONFIG_HZ一次（在x86_64 Ubuntu上通常设置为值250，在x86_ 64 Fedora上设置为值1000）！不过，请稍等，我们在第8章“模块作者的内核内存分配——第1部分”的“永不休眠中断或原子上下文”部分学到了一条黄金法则：你不能在任何类型的原子（包括中断）上下文中调用调度程序（就像刚才一样提到）。因此，按照这个规则，我们根本不能在计时器中断中调用schedulercode路径（这样做会立即导致akernel错误）。那么操作系统是做什么的呢？我们将深入探讨，但首先，我们需要介绍一个名为thread_info的结构的一些基础知识。</p>
<p>​    最低限度地理解thread_infostructure为了清楚地理解以下几点，您需要了解与名为thread_info的每个线程依赖于arch的数据结构有关的基本知识。这个结构很小，包含一些关键的“热点”成员（这些成员最初位于任务结构中）。这种thread_infostructure的原因是常见的——性能；查找thread_info内容比查找大型任务结构的内容快得多，因为它要小得多，通常设计为适合单个CPU缓存行。（好吧，至少在x86_64和AArch64上都是这样：它的大小只有24字节。此外，在AArch32中计算电流时也利用了这种结构。）thread_info结构有丰富多彩的放置历史。在早期的Linux中，它是一个完全独立的实体；从2.6 Linux开始，对于32位平台（至少x86-32和AArch32），它位于每个线程的内核模式堆栈中。在较新的Linux版本（从4.0或4.4开始）和某些版本中，当CONFIG_THREAD_INFO_IN_TASK=y时，它已成为任务结构本身的成员（主要是由于安全问题）。您可以看到x86[_64]的thread_info的定义: <a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/arch/x86/include/asm/thread_info.h\#L56对于AArch64https://elixir.bootlin.com/linux/v6.1.25/source/arch/arm64/include/asm/thread_info.h\#L24.For我们的直接目的，只是thread_info的一个成员是有意义的&amp;一个位掩码：无符号长标志。正如你所猜到的，它是各种标志值的一个掩码（都是TIF\_\">https://elixir.bootlin.com/linux/v6.1.25/source/arch/x86/include/asm/thread_info.h\#L56对于AArch64https://elixir.bootlin.com/linux/v6.1.25/source/arch/arm64/include/asm/thread_info.h\#L24.For我们的直接目的，只是thread_info的一个成员是有意义的&amp;一个位掩码：无符号长标志。正如你所猜到的，它是各种标志值的一个掩码（都是TIF\_\</a><FOO>样式，其中TIF是“thread_info flag”的缩写）。您将在代码库中找到此处定义的所有TIF_*标志宏：<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/arch/x86/include/asm/thread_info.h\#L76.在现有的众多标志中，我们讨论任务调度的关键标志是TIF_NED_RESCHED。正如稍后将解释的那样，如果设置，则意味着内核“需要尽快重新安排”；">https://elixir.bootlin.com/linux/v6.1.25/source/arch/x86/include/asm/thread_info.h\#L76.在现有的众多标志中，我们讨论任务调度的关键标志是TIF_NED_RESCHED。正如稍后将解释的那样，如果设置，则意味着内核“需要尽快重新安排”；</a></p>
<p>​    调度代码路径（schedule（））的“何时”及其调用的所有内容分为两部分：一是TIF_NED_RESCHED位何时设置？第二，什么时候检查TIF_NED_RESCHED位？让我们看看：何时设置了“需要重新筛选”（TIF_NED_resched）位？</p>
<p>​    thread_info.flags:TIF_NEED_RESCHED位（这不是Ccode；它只是在概念上显示“需要重新筛选”位），当设置时，实际上类似于一个红旗，通知内核必须尽快执行（重新）调度（实际上，当前必须立即被抢占！）。此标志可以在以下情况下设置：（定时器）中断内务处理：在每个定时器中断时（技术上，在定时器softirq代码路径中），执行与调度器相关的“内务处理”；</p>
<p>​    在这里所做的工作中，一个关键问题是：当前是否需要被抢占？如果是，则设置TIF_NED_RESCHED位。（注意：只有位的set；此处不调用schedule（），因为这是不允许的。）任务唤醒：当任务被唤醒时，它会被放入适当的运行队列中；现在，如果确定必须抢占当前，请设置thread_info.flags:TIF_NEED_RESCHED位。何时检查“需要重新筛选”（TIF_NED_RESCHED）位？调度机会-进程上下文识别：对thread_info标志进行当前检查：TIF_NEED_RESCHED位设置在某些设计良好的进程上下文“机会点”；如果该位已设置，则调用调度代码路径；否则，照常继续。你注意到了吗？在（定时器）中断管理和任务唤醒的情况下，即使我们在中断上下文中运行，也不会出现任何问题。这是因为我们不在此时调用schedule（）；我们只需设置TIF_NED_RESCHED标志，通知内核我们需要重新调度SAP，并且必须在下一个可用的“机会点”进行重新调度！我们将在以下几节中详细介绍这一讨论。</p>
<h4 id="定时器中断内务管理–设置TIF-NED-RESCHED"><a href="#定时器中断内务管理–设置TIF-NED-RESCHED" class="headerlink" title="定时器中断内务管理–设置TIF_NED_RESCHED"></a>定时器中断内务管理–设置TIF_NED_RESCHED</h4><p>​    在定时器中断（在kernel/sched/core.c的代码中：scheduler_tick（），其中中断在本地内核上被禁用）中，内核执行保持调度平稳运行所需的元工作（内务管理）；这涉及到根据需要不断更新每个CPU的运行队列、任务负载平衡工作等。请注意，这里从未调用实际的schedules（）函数。在最好的情况下，调度类挂钩函数（用于被中断的当前进程上下文）sched_class:task_tick（），如果为空，则会被调用（参见图10.13）。例如，对于属于fair（CFS）类的任何线程，vruntime成员（虚拟运行时）的更新以及任务在处理器上花费的（优先级偏向的）时间都是在名为task_tick_fair（）的钩子函数中完成的。从技术上讲，前一段中描述的所有这些工作，即scheduler_tick（）的代码，都在定时器中断softirq代码路径TIMER_softirq.Now（除了其他与调度相关的内务处理）内运行，而在这个timeprinterrup（softirq）上下文中，我们必须决定：当前是否需要被抢占？通过检查以下条件并在其中任何一个条件为真时抢占电流来做出这一关键决定：电流是否超过了其时间范围？此外，它是否超过了邻国的足够大的门槛？这正是thetabable（或sysctl）/sys/kernel/debug/sched/min_granularity_nshold的阈值；这是有效的CFS时间片。默认值各不相同（在x86_64 Ubuntu 22.04上为3毫秒，在Fedora 38/39上为2.25毫秒。作为快速提醒，我们在关于CFS调度周期和时间片部分的a说明中介绍了有关CFS有效时间片的信息。</p>
<p>新生成并运行或最近唤醒的任务（在此CFSrunqueue上）是否比当前任务具有更高的优先级？CFS-rb树是否有一个vruntime低于current的任务（换句话说，current不再是该树上最左侧的叶子节点）？（仔细想想，第一点和第三点非常相似；如果超过了时间量，vruntime值很可能会增加到不再是therunqueue中最左侧的叶子节点的程度。）假设刚才描述的内核代码路径决定了一个新任务更值得CPU处理；然后呢？它调用schedule（）吗？不如上所述，我们不能在中断上下文中调用schedule（）。内核现在只是通过设置一个“全局”标志来“标记”我们需要在“下一个调度机会点”尽快重新调度的事实，即thread_info-&gt;flags的TIF_NED_RESCHED位。（我们将单词global放在引号内的原因是，它并不是一个真正的全内核全局；它实际上只是当前实例的thread_ininfo-&gt;flagsbitmask中的一个位，名为TIF_need_RESCHED。为什么？这样访问该位比通过全局更快！）此外，要记住的是，如果需要调度一个新生成或最近唤醒的任务，它会被放置在一个合适的runqueue，但它还没有运行；它将在不久的将来下一个调度机会到来时运行。</p>
<p><img src="./image-20240717074612908.png" alt="image-20240717074612908"></p>
<p>​    图10.13以概念方式显示了定时器软件上下文中的TIF_NED_RESCHED位。当定时器中断（或IRQ）触发时，快速而小的所谓上半部分或hardirq手柄比例会运行，非常快速地执行其工作；完成后，内核调用计时器下半部分或softirq处理程序（图10.13的左侧部分）。如前所述，这里的一部分工作是定时家务任务。我们从概念上展示了CFS-rb树，节点x表示最左侧的叶子节点，c表示当前节点（图10.13的中间部分）。因此，在这个图中，current不再是最左侧的叶子节点（这意味着它的vruntime值高于x）。定时器（与调度程序相关）内务代码路径中的代码检测到这种情况，并设置TIF_NEED_RESCHED位（ti是thread_info的缩写，在现代Linux中，它位于任务结构中，如图10.13的右侧所示）。另一个进行类似检查的地方是任务被唤醒时。当发生这种情况时，它会从其所在的等待队列中退出并排队</p>
<p>​    在CPU运行队列中。现在，如果发现最近唤醒的任务（在该核心上：runqueue）必须抢占当前任务（由于其具有更高的优先级、更少的vruntime或其他原因），则设置TIF_NEED_RESCHED位。（我们将在即将到来的CPU调度程序入口点（摘要部分）中更详细地讨论这种情况。）同样值得强调的是，在典型（可能）的情况下，当运行定时器软irq代码路径时，通常不需要抢占当前，因此不需要设置thread_info.flags:TIF_NED_RESCHED位；它将保持清晰。如果设置了，调度程序很快就会激活，但具体是什么时候？请继续阅读…进程上下文部分——检查TIF_NEED_RESCHEDO硬币的一面，即调度内务工作中刚刚描述的定时器中断（softirq）部分，它可能会将thread_info:TIF_NED_RESCHED位设置为向内核发出“信号”，表示应尽快调用调度代码，随着系统的运行而不断执行。硬币的另一面是检查或识别此位是否已设置，如果是，则调用schedule（）；后一部分——调用schedule（）——请注意：仅在进程上下文中执行，并且仅在散布在整个内核代码路径中的某些特定“机会点”执行。以下是thread_info-&gt;标记的典型所谓机会点。检查TIF_NED_RESCHED（通常通过need_sched（）辅助函数）：从系统调用代码路径返回时。从中断代码路径返回时。一般来说，内核中从不可抢占模式到可抢占模式的任何切换都是一个机会点（当调用preced_enable（）时）。一个典型的例子是当自旋锁被解锁时。所以，想想看：每次在用户空间中运行的任何线程发出系统调用时，该线程都会（上下文）切换到内核模式，然后在内核中以内核权限运行代码（这是单片内核设计）。当然，系统调用的长度是有限的；完成后，它们将遵循一个众所周知的返回路径，以便切换回用户模式并在那里继续执行。在内核的这个返回路径上，引入了一个调度机会点：检查是否设置了TIF_NED_RESCHED位（在thread_info结构的标志成员中）。如果是，则通过让进程上下文调用schedule（）来激活调度器。可以调用schedule（）的其他地方是：任何显式（或隐式）调用schedule*（）（例如，当发出阻塞调用时）任何对cond_resched*（）函数的调用都可能导致schedule*被调用。显然，在进程上下文中显式或隐式调用schedule（）将触发其运行。此外，内核提供了一些“条件调度”API（如cond_resched（）），允许驱动程序检查：我是否消耗了太多的CPU？如果是这样，屈服……他们导致schedule（）在需要时被调用（实际上，只有当当前-&gt;ti-&gt;flags.TIF_NEED_RESCHED位被设置时）。</p>
<p>​    请注意，内核可以准备切换回用户模式不仅仅是为了调度；它还包括它必须处理的其他几件事（实际上，这是处理其他事情的机会点，比如处理挂起的信号、uprobes、内核实时补丁等等）。如果设置了上述任何位，EXIT_TO_USER_MODE_WORK宏将返回True；然后，内核设置退出到用户模式并调用schedule（）</p>
<p><img src="./image-20240717074745863.png" alt="image-20240717074745863"></p>
<h4 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h4><p>​    为了完成本章，让我们快速浏览一下（CPU调度器）上下文切换。上下文切换（在CPU/任务调度器的上下文中）的工作非常明显：在简单地切换到下一个任务之前，操作系统必须保存前一个任务的状态，即当前正在执行的任务（换句话说，当前的状态）。任务结构包含另一个嵌入其中的结构，用于存储/检索线程的硬件上下文；它是成员结构thread_struct-thread（在x86上，它总是任务结构的最后一个成员）。在Linux中，内联函数kernel/sched/core.c：context_switch（）执行上下文切换工作；当然，您现在会意识到它的代码是由current运行的，这被认为是“前一个”任务。它执行从上一个任务（从当前任务）切换到下一个任务的工作，即本次调度回合或抢占战的获胜者。这种上下文切换基本上分为两个非常具体的阶段：</p>
<p>​    内存（MM）开关：将特定于拱形的CPU寄存器拓扑点切换到next的内存描述符结构（struct MM_struct）。在x86[_64]上，这个寄存器称为CR3（控制寄存器3）；在RAM（AArch32）上，它被称为TTBR0（转换表基寄存器0）寄存器。为什么？因为它来自mm_struct，内核可以在其中“看到”进程的整个内存图片，重要的是，包括指向其分页表基的指针；正确设置此指针将使MMU在下次执行地址转换时引用下一个的分页表！实际CPU切换：通过保存prev的堆栈和CPU寄存器状态，并将next的堆栈和CPU寄存器状态恢复到处理器旁边，从prev切换到next；这是在switchto（）宏中完成的。这将使下一个简历处理精确到它停止的地方。。。上下文切换的更详细的实现我们不会在这里介绍；请查看“进一步阅读”部分以获取更多资源。最后，有一点非常有趣：内核提供了一种将一组处理器与干扰隔离开来的方法——实际上，与调度程序类和SMP负载平衡的影响隔离开来！这是通过指定akernel参数来实现的，isolcpus=[flag list，]\<cpu list>。标志列表默认为域；当指定时，默认情况下，指定cpu列表中的所有cpu内核都与“通用SMP平衡和调度算法”隔离。（这往往对某些类型的实时应用程序有用。）不过，请稍等：isolcpus=kernel参数现在被认为已弃用</p>
<h2 id="CPU调度程序-第2部分"><a href="#CPU调度程序-第2部分" class="headerlink" title="CPU调度程序-第2部分"></a>CPU调度程序-第2部分</h2><h4 id="理解、查询和设置CPU关联掩码"><a href="#理解、查询和设置CPU关联掩码" class="headerlink" title="理解、查询和设置CPU关联掩码"></a>理解、查询和设置CPU关联掩码</h4><p>​    任务结构——线程（或任务）的根数据结构，包含几十个线程属性——有几个与调度直接相关的属性：优先级（nice和实时（RT）优先级值）、调度类结构指针、线程所在的运行队列（如果有的话）等等。（仅供参考，我们在第6章“内核内部要素——进程和线程”中介绍了任务结构的一般细节）。其中有一个重要的成员，CPU亲和位掩码（实际结构成员是cpumask_t*cpus_ptr.FYI，在5.3内核之前，它是一个名为cpus_allowed的成员；这在这次提交中发生了变化：<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/commit/3bd3706251ee8ab67e69d9340ac2abdca217e733">https://github.com/torvalds/linux/commit/3bd3706251ee8ab67e69d9340ac2abdca217e733</a>). 这个位掩码就是：允许线程（由该任务结构表示）在其上运行的CPU内核的位掩码。简单的可视化会有所帮助；在配备8个CPU的系统上核心，这就是典型的CPU亲和位掩码（概念上）的样子：</p>
<p><img src="./image-20240717075311216.png" alt="image-20240717075311216"></p>
<p>​    亲和位在上面的例子中，每个单元格代表一个CPU核；最上面一行表示CPU核心编号，下面一行的单元格显示了它的示例值：最下面一行单元格可以设置为0或1，表示线程是否可以在相应的CPU核心上运行。因此，在这里，CPUbitmask值为0x3f（将二进制数0011 1111转换为十六进制），这意味着该线程可以在CPU内核0到5上调度，但不能在内核6和7上调度。默认情况下，所有CPU关联掩码位都已设置；因此，默认情况下，线程可以在任何核心上运行；这是有道理的。例如，在一个有8个CPU核的盒子上，每个线程的默认CPU亲和性位掩码将是二进制1111 1111 1111（0xff十六进制）。由于这个CPU亲和位掩码成员保存在任务结构中，这告诉我们CPU亲和位面具是每个线程的数量；这也很重要——毕竟Linux上的KSE是一个线程。在运行时，调度器决定了线程实际运行的核心。事实上，仔细想想，这是隐含的：根据设计，每个CPU核都有一个与之关联的运行队列。每个可运行的线程都将位于一个CPU运行队列上；因此，它符合torun条件，默认情况下，在其runqueue所代表的CPU上运行。当然，调度器有一个负载均衡器组件，可以根据需要将线程迁移到其他CPU内核（实际上是运行队列）（称为migration/n的内核线程在需要时协助执行此任务，其中n是内核编号）。</p>
<p>​    内核确实将API暴露给用户空间（当然是系统调用sched_{s,g}etaffinity（2） 以及它们的pthread包装器库API），这允许应用程序根据需要将一个线程（或多个线程）仿射或关联到特定的CPU内核（根据相同的逻辑，我们也可以在内核中为任何给定的内核线程执行此操作）。例如，将CPU关联掩码设置为1000 0001二进制，在十六进制中等于0x81，意味着线程只能在CPU核7和0上执行（记住，核计数从0开始）。一个关键点：虽然你可以操纵给定线程的CPU亲和性掩码，但建议避免这样做；内核调度程序子系统详细了解CPU拓扑（或域），可以最好地平衡系统负载。话虽如此，显式设置线程的CPU关联掩码可能是有益的，原因如下：通过确保线程始终在同一CPU核上运行，可以大大减少频繁的缓存失效（从而减少不愉快的缓存“反弹”）。（第13章，内核同步-第2部分，更详细地介绍了CPU缓存）。可以有效地消除内核之间的线程迁移成本。实现CPU预留——一种通过保证所有其他线程都明确不允许在该核心上执行来将核心独占给一个线程的策略。前两种方法在某些极端情况下很有用；第三种是CPU预留，这是一种在一些时间关键的实时系统中使用的技术，在这些系统中这样做的成本是合理的（仅供参考，这是通过isolcpus=内核参数实现的；现在，它被认为是不推荐的，你应该使用cpusets cgroup控制器）。现在您已经了解了它背后的理论，让我们实际编写一个用户空间C程序来查询和/或设置任何给定读数的CPU关联掩码。查询和设置线程的CPU亲和性掩码作为演示，我们提供了一个小型用户空间C程序来查询和设置用户空间进程（实际上是线程）的CPU亲和度掩码。查询cpu关联掩码是通过sched_getaffinity（）系统调用实现的，设置它是通过其对应的sched_setaffinity）系统调用完成的。</p>
<p>​    名为cpu_set_t的专用数据类型用于表示cpu亲和性位掩码（第三个参数）。它非常复杂：它的大小是根据系统上看到的CPU内核数量动态分配的。此CPU掩码（类型为CPU_set_t）必须首先初始化为零；CPU_ZERO（）宏实现了这一点（存在几个类似的辅助宏；参见CPU_SET（3）上的手册页）。前两个系统调用中的第二个参数是CPU集的大小（我们简单地使用sizeof操作员获取它）。第一个参数是要查询或设置其CPU关联掩码的进程或线程的进程ID（PID）</p>
<p>​    在此模式下，它查询自身的CPU亲和性掩码（用户pc_cpuaffinity调用过程的含义）。我们打印出位掩码的位：正如您在前面的屏幕截图（图11.1）中清楚地看到的那样，它是二进制1111 1111 1111 1111（相当于0xfff），这意味着，默认情况下，该进程有资格在系统上可用的12个CPU核中的任何一个上运行！该应用程序通过有用的popen（）库API运行thenproc实用程序，在内部检测可用的CPU内核数量。不过，请注意nproc返回的值是调用进程可用的CPU核数；它可能少于（在线和离线）CPUcores的实际数量，尽管它通常是相同的。可用内核的数量可以通过几种方式更改，正确的方式是通过cgroup cpuset资源控制器（我们将在本章稍后介绍</p>
<p><img src="./image-20240717075430416.png" alt="image-20240717075430416"></p>
<p>​    我们的disp_cpuask（）函数绘制位掩码（我们将其留给您检查）。如果向该程序传递了其他参数——进程（或线程）的PID作为第一个参数，CPU位掩码（十六进制）作为第二个参数——那么我们会尝试将该进程（或进程）的CPU关联掩码设置为传递的值。当然，更改CPU亲和位掩码需要您拥有该进程或拥有root权限（更准确地说，是拥有CAP_SYS_NICE功能）。</p>
<p>​    下面是一个快速演示：在图11.2中，nproc向我们显示了CPUcores的数量（12）；然后，我们运行应用程序查询并设置（bash）shell进程的CPU关联掩码。在具有12核的笔记本电脑上，假设亲和性maskof-bash一开始就是0xfff（二进制1111 1111 1111 1111），正如预期的那样；在这里，我们将其更改为0xdae（二进制1101 1010 1110），并再次查询以验证更改：</p>
<p><img src="./image-20240717075451700.png" alt="image-20240717075451700"></p>
<p>​    我们的演示应用程序查询并将bash的CPU关联掩码设置为0xdaeOkay，这很有趣。首先，该应用程序正确地检测到可用的CPU内核数量为12。然后，它查询bash进程的（默认）CPU亲和性掩码（当我们将其PID作为第一个参数传递时）；正如预期的那样，它显示为0xfff。然后，由于我们还传递了第二个参数——现在将位掩码设置为（0xdae）——它这样做，将bash的CPU关联掩码设置为0xdae。现在，由于我们所在的终端窗口是同一个bashprocess，再次运行nproc会显示值为8，而不是12！这是不正确的：bash进程现在只有八个CPU核可用。（这是因为我们没有将CPU关联掩码还原为其原始值onexit。）以</p>
<p>​    在前面的代码片段中，您可以看到我们首先适当地设置了cpu_set_tbitmask（通过循环每个位；如您所知，表达式（位掩码&gt;&gt;i）&amp;1测试第i位是否为1），然后使用sched_setaffinity（）系统调用在给定的pid上设置新的cpu亲和性掩码。</p>
<p>​    值得注意的是，虽然任何人都可以随时查询任何任务的CPU关联掩码，但除非您拥有该任务、拥有根访问权限或具有CAP_SYS_NICE功能，否则无法设置它。使用任务集执行CPU亲和性。正如（在前一章中）我们如何使用方便的用户空间实用程序chrt来获取（或设置）进程（或线程）的调度策略和/或优先级一样，您可以使用用户空间任务集实用程序来获取和/或设置给定进程（或进程）的CPU亲和性掩码。下面是几个快速的例子；请注意，这些示例是在具有6个CPU核的x86_64Linux VM上运行的：使用任务集查询systemd的CPU关联掩码（PID 1）：</p>
<pre class="line-numbers language-none"><code class="language-none">$ taskset-p 1
pid 1的当前关联掩码：3f<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>想想看：0x3f在二进制中是0011 1111，表示为所讨论的进程/线程（此处为systemd）启用了（所有）6个CPUcore。现在，作为一个例子，让我们在任务集的支持下运行编译器，使用它来确保GCC及其后代（汇编程序和链接进程）仅在前两个CPU核上运行；任务集的第一个参数是CPU亲和性位掩码（03是二进制0011）</p>
<p>​    请查看任务集（1）的手册页，了解完整的使用细节。（仅供参考，如前一章所述，schedtool（8）实用程序也可用于获取/设置给定线程/进程的CPU关联位掩码。）在内核线程上设置CPU关联掩码作为一个非常有趣的例子，如果我们想演示一种称为每CPU变量的同步技术（正如我们将在第13章“内核同步-第2部分”中的“每CPU-内核模块示例”一节中学习和做的那样），我们需要创建两个内核线程（kthreads），并保证它们中的每一个都在单独的CPU内核上运行。因此，我们当然必须明确地将每个内核线程的CPU亲和性掩码设置为不同且不重叠（为了简单起见，让我们将第一个k线程的亲和性掩码设为0，将第二个k线程掩码设为1，以确保它们分别仅在CPU核0和1上执行）。但有个问题。。。下一节将对此进行解释。黑客攻击非导出符号的可用性。问题是，现在从模块内设置CPU亲和力不幸不是一件干净的工作——说实话，这是一次相当大的黑客攻击；我们在这里展示，但绝对不建议用于生产目的。原因是内核中我们需要设置CPUaffinity位掩码的API存在，但没有导出。正如我们从前面关于编写模块的章节中了解到的那样，树外内核模块（如我们的）只能使用导出的函数（和数据）。我们该怎么办？</p>
<p>模块开发人员多年来使用的“常用”方法（也是我在本书第一版中使用的！）是使用方便的例程kallsyms_lookup_name（）在内核中查找任何给定的符号并获得其（内核虚拟）地址。有了这个，任何优秀的C程序员都可以将地址视为函数指针并随意调用它，从而有效地克服了只能从树外模块调用导出函数的限制！（一个巧妙的破解！不过，经验丰富的内核人员几乎肯定会对此感到愤怒。）没错，但从内核版本5.7开始，社区决定是时候停止这种（愚蠢的）滥用了，干脆不公开kallsyms_lookup_name（）（和类似的kallsym_son.each_symbol（））函数！（简式commitID是0bd476e6c671，看看。）那么，现在怎么办？好吧，我们总是可以通过/proc/kallsyms伪文件查找任何内核符号，只要我们有root访问权限（这就是安全性）。此外，在启用了内核地址空间布局随机化（KASLR）的情况下（通常在现代内核中），该值在每次启动时都会发生变化，因此无法进行硬编码（对安全性也有好处）。因此，我们编写了一个小的包装器脚本来实现这一点（它在这里：ch13/3_lockfree/percpu/run；是的，代码来自第13章，内核同步–第2部分），并将地址（通过/proc/kallsyms查找的sched_setaffinity（）例程）作为参数（ch13/3.lockfree/pecpu/percpu_var.c）传递给模块，然后将其视为函数指针，设法调用它。</p>
<h4 id="查询和设置线程的调度策略和优先级"><a href="#查询和设置线程的调度策略和优先级" class="headerlink" title="查询和设置线程的调度策略和优先级"></a>查询和设置线程的调度策略和优先级</h4><p>​    在第10章“CPU调度器-第1部分”的“线程优先级”部分，您学习了如何通过chrt实用程序查询任何给定线程的调度策略和优先级（我们还演示了一个简单的Bash脚本）。在那里，我们提到了这样一个事实，即chrt在内部调用sched_getatt（）系统调用来查询这些属性。非常类似地，设置调度策略和优先级可以通过使用chrt实用程序来执行（例如，在脚本中可以很容易地执行），也可以在（用户空间）C应用程序中通过sched_setattr（）系统调用以编程方式执行。此外，内核还公开了其他API：sched_{g,s}etscheduler（）及其pthread库包装器API pthread_{g,s}etschedparam（）（由于这些都是用户空间API，我们让您浏览它们的手册页以获取详细信息，并亲自尝试）。</p>
<h4 id="在内核中设置策略和优先级"><a href="#在内核中设置策略和优先级" class="headerlink" title="在内核中设置策略和优先级"></a>在内核中设置策略和优先级</h4><p>​    在内核线程上。如您所知，内核肯定既不是进程也不是线程。话虽如此，Linux内核肯定是多线程的，并且确实包含线程，即所谓的内核线程（或kthreads）。与用户空间中的对应线程一样，可以根据需要创建内核线程（从核心内核、设备驱动程序或内核模块中创建；内核为此公开了API）。它们是可调度实体（KSE！），当然，它们中的每一个都有atask结构和内核模式堆栈；因此，与常规线程一样，它们竞争CPU资源，并且可以根据需要以编程方式查询或设置它们的调度策略和优先级。</p>
<p>​    到目前为止：在用户空间中，查询和设置线程调度属性的现代首选系统调用分别是sched_getatt（）和sched_setattr（）。在早期，它曾经是sched_{g|s}et_scheduler（）对系统调用。现在，sched_{g|s}etattr（）系统调用会收到一个指向结构sched_attr的指针，该结构包含所有可能需要的详细信息；查看手册页(<a target="_blank" rel="noopener" href="https://man7.org/linux/man￾pages/man2/sched_setattr.2.html）。因此，按照现代的方式，人们会假设我们将使用这些系统调用的内核实现在内核中执行类似的工作。别那么快；内核社区认为，旧的（er）设计——允许用户（应用程序）和模块开发人员使用SCHED_FIFO等策略愉快地调用这些API，并使用他们认为正确的任何（实时）优先级——从根本上被打破了。为什么？因为我们很容易遇到这样的情况：两个或多个具有相同优先级的SCHED_FIFO线程，和/或使用“随机”优先级值，而没有仔细考虑它们。这些可能会导致CPU调度混乱，从而导致资源管理混乱。">https://man7.org/linux/man￾pages/man2/sched_setattr.2.html）。因此，按照现代的方式，人们会假设我们将使用这些系统调用的内核实现在内核中执行类似的工作。别那么快；内核社区认为，旧的（er）设计——允许用户（应用程序）和模块开发人员使用SCHED_FIFO等策略愉快地调用这些API，并使用他们认为正确的任何（实时）优先级——从根本上被打破了。为什么？因为我们很容易遇到这样的情况：两个或多个具有相同优先级的SCHED_FIFO线程，和/或使用“随机”优先级值，而没有仔细考虑它们。这些可能会导致CPU调度混乱，从而导致资源管理混乱。</a></p>
<p>因此，5.9内核所做的工作如下（请允许我直接引用提交的内容，因为这确实是传达消息的最佳方式）；这是承诺的一部分，<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/commit/7318d4cc14c8c8a5dde2b0b72ea50fd2545f0b7a:…">https://github.com/torvalds/linux/commit/7318d4cc14c8c8a5dde2b0b72ea50fd2545f0b7a:…</a></p>
<blockquote>
<p>因此，暴露优先级字段是没有意义的；thkernel从根本上无法设置一个合理的值，这是它没有的系统知识。从模块中删除sched_setschedule（）/sched_setatter（），并将其替换为：-scched_set_fifo（p）；创建FIFO任务（在优先级50处）-scched_set_FIFO_low（p）；创建一个高于NORMAL的任务，最终在优先级1处成为FIFO任务。-sched_set_normal（p，nice）；（重新）将任务设置为正常。这可以阻止随机选择的、不相关的、无论如何都没有真正意义的优先级的激增。系统管理员/集成商，无论谁了解实际的系统设计和需求（用户空间），都可以在需要时设置适当的优先级。。。</p>
</blockquote>
<p>​    啊；因此，现在，亲爱的模块作者们，在内核中设置（sched_）fifo任务（线程）时，我们将使用这些API——sched_set_fifo（）、sched_set_fifo_low（）和sched_set_normal（）。正如上述承诺所述，我们信任管理员和/或用户空间开发人员对用户应用程序进行编程，并根据需要为其提供正确和有意义的实时优先级值；内核（或模块）不应该知道或质疑这些决定，它只是执行这些决定（再次，这是提供机制的一个例子，而不是实际的策略设计指南）。前两个API是内核中sched_setscheduler_nocheck（）函数的包装器，将线程的调度策略设置为sched_FIFO，将线程（实时）优先级分别设置为MAX_RT_PRIO/2（即50）和1。sched_set_normal（）：是sched_setatr_nocheck（）的包装器足够的特权；不管怎样，它都会通过。（请参阅此处的评论：<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/kernel/sched/core.c\#L7742.)此外，这三个API是GNU公共许可证（GPL）导出的，这意味着它们只能由在GNUGPL下许可的模块使用。">https://elixir.bootlin.com/linux/v6.1.25/source/kernel/sched/core.c\#L7742.)此外，这三个API是GNU公共许可证（GPL）导出的，这意味着它们只能由在GNUGPL下许可的模块使用。</a></p>
<h4 id="一个真实世界的例子——线程中断处理程序"><a href="#一个真实世界的例子——线程中断处理程序" class="headerlink" title="一个真实世界的例子——线程中断处理程序"></a>一个真实世界的例子——线程中断处理程序</h4><p>​    内核使用内核线程的一个例子是当内核（非常常见）使用线程中断时（工作队列是另一个例子）示例）。在这里，内核必须使用SCHED_FIFO（软）实时调度策略和50（中间值）的实时优先级值创建一个专用的内核线程，以正确处理所谓的线程中断。让我们看看相关的代码路径，kthread_create（）宏作为线程函数）将作为其代码路径的一部分，适当地设置调度策略和优先级</p>
<h4 id="cgroups简介"><a href="#cgroups简介" class="headerlink" title="cgroups简介"></a>cgroups简介</h4><p>​    在模糊的过去，内核社区正努力解决一个更棘手的问题：尽管调度算法及其实现——早期的2.6.0 O（1）调度器和稍后的（2.6.23）完全公平调度器（CFS）——承诺了完全公平的调度，但从任何有意义的意义上讲，它都不是“完全公平”的！想一想：假设你和其他九个人一起登录到Linux服务器。在其他条件相同的情况下，处理器时间很可能（或多或少）在你们十个人之间公平分配；属于当然，你会明白，在处理器上运行并吃掉内存的并不是人，而是代表他们这样做的进程和线程。至少就目前而言，让我们假设它（大部分）是公平共享的。但是，如果你，登录的十个用户之一，编写了一个用户空间程序，在循环中不加选择地生成几个新线程，每个线程在每次循环迭代中执行大量CPU密集型工作（也许作为额外的好处，还分配了大量内存），该怎么办！？CPU带宽定位（即使通过CFS）在任何真正意义上都不再公平；您的帐户将有效地占用CPU（可能还有其他系统资源，如内存和I/O）！需要一种通用的解决方案，精确有效地管理CPU（和其他资源）带宽，在达到指定限制时限制（检查，不允许）消耗更多的资源。许多拟议的补丁被讨论并丢弃；最终，来自谷歌、IBM和其他公司的工程师不得不使用一个补丁集，将现代的控制组（cgroups）解决方案放入Linux内核（反向反转2.6.242007年10月）。最初的想法和实现是由谷歌的Paul Menage和Rohit Seth于2006年提出的。）。简而言之，cgroups是一个内核功能，它允许系统管理员（或任何拥有rootaccess的人）能够优雅地对系统上的各种资源或控制器（在cgroup词典中称为）执行带宽分配和细粒度资源管理。请注意：使用cgroups，不仅是处理器（CPU带宽），还有内存和块I/O带宽（以及更多），可以根据项目或产品的需要进行仔细的分区、分配和监控。因此，在这个例子中，我们以Linux系统上的十个用户开始本主题，如果所有进程都放在同一个cgroup和cgroups的CPU控制器被启用，那么，面对CPUContents，它真的会为每个进程带来公平的CPU份额！或者，正如他们所说，你可以做更复杂的事情：你可以把系统分成几个cgroup——一个用于构建项目（比如Yocto构建），一个用于web浏览器，一个适用于虚拟机，等等——然后根据需要对每个cgroup进行微调并分配资源（CPU、内存和I/O）！事实上，这是几乎所有现代发行版都会自动完成的，这是强大的systemd框架的功劳（更多内容如下）；这也是嵌入式Linux通常所做的，包括Android。所以，嘿，你现在感兴趣了！如何启用此cgroups功能？很简单——这是一个内核功能，你可以用通常的方式以相当精细的粒度启用（或禁用）：通过配置内核。相关菜单（通过方便的make menuconfig用户界面）是General setup | Control Group support。试试这个：grep CGROUP的内核配置文件；然后，如果需要，调整内核配置，重新构建，使用新内核重新启动，并进行测试。（我们在第2章“从源代码构建6.x Linux内核-第1部分”中详细介绍了内核配置，在第3章“从源码构建6.x Linux内核-第2部分”中介绍了内核构建和安装）。</p>
<blockquote>
<p>好消息：默认情况下，cgroups在运行systemd init框架的任何（最近）Linux系统上都是启用的。正如刚才提到的，您可以通过抓取内核配置文件来查询启用的cgroup控制器，并根据需要修改该配置；在桌面和服务器级系统上，通常不需要这样做。</p>
</blockquote>
<p>从2.6.24开始，cgroups和所有其他内核特性一样，不断发展。最近，已经达到了一个阶段，充分改进的cgroup功能与旧功能不兼容，导致新的cgroup设计和发布，一个名为cgroups v2（或简称cgroups2——Tejun Heo是维护者）；这在4.5内核系列中被声明为生产就绪（旧的内核现在被称为cgroupsv1-oras，即遗留的cgroups实现）。请注意，在撰写本文时，两者可以而且确实存在，但存在一些局限性；许多应用程序和框架仍然使用较旧的cgroups v1，并且尚未迁移到v2。然而，这种情况正在发生变化；很快，如果还没有的话，cgroups2将成为实际使用的版本，所以计划使用它。在本篇报道中，我们将几乎只关注使用现代版本cgroups v2。最好的文档是官方的内核文档，可以在这里找到（适用于内核6.1）：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/v6.1/admin￾guide/cgroup-v2.html。（仅供参考，最新内核版本的文档也始终可用，如下所示：https://docs.kernel.org/admin-guide/cgroup-v2.html.A为什么使用cgroups">https://www.kernel.org/doc/html/v6.1/admin￾guide/cgroup-v2.html。（仅供参考，最新内核版本的文档也始终可用，如下所示：https://docs.kernel.org/admin-guide/cgroup-v2.html.A为什么使用cgroups</a> v2而不是tocgroups v1的详细原理可以在内核文档中找到</p>
<h4 id="C组-控制器"><a href="#C组-控制器" class="headerlink" title="C组 控制器"></a>C组 控制器</h4><p>​    cgroup控制器是底层内核组件，负责在cgroup层次结构（cgroup及其后代）内和通过cgroup层次分布给定的资源（如CPU周期、内存和I/O带宽等）。您可以将其视为敏捷cgroup层次结构的某种“资源限制器”。cgroups（7）的手册页详细描述了接口和各种可用的（资源）控制器（或子系统，因为它们有时会被提及）。通常可用的cgroups v2控制器如下（表11.1显示了cgroups v2的内容；许多控制器的原始cgroups v1实现可以追溯到2.6.24）</p>
<p>​    我们建议感兴趣的读者参阅上述官方内核文档和手册页以获取详细信息；例如，PIDS控制器在防止分叉炸弹方面非常有用，它允许您限制可以从该cgroup或其后代分叉的进程数量。（分叉炸弹是一种愚蠢但致命的DoS攻击，其中Fork（）系统调用通常在无限循环中发出！）接下来，非常重要的是，如何使内核cgroup对用户空间可见（公开）或与用户空间交互？啊，在Linux上通常的方式是：控制组通过专门构建的合成或伪文件系统公开！它是cgroup文件系统，通常挂载在/sys/fs/cgroup。好吧，使用cgroups v2，文件系统类型现在被称为cgroup2（您可以简单地执行mount|grep-cgroup来查看此内容）。里面有很多有趣的东西可以探索；这是我们取得进步时所做的事情。。。</p>
<p>​    让我们从这个开始：我如何找到为我的系统（实际上是内核）启用了哪些控制器？很简单：</p>
<pre class="line-numbers language-none"><code class="language-none">$cat&#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cgroup.controllers 
cpuset cpu io memory hugetlb pids rdma misc很明显，<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    它显示了一个用空格分隔的可用控制器列表（我在x86_64 Fedora 38 VM上运行了这个。此外，请注意，使用/proc/cgroups查看控制器仅与cgroups v1兼容；不要依赖它来查看cgroupsv2。）。您在这里看到的确切控制器取决于内核的配置方式。在cgroups v2中，所有控制器都挂载在一个层次结构（或树）中。这与cgroups v1不同，后者可以在多个层次结构或组下挂载多个控制器。现代init框架systemd是v1和v2 cgroups的用户。事实上，是systemd在启动过程中自动挂载cgroups v2文件系统（位于/sys/fs/cgroup/）。探索cgroups v2层次结构在cgroups（v2）伪文件系统挂载点下查看——默认情况下总是/sys/fs/cgroup——会让你惊奇地盯着里面的所有伪文件（和文件夹）（继续，看看图11.3）；本节将探索它的许多更有趣、更有用的角落和缝隙！让我们首先确认cgroups v2层次结构的挂载位置：</p>
<pre class="line-numbers language-none"><code class="language-none">mount | grep cgroup2
cgroup2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    显然，正如预期的那样，在/sys/fs/cgroup。（对括号中的各种挂载选项感兴趣吗？它们记录在这里：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/v6.1/admin-guide/cgroup-v2.html\#挂载）。如果你运行的是一个较旧的发行版（比如Ubuntu18.04左右，就像我们在本书第一版中所做的那样），你可能在cgroup2中找不到任何控制器。在混合cgroups、v1和v2的情况下就是这种情况。要专门使用较新版本（正如我们所期望的），并因此使所有配置的控制器可见，你必须首先在引导时传递以下内核命令行参数来禁用cgroups">https://www.kernel.org/doc/html/v6.1/admin-guide/cgroup-v2.html\#挂载）。如果你运行的是一个较旧的发行版（比如Ubuntu18.04左右，就像我们在本书第一版中所做的那样），你可能在cgroup2中找不到任何控制器。在混合cgroups、v1和v2的情况下就是这种情况。要专门使用较新版本（正如我们所期望的），并因此使所有配置的控制器可见，你必须首先在引导时传递以下内核命令行参数来禁用cgroups</a> v1：cgroup_no_v1=all（回想一下，所有可用的内核参数都可以方便地看到）<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html.然后重新启动并重新检查。对于较新的发行版（如Ubuntu">https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html.然后重新启动并重新检查。对于较新的发行版（如Ubuntu</a> 22.04或Fedora 38），您不需要这样做。现在，让我们开始探索它！在本次会议中，我正在开发一个x86_64 Fedora 38虚拟机，在那里我构建并启动了一个自定义的6.1.25内核。让我们来看看整个场景：</p>
<p>​    图11.3：cgroups v2层次结构的根在根cgroup位置–/sys/fs/cgroup下，您可以看到几个文件和文件夹（不用说，这些都是易失性伪文件对象；它们通过sysfs安装在RAM中）。首先：看到的“常规”文件（如cgroup.controllers、cpu.pressure等）是cgroup2接口文件。这些进一步细分为核心和控制器接口；所有的group.<em>文件都是核心接口文件，cpu.</em>文件是cpu控制器的接口文件，内存.*文件用于内存控制器，等等。看到的文件夹代表——终于！——控制组或cgroups！在众多人中，你会发现并非所有人都受到约束。你可能会想知道是谁创造了它们；简短的答案（至少对于默认情况下的答案）是systemd；稍后将对此进行更多介绍。</p>
<h4 id="启用或禁用控制器"><a href="#启用或禁用控制器" class="headerlink" title="启用或禁用控制器"></a>启用或禁用控制器</h4><p>​    让我们查看一个关键的核心接口文件cgroup.controllers。上一节简要提到了这一点。其内容是c组可用控制器的列表；对于根cgroup，它是内核所具有的控制器</p>
<h4 id="systemd和cgroups"><a href="#systemd和cgroups" class="headerlink" title="systemd和cgroups"></a>systemd和cgroups</h4><p>​    cgroups的手动管理可能是一项艰巨的任务；大多数工作站发行版、企业和数据中心服务器，甚至嵌入式Linux默认运行的powerful systemd init框架都起到了拯救作用。正如我们已经开始注意到的，systemd的一个有趣的方面是，它在启动时创建和管理cgroup的角色，从而自动利用它们的功能为用户和他们的应用程序带来好处。（当然，你对它是如何做到这一点了解得越多，你就越能调整工具包以适应你的项目。）此外，要意识到有几个工具可以帮助你在系统上可视化定义的cgroups（和切片/范围）；它们包括ps，还有一些来自systemd项目本身的systemdcgls、systemctl和systemdcgtop。（我们很快也会看到我们自己的cgroups可视化脚本！）切片和范围如图11.6所示，systemd具有自动构造cgroups的智能，可以将进程逻辑地分组在一起。为此，它定义并使用工件——切片和范围。切片用于表示属于特定用户的所有进程，或者，它可以表示资源通过该单元管理的“一堆”应用程序（进程）。（在图11.6中，对于UID值为1000的用户帐户，很明显，我的sliceis名为user-1000.slice）。范围代表切片的进一步逻辑拼接或分割（相当无张力扭曲，不是吗？）；</p>
<p>​    一个很好的例子是，在终端窗口中运行的所有进程通常按systemd分组到一个会话-<number>.scope cgroup中（该术语前缀为单词“session”，因为会话表示在终端窗口内生成和管理的进程）！同样，在图11.6中，您可以清楚地看到，由名为session-9.scope的作用域表示的终端窗口是通过sshd设置的，具有Bash shell（其PID为1283555，电传打字机（tty）设备为pts/4），被表示或组织为用户切片的适用对象，并在其中处于“会话”类型作用域中。此外，systemd组织层次结构，将（启动时）范围和服务单元分配给适当的切片（内部获取其自己的cgroups）。如上所述，登录到系统的每个用户也将被视为树中通用user.slice节点下的“切片”，他们运行的应用程序当然会显示在该cgroup下（同样，您可以在图11.6中看到我的用户切片；它显示为user-1000.slice，在这个层次结构下是“范围”单元）。引用systemddocs：“（切片）名称由破折号分隔的一系列名称组成，这些名称描述了从另一个切片到切片的路径。根切片名为-.slice。示例：foo-bar.slice是一个位于info.slice内的切片，而info.slices又位于根切片-.slice中……”（您可以在图11.7中看到根切片-.slice作为第一个切片）。如果您想更改默认值，即systemd设置cgroups的方式，该怎么办？大致有三种方法：第一，手动编辑服务单位文件；其次，使用systemctl set propertysub命令执行编辑；第三，在systemd目录结构中使用所谓的插入文件。举个简单的例子：</p>
<pre class="line-numbers language-none"><code class="language-none">$ cat &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;user@.service
[ … ]
[Unit]Description&#x3D;User Manager for UID iDocumentation&#x3D;man:user@.service(5)After&#x3D;user-runtime-dir@i.service dbus.service systemd-oomd.serviRequires&#x3D;user-runtime-dir@i.serviceIgnoreOnIsolate&#x3D;yes
[Service]
User&#x3D;iPAMName&#x3D;systemd-userType&#x3D;notify-reloadExecStart&#x3D;&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;systemd --userSlice&#x3D;user-i.sliceKillMode&#x3D;mixedDelegate&#x3D;pids memory cpuTasksMax&#x3D;infinity[ … ]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可视化cgroups（以及切片和作用域）</p>
<p>​    我们已经了解了如何使用systemd cgls扫描cgroup层次结构。另一种查看它的方法（在systemd的支持下）是通过systemctlapp和systemd单元类型。systemd定义了几种单元类型：服务、挂载、交换、套接字、目标、设备、自动挂载、计时器、路径、切片和作用域。其中，只有最后两个与我们相关，所以让我们通过systemctl命令来查看它们：</p>
<p><img src="./image-20240717080431416.png" alt="image-20240717080431416"></p>
<p><img src="./image-20240717080439108.png" alt="image-20240717080439108"></p>
<h4 id="快速了解内核命名空间"><a href="#快速了解内核命名空间" class="headerlink" title="快速了解内核命名空间"></a>快速了解内核命名空间</h4><p>​    一个快速但有用的偏差：有趣的是，容器的整个过程——一种强大的、行业标准的、事实上的管理应用程序部署的方法——基本上基于Linux内核中的两项关键技术：cgroups和命名空间。你认为容器本质上是轻量级的虚拟机（在某种程度上）；目前使用的大多数容器技术（Docker、LXC、Kubernetes等）本质上是这两种内置Linux内核技术的结合：cgroups和命名空间。内核命名空间是整个容器思想实现的一个至关重要的概念和结构（内核中的结构是structnsproxy）。使用名称空间，内核可以以一种方式对其资源进行分区，即一个名称空间中的一组进程看到某些值，而另一个名称环境中的一套进程看到某些其他值。这是为什么必修的？以两个容器为例；为了实现干净的隔离，每个进程都必须看到PID为1、2的进程，以此类推。同样，每个进程可能都必须有自己的域名和主机名、自己的一组内容对该容器唯一的挂载（例如/proc）、每个进程唯一的网络接口等等。内核可以维护许多命名空间；默认情况下，它们都是可选的，因此内核始终为每个命名空间维护一个\<FOO>全局命名空间的概念（其中FOO是命名空间的名称，如mount、PID等）</p>
<p><img src="./image-20240717080541975.png" alt="image-20240717080541975"></p>
<p>表11.2：内核命名空间相关说明：如您所知，clone（）系统调用用于在Linux上创建线程（pthread_create（）调用它）。在它的许多标志中——用于通知内核如何创建自定义进程，或者换句话说，线程——有标记为CLONE_NEW*的标志（例如，CLONE_NEWPID、CLONE_NNEWNS、CLONE_NAMET等）。这些是让内核在新名称空间中创建进程的方法。其他与命名空间相关的系统调用包括setns（）、unshare（）和octl_ns（）；请查看他们的手册页了解更多信息。（同样，本章的进一步阅读部分有更多关于内核命名空间和容器技术的链接。）好的，回到我们的cgroups讨论！使用systemd cgtop另一种既可以可视化cgroups层次结构，又可以在运行时同时观察哪些cgroups及其内部的切片/服务正在使用最大份额的资源的方法是通过非常有用的systemd cgtops工具（实际上，相当于systemd cgroups古老的顶级实用程序）！默认情况下，在systemd-cgtop的输出中，cgroups按CPUload排序。</p>
<p>我们的cgroups v2 explorer脚本使用现有的cgroup可视化工具，一个问题是：我们无法立即看到cgroup是已填充还是为空；此外，即使它被填充，我们也无法立即看到它内的哪些控制器被启用（或禁用）。了解这些是理解系统上的cgroup树的关键。我们的Bash脚本试图通过显示以下内容（以及更多内容）来纠正这种情况：</p>
<ul>
<li><p>给定一个起始cgroup作为参数，它递归迭代所有嵌套的cgroup；如果没有指定，它只会从组树的根（/sys/fs/cgroup）开始，从而扫描整个树。</p>
</li>
<li><p>对于它解析的每个cgroup，它首先检查：</p>
<p>如果它没有被填充（如果它里面没有活动进程），跳到下一个cgroup，否则显示一些关于它的内容，比如：子控制器（实际上，该cgroup的cgroup.subtree_controlseudoff文件的内容！请参阅我们关于子控制器的简报…）cgroup类型（域/域线程化/线程化/…）冻结状态（0/1，否/是）属于此cgroup的进程：</p>
<p>默认情况下，它显示进程数量（括号内），然后显示PID列表；如果将-p选项传递给此脚本，它将显示其中的进程（通过ps）属于此cgroup的线程：默认情况下，它显示线程数（在括号内），然后显示PID列表；如果-t如果将选项传递给此脚本，它将显示其中的线程（viaps）与cgroup中的几个控制器相关的数据；截至目前（它仍在发展中！）：CPUMemory</p>
</li>
</ul>
<p>​    此外，我们的脚本还接受一些选项开关：-d：控制扫描树的深度-v：以详细模式显示-p/-t：显示属于每个cgroup的进程和/或线程（如前所述）cgroupv2_oxpore脚本的帮助屏幕一下子显示了所有这些：</p>
<p><img src="./image-20240717080707178.png" alt="image-20240717080707178"></p>
<p><img src="./image-20240717080714429.png" alt="image-20240717080714429"></p>
<h4 id="尝试1-1–在没有资源约束、SCHED-FIFO策略和rtprio-83Right的systemd下执行素数生成器。"><a href="#尝试1-1–在没有资源约束、SCHED-FIFO策略和rtprio-83Right的systemd下执行素数生成器。" class="headerlink" title="尝试1.1–在没有资源约束、SCHED_FIFO策略和rtprio 83Right的systemd下执行素数生成器。"></a>尝试1.1–在没有资源约束、SCHED_FIFO策略和rtprio 83Right的systemd下执行素数生成器。</h4><p>​    让我们简单地让systemd执行脚本。我们执行setup脚本，将服务单元文件作为参数传递，该脚本使systemd执行了run_pimegen程序（有关详细信息，请参阅源代码；下面的输出来自我的x86_64 Fedora 38客户机，运行我们自定义的6.1.25内核）：</p>
<p><img src="./image-20240717080753395.png" alt="image-20240717080753395"></p>
<p>​    好的！systemctl status<service.unit>命令显示其状态和生成的任何输出（图11.12；有用的是，systemd会自动将所有stdout、stderr和内核printk输出保存到日志中）。在这个特殊的运行中，它设法在3秒内生成了2到99991的素数，没有资源（CPU）限制，并以高优先级的SCHED_FIFO运行。（当然，你会意识到生成的素数数量可能因硬件系统而异。快速提示：要查看完整输出，只需运行journalctl-b。）顺便说一句，我们的脚本在运行一次后故意禁用了该服务；您可以通过在setup_service脚本中将变量KEEP_PROGRAM_ENABLED_ON_BOOT更改为值1来更改此设置。</p>
<p>我们突出显示了在服务单元文件svc1_primes_normal.service中明确指定的几个CPU设置。当然，其他设置为默认值（顺便说一句，名为LimitCPU*的设置用于指定服务单元内进程的（旧式）资源限制）。因此，请记住，这次运行——完全没有CPU限制，采用SCHED_FIFO策略，RT优先级为83（在大约3秒内）——在我的系统上产生了大约99991个素数。</p>
<h4 id="尝试1-2–在systemd下执行素数生成器，并对CPU资源、SCHED-OTHER和rtprio0进行约束。"><a href="#尝试1-2–在systemd下执行素数生成器，并对CPU资源、SCHED-OTHER和rtprio0进行约束。" class="headerlink" title="尝试1.2–在systemd下执行素数生成器，并对CPU资源、SCHED_OTHER和rtprio0进行约束。"></a>尝试1.2–在systemd下执行素数生成器，并对CPU资源、SCHED_OTHER和rtprio0进行约束。</h4><p>​    现在，我们在同一个系统上运行相同的素数生成程序，但这一次，通过systemd指定了一些明确的CPU约束。现在使用的服务单元文件是：ch11/cgroups/cpu_constraine/systemd_svcunit/svc2_primes_lowcpu.service。几乎所有内容都与第一个（我们刚刚在上一节中看到的）相同，除了以下几点：#—-应用CPU约束—-CPUQuota=10AllowedCPU=1我们还删除了CPUSchedulingPolicy=fifo和CPUschedulingPriority=83行，从而将进程保持为默认值：调度策略为SCHED_OTHER，实时优先级为0，当然，我们限制它只使用10的CPU带宽和1个内核！让我们运行它，然后检查状态：</p>
<p><img src="./image-20240717080900148.png" alt="image-20240717080900148"></p>
<p>​    Aha！这一次，该程序在仅10的CPUbandwidth（配额）的约束下，只允许在1个核心、SCHED_OTHER和rtprio0上运行，在允许运行的3秒内（内部）只产生数字31541的素数，而第一种“正常”情况下则有超过99000个素数，这表明第一种情况比第二种情况产生的素数多出近70，证明了systemd cgroups控制的有效性。所以，我们到了。为了演示如何在acgroup上设置内存限制，我们提供了另一个示例服务单元：svc3_pimes_lowram.service。其中，c组内存限制是通过MemoryHigh和MemoryMaxsystemd设置指定的（请查看systemd.resourcecontrol手册页，特别是名为内存帐户和控制的部分以获取详细信息）。我们的服务故意让压力程序分配大量内存，从而突破了指定的限制，导致内存不足</p>
<p>内存（OOM）杀手（或systemd-OOM进程，如果已配置），用于杀死cgroup任务。（我们在第9章“模块作者的内核内存分配——第2部分”的“保持活力——OOM杀手”一节中详细介绍了OOM杀手）。运行时要小心；我们强烈建议在测试VM上这样做。</p>
<h4 id="手动方式–cgroups-v2"><a href="#手动方式–cgroups-v2" class="headerlink" title="手动方式–cgroups v2"></a>手动方式–cgroups v2</h4><p>​    CPU控制器让我们尝试，不，让我们做一些有趣的事情（做或不做。没有尝试-Yoda。）。现在，我们将在系统的cgroups v2hierarchy下手动创建一个新的cgroup。然后，我们将为它设置一个CPU控制器，并为cgroup中的进程实际可以使用的CPU带宽设置一个指定的上限！然后，我们将在其中运行素数生成器程序，看看它是如何受到我们设置的约束的影响的。在这里，我们概述了您通常会采取的步骤（所有这些步骤都要求您以root权限运行）：</p>
<ol>
<li>确保你的内核支持cgroups v2；我们希望您在启用了cgroupsv2支持的4.5或更高版本的内核上运行。如何检查我是否正在运行cgroups v2？简单：运行mount | grep cgroup；输出必须包含子字符串类型cgroup2.2。</li>
<li>在层次结构中创建一个cgroup（通常在/sys/fs/cgroup/中）。这是通过简单地创建一个目录来实现的cgroup v2层次结构下所需的cgroup名称；例如，要创建一个名为testgroup的子组，请执行以下操作：mkdir/sys/fs/cgroup/testgroup</li>
<li>将cpu控制器添加到新的cgroup；这是通过这样做（以root身份）来实现的：echo“+cpu”&gt;/sys/fs/cgroup/test_group/cgroup.subtre_contr回想一下，如果没有控制器，就不会对cgroup（及其后代）施加资源约束；如果你愿意，请重新阅读启用或设备控制器部分，特别是我们在那里提到的自顶向下约束段落）。</li>
<li>有趣的是：为属于此cgroup的进程设置最大允许的CPU带宽。这是通过将两个整数写入\<cgroups-v2-mont-point>/&lt;我们的\cgroup&gt;/cpu.max（伪）文件来实现的。为清楚起见，请按照内核文档解释此文件(<a target="_blank" rel="noopener" href="https://docs.kernel.org/admin-guide/cgroup-html\#cpu接口文件），在这里再现：cpu.maxA存在于非根cgroups上的读写双值文件最大带宽限制。它的格式如下：$MAX$PERIOD，表示该组在eac中最多可以消耗$MAX">https://docs.kernel.org/admin-guide/cgroup-html\#cpu接口文件），在这里再现：cpu.maxA存在于非根cgroups上的读写双值文件最大带宽限制。它的格式如下：$MAX$PERIOD，表示该组在eac中最多可以消耗$MAX</a></li>
</ol>
<p>​    实际上，cgroup中的所有进程都可以在$period微秒的时间段内共同运行$MAX；因此，例如，在MAX=300000和PERIOD=1000000的情况下，我们有效地允许子控制组内的所有进程在1秒内运行0.3秒！换句话说，用30的CPU带宽或利用率。正如内核文档所说，默认情况下，MAX与PERIOD相同，因此默认情况下意味着100的CPU利用率。在新的cgroup中插入一个（或多个）进程；这是通过将它们的PID写入\<cgroups-v2-mont-point>/&lt;我们的\cgroup&gt;/cgroup.procs伪文件来实现的。就是这样；新cgroup下的进程现在将在施加的CPU带宽约束下执行其工作（如果有的话）；完成后，他们将像往常一样死去。。。您可以使用简单的rmdir\<cgroups-v2-mount-point>/<our cgroup>删除（或删除）cgroup。</p>
<h4 id="将Linux作为RTOS运行"><a href="#将Linux作为RTOS运行" class="headerlink" title="将Linux作为RTOS运行"></a>将Linux作为RTOS运行</h4><p>​    介绍Mainline或vanilla Linux（您下载的内核from<a target="_blank" rel="noopener" href="https://kernel.org，甚至是典型的Linux">https://kernel.org，甚至是典型的Linux</a> Git内核树）确定不是RTOS；它是一个通用操作系统（GPOS；以及Windows、macOS和Unix）。在实时操作系统中，当硬实时（RT）特性发挥作用时，软件不仅必须获得正确的结果，而且还有与此相关的截止日期；它必须保证每次都能在截止日期前完成。人们可以通过这种方式根据操作系统的RT特性对其进行非常广泛的分类（见图11.16）；最左端是非RT操作系统，最右端是RTOS：图11.16：在RT规模上对操作系统进行分类主流或“香草”Linux操作系统虽然不是RTOS，但在工作性能方面做得非常出色，甚至不费吹灰之力。很容易符合软实时操作系统的条件：在“尽最大努力”的基础上，大多数时间都能在截止日期前完成（有时人们说它符合“五个9”的限定条件，因为它在99.999的时间里都能在最后期限前完成！）。然而，真正的硬实时领域（例如，许多类型的军事行动、运输、机器人、电信、工厂车间自动化、证券交易所、医疗电子等）需要硬实时保证，因此需要RTOS。因此，对于这些领域来说，普通的Linux（GPOS）根本无法解决问题。在这种情况下，一个关键点是确定性：关于实时性的一个经常被忽视的点是，软件对（外部）事件的响应时间并不总是很快（比如说，在几微秒内响应）。它可能要慢得多（比如，在几十毫秒的范围内）；就其本身而言，这在RTOS中并不是真正重要的。重要的是，该系统是可靠和可预测的，以一致的方式工作，并始终保证在截止日期前完成；这种系统被认为具有确定性响应，这是实时系统的一个关键特征。例如，响应日程安排请求所需的时间应该是一致的、可预测的，而不是到处都是。与所需时间（或基线）的偏差通常被称为抖动；RTOS的工作原理是保持抖动很小，甚至可以忽略不计。在GPOS中，这通常是不可能的，甚至不是一开始的设计目标！因此，在这种非RT系统中，抖动可能会有很大的变化，在一点上很低，在下一点上非常高。总体而言，即使在极端的工作负载压力下，也能以最小的抖动保持稳定、均匀、可预测的响应，这被称为确定性，是RTOS的标志。提供这样一个确定性响应，其算法必须尽可能设计为与O（1）（大Oh 1）算法时间复杂度相对应。RT系统的另一个目标是减少延迟和延迟。实际上，这一说法并不十分准确：目标是将最大或最坏情况下的延迟降低到可接受的水平；（具有讽刺意味的）现实是，最小和平均延迟可能——而且通常——比非RT系统更差。Thomas Gleixner与社区支持一起，长期致力于将常规（或普通）非RT Linux内核转换为ahard RTOS的目标。他和他的合作者在很久以前就取得了成功：自从2.6.18内核（2006年9月发布）以来，已经出现了将Linux内核转换为RTOS的树外补丁！这些补丁可以在这里找到，适用于许多版本的内核：<a target="_blank" rel="noopener" href="https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/.这个项目的旧名称是“抢占式实时”，或者简称为PREEMPT_RT。后来（从2015年10月开始，内核版本4.1及以后），Linux基金会（LF）接管了这个项目的管理——这是一个非常积极的步骤并将其更名为实时Linux（RTL）协作项目(https://wiki.linuxfoundation.org/realtime/rtl/start)或者简单地说，RTL（不要将此项目与Xenomai或RTAI等协同内核方法混淆，也不要将旧的、现已失效的RTLinux尝试混淆）。当然，一个常见问题是“为什么这些补丁不能在主线本身将Linux转换为实时操作系统？”事实证明：">https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/.这个项目的旧名称是“抢占式实时”，或者简称为PREEMPT_RT。后来（从2015年10月开始，内核版本4.1及以后），Linux基金会（LF）接管了这个项目的管理——这是一个非常积极的步骤并将其更名为实时Linux（RTL）协作项目(https://wiki.linuxfoundation.org/realtime/rtl/start)或者简单地说，RTL（不要将此项目与Xenomai或RTAI等协同内核方法混淆，也不要将旧的、现已失效的RTLinux尝试混淆）。当然，一个常见问题是“为什么这些补丁不能在主线本身将Linux转换为实时操作系统？”事实证明：</a></p>
<p>​    RTL的大部分工作确实已经合并到主线内核中；这包括调度子系统、互斥和自旋锁、lockdep、线程中断、PI（优先级继承）、跟踪等重要领域。事实上，RTL的一个持续的主要目标是将自己合并到主线中；在撰写本文时，它（非常）接近！传统上，Linus Torvalds认为Linux主要是作为GPOS设计和架构的，不应该具有只有RTOS真正需要的高度侵入性功能；因此，尽管补丁确实会被合并，但这是一个缓慢的深思熟虑的过程。我们在本章的进一步阅读部分包括了几篇有趣的文章和对RTL（以及一般的硬实时）的参考；你看。接下来你要做的事情确实很有趣：我们简要介绍了如何用（目前仍然）树外RTL补丁修补主线6.1 LTS内核，配置它，构建它，并引导它；因此，您将最终运行RTOS——实时Linux或RTL！我们将在x86_64Linux VM（或本机系统）上执行此操作。</p>
<h2 id="内核并发"><a href="#内核并发" class="headerlink" title="内核并发"></a>内核并发</h2><h4 id="临界区、独占执行和原子性"><a href="#临界区、独占执行和原子性" class="headerlink" title="临界区、独占执行和原子性"></a>临界区、独占执行和原子性</h4><p>​    想象一下，你正在为多核系统编写软件（好吧，现在，你通常会在多核系统上工作，即使是在大多数嵌入式项目上）。正如我们在引言中提到的，并行运行多个代码路径不仅是安全的，而且是可取的（为什么要花这些钱呢，对吧？）。另一方面，在以任何方式访问共享可写数据（也称为sharedstate）的并发（并行和同时）代码路径中，您需要保证在任何给定时间点，一次只能有一个线程处理该数据！这是关键。为什么？想想看：如果你允许多个并发代码路径在共享的可写数据上并行工作，你就是在自找麻烦：数据损坏（“数据竞争”）可能会因此发生。在介绍了一些关键点之后，下一节将通过几个伪代码示例清楚地说明数据竞赛概念（如果你愿意，也可以看看图12.6）。什么是关键部分？以下几点非常重要；请仔细阅读。关键部分是必须满足以下两个条件的代码路径：</p>
<p>条件一：代码路径可能是并发的，也就是说，它有可能并行运行。</p>
<p>条件二：它处理（读取和/或写入）共享可写数据（也称为共享状态）。</p>
<p>​    因此，根据定义，关键部分需要防止并行性。换句话说，关键部分是一段必须以独占方式运行的代码，有时甚至是原子性的。通过排他性，我们暗示在任何给定的时间点，只有一个线程正在运行关键部分的代码；也就是说，它可以单独运行（序列化，而不是并行化）。这是数据安全原因所必需的。原子一词意味着不可分割的东西；在这种情况下，它意味着能够不间断地运行到完成。如果两个或多个线程可以同时执行一个关键部分的代码，这是一个bug或缺陷；这通常被称为竞争条件或数据竞争。识别和保护关键部分免受同时执行（数据竞争）的影响是正确软件的隐含要求，你——设计师/架构师/开发人员——必须确保这一点。学习如何保护关键部分（相对）容易；正确识别每个关键部分是你必须掌握的技能。</p>
<p>​    现在让我们重新审视原子性的关键概念：原子操作是不可分割的。在任何现代处理器上，两个操作通常被认为总是原子性的；也就是说，它们将不间断地运行到完成：执行单个机器语言指令。读取或写入处理器字长（通常为32或64位）内的对齐原始数据类型；因此，在64位系统上读取或写入32位或64位整数保证是原子性的。读取该变量的线程永远不会看到介于两者之间、撕裂或肮脏的结果；他们要么会看到旧的价值，要么会看到新的价值。另一方面，在64位项目上运行的32位处理器不能保证是原子性的，可能会导致读取（或写入）被撕裂或弄脏。</p>
<p>​    给智者一句话：在这里小心翼翼是值得的！研究表明，在现代硬件处理器上使用现代高度优化的编译器，即使是这个“真理”——在处理器的字长内加载/存储（意味着读取/写入）对齐的原始数据类型——也可能不成立！编译器现在可以采用加载/存储撕裂技术等；在这篇优秀的文章中阅读更多：谁害怕一个糟糕的大型优化编译器？LWN，2019年7月：<a target="_blank" rel="noopener" href="https://lwn.net/Articles/793253/（更多信息请参阅本章的进一步阅读部分）。因此，如果你有一些处理共享（全局或静态）可写数据的代码行，在没有显式同步机制的情况下，它们不能保证以独占方式运行。">https://lwn.net/Articles/793253/（更多信息请参阅本章的进一步阅读部分）。因此，如果你有一些处理共享（全局或静态）可写数据的代码行，在没有显式同步机制的情况下，它们不能保证以独占方式运行。</a></p>
<p>​    请注意，有时需要以原子方式和独占方式运行关键部分的代码，但并非总是如此；让我们进一步深入探讨这方面。<strong>当关键部分的代码在安全睡眠状态下运行时，可能会阻塞进程上下文（例如通过用户应用程序对驱动程序进行的典型文件操作（打开、读取、写入、ioctl、mmap等），或者内核线程或工作队列的执行病理），关键部分不是真正原子的可能是可以接受的，但它确实需要是独占的。然而，当它的代码在非阻塞原子上下文中运行时（例如在ahardware中断中：hardirq、tasklet或softirq）</strong>，它必须以原子方式和独占方式运行（我们将在Mutex或spinlock？when部分更详细地介绍这些点）。一个概念性的例子将有助于澄清事情。假设三个线程（来自用户空间应用程序）发出open（）和read（）系统调用，从而在多核系统上或多或少同时处理您的驱动程序（作为内核模块或在内核中实现）。（回想一下，Linux是一个单片内核；当处理器线程发出系统调用时，它会切换到内核模式，并在进程上下文中运行适当的内核/驱动程序代码路径。）在没有任何干预的情况下，它们很可能最终会并行运行关键部分的代码，从而并行处理共享的可写数据（数据竞争！），并且很可能会导致错误洗吧！现在，让我们来看一个概念图，看看关键部分代码路径中的非独占执行是如何错误的（我们甚至不会在这里讨论原子性）：</p>
<p><img src="./image-20240718074451337.png" alt="image-20240718074451337"></p>
<p>​    图12.1：一个概念图，显示了关键部分代码路径是如何被同时在其内运行多个线程所违反的</p>
<p>​    如上图所示，在您的设备驱动程序中，在其（比如）读取方法中，您让它运行一些代码来执行其工作（从硬件读取一些数据）。让我们更深入地看看这个图表，看看在不同时间点进行的数据访问：</p>
<p>从时间t0到t1：没有或只有局部变量数据被访问。这是并发安全的，不需要保护，可以并行运行（因为每个线程都有自己的私有堆栈）。</p>
<p>从时间t1到t2：访问全局/静态共享可写数据。这不是自动并发安全的；这是一个关键部分（如图12.1所示，它肯定满足了这两个条件）。因此，必须保护它免受并发访问。它必须独占运行（单独运行，一次只能运行一个线程，并且是序列化的），也许是原子性的。</p>
<p>从时间t2到t3：不访问或仅访问局部变量数据。这是并发安全的，不需要保护，可以并行运行（因为每个线程都有自己的私有堆栈）</p>
<p>​    。在本书中，根据到目前为止所涵盖的材料和您自己的知识，我们假设您现在已经意识到同步关键部分的必要性，该书详细介绍了这些要点（特别是第15章，使用Pthreads的多线程第二部分——同步）。因此，知道这一点后，我们现在可以重申关键部分的概念，同时也提到情况何时出现。关键部分是必须按如下方式运行的代码：（始终）独占：单独（序列化）（在原子上下文中时）原子：不可分割地完成，不中断在下一节中，我们将介绍一个经典场景——全局整数的增量。</p>
<h4 id="一个经典的例子——全局i"><a href="#一个经典的例子——全局i" class="headerlink" title="一个经典的例子——全局i++"></a>一个经典的例子——全局i++</h4><p>​    想想这个经典的例子：一个全局整数i在并发代码路径中递增，其中多个执行线程可以同时执行。对计算机硬件和软件的天真理解会让你相信这种操作显然是原子性的。然而，现实是，现代硬件和软件（编译器和操作系统）比你想象的要复杂得多，因此导致了各种（对应用程序开发人员来说）不可见的性能驱动优化。我们不会在这里深入探讨太多细节，但现实是现代处理器非常复杂：在它们为提高性能而采用的许多技术中，有一些是超标量和超流水线执行，以便并行执行多个独立指令和各种指令的几个部分（分别），执行即时指令和/或内存重新排序，在复杂的CPU上分层缓存中缓存内存，加载/存储撕裂等！我们将在第13章“内核同步-第2部分”的“了解CPU缓存基础知识、缓存效应和错误共享”和“介绍内存屏障”部分深入探讨其中的一些细节。在“进一步阅读”部分可以找到几篇值得深入研究这些引人入胜的主题的论文（和书籍）。所有这些使得情况比乍一看要复杂得多。</p>
<pre class="line-numbers language-none"><code class="language-none">static int i &#x3D; 5;
[...]
foo()
&#123;
	[...]
	i++;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    那么，这个增量安全吗？简短的回答是不，你必须保护它。为什么？这是一个关键部分——我们正在一个可能并发的代码路径中访问（读/写）共享的可写数据！更长的答案是，它真的取决于：a.函数foo（）的代码是否保证独占运行。b.这里的增量操作是否真的是原子性的（不可分割的）；如果是，那么在并行性存在的情况下，i++不会构成危险；如果不是，它会！因此，假设围绕i++的代码路径的执行是非独占的——也就是说，其他线程可以并行执行此代码路径foo（）——为了使其正常工作，我们要求i++操作是真原子的。作为一个简单的高级语言操作，乍一看它可能“看起来”是原子性的，但真的吗？我们怎么知道是不是这样？有两件事决定了这一点：处理器的指令集架构（ISA），它决定了（在与处理器低级相关的几件事中）此操作运行时在运行时执行的机器指令编译器，它当然会将高级语言源转换为汇编（然后汇编生成最终在处理器上执行的机器代码）如果ISA具有使用单个机器指令执行整数增量的能力，并且编译器有智能和机会使用它，那么它就是真正的原子性的——它是安全的，不需要显式保护，通常是锁定。否则，它不安全，需要上锁！那么，在您的计算机上，使用当前的编译器，如何知道？</p>
<p>​    试试这个：将浏览器导航到这个很棒的编译器资源管理器网站：<a target="_blank" rel="noopener" href="https://godbolt.org/.SelectC作为编程语言，然后在左侧窗格中声明全局i整数并在函数内递增它。在右侧窗格中使用适当的编译器和编译器选项进行编译。您将看到为C高级i++生成的实际机器代码；声明。如果它确实是一条单机器指令，那么它将是安全和原子的；如果没有，则需要锁定。通常，在基于CISC的机器上，如x86[_64]，2级及以上的编译器优化级别确实会使代码原子化，但RISC机器（如基于ARM的机器）的情况并不总是如此。总的来说，你会发现你无法真正分辨；实际上，你不能想当然地认为i++操作是不安全的，也就是说，默认情况下是非原子的，并对其进行保护！这可以在下面的屏幕截图中看到：">https://godbolt.org/.SelectC作为编程语言，然后在左侧窗格中声明全局i整数并在函数内递增它。在右侧窗格中使用适当的编译器和编译器选项进行编译。您将看到为C高级i++生成的实际机器代码；声明。如果它确实是一条单机器指令，那么它将是安全和原子的；如果没有，则需要锁定。通常，在基于CISC的机器上，如x86[_64]，2级及以上的编译器优化级别确实会使代码原子化，但RISC机器（如基于ARM的机器）的情况并不总是如此。总的来说，你会发现你无法真正分辨；实际上，你不能想当然地认为i++操作是不安全的，也就是说，默认情况下是非原子的，并对其进行保护！这可以在下面的屏幕截图中看到：</a></p>
<p><img src="./image-20240718074730165.png" alt="image-20240718074730165"></p>
<p>图12.2：即使使用最新的稳定gcc版本但没有优化，x86_64 gcc也会为i++生成多个机器指令。前面的屏幕截图清楚地显示了这一点：左侧和右侧窗格中的浅黄色背景区域是我们著名的i++的C源代码；语句和编译器分别生成的相应程序集（基于x86_64 ISA和特定编译器的优化级别）。（仅供参考，在图12.2中，我通过从右侧窗格的设置齿轮中取消选择Intel asm语法，将汇编语法从Intel更改为更通用的AT&amp;T）。通常，如果不进行优化，i++会变成三条机器指令。这正是我们所期望的：它对应于i（内存到寄存器）、内存和存储（寄存器到内存）的获取或加载！现在（至少在这种情况下，没有优化）这不是原子性的；因此，在一条机器指令执行后，控制单元完全有可能干扰并将指令流切换到不同的点。这甚至可能导致另一个进程或线程被上下文切换（除非您对其使用了锁定）！好消息是，在编译器选项中使用快速-O2。。。窗口，i++变成了一个机器指令&amp;真正的原子！（但并不总是如此。）然而，我们无法提前预测这些事情；有一天，你的代码可能会在相当低端的ARM（RISC）系统上执行，这增加了i++需要多机指令的可能性。你现在可能想知道——要解决这个问题，对i++使用amutex（甚至是自旋锁）锁似乎不是最佳选择；你说得对。我们将在第13章“内核同步——第2部分”的“使用atomic_t和refcount_t接口”一节中介绍一种专门用于整数运算的优化锁定技术。</p>
<p>​    现代语言提供原生原子运算符；对于C/C++来说，它是相当新的（从2011年开始）；ISO C++11和ISO C11标准提供现成的和内置的原子变量。只需在谷歌上搜索一下，它们就会很快显示给你。现代glibc也利用了它们。例如，如果您在用户空间中处理过信号，您将知道使用volatile sigatomict数据类型，用于在信号处理程序中安全地原子访问和/或更新整数。在内核中呢？在下一章中，您将了解Linux内核对此关键问题的解决方案。请尽早意识到：Linux内核当然是一个并发环境；多个执行线程在多个CPU核上并行运行。不仅如此，即使在单处理器（UP/单CPU）系统上，硬件中断、陷阱、故障、异常和软件信号的存在也会导致数据完整性问题（数据竞争）。不用说，在代码路径中的关键部分防止并发性说起来容易做起来难；使用锁定等技术以及其他同步原语和技术来识别和保护关键部分是绝对必要的，这就是为什么这是本章和下一章的核心主题。</p>
<h4 id="概念——锁"><a href="#概念——锁" class="headerlink" title="概念——锁"></a>概念——锁</h4><p>​    我们需要同步，因为在没有任何干预的情况下，线程可以并发执行正在处理共享可写数据（共享状态）的关键部分。为了克服这些关键部分的并发性，我们需要摆脱并行性；我们需要对关键部分的代码流进行序列化。为了强制代码路径序列化，一种常见的技术是使用锁。本质上，锁的工作原理是保证在任何给定的时间点，只有一个执行线程可以“获取”或拥有锁；一旦接受，只有这条线才能向前发展——我们称之为“赢家”。这些概念很快就会扩展。因此，使用锁来保护代码中的关键部分将为您提供我们想要的东西——以独占方式运行关键部分的代码（也可能以原子方式运行；更多内容将在后面介绍）。请查看此图（图12.3）：</p>
<p><img src="./image-20240718074832959.png" alt="image-20240718074832959"></p>
<p>图12.3：一个概念图，显示了在给定独占性的情况下，如何通过使用锁来尊重关键部分代码路径图12.3显示了一种解决上述情况的方法（图12.1）：使用锁来保护关键部分！从概念上讲，锁（和解锁）是如何工作的？锁的基本前提是，每当有争用时——也就是说，当多个竞争线程（比如n个线程）试图获取锁（通过概念性的lock操作）时——只有一个线程会成功。此线程被视为锁的“赢家”、“所有者”。它将锁API视为一个非阻塞调用，因此继续愉快地运行——而且是独占的！——在执行关键部分的代码时（关键部分实际上是锁定和解锁操作之间的代码！）。n-1个“失败者”线程会发生什么？他们（也许）将锁定API看作一个阻塞调用；实际上，他们在等待。等什么？当然，解锁操作（必须）由车主执行当关键部分的工作完成时，锁定（“获胜者”线程）！一旦解锁，剩余的n-1线程现在竞争下一个“获胜者”插槽；当然，他们中只有一个人会赢并继续前进。在此期间，n-2失败者现在将等待（新的）获胜者解锁。重复此过程，直到所有n个线程（最终和顺序）都获得锁。现在，锁定当然有效，但是——这应该是相当直观的——它会导致（相当陡峭的！）开销，因为它会破坏并行性并序列化执行流！为了帮助你想象这种情况，想象一个漏斗，窄杆是关键部分，一次只能安装一根螺纹。所有其他线程都被阻塞，等待解锁；锁定会造成瓶颈。下图旨在显示这种类比：</p>
<p><img src="./image-20240718074859124.png" alt="image-20240718074859124"></p>
<p>图12.4：锁会产生瓶颈，类似于物理漏斗。</p>
<p>​    另一个经常提到的锁定物理类比是一条高速公路，它有几条车道合并成一条非常繁忙且交通堵塞的车道，也许是一个设计不佳的收费站。同样，并行性——汽车（线程）与不同车道（CPU）上的其他汽车并行行驶——已经丧失，需要串行化行为；汽车被迫一辆接一辆排队。因此，作为软件架构师，我们必须尝试用最小的锁定来设计我们的产品/项目。虽然在大多数实际项目中完全消除全局变量实际上是不可能的，但需要优化和最小化它们的使用。稍后，我们将对此进行更多介绍，包括一些非常有趣的无锁编程技术。另一个真正关键的点是：新手程序员可能会天真地认为，对共享的可写数据对象执行读取是完全安全的，因此不需要明确的保护；（处理器总线大小范围内的对齐原始数据类型除外）这是不正确的。这种情况可能会导致所谓的脏读或撕裂读，即即使在另一个写入线程同时写入时，也可能正在读取过时和/或不一致的数据。寓意很明确：你需要保护对共享可写数据的所有访问，即读写，实际上，在所有关键部分，可能是并发代码路径。正如我们刚刚学到的，由于我们正在讨论原子性的话题，在典型的现代微处理器上，唯一能保证原子性的是一条机器语言指令，或者（正如我们学到的，可能）在处理器总线宽度内对分析原始数据类型的读/写。那么，我们如何标记几行C代码，使其真正具有原子性呢？在用户空间中，这甚至是不可能的（我们可以接近，但不能保证原子性）。你如何在用户空间应用程序中“接近”原子性？您始终可以构造一个用户线程来使用SCHED_FIFO任务调度策略和99的实时（RT）优先级。这样，当它想要运行时，除了硬件中断/异常之外，几乎没有什么可以抢占它。（旧的音频子系统实现严重依赖于这种语义。）在内核空间中，我们可以编写真正原子的代码。如何，确切地说？简短的回答是，我们使用自旋锁来做到这一点！我们稍后将更详细地了解自旋锁。</p>
<h4 id="关键部分——关键点总结"><a href="#关键部分——关键点总结" class="headerlink" title="关键部分——关键点总结"></a>关键部分——关键点总结</h4><p>​    让我们总结一些关于关键部分的关键点。仔细阅读这些内容非常重要，把它们放在手边，并确保在实践中使用它们：关键部分是一个可能并发的代码路径，一个可以并行执行的路径，它处理（读取和/或写入）共享的可写数据（也称为共享状态）。因为它适用于共享的可写数据，所以关键部分：需要防止并行性和并发性（也就是说，它必须单独运行/序列化/以互斥的方式运行）。当在原子非阻塞上下文（包括任何类型的中断上下文）中运行时，您必须保证它以原子方式运行：不可分割地完成，不中断。一旦受到保护，您就可以安全地访问共享状态，直到您“解锁”。代码库中的每个关键部分都必须被识别和保护：识别关键部分至关重要！仔细检查你的代码，确保你不会错过它们。（任何全局或静态变量都是一个典型的危险信号；但不仅如此，可能并发代码路径中的任何类型的共享状态——硬件寄存器、邮箱等——都可能是一个关键部分。）保护它们可以通过各种技术来实现；一种非常常见的技术是锁定（我们稍后将详细介绍）。还有原子运算符s和无锁编程技术，我们将在下一章中介绍。</p>
<p>一个常见的错误是只保护写入共享可写数据的关键部分；您还必须保护读取共享可写数据的关键部分。否则，你可能会面临被撕毁或弄脏的风险！为了明确这一关键点，请将一个无符号的64位数据项在32位系统上读写可视化；在这种情况下，操作不能是原子操作（每次读/写都需要两个加载/存储操作）。因此，如果一个线程在读取数据项的值时，另一个线程同时对其进行写入，该怎么办！？写入线程会对访问采取某种“锁”，但因为你认为读取是安全的，所以读线程不会采取这种锁；由于意外的时间巧合，您最终可能会执行部分/撕裂/脏读。在接下来的部分和下一章中，我们将学习如何通过使用各种锁定技术来克服这些问题。</p>
<p>另一个致命的错误是没有使用相同的（正确的）锁来保护给定的数据项。例如，如果你使用锁A来保护全局数据结构X，那么无论何时访问锁A，你都必须始终使用它；使用锁B没有帮助。这可能比一开始看起来更困难，因为大型项目（如Linux内核）可能有数以万计的锁！未能保护关键部分会导致数据竞争，在这种情况下，结果——读取/写入共享数据的实际价值——是“不稳定的”，这意味着它会根据运行时的情况和时间而变化。这是一个缺陷，一个bug（一个一旦进入“现场”就很难看到、重现、确定其根本原因并修复的bug。我们将在下一章内核中的锁定调试部分介绍</p>
<p>一些非常强大的东西来帮助你解决这个问题；一定要阅读它！）。例外情况：在以下情况下，您是安全的（隐式的，没有显式的保护）：当您处理局部变量时。它们被分配在线程的私有堆栈上（或者，在中断上下文中，在本地IRQ堆栈上），因此根据定义是安全的。当您在无法在其他上下文中运行的代码中处理共享可写数据时；也就是说，它天生就是序列化的。在我们的上下文中，内核模块的init和cleanup方法是合格的（它们仅在insmod（或modprobe）和rmmod上串行运行一次）。当你处理真正恒定且只读的共享数据时（不过，不要让C的const关键字欺骗你！）。锁定本身就很复杂；您必须仔细思考、设计和实现锁定模式，同时避免死锁。我们将在锁定-常见错误和指南部分更详细地介绍这一点。</p>
<h4 id="数据竞争——一个更正式的定义"><a href="#数据竞争——一个更正式的定义" class="headerlink" title="数据竞争——一个更正式的定义"></a>数据竞争——一个更正式的定义</h4><p>​    内存（一致性）模型提供了一种在存在多个并发加载/存储操作的情况下对内存一致性重要概念的更正式的方法；它对系统内存行为进行“建模”，预测通过加载可能产生的值（从m读取当代码在该系统上执行时，执行内存操作。Linux内核就是这样一个模型；它被称为Linux内核内存模型（LKMM）。这里并不需要深入研究它的细节，但确实可以阅读一些有趣的内容；在此处查看官方内核文档中的explanation.txt文档：<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v6.1.25/source/tools/memory-model/Documentation/explanation.txt。">https://elixir.bootlin.com/linux/v6.1.25/source/tools/memory-model/Documentation/explanation.txt。</a></p>
<p><img src="./image-20240718075100752.png" alt="image-20240718075100752"></p>
<p>图12.5：“什么是数据竞赛？”幻灯片。来源：Marco Elver</p>
<p>​    如您所见，图12.5右侧是两个线程并发运行（在不同的CPUcore上）的示例，它们在同一个内存对象（同一位置，共享可写数据）上工作。左侧的红十字表示数据竞争，绿色的勾号表示数据竞争正常（中间的第3行和第5行是“可能”；当被解释为“严格”时，它们会竞争）。这可能会让你想：“为什么不总是使用标记访问，从不进行数据竞争？”请不要这样做。标记的访问意味着由内核代码在内部使用和/或当你知道存在潜在的数据竞争但不太关心它时使用（一个典型的例子是网络驱动程序统计代码，它在没有显式锁定原语的情况下递增计数器；这里的数据竞争被认为不太重要）。不过，这里的关键点，尤其是对于模块/驱动程序作者来说，是这样的：使用标记的访问实际上可以防止像KCSAN这样的工具捕获数据竞争。在大多数情况下继续使用纯C访问非常重要。此外，请注意——尽管标记的访问保证了原子加载和存储，但它们并不能保证内存排序；这必须通过记忆屏障来实现（下一章将对此进行一些说明）。现在，我们将转向另一个关键领域——在使用Linux操作系统时识别并发性和关键部分。Linux内核中的并发问题识别内核代码中的关键部分至关重要；如果你甚至看不见它，你怎么能保护它呢？以下是一些指导方针，可以帮助您作为一名初露头角的内核/驱动程序开发人员认识到可能出现的并发问题，从而认识到关键部分：对称多处理器（SMP）系统（CONFIG_SMP=y）的存在可抢占内核（CONFIG_PREEMPTION=y）阻止I/O硬件中断（在SMP和/或UP系统上）这些都是需要理解的关键点，我们将在本节中逐一讨论。多核SMP系统和数据道第一点非常明显；请看图12.6所示的伪代码：</p>
<p><img src="./image-20240718075125736.png" alt="image-20240718075125736"></p>
<p>图12.6：伪代码——（虚构的）驾驶员阅读方法中的关键部分（时间t2到t3）；由于没有锁定，它可能存在漏洞。这与我们在图12.1和图12.3中显示的情况类似。如图所示，从时间t2到时间t3，函数可以并行运行，并且它正在处理一些全局共享的可写数据，因此这是一个关键部分。现在，想象一个有四个CPU核的系统（SMP/多核系统）；两个用户空间进程P1（在CPU 0上运行）和P2（在CPU 2上运行）可以同时打开设备文件并同时发出read（）系统调用。现在，这两个进程将同时执行驱动程序的读取“方法”，从而同时处理共享的可写数据！众所周知，t2和t3之间的代码是关键部分，由于我们违反了基本的排他性规则——关键部分在任何时候都只能由一个线程执行——我们很可能最终会损坏数据、应用程序，甚至更糟。换句话说，这种方法可能会导致数据竞赛；根据微妙的时间巧合，我们可能会也可能不会产生错误（bug）。正是这种不确定性——微妙的时间巧合——使得发现和修复这样的错误变得极其困难（它可以逃避你的测试工作）。不幸的是，这句格言太正确了：测试可以检测到错误的存在，而不是它们的缺失。此外，如果你的测试未能捕捉到数据竞争（和错误），让它们在现场自由发挥，你的处境会更糟。您可能会说，由于您的产品是在一个CPU核（UP）上运行的小型嵌入式系统，因此关于控制并发性（通常是通过锁定）的讨论不适用于您。我们不同意：几乎所有的现代产品，如果还没有的话，都将转向多核（也许在下一代阶段）。更重要的是，正如我们即将探讨的那样，即使是UP系统也存在并发问题。</p>
<h4 id="可抢占内核、阻塞I-O和数据通道"><a href="#可抢占内核、阻塞I-O和数据通道" class="headerlink" title="可抢占内核、阻塞I/O和数据通道"></a>可抢占内核、阻塞I/O和数据通道</h4><p>​    想象一下，你正在一个配置为可抢占的Linux内核上运行内核模块或驱动程序（即CONFIG_PREEMPT已打开；我们在第10章“CPU调度器-第1部分”中介绍了这个主题）。再次参考图12.6，考虑一个进程P1正在进程上下文中运行驱动程序的读取全局数组。现在，当它处于关键部分（在时间t2和t3之间）时，如果内核抢占进程P1并将上下文切换到另一个进程P2，该进程正在等待执行此代码路径，该怎么办？很危险；这可能会导致数据竞争。这甚至可能发生在单CPU（UP）系统上！（请注意，尽管我们在这里使用了“进程”一词，但它可以与“线程”互换。）另一种情况有些相似（也可能发生在单核（UP）或多核系统上）：进程P1正在运行驱动程序方法的关键部分（在时间t2和t3之间；再次见图12.6）。这一次，如果在关键区域内，它遇到阻塞呼叫怎么办？阻塞调用是一种函数，它使调用进程上下文进入睡眠状态，等待事件发生；当该事件发生时，内核（或底层驱动程序）将“唤醒”任务，并从中断的位置继续执行。这也称为I/O阻塞，非常常见；许多API（包括几个用户空间库和系统调用，以及几个内核API）本质上都是阻塞的）。在这种情况下，进程P1有效地关闭了CPU并进入睡眠状态，这意味着schedule（）的代码运行并将其排队到等待队列中。在此期间，在P1切换回之前，如果另一个进程P2被安排运行怎么办？如果该进程也在运行此特定的代码路径怎么办？想想看——首先，P2现在处理的数据可能处于中间状态，没有完全更新。此外，当P1回来时，共享数据可能已经“在它下面”发生了变化，导致各种错误；再一次，一场数据竞赛，一个bug！</p>
<h4 id="硬件中断和数据跟踪"><a href="#硬件中断和数据跟踪" class="headerlink" title="硬件中断和数据跟踪"></a>硬件中断和数据跟踪</h4><p>​    最后，设想一下这种情况：进程P1正在无意中运行驱动程序的读取方法代码；因此，它进入临界区（在时间t2和t3之间；再次见图12.6）。它取得了一些进展，但不幸的是，在同一个CPU核上触发了一个中断！（您可以在Linux内核编程–第2部分配套卷中详细了解硬件中断及其处理）。在Linux操作系统上，硬件中断具有最高优先级；默认情况下，它们抢占所有代码（包括内核代码）。因此，进程（或线程）P1将击败暂时搁置最少的进程，失去处理器，因为中断处理代码路径肯定会抢占并运行它。好吧，你可能会想，那又怎样？事实上，这完全是司空见惯的事情！在现代系统中，硬件中断非常频繁地触发，有效地（字面上）中断了各种任务上下文（在shell上快速执行vmstat 3；中标记的系统下的列显示了过去1秒内系统上触发的硬件中断次数！）。这里，要问的关键问题是：中断处理代码（hardirq、ISR或“上半部分”，或所谓的tasklet或softirq“下半部分”），sh与刚刚中断的流程上下文共享和处理相同的可写数据？如果这是真的，那么休斯顿，我们有一个问题——数据竞赛！如果没有，那么您的中断代码就不是中断代码路径的关键部分，这很好。事实上，大多数设备驱动程序都会处理中断；因此，驱动程序作者（您的！）有责任确保进程上下文和中断上下文代码路径之间没有共享全局或静态数据（实际上是非关键部分）。如果是（有时确实会发生），您必须以某种方式保护这些数据免受数据竞争和可能的损坏（这通常是通过使用自旋锁来实现的；不用担心，我们会解决的）。</p>
<p>这些场景可能会让你觉得，防止这些并发问题是一项艰巨的任务；面对现有的关键部分，以及刚才讨论的各种可能的货币问题：多核（或SMP）、内核抢占、阻塞I/O和硬件中断，你到底如何实现数据安全？好消息是，这真的很容易；保护关键部分的实际（锁定）API并不难学习使用。我们再次强调，识别并保护关键部分是关键。闲话少说，现在让我们开始深入了解主要的同步技术，该技术将用于保护我们的关键部分——锁定。</p>
<h4 id="锁定准则和死锁"><a href="#锁定准则和死锁" class="headerlink" title="锁定准则和死锁"></a>锁定准则和死锁</h4><p>​    锁定，就其本质而言，是一种复杂的野兽；它往往会引发复杂的连锁场景。对它的理解不够深入可能会导致性能问题和错误——死锁、循环依赖、中断不安全锁定等等。以下锁定指南是确保使用锁定时正确编写代码的关键：锁定粒度锁定和解锁之间的“距离”——实际上是关键部分的长度——不应太粗（关键部分太长）；它应该“足够好”。以下几点对此进行了扩展。你在这里需要小心。当你在处理大型项目时，锁太少是一个问题，锁太多也是一个问题！锁太少会导致性能问题（因为相同的锁被重复使用，因此往往会引起高度竞争）。拥有大量锁实际上对性能有好处，但对复杂性控制不利。这也让你，开发人员，了解另一个关键点：在代码库中有很多锁的情况下，你应该非常清楚哪个锁保护哪个共享数据对象。如果你使用锁a来保护mystructX，这是完全没有意义的，但在远处的代码路径中（可能是中断处理程序），你忘记了这一点，在处理同一结构时使用其他锁锁锁锁B来保护！现在，这些事情听起来可能很明显，但是（正如经验丰富的开发人员所知），在足够的压力和复杂性下，即使是显而易见的事情也并不总是如此！试着平衡一下。在大型项目中，使用一个锁来保护一个全局（共享）数据结构是典型的。现在，很好地命名锁变量本身就可能成为一个大问题！这就是为什么我们经常将保护数据结构的锁作为成员放入其中。原子性的长关键部分会导致高延迟并成为性能瓶颈，特别是在时间关键的实时系统中。有几个工具（处于各种稳定状态）可以帮助您了解这些部分发生在哪里（以及持续多久）。eBPF稳定版中的一个工具名为criticalstat[-bpfcc]。它可以检测和报告长关键部分（它还可以帮助显示内核堆栈痕迹，从而显示其来源）在长时间内禁用抢占和/或IRQ的情况下，持续时间较长。criticalstat实用程序的手册页可以在这里找到：<a target="_blank" rel="noopener" href="https://manpages.ubuntu.com/manpages/focal/man8/criticalstat-bpfcc.8.html;这是它的“示例”页面：https://github.com/iovisor/bcc/blob/master/tools/criticalstat_example.txt.（Ftrace也有跟踪器，可以捕捉长时间的抢占/IRQ关闭时间。）">https://manpages.ubuntu.com/manpages/focal/man8/criticalstat-bpfcc.8.html;这是它的“示例”页面：https://github.com/iovisor/bcc/blob/master/tools/criticalstat_example.txt.（Ftrace也有跟踪器，可以捕捉长时间的抢占/IRQ关闭时间。）</a></p>
<p>只有锁的“所有者”，即当前的持有者，才能释放（解锁）它；试图释放你没有放弃的锁或在持有时重新获取它被认为是错误（后者可以通过使用递归锁定来绕过；不过请参阅下一点）。尽可能避免递归锁定；内核社区普遍对此表示反对。</p>
<p>锁的排序至关重要，可以大大缓解死锁。您必须确保锁始终以相同的顺序取用；所有参与该项目的开发人员都应该记录并遵循这些“锁排序规则”（注释锁也很有用；下一章关于lockdep的部分将对此进行更多介绍）。不正确的锁顺序通常会导致死锁。另一方面，释放锁的顺序并不重要（当然，你必须在某个时候释放所有持有的锁，以免造成饥饿）。注意防止饥饿；验证锁一旦被取下，是否确实“足够快”地释放。简单是关键：尽量避免复杂性或过度设计，特别是在涉及锁的复杂场景中。关于锁定的话题，出现了死锁的（危险的）问题。僵局是指无法取得任何进展；换句话说，应用程序进程/线程和/或内核组件似乎无限期挂起。</p>
<p>虽然我们不打算在这里深入探讨死锁的血腥细节，但我会很快提到一些可能发生的更常见的死锁场景：简单情况、单锁、进程上下文：尝试两次获取同一锁被认为是一种缺陷，会导致自死锁。想想看；在持有锁的同时，您尝试重新获取它。现在，由于锁已锁定，您必须等待它解锁。但你拿着锁等待（只有你能解锁），因此无法解锁；结果就是（自我）死锁！递归锁定可以解决这个问题，但它通常被禁用，使用它是不可取的。简单的情况，多个（两个或多个）锁，进程上下文——让我们用一个例子来研究一下：在CPU 0上，线程A获取锁A，然后想要获取锁B。同时，在CPU 1上，线程B获取锁B，然后想要获得锁A。因此，每个线程都会永远等待另一个。。。其结果是一个典型的循环死锁案例，通常称为AB-BA死锁。这一点的说明如下（时间线垂直向下）：CPU 0:线程A CPU</p>
<p><img src="./image-20240718075444661.png" alt="image-20240718075444661"></p>
<p>这可以无限期延长；例如AB-BC-CA循环依赖（A-B-C锁链）导致死锁。复杂情况、单锁、进程和中断上下文——让我们通过一个例子再次研究这个问题（这个例子实际上是针对自旋锁的；我们很快就会了解细节）：进程P1，运行驱动程序（模块）的读取方法，在CPU核上获取锁A0</p>
<p>​    一毫秒后，驱动程序的硬件中断发生在同一个内核上，因此驱动程序的中断处理程序立即抢占P1。现在，如果中断上下文试图获取这个相同的锁，锁A，该怎么办？由于锁A当前被锁定（由进程上下文P1），中断上下文被迫等待解锁；但是P1正在持有锁并等待取回CPU，只要中断正在运行，就不会发生这种情况。。。因此，它无法执行解锁，中断上下文也会永远等待……结果又是（自）死锁！当然，这种情况的规定解决方案是在获取锁时禁用（屏蔽）本地核心上的所有硬件中断；则流程上下文不能被中断，它将运行关键部分以完成。换句话说，它现在是真正的原子。当它执行解锁时，此操作将重新启用本地核心上的所有中断，一切正常！因此，在中断（或更一般地说，原子）上下文中获取的锁必须始终在禁用中断的情况下使用。（我们到底是如何做到这一点的？对于自旋锁，我们当然会在介绍自旋锁时更详细地研究这些方面。）更复杂的情况、多个锁以及进程和中断（hardirq和softirq）上下文。（我们在这里不再进一步讨论；您将在即将到来的锁定和中断部分找到详细信息。）在更简单的情况下，始终遵循锁顺序指南就足够了：始终以有良好记录的顺序获取锁（我们将在使用互斥锁部分的内核代码中提供一个例子）。然而，正如您可能开始意识到的那样，事情可能会变得非常复杂，复杂的死锁场景甚至会让有经验的开发人员陷入困境。幸运的是，lockdep（Linux内核的运行时锁依赖验证工具）可以捕获（几乎）每一个死锁情况！（别担心，我们会到达那里的，我们将在下一章中介绍lockdepin的细节；只需一步一步地进行）。当我们介绍自旋锁时（在使用自旋锁部分），我们会遇到前面提到的进程和/或中断上下文场景；其中明确了要使用的具体自旋锁API（以避免死锁等）。现实情况是，即使是活锁情况也可能和死锁一样致命！Livelock本质上是一种概念上类似于死锁的情况；只是参与任务的状态正在运行，而不是等待。例如，中断“风暴”（数百甚至数千个硬件中断及其相关的软中断以突发形式发生，需要非常快速地处理，给系统带来压力）可能会导致活锁；现代网络驱动程序通过关闭中断（在中断负载下）并采用名为NewAPI（NAPI）的轮询技术，在适当的时候重新打开中断来减轻这种影响。（好吧，这比这更复杂，但我们就说到这里吧。）对于那些没有生活在农村的人来说ock，你会知道Linux内核有两种主要类型的锁：互斥锁和自旋锁。实际上，还有其他几种类型，包括其他同步（和“无锁”编程）技术，所有这些都将在本章和下一章中介绍。内核文档提到了内核中实现的三种锁类别：睡眠锁、CPU本地锁和旋转锁。休眠锁包括（RT）互斥锁、信号量和变体。旋转锁包括旋转锁、读写器旋转锁和变体。“本地锁”通常用于RT使用，尽管非RT使用包括将其用于锁调试。</p>
<p>​    现在，让我们深入探讨互斥锁和自旋锁的真正含义</p>
<h4 id="在什么情况下应该使用哪种锁-互斥还是自旋锁？"><a href="#在什么情况下应该使用哪种锁-互斥还是自旋锁？" class="headerlink" title="在什么情况下应该使用哪种锁,互斥还是自旋锁？"></a>在什么情况下应该使用哪种锁,互斥还是自旋锁？</h4><p>​    当学习使用互斥锁和旋转锁的确切语义非常简单（内核API集合中的适当抽象使典型的驱动程序开发人员或模块作者更容易）。这种情况下的关键问题是一个概念问题：这两种锁类型之间的真正区别是什么？更重要的是，在什么情况下应该使用哪把锁？您将在本节中了解这些问题的答案。以我们之前的驱动程序读取方法的伪代码（图12.6）为例，假设三个线程——tA、tB和tC——通过此代码并行运行（在SMP系统上）。我们将通过在关键部分开始之前（时间t2）获取锁，并在关键部分代码路径结束后（时间t3）释放锁（解锁），来解决这种并发问题，同时避免任何数据竞争。让我们通过图表再次查看伪代码（图12.7），这次是锁定以确保其正确：</p>
<p><img src="./image-20240718075758624.png" alt="image-20240718075758624"></p>
<p>图12.7：伪代码：（虚构的）驱动程序读取方法中的关键部分；在这里，它正确地完成了锁定当三个线程试图同时获取锁时，锁API语义保证它们中的任何一个都会获得锁。假设tB（线程B）获得锁：它现在是“赢家”或“所有者”线程。这意味着线程tA和tC是“失败者”；他们做什么？他们等待解锁！当“胜利者”（tB）完成关键部分并解锁锁时，之前的失败者之间的战斗就会重新开始；其中一人将成为下一个赢家，这个过程会重复。（请务必理解，图12.7中的“API”只是伪代码，而不是实际的（非）锁API；我们将在本节后面的两个主要部分中介绍这些内容。）两种锁类型（互斥锁和自旋锁）之间的关键区别在于失败者如何等待解锁事件。使用互斥锁，失败线程将进入睡眠状态；也就是说，他们通过睡觉来等待</p>
<p>​    效果是，当他们试图锁定互斥体并且互斥体已经锁定时，他们会将其视为阻塞调用；它们被调度或上下文关闭了CPU——它们现在处于“睡眠”状态）。获胜者执行解锁的那一刻，内核会唤醒失败者线程（所有线程），它们会运行，再次争夺锁。（事实上，互斥体和信号量有时被称为睡眠锁。）然而，有了自旋锁，就没有睡眠的问题了；失败者线程通过在锁上“旋转”来等待，直到它被解锁。从概念上讲，这看起来如下：</p>
<p>while（locked）；</p>
<p>​    请注意，这只是概念性的。想想看——这实际上是民意调查。然而，作为一名优秀的程序员，你会明白轮询通常被认为是一个坏主意。那么，为什么自旋锁会这样工作呢？好吧，事实并非如此；它仅以这种方式呈现用于概念目的。正如您很快就会理解的那样，自旋锁只有在多核（SMP）系统上才真正有意义。在这样的系统中，当winnerthread离开并运行关键部分代码时，失败者会通过在其他CPU内核上旋转来等待！实际上，在实现层面上，用于实现现代自旋锁的代码是高度优化的（并且是特定于arch的），并且不会通过一段时间的琐碎“旋转”（锁定）来工作；语义类型（例如，ARM的许多自旋锁实现使用等待事件（WFE）机器语言指令，该指令使CPU在低功耗状态下最佳地等待。请参阅进一步阅读部分，了解内核中互斥体和自旋锁的内部实现的几个资源）。确定使用哪个锁——在理论上，自旋锁是如何实现的，在这里我们真的不关心；自旋锁的开销比互斥锁低。这是怎么回事？这很简单，真的：为了使互斥锁工作，失败者线程必须进入睡眠状态（然后在解锁时被唤醒）。为此，在内部调用schedule（）函数，这意味着失败者将互斥锁API视为阻塞调用！对调度程序的调用最终将导致线程从CPU上上下文关闭。相反，当所有者线程最终解锁锁时，必须唤醒失败者线程；同样，其中一个，即下一个“赢家”，将被上下文切换回处理器。因此，互斥锁/解锁操作的最小“成本”是在给定机器上执行两次上下文切换所需的时间。（见下一节中指定为[1]的信息框。）通过重新查看图12.7，我们可以确定在关键部分（“锁定”代码路径）花费的时间；也就是说，t_locked=t3-t2。假设t_ctxsw表示上下文切换的时间。正如我们所了解到的，mutexlock/unlock操作的最小成本是两个上下文开关（第一个是“进入睡眠”，第二个是“唤醒”）：<code>t_locked&lt;2*t_ctxsw</code>。现在，假设以下表达式为真：<code>t_locked&lt;2*t_ctxsw</code>的话，如果在关键部分花费的时间少于两次上下文切换所花费的时间怎么办？在这种情况下，使用互斥锁是错误的，因为这会带来太多的开销；执行元工作所花费的时间比实际工作要多，这种现象被称为“鞭打”。正是这个精确的用例——存在非常短的关键部分——在Linux等现代操作系统上经常出现这种情况，这让我们优先使用自旋锁而不是互斥锁。因此，总之，当你有短的、非阻塞的关键部分时，选择自旋锁，当关键部分较长并且（可能）阻塞时，选择互斥体。为什么强调“封锁”？以下部分——实际内容——清楚地说明了这一点</p>
<h4 id="互斥锁——剩下的几个要点"><a href="#互斥锁——剩下的几个要点" class="headerlink" title="互斥锁——剩下的几个要点"></a>互斥锁——剩下的几个要点</h4><p>​    在本节中，我们将介绍一些关于互斥锁的额外要点。互斥锁API变体首先，让我们来看看互斥锁API的几个变体；除了可中断变体（在Mutex锁-通过[un]可中断睡眠？一节中描述）外，我们还有trylock、killable和io变体。互斥trylock变量如果你想实现忙等待语义怎么办；也就是说，测试（互斥）锁的可用性，如果可用（意味着它当前已解锁），则获取它并继续关键部分代码路径。但是，如果它不可用（意味着它当前处于锁定状态），不要等待锁定；相反，执行一些其他工作并重试。实际上，这是一个非阻塞互斥锁变体，因此被称为trylock；以下流程图大致描述了它的工作原理：</p>
<p><img src="./image-20240718080050279.png" alt="image-20240718080050279"></p>
<p>图12.9：“忙碌等待”语义，互斥锁的非阻塞trylock变体图12.9中的虚线框表示内部实现——检查锁是否解锁，然后锁定它——是原子性的。这个互斥锁的trylock变体的API如下：</p>
<pre class="line-numbers language-none"><code class="language-none">int__sched-mutex_trylock(structmutex*lock);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    这个API的返回值表示运行时发生的情况：返回值1表示锁已成功获取。返回值0表示锁当前已争用（锁定）。尽管这可能很诱人，但不要试图使用mutex_trylock（）API来判断amutex锁是处于锁定状态还是未锁定状态；这本质上是“活泼的”。接下来，请注意，在竞争激烈的锁路径中使用trylock变体可能会大大降低您获得锁的机会。trylock变体传统上用于死锁预防代码，这些代码可能需要退出某个锁顺序序列，并通过另一个序列（顺序）重试。此外，关于trylock变体，尽管文献中使用了try and acquire mutexotical的措辞，但它在原子或中断上下文中不起作用——它只在进程上下文中起作用（与任何类型的互斥锁一样）。像往常一样，锁必须通过所有者上下文调用mutex_unlock（）来释放。</p>
<h4 id="信号量和mutex"><a href="#信号量和mutex" class="headerlink" title="信号量和mutex"></a>信号量和mutex</h4><p>Linux内核确实提供了一个信号量对象，以及您可以对（二进制）信号量执行的常见操作：通过down[_interuptible]（）（和变体）API获取信号量锁通过up（）API解锁信号量通常，信号量是一个较旧的实现，因此建议您使用互斥锁代替它。不过，一个值得探讨的常见问题是：互斥锁和信号量之间有什么区别？它们在概念上看似相似，但实际上却截然不同；一个答案可以总结为以下几点（当然，这些主要是Linux内核编写的）：信号量是互斥体的一种更通用的形式；互斥锁可以只获取一次（随后释放或解锁），而信号量可以多次获取（随后释放）。互斥体用于保护关键部分免受同时访问，而信号量应作为一种机制，向另一个等待的任务发出信号，表明已经达到某个里程碑（通常，生产者任务通过信号量对象发布信号，消费者任务正等待接收该信号，以便继续进行进一步的工作）。互斥体具有锁的所有权概念，只有所有者上下文可以执行解锁；二进制信号量没有所有权。优先级反转和RT-mutexA使用任何类型的锁定时需要注意的一点是，您应该仔细设计和编写代码，以防止可能出现的死锁情况（同样，有关捕获此情况的更多信息，请参阅锁验证器lockdep-捕获锁定问题早期部分的下一章）。除了死锁之外，使用互斥体时还会出现另一种风险情况：优先级反转（同样，我们不会在本书中深入探讨细节）。只需说，无限优先级反转的情况可能是致命的；最终结果是产品的高（est）优先级线程在CPU之外停留的时间过长。正如我在之前的书《Linux的动手系统编程》中详细介绍的那样，正是这个优先级反转问题在1997年7月袭击了美国宇航局的火星探路者机器人，该机器人位于火星表面！每当项目的高优先级线程在互斥体上等待太久，超过截止日期时，使用硬件监视器就会重新启动系统；这个麻烦的是，这种情况经常发生！由于启用了调试遥测（耶！），从地球上诊断并修复了潜在问题（通过使用优先级继承（PI）互斥体属性来防止持有互斥体的低优先级线程在释放互斥体之前被抢占）。然后将固件上传到火星上的机器人（！），一切正常！有关这方面的有趣资源，请参阅本章的进一步阅读部分，这是每个软件开发人员都应该知道的！用户空间Pthreads互斥实现当然具有可用的优先级继承（PI）语义。但是在Linux内核中呢？为此，Ingo Molnar提供了基于PI的RT-mutex（一种real-timemutex；实际上，一种扩展为具有PI功能的互斥对象。仅供参考，futex（2）API是一种复杂的系统调用，提供快速的用户空间互斥对象）。当CONFIG_RT_MUTEXES配置选项启用时，它变得可用。与“常规”互斥语义非常相似，提供了RT互斥API来初始化、（取消）锁定和销毁RT互斥对象。（此代码已从Ingo Molnar的-rt树合并到主线内核中。）就实际使用而言，rt互斥体用于在内部实现PI futex（你知道在Linux上，futex（2）系统调用本身在内部实现了用户空间Pthreads互斥体吗？）。除此之外，内核锁定自检代码和I2C子系统直接使用RT互斥体。因此，对于典型的模块（或驱动程序）作者来说，这些API不会经常使用。内核提供了一些关于RT互斥体内部设计的文档at<a target="_blank" rel="noopener" href="https://docs.kernel.org/locking/rt-mutex-design.html（包括优先级反转、优先级继承等）。内部设计关于内核结构深处互斥锁内部实现的现实：Linux试图尽可能实现快速路径方法。快速路径是最优化的高性能代码路径，通常是没有锁和无锁的路径。目的是让代码尽可能地遵循这条快速路径。只有当它真的不可能时，内核才会退回到（可能的）“中间路径”，然后是“慢路径”方法；它仍然有效，但很慢（呃）。这种快速路径是在没有锁争用的情况下采取的（即锁从一开始就处于解锁状态）。所以，锁很快就锁上了。然而，如果互斥体已经被锁定，那么内核通常会使用“中间路径”乐观旋转实现，使其更像是混合（互斥体/自旋锁）锁类型。即使这不可能，也会遵循“慢路径”——尝试获取锁的进程上下文很可能会进入睡眠状态。如果您对互斥体的内部实现感兴趣，可以在此处的官方内核文档中找到更多详细信息：https://docs.kernel.org/locking/mutex-design.html.TheLDV（Linux驱动程序验证）项目：back在线章节，内核工作区设置，在LDV–Linux驱动程序验证–项目一节中，我们提到这个项目有关于Linux模块（主要是驱动程序）以及核心内核的各种编程方面的有用“规则”。关于我们当前的主题，这里有一条规则：锁定互斥体两次或在没有事先锁定的情况下解锁(http://linuxtesting.org/ldv/online?action=show_rule&amp;rule_id=0032">https://docs.kernel.org/locking/rt-mutex-design.html（包括优先级反转、优先级继承等）。内部设计关于内核结构深处互斥锁内部实现的现实：Linux试图尽可能实现快速路径方法。快速路径是最优化的高性能代码路径，通常是没有锁和无锁的路径。目的是让代码尽可能地遵循这条快速路径。只有当它真的不可能时，内核才会退回到（可能的）“中间路径”，然后是“慢路径”方法；它仍然有效，但很慢（呃）。这种快速路径是在没有锁争用的情况下采取的（即锁从一开始就处于解锁状态）。所以，锁很快就锁上了。然而，如果互斥体已经被锁定，那么内核通常会使用“中间路径”乐观旋转实现，使其更像是混合（互斥体/自旋锁）锁类型。即使这不可能，也会遵循“慢路径”——尝试获取锁的进程上下文很可能会进入睡眠状态。如果您对互斥体的内部实现感兴趣，可以在此处的官方内核文档中找到更多详细信息：https://docs.kernel.org/locking/mutex-design.html.TheLDV（Linux驱动程序验证）项目：back在线章节，内核工作区设置，在LDV–Linux驱动程序验证–项目一节中，我们提到这个项目有关于Linux模块（主要是驱动程序）以及核心内核的各种编程方面的有用“规则”。关于我们当前的主题，这里有一条规则：锁定互斥体两次或在没有事先锁定的情况下解锁(http://linuxtesting.org/ldv/online?action=show_rule&amp;rule_id=0032</a>). 它提到了你不能用互斥锁做的事情（我们已经在正确使用互斥锁一节中介绍了这一点）。这里有趣的是，您可以在内核驱动程序中看到一个错误的实际示例——互斥锁双重获取重试，导致（自）死锁（以及后续修复）。我们将要提到的另一种类型的互斥体是所谓的w/w–wait/wund（或简称WW互斥体）–one（其中wond与“destroyed”押韵）。该术语起源于RDBMS文献，是处理死锁的一种方式（文档甚至使用了“死锁证明”一词）。在Linux内核中使用w/w时，主要是在图形子系统中使用，在某种程度上是在DMA中使用。这里，获取mutexlock的任务接收唯一的预订或票证标识符。现在，获取WW互斥体的任务的“年龄”被考虑在内。在检测到死锁的情况下，将优先处理“最旧”的任务，即保留时间最长的任务。怎么用？这是通过让“年轻”任务退出，让他们（强迫）释放他们持有的WW锁来实现的；因此，年轻的任务是“受伤的”（可怜的家伙）。WW互斥体在内核中的使用率相当低，特别是与常规互斥体相比。有关更多信息，请参阅进一步阅读部分。现在您已经了解了如何使用互斥锁，让我们继续看内核中另一个非常常见的锁——自旋锁！</p>
<h4 id="使用自旋锁"><a href="#使用自旋锁" class="headerlink" title="使用自旋锁"></a>使用自旋锁</h4><p>在“确定使用哪种锁”的实践部分中，您学习了何时使用自旋锁而不是互斥锁，反之亦然。为了方便起见，我们复制了之前在这里提供的关键语句：关键部分是在原子（例如中断）上下文中运行，还是在无法休眠的进程上下文中运行？使用旋转锁。关键部分是否在进程上下文中运行，关键部分是否可能休眠或阻塞I/O？使用互斥锁。在本节中，我们将考虑您现在已决定使用自旋锁。</p>
<h4 id="Spinlock–简单用法"><a href="#Spinlock–简单用法" class="headerlink" title="Spinlock–简单用法"></a>Spinlock–简单用法</h4><p>对于所有Spinlock API，您必须包含相关的头文件，即#include<linux/Spinlock.h>。与互斥锁类似，在使用之前，您必须声明自旋锁并将其初始化为解锁状态。Thespinlock是一个通过名为spinlock_t的typedef数据类型声明的“对象”（在内部，它是include/linux/spinlock_types.h中定义的结构）。它可以通过spin_lock_init（）宏动态初始化：</p>
<p>​    或者，这可以通过DEFINE_SPINLOCK（锁）静态执行（声明和初始化）；宏。与互斥体一样，在其旨在保护的（全局/静态）数据结构中声明自旋锁（防止并发访问）通常是一个非常好的主意。正如我们前面提到的，这个想法经常在Linux内核中使用；例如，表示内核中打开文件的数据结构称为struct file</p>
<pre class="line-numbers language-none"><code class="language-none">struct file&#123;
[…]
	struct path f_path;
	struct inode*f_inode;&#x2F;*缓存值*&#x2F;
	const struct file_operations*f_op;&#x2F;**保护f_ep_links，	f_flags。*不能取自IRQ上下文。*&#x2F;
	spinlock_t f_lock;
	[…]
	结构互斥锁
	f_pos_lock; 
	loff_t f_pos;
[……]
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    请检查：对于文件结构，名为f_lock的自旋锁变量是保护（正如注释所说）f_ep_link的自旋锁nks和f_flags是文件数据结构的成员；此外，它有一个互斥锁来保护另一个成员，即文件的当前寻道位置f_pos。您实际上是如何使用spinlock执行锁定和解锁操作的？</p>
<h4 id="锁定和中断"><a href="#锁定和中断" class="headerlink" title="锁定和中断"></a>锁定和中断</h4><p>​    到目前为止，我们已经学习了如何使用互斥锁，以及对于自旋锁，如何使用基本的spin_[un]lock（）API。还有一些关于自旋锁的其他API变体，我们将在这里研究更常见的变体。在本节中，有更高级的介绍，如果你至少了解在Linux上编写（char）设备驱动程序和硬件中断处理的基础知识（通常在设备驱动程序上下文中），这肯定会有所帮助。本书《Linux内核编程-第2部分》第1章“编写简单的misc CharacterDevice驱动程序”和第4章“处理硬件中断”（LKP-2电子书可免费下载）深入探讨了这些主题。此外，作为快速指南/复习，我们提供了一个题为“Linux上的中断处理”的小节，这是本节后面的要点摘要。（如果你不熟悉Linux上的中断处理概念，我们建议你先看看LKP-第2部分书和/或本节，然后从这里继续。）为了准确理解为什么你可能需要其他API来处理自旋锁，让我们来看一个场景：作为驱动程序作者，你发现你正在使用的设备断言了硬件中断；因此，您为它编写了中断处理程序。现在，在为驱动程序实现读取方法时，您发现其中有一个非阻塞关键部分。这很容易处理：正如您所了解的，您应该使用自旋锁来保护它。太好了！但是，想想看，如果在读取方法的关键部分，设备的硬件中断触发怎么办？如您所知，硬件中断会抢占任何东西；因此，控制权将转到中断处理程序代码，抢占驱动程序的读取方法。这里的关键问题是：这是一个问题吗？这个答案取决于驱动程序的中断处理程序和read方法正在做什么，以及它们是如何实现的。让我们想象一下几个场景：驱动程序的中断处理程序（理想情况下）只使用局部变量，所以即使读取方法位于关键部分，也没关系；中断处理将非常快速地完成（通常在10到100微秒的范围内进行广泛的峰值处理），控制权将交还给被中断的任何东西（同样，还有更多的事情要做；任何现有的下半部分机制，如softirq ortasklet，可能也需要在驱动程序的读取方法交还给处理器之前执行）。所以，假设在这种情况下真的没有种族。驱动程序的中断处理程序正在处理（全局）共享可写数据，但没有在驱动程序的读取方法正在使用的共享数据项上。因此，同样，与read方法的代码没有冲突和竞争。（当然，您还应该意识到，当您的中断处理程序处理共享状态时，它确实有一个必须保护的关键部分（通常通过另一个自旋锁）。）</p>
<p>驱动程序的中断处理程序正在处理与驱动程序的读取方法所处理的共享可写数据相同（或部分相同）的数据。在这种情况下，我们可以看到数据竞争的可能性肯定存在，所以我们需要锁定！（回想一下我们在数据竞赛中对数据竞赛的定义——一个更正式的定义部分。）当然，让我们关注第三种情况，即有可能发生数据竞赛的情况。显然，我们必须使用aspinlock来保护中断处理代码中的关键部分（回想一下，当我们处于任何类型的原子或中断上下文中时，不允许使用互斥体）。此外，除非我们在驱动器的读取方法和中断处理程序代码路径中使用相同的自旋锁，否则它们根本不会受到保护！正如本文所述，使用锁时要格外小心；花时间仔细思考你的设计和代码。让我们试着让这个讨论更有实践性（使用伪代码）：假设我们有一个名为gctx的（全局）共享数据结构；我们在驱动程序中的read方法和中断处理程序（上半部分和/或tasklet）中对其进行操作。关于我们的读取方法，由于此代码路径可以并发运行并且包含共享状态，因此它是一个关键部分，因此需要保护。现在，由于我们在processcontext中运行，在这里使用互斥体似乎是可以的。不认为…为了有效，我们显然需要在驱动程序的读取方法和中断处理程序中使用相同的锁来保护相同的共享状态。现在，中断处理程序的关键部分也需要保护，正如我们所了解到的，我们在这里真的没有太多选择：我们必须使用自旋锁。因此，我们发现驱动程序的读取方法和驱动程序的中断处理程序必须使用相同的自旋锁！（在这里，我们称spinlock变量为slock；将其读取为“s lock”）。以下伪代码显示了这种情况的一些时间戳（t1、t2、…）</p>
<p><img src="./image-20240718080836549.png" alt="image-20240718080836549"></p>
<p>场景1——驱动读方法和中断串行运行</p>
<p>场景2——（更有趣的是）它们以交错的方式运行（存在数据竞争的可能性）</p>
<p>场景3——它们交错运行，一些中断被屏蔽（有些没有；存在数据争用的可能性）</p>
<p>我们从第一个场景开始。</p>
<h4 id="场景1——驱动程序方法和硬件中断处理程序按顺序串行运行。"><a href="#场景1——驱动程序方法和硬件中断处理程序按顺序串行运行。" class="headerlink" title="场景1——驱动程序方法和硬件中断处理程序按顺序串行运行。"></a>场景1——驱动程序方法和硬件中断处理程序按顺序串行运行。</h4><p>以下伪代码用于设备驱动程序的中断处理程序。</p>
<p><img src="./image-20240718080936793.png" alt="image-20240718080936793"></p>
<h4 id="场景2——驱动程序方法和硬件中断处理程序交错运行。"><a href="#场景2——驱动程序方法和硬件中断处理程序交错运行。" class="headerlink" title="场景2——驱动程序方法和硬件中断处理程序交错运行。"></a>场景2——驱动程序方法和硬件中断处理程序交错运行。</h4><p>​    无论你的代码是在UP（单处理器，只有一个CPU核）还是SMP（多核）系统上运行，都很重要。让我们首先考虑UP系统上的这种情况。</p>
<h5 id="单核（UP）系统上的场景2"><a href="#单核（UP）系统上的场景2" class="headerlink" title="单核（UP）系统上的场景2"></a>单核（UP）系统上的场景2</h5><p>硬件中断当然是异步的（它们可以随时到达）。如果你的外围芯片（你的驱动程序是专门为“驱动”而构建的）在读取方法运行的同一CPU核上，在不太合适的时间（对我们来说）发生中断，比如在读取方法的关键部分运行时，即在t1和t2之间（见图12.12），该怎么办？那么，自旋锁（在t1时拍摄）不应该简单地完成它的工作并保护我们的数据吗？不，请仔细考虑：此时，中断处理程序将抢占读取方法的关键部分，并很快进入其关键部分；这样做，它显然会试图获得相同的自旋锁（&amp;slock）。但是等待一段时间——它无法获取（锁定）它，因为它当前已被锁定（由运行read方法的进程上下文锁定）！因此，它“旋转”，实际上是在等待解锁。但它怎么可能被解锁呢？驱动程序的读取进程上下文必须解锁它（因为它拥有它），但不能，因为它被硬件中断抢占了！因此，它无法解锁，因此中断侧自旋锁永远“旋转”；所以，我们陷入了（自我）僵局。那么，解决方案是什么？我们稍后会讲到，所以请继续阅读…</p>
<h5 id="多核（SMP）系统上的场景2"><a href="#多核（SMP）系统上的场景2" class="headerlink" title="多核（SMP）系统上的场景2"></a>多核（SMP）系统上的场景2</h5><p>​    有趣的是，自旋锁在SMP（或多核）系统上更直观，完全有意义。因此，在这里，让我们考虑一个与前一个略有不同的场景——在多核上运行。假设therad方法在CPU核1上运行；中断可以在另一个CPU核心（例如核心2）上传递。鉴于read方法位于其关键部分，这意味着自旋锁被锁定（当然）；因此，试图获取相同自旋锁的中断代码路径将在CPU核2上的锁上“旋转”。一旦核心1上的read方法完成其关键部分，它将解锁自旋锁，从而解锁中断处理程序，中断处理程序现在可以“获取”自旋锁并继续前进；太棒了但是UP呢？那么，它将如何运作？毕竟，一个人不能在一个CPU核心上的一个（比如进程）上下文中运行逻辑，同时在另一个（例如中断）上下文中“旋转”。如果在多核（SMP）机器上，驱动程序的读取方法和硬件中断处理程序恰好在同一个核心上执行，该怎么办？别担心，确实有解决办法！用spin_[un]lock_irq（）APIvariantAh解决UP和SMP上的问题，所以最后，这里是这个难题的解决方案：当与中断“比赛”时，无论是处理器还是SMP系统，只需使用spinlock API的_irq变体：spin_lock_irq（）API在内部屏蔽其运行的处理器内核（即本地内核）上的硬件中断（不可屏蔽的中断除外，如（NonMaskable Interrupt（NMI））。因此，通过在我们的驱动程序读取方法中使用此API，在关键部分的长度期间，将有效地禁用本地内核上的中断，从而使任何可能的“竞赛”都无法通过硬件中断实现。（如果interrupt确实在另一个CPU核上启动，那么自旋锁技术将如之前所讨论的那样简单地工作！）spin_lock_irq（）实现非常嵌套（与大多数自旋锁功能一样），但速度很快；接下来，它最终调用local_irq_disable（）和preempt_sable（）宏，从而在运行它的本地处理器内核上禁用中断和内核抢占。换句话说，使用这个spinlock API变体，禁用硬件中断也会产生禁用内核抢占的（理想的）副作用！spin_lock_irq（）API与相应的spin_unlock_irq（）API配对。因此，针对此场景的正确使用方法（与我们之前看到的天真方法相反，这种方法实际上可能会导致自死锁）如下</p>
<p><img src="./image-20240718081109725.png" alt="image-20240718081109725"></p>
<h4 id="场景3——一些中断被屏蔽，驱动程序方法和硬件中断处理程序交错运行。"><a href="#场景3——一些中断被屏蔽，驱动程序方法和硬件中断处理程序交错运行。" class="headerlink" title="场景3——一些中断被屏蔽，驱动程序方法和硬件中断处理程序交错运行。"></a>场景3——一些中断被屏蔽，驱动程序方法和硬件中断处理程序交错运行。</h4><p>​    在我们挺直腰板休息一天之前，让我们考虑另一种场景。在这种情况下，在一个更复杂的产品（或项目）上，在处理代码库的几个开发人员中，很可能有人故意将硬件中断（位）掩码设置为某个值，从而锁定一些硬件中断，同时允许其他中断（disable_irq（）/enable_irk（）API允许您选择性地禁用/启用单个irq行）。为了我们的示例，假设这发生在时间t0的某个时间点。现在，正如我们之前所述，另一个开发人员（你！）出现了，为了保护驱动程序阅读中的关键部分</p>
<p>方法使用spin_lock_irq（）API（正如我们刚才在使用spin_[un]lock_irq）API变体解决UP和SMP问题部分中所了解的）。听起来不错，是吗？是的，但这个API有能力关闭（屏蔽）本地CPU内核上的所有硬件中断（以及内核抢占，我们现在将忽略它）。它通过在较低级别操纵（非常特定于拱门的）硬件CPU状态寄存器来实现。仅供参考，在x86[_64]上，spin_lock_irq（）API保存EFLAGS（32位）/RFLAGS（64位）寄存器内容（更正确地说，它保存LSB 16位，即称为“FLAGS”的内容）。在AArch32上保存EFLAGS寄存器内容，在AArch64上保存DAIF（调试、异步（serror）、中断和FIQ异常）寄存器内容。当然，Thespin_unlock_irqrestore（）API会恢复它。那么，你问呢？考虑这个场景展开：时间t0：中断掩码设置为某个值，例如0x8e（10001110b），启用一些中断并禁用一些中断（例如，通过仔细使用disable_irq（）API）。此设置对项目很重要（这里，为了简单起见，我们假设它是一个8位掩码寄存器）：[…时间流逝…]。时间t1：在进入驱动程序读取方法的关键部分之前，调用spin_lock_irq（&amp;slock）；。正如我们现在所理解的，这个API将在内部保存一些CPU状态寄存器，并具有将中断屏蔽寄存器中的所有位清除为0的内部效果，从而有效地屏蔽所有中断。时间t2：现在，硬件中断无法在这个CPU核上处理，所以我们继续完成关键部分。那很好。完成关键部分后，我们调用spin_unlock_irq（&amp;slock）；。此API将具有恢复某些（特定于架构的）CPU状态寄存器的内部效果，这也将具有将中断屏蔽寄存器中的所有位设置为1的内部副作用，从而重新启用所有中断。然而，中断掩码寄存器现在被错误地“恢复”为0xff（1111111b）值，而不是原始开发人员想要、要求和假设的0x8e值！这可能会（也可能会）破坏项目中的某些东西。听起来很难。不过，解决方案非常简单：在保存CPU状态时，不要做任何假设；只需保存并重新存储现有的CPU状态，从而保存中断掩码状态。这样，如果中断掩码最初的值为0x8e（10001110b），则这就是被保存的内容，稍后将被恢复；太好了！这个保存和恢复pu-state（带自旋锁）可以通过以下自旋锁API对实现：</p>
<pre class="line-numbers language-none"><code class="language-none">\#include＜linux&#x2F;spinlock.h＞
unsigned long spin_lock_irqsave（spinlock_t*lock，unsigned long flags）;
void spin_unlock_irqrestore（spinlock_t*lock，unsigned long flags）;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>这两个锁定和解锁函数的第一个参数是指向要使用的spinlock变量的指针。第二个参数flags必须是无符号长数据类型的局部变量。这将用于保存和恢复拱门规格ic CPU寄存器（以及中断掩码状态）。所以，最后，对于这种情况，正确的（伪）代码是这样的：</p>
<p><img src="./image-20240718081253523.png" alt="image-20240718081253523"></p>
<h4 id="中断处理、下半部分和锁定"><a href="#中断处理、下半部分和锁定" class="headerlink" title="中断处理、下半部分和锁定"></a>中断处理、下半部分和锁定</h4><p>​    在开始关于锁定和下半部分的要点之前，快速概述（实际上是总结）Linux上中断处理的一些关键点会有所帮助。</p>
<h5 id="Linux上的中断处理——关键点"><a href="#Linux上的中断处理——关键点" class="headerlink" title="Linux上的中断处理——关键点"></a>Linux上的中断处理——关键点</h5><p>​    摘要中断处理程序必须是非阻塞的，并快速完成工作。多快？经验法则是，在100微秒内。但是，如果在处理程序中有相当多的工作要执行呢？这可能需要更长的时间……这可能会引入延迟。一种解决方案（大多数现代操作系统都会采用）是将中断处理“拆分”为两半——顶部和底部。“上半部分”（或hardirq）处理程序是在硬件中断触发时几乎立即调用的处理程序；你，作为驱动程序的作者，要在这里做最基本的工作，尽可能简短。如果需要执行更多的工作，您（早些时候）注册并调用“下半部分”，这是一个“稍后”运行的延迟函数。实际上，下半部分是作为“任务集”实现的，而这些任务集又是基于内核的低级软技术构建的。tasklet或softirq几乎在上半部分完成后立即运行。但这种“拆分”方法的好处在哪里？啊，这里有一件关键的事情，与锁定有关的重要副作用：上半部分（hardirq）总是在当前CPU上禁用（屏蔽）所有中断的情况下运行，并且它在所有CPU上处理的IRQ都是禁用（屏蔽的）的；下半部分处理程序在启用所有中断的情况下运行。重要的是要意识到，即使是下半部分机制——softirq和tasklet——也在中断（而非进程）上下文中运行。因此，与上半部分或hardirq处理程序一样，你不能做任何可能阻塞它们的事情。hardirq处理程序永远不会与自身并行运行（因此，它是不可重入的）。任务小程序（基于引擎盖下的softirq机制构建）也永远不会与自身并行运行；此属性允许使用tasklet更容易的。不过，softirq可以与自身并行运行（在其他内核上）。接下来，使用线程处理程序进行中断处理现在在许多类型的驱动程序中都很流行（特别是对于速度稍慢的设备，与许多块、网络、图形设备不同，这些设备没有极高的性能要求，事实上这是注册中断处理程序时的默认设置）。在这种情况下，由于中断处理程序实体实际上只是一个内核线程（在SCHED_FIFO调度策略和实时优先级50下），因此允许在其中发出阻塞调用。此外，这也消除了“上下半部分”的二分法。下半部和锁定现在，在理解了这些要点后，让我们继续锁定。如果你的驱动程序的softirq或tasklet有一个关键部分与你的上半部分（hardirq）中断处理程序“竞争”（通过在与上半部分执行的核心不同的核心上执行），该怎么办？简单：在两者之间使用常规的旋转锁来保护关键部分。接下来，如果你的驱动程序的softirq或tasklet有一个关键部分与你的流程上下文代码路径“竞争”怎么办？在这种情况下，可能需要在驱动程序的方法中使用spin_lock_bh（）例程，因为它首先禁用本地处理器上的下半部分，然后获取自旋锁，从而保护关键部分（类似于spin_lock_irq[save]（）通过禁用本地核上的硬件中断来保护进程上下文中的关键部分）：void spin_lock_bh（spinlock_t*lock）；相应的解锁API是spin_unlock_bh（）。当然，在对性能高度敏感的代码路径中，开销确实很重要（实现网络堆栈的内核代码就是一个很好的例子）。因此，与更复杂的变体相比，使用最简单的自旋锁形式将有助于提高性能。话虽如此，但肯定会有一些场合要求使用更强形式的屏蔽API。例如，关于6.1.25 LTSLinux内核代码库，这里是我们所看到的不同形式的自旋锁API的使用实例数量的近似值：</p>
<ul>
<li>spin_lock（）：超过10200个使用实例</li>
<li>spin_lock_irq（）：3800个使用实例</li>
<li>spin_lock_irqsave（）：15500个以上使用实例</li>
<li>spin_lock_bh（）：4400多个使用实例（相比之下，这本书第一版的5.4.0 LTS内核分别为9400个、3600多个、15000多个和3700多个使用示例）。</li>
</ul>
<p>​    在这种情况下；我们只想指出，在Linux内核中，使用更强大形式的spinlockAPI非常普遍。最后，对自旋锁的内部实现做一个非常简短的说明：就引擎盖内部而言，实现往往是非常特定的代码，通常由原子机器语言指令组成在微处理器上执行非常快。例如，在流行的x86[_64]架构上，自旋锁最终归结为一个原子测试，并在自旋锁结构的一个成员上设置机器指令（通常通过cmpxchg机器语言指令实现）。正如我们之前提到的，在许多ARM机器上，实现的核心通常是wfe（等待事件，以及SetEvent（SEV））机器指令。（您可以在“进一步阅读”部分找到有关其内部实现的资源。）无论如何，作为内核或驱动程序的作者，您应该只在使用自旋锁时使用公开的API（和宏）。</p>
<h4 id="使用spinlocks–快速总结"><a href="#使用spinlocks–快速总结" class="headerlink" title="使用spinlocks–快速总结"></a>使用spinlocks–快速总结</h4><p>​    让我们快速总结spinlocks，API-wise：</p>
<ul>
<li>最简单、最低的开销：在保护流程上下文中的关键部分时，使用非irq spinlock原语spin_lock（）/spin_unlock（）（要么没有硬件中断要处理，要么有中断，但我们根本不与它们竞争；实际上，当中断不起作用或无关紧要时，使用它）。此外，此表单可用于保护上半部分和下半部分处理器之间的关键部分。</li>
<li>中等开销：当硬件中断正在发挥作用并且很重要时（在这里，进程和中断上下文可以“竞争”；也就是说，它们共享全局可写数据），使用irq禁用（以及内核抢占禁用）版本spin_lock_irq（）/spin_unlock_irq。此外，在保护进程上下文和下半部分之间的关键部分时，可以使用spin_[un]lock_bh（）API对（它在内部禁用/启用本地内核上的下半部分）。</li>
<li>最坚固的形式，（相对）较高的开销：这是使用自旋锁最安全的方法。它的操作与中等开销的一个相同，只是它通过pin_lock_irqsave（）/spin_unlock_irqrestore（）API对CPU状态执行保存和恢复，以确保实际上不会无意中覆盖以前的中断掩码设置，这在前一种情况下可能会发生。</li>
</ul>
<p>​    正如我们之前看到的，在UP上不可能出现自旋锁——在等待锁的时候，它在运行的处理器上“旋转”——（你怎么能在一个可用的CPU上旋转，而另一个线程同时在同一个CPU上运行？）。事实上，在UP系统上，自旋锁API成为禁止操作（除非启用了自旋锁调试配置）；这里自旋锁API的唯一真正效果是，它们禁用（屏蔽）处理器上的硬件中断和内核抢占！然而，在SMP（多核）系统上，旋转逻辑实际上开始发挥作用，因此锁定语义按预期工作。等等——这些细节不应该让你感到压力，初露头角的内核/驱动程序开发人员；事实上，关键在于你应该简单地使用所描述的自旋锁API，你永远不必担心UP和SMP、内核抢占等等；内部完成和未完成的细节都被实现所隐藏。添加了一项新功能实时Linux（RTL，以前称为PREEMPT_RT）项目的5.8内核，这里值得一提：“本地锁”。虽然本地锁的主要用例是用于（硬）实时内核，但它们也有助于非实时内核，主要用于通过静态分析进行锁调试，以及通过lockdep进行运行时调试（我们介绍lockdep下一章）。以下是LWN关于此主题的文章：<a target="_blank" rel="noopener" href="https://lwn.net/Articles/828477/">https://lwn.net/Articles/828477/</a></p>
<p>​    当一个线程保持irq关闭/抢占关闭自旋锁时，根据定义，它不能被抢占。这对Linux实时内核（RTL）来说是一个棘手的问题；显然，无论发生什么，它都需要能够保证在较高优先级的实时线程变得可运行时，较低优先级的线程被抢占。与传统的自旋锁相比，这种设计被击败了；因此，当启用RTL时，自旋锁实际上被重新实现为“睡眠自旋锁”！这是通过用rt互斥锁替换自旋锁来实现的，实际上使关键部分可以休眠，从而可以抢占。只是需要注意的事情。至此，我们完成了关于自旋锁的部分，自旋锁是Linux内核中几乎所有子系统（包括驱动程序）都使用的一种极其常见的密钥锁。</p>
<h4 id="锁定-常见错误和指南"><a href="#锁定-常见错误和指南" class="headerlink" title="锁定-常见错误和指南"></a>锁定-常见错误和指南</h4><p>​    总结一下，如果你愿意，可以快速参考或总结一下锁定时常见的错误，以及（重复一下）锁定指南。（请注意，这里提到的一些技术，如无锁编程，将在下一章中介绍）。</p>
<h5 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h5><p>​    不识别关键部分：</p>
<ul>
<li>“简单”的增量/减量（i++或i-类型）：正如我们在A经典案例中了解到的那样，全局i++部分，这些也可能是关键部分。在下一章中，我们将展示使用它们的优化和原子方法。</li>
<li>“嘿，我只是在读取共享数据”：如果满足一个条件的两个条件，这仍然是一个关键部分；不保护它可能会导致读取不干净或撕裂，数据不一致或损坏。</li>
<li>死锁：不可能取得进展的情况；仔细设计您的锁定模式，并遵循易于理解的锁定规则或指导方针，以避免死锁。它基本上归结为这些关键点：记录并始终遵循锁排序规则。不要试图重新获得你已经持有的锁。仅释放您当前持有的锁。</li>
<li>防止饥饿。</li>
</ul>
<h5 id="锁定指南"><a href="#锁定指南" class="headerlink" title="锁定指南"></a>锁定指南</h5><p>​    关于锁定指南的总体总结如下：</p>
<ul>
<li>首先，尽量避免锁定：现在，这不仅仅意味着：“不使用全局变量。”相反，你必须制定一个总体架构，在这个架构中，尽可能没有写入线程（共享可写数据）可以与对该数据的任何其他读/写访问同时运行。接下来，如果您正在使用共享可写数据，例如在全局结构中，请尝试保留所有或尽可能多的（整数）成员，如refcount_t或atomic_t（稍后介绍）。考虑记忆障碍（必要时）。使用免锁技术！</li>
<li>如果必须使用锁定，请按以下顺序进行：尝试使用无锁技术：根据CPU变量RCU如果不能，请使用正常锁定：Mutex：在进程上下文中，当关键部分较长时，和/或需要或可能发生关键部分中的阻塞I/O（睡眠）Spinlock：在任何原子上下文中工作时（如中断处理），当关键段较短时；关键区域必须无阻塞（不允许睡眠）。或者，即使在关键部分没有阻塞的进程上下文中也可以使用它。如果互斥体或自旋锁都可以使用，那么最好使用自旋锁（它不仅可以让你获得更好的性能，还可以在必须遵循的关键部分内强制执行更严格的规则）.refcount_t用于整数操作（atomic_t原子运算符是此操作的旧接口）。在操作位时使用内核的RMW位运算符（将在下一章中介绍）。读写器（自旋）锁（支持RCU）。</li>
<li>始终记住锁的顺序：始终以相同的顺序取锁；记录订单并严格遵守；这有助于防止死锁（释放锁的顺序并不重要）。锁定数据，而不是代码：在可能的情况下，转向细粒度（r）锁定。这一点还有（更多）原因；在更深层次上，这意味着通过仔细查看你正在保护的数据结构（甚至是其中的成员）来设计你的锁定模式，确切地指定如何保护它免受并发访问——实际上，使用以数据为中心的方法，而不是以代码为中心的方式，在这种方式下，你或多或少地随机在代码中撒一些互斥锁或自旋锁，直到看起来“有效”。Daniel Vetter在2022年7月的《锁定工程原理》一文中深入探讨了这些想法和更多想法：<a target="_blank" rel="noopener" href="https://blog.ffwll.ch/2022/07/locking-engineering.html）。">https://blog.ffwll.ch/2022/07/locking-engineering.html）。</a></li>
<li>性能受到关键部分长度（锁和解锁之间的代码路径）的影响；保持简短！（回想一下我们之前提到的criticalstat eBPF实用程序；您可以使用它来检查和报告遇到的长原子关键部分。）</li>
<li>防止饥饿。记住缓存效果和内存屏障（错误共享和缓存行反弹；</li>
<li>将在下一章中介绍）。使用调试内核运行所有测试用例；关于锁定，调试内核必须启用“lockdep”；</li>
<li>此外，启用锁定统计还可以帮助查明热点（在下一章中介绍）。</li>
<li>保持锁定模式尽可能简单。</li>
</ul>
<h2 id="字符设备驱动"><a href="#字符设备驱动" class="headerlink" title="字符设备驱动"></a>字符设备驱动</h2><h4 id="了解设备基本知识。"><a href="#了解设备基本知识。" class="headerlink" title="了解设备基本知识。"></a>了解设备基本知识。</h4><p>​    有必要快速了解一些背景知识。设备驱动程序是操作系统和外围硬件设备之间的接口。它可以内联编写，即在内核映像文件中编译，或者更常见的是，作为内核模块在内核源代码树外部编写（我们在配套指南《Linux内核编程》第4章“编写第一个内核模块”LKM第1部分和第5章“编写第一个内核模块》LKM第2部分中详细介绍了LKM框架）。无论如何，驱动程序代码肯定会在内核空间中以操作系统权限运行（用户空间设备驱动程序确实存在，但可能会出现性能问题；虽然在许多情况下很有用，但我们在这里不会介绍它们。请看进一步阅读部分）。为了让用户空间应用程序访问内核中的底层设备驱动程序，需要一些I/O机制。Unix（以及Linux）的设计是让进程打开一种特殊类型的文件——设备文件或设备节点。这些文件通常位于/dev目录中，在现代系统中是动态的和自动填充的。设备节点充当设备驱动程序的入口点。为了让内核区分设备文件，它在索引节点数据结构中使用了两个属性：文件类型——字符（char）或块主要和次要数字</p>
<p>​    你会看到命名空间——设备类型和{major，minor}对——形成层次结构。设备（以及它们的驱动程序）在内核中组织成树状层次结构（内核中的驱动程序核心代码负责此项工作）。层次结构首先根据设备类型（块或字符）进行划分。其中，每种类型都有n个主要数字，每个主要数字都通过m个次要数字进一步分类；图1.1显示了这个层次结构。现在，块设备和字符设备之间的关键区别在于，块设备具有（内核级）挂载能力，从而成为用户可访问的文件系统的一部分。字符设备无法安装；因此，存储设备往往是基于块的。这样想（有点简单但有用）：如果（硬件）设备不是存储设备，也不是网络设备，那么它就是字符设备。大量设备属于“字符”类，包括典型的I2C/SPI（内部集成电路/串行外围接口）传感器芯片（温度、压力、湿度等）、触摸屏、实时时钟（RTC）、媒体（视频、相机、音频）、键盘、鼠标等。USB在内核中形成了一个类，用于基础设施支持。USB设备可以是块设备（笔驱动器、USB磁盘）、字符设备（鼠标、键盘、相机）或网络设备（USB加密狗）。从2.6 Linux开始，{major:minior}对是inode中的一个无符号32位量，一个位掩码（它是dev_ti_rdev成员）。在这32位中，MSB 12位表示主要数字，其余LSB 20位表示次要数字。快速计算表明，因此每个大数最多可以有212=4096个大数和220个小数，即100万个小数。所以，请看图1.1；在区块层次结构中，可能有4096个主要区块，每个区块最多有100万个次要区块。同样，在字符层次结构中，可能有4096个主要字符，每个字符最多可以有100万个次要字符：图1.1-设备命名空间或层次结构</p>
<p><img src="./image-20240721072330075.png" alt="image-20240721072330075"></p>
<p>​    你可能想知道：这个major:minor数字对到底是什么意思？将主要数字视为表示设备的类别（是SCSI磁盘、键盘、工作室终端（tty）还是伪终端（pty）设备、环回设备（是的，这些是伪硬件设备）、操纵杆、磁带设备、帧缓冲区、传感器芯片、atouchscreen等？）。确实有各种各样的设备；为了了解到底有多少，我们敦促您查看这里的内核文档：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/admin-guide/devices.txt（它实际上是Linux操作系统所有可用设备的官方注册表。它的正式名称是LANANA——Linux名称和数字分配机构！只有这些人才能正式为设备分配设备节点——类型和主要编号：次要编号）。次要数字的含义（解释）完全由驱动作者决定；内核不会干扰。通常，驱动程序将设备的次要数字解释为表示设备的物理或逻辑实例，或表示某种功能。（例如，小型计算机系统接口（SCSI）驱动程序（类型块，major\#8）使用小数字表示最多16个磁盘的逻辑磁盘分区。另一方面，字符major\#119由VMware的虚拟网络控制驱动程序使用。在这里，未成年人被解释为第一个虚拟网络、第二个虚拟网络，以此类推。）同样，所有驱动程序本身都会为其未成年人赋予意义。但每一条好规则都有例外。这里，规则的例外是misc类（类型字符，主\#10），即内核不解释次要数字。它使用次要数字作为二级专业。这将在下一节中介绍。一个常见的问题是命名空间耗尽。几年前的一项决定“收集”了各种各样的字符设备——很多鼠标（不，不是动物界品种）、传感器、触摸屏等——归入一个名为“杂项”或“杂项”的类别，该类别被分配了字符主要编号10。misc类中有很多设备及其相应的驱动程序。实际上，他们共享同一个主要号码，并依靠一个唯一的次要号码来识别自己。我们将使用这个类并利用内核的“misc”框架编写一些驱动程序。">https://www.kernel.org/doc/Documentation/admin-guide/devices.txt（它实际上是Linux操作系统所有可用设备的官方注册表。它的正式名称是LANANA——Linux名称和数字分配机构！只有这些人才能正式为设备分配设备节点——类型和主要编号：次要编号）。次要数字的含义（解释）完全由驱动作者决定；内核不会干扰。通常，驱动程序将设备的次要数字解释为表示设备的物理或逻辑实例，或表示某种功能。（例如，小型计算机系统接口（SCSI）驱动程序（类型块，major\#8）使用小数字表示最多16个磁盘的逻辑磁盘分区。另一方面，字符major\#119由VMware的虚拟网络控制驱动程序使用。在这里，未成年人被解释为第一个虚拟网络、第二个虚拟网络，以此类推。）同样，所有驱动程序本身都会为其未成年人赋予意义。但每一条好规则都有例外。这里，规则的例外是misc类（类型字符，主\#10），即内核不解释次要数字。它使用次要数字作为二级专业。这将在下一节中介绍。一个常见的问题是命名空间耗尽。几年前的一项决定“收集”了各种各样的字符设备——很多鼠标（不，不是动物界品种）、传感器、触摸屏等——归入一个名为“杂项”或“杂项”的类别，该类别被分配了字符主要编号10。misc类中有很多设备及其相应的驱动程序。实际上，他们共享同一个主要号码，并依靠一个唯一的次要号码来识别自己。我们将使用这个类并利用内核的“misc”框架编写一些驱动程序。</a></p>
<p>​    许多设备已经通过LANANA（Linux分配名称和数字机构）分配到misc字符的设备类中。图1.2显示了部分屏幕截图<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/admin-guide/devices.txt展示的前几个misc设备、分配的次要编号和简要说明。请参阅完整列表的参考链接：">https://www.kernel.org/doc/Documentation/admin-guide/devices.txt展示的前几个misc设备、分配的次要编号和简要说明。请参阅完整列表的参考链接：</a></p>
<p><img src="./image-20240721072546568.png" alt="image-20240721072546568"></p>
<p>​    在图1.2中，最左侧的列有10个char，指定它在设备层次结构的字符类型下被分配了major#10（图1.1）。右侧的列格式为<code>minor\#=/dev/&lt;foo&gt;&lt;description&gt;</code>；很明显，这是分配的小编号，后面（在=符号之后）是设备节点和单行描述。</p>
<h4 id="关于Linux设备模型的快速说明"><a href="#关于Linux设备模型的快速说明" class="headerlink" title="关于Linux设备模型的快速说明"></a>关于Linux设备模型的快速说明</h4><p>​    在不详细介绍的情况下，快速概述现代统一的Linux设备模型（LDM）非常重要。从2.6内核开始，现代Linux有一个奇妙的特性，LDM，它通过一个广泛而大胆的举措实现了与系统及其上的设备有关的许多目标。在其众多功能中，它创建了一个复杂的层次树，统一了系统组件、所有外围设备及其驱动程序。这棵树通过sysfs伪文件系统（类似于procfs如何将内核和进程/线程内部细节暴露给用户空间）暴露到用户空间，通常在/sys下挂载。在/sys中，您会发现几个目录——您可以将它们视为LDM中的“视口”。在我们的x86_64 Ubuntu虚拟机上，我们显示了挂载在/sys:</p>
<pre class="line-numbers language-none"><code class="language-none">$mount | grep-w sysfs sysfs On&#x2F;sys type sysfs（rw、nosuid、nodev、noexec、relatime）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>下的sysfs文件系统。此外，看看里面：$</p>
<pre class="line-numbers language-none"><code class="language-none">ls-F &#x2F;sys&#x2F; 
block&#x2F; bus&#x2F; class&#x2F; dev&#x2F; devices&#x2F; firmware&#x2F; fs&#x2F; hypervisor&#x2F; kernel&#x2F; module&#x2F; power&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    将这些目录视为LDM的视口——查看系统上设备的不同方式。当然，随着事情的发展，更多的人倾向于进入而不是离开（懒惰的方面！）。几个不明显的目录现在已经进入了这里。尽管（与procfs一样）sysfs被正式记录为应用程序二进制接口（ABI）接口，但这随时可能被更改/弃用；现实情况是，随着时间的推移，这个系统将继续存在，当然也会不断发展。简单地说，LDM可以被认为具有并连接了这些主要组件：系统上的总线。他们身上的设备。驱动设备的设备驱动程序（也称为客户端驱动程序）。</p>
<p>LDM的一个基本原则是，每个设备都必须驻留在总线上。这可能看起来很明显：USB设备将位于USB总线上，PCI设备位于PCI总线上，I2C设备位于I2C总线上，以此类推。因此，在/sys/bus层次结构下，您将能够通过它们所在的总线“看到”所有设备：</p>
<p><img src="./image-20240721073039518.png" alt="image-20240721073039518"></p>
<p>图1.3-现代Linux（在x86_64上）上的不同总线或总线</p>
<p>​    驱动程序基础设施内核的驱动程序核心提供总线驱动程序（通常是内核映像本身的一部分，或者根据需要在启动时自动加载），这当然使总线发挥作用。他们的工作是什么？至关重要的是，他们组织和识别上面的设备。如果新设备出现（可能是您插入了笔式驱动器），USB总线驱动程序将识别该行为并将其绑定到其（USB大容量存储）设备驱动程序！一旦成功绑定（使用许多术语来描述：绑定、枚举、发现），内核驱动程序框架就会调用驱动程序的已注册probe（）方法（函数）。这个问题方法现在可以设置设备、分配资源、IRQ、内存设置、根据需要注册它等等。关于LDM，另一个需要理解的关键方面是，现代LDM基址驱动器通常应该执行以下操作：将自己注册到（专门的）内核框架。将自己注册至总线。它注册到的内核框架取决于您使用的设备类型；例如，驻留在I2C总线上的RTC芯片的驱动程序将其自身注册到内核的RTC框架（通过RTC_register_device（）API）和I2C总线（内部通过I2C_register_driver（）API）。另一方面，PCI总线上网络适配器（NIC）的驱动程序通常会将其自身注册到内核的网络基础设施（通过register_netdev（）API）和PCI总线（通过PCI_register_driver（）API）。在专门的内核框架中注册可以使您作为驱动程序作者的工作变得更加容易——内核通常会提供辅助例程（甚至数据结构）来处理I/O细节，等等。例如，以前面提到的RTC芯片驱动程序为例。</p>
<p>​    你不需要知道如何通过I2C总线与芯片通信的细节，按照I2C协议的要求在串行时钟（SCL）/串行数据（SDA）线上输出数据。内核I2C总线框架为您提供了便利的例程（例如通常使用的I2C_smbus_*（）API），使您可以轻松地通过总线与相关芯片通信！如果你想知道如何获取有关这些驱动程序API的更多信息，这里有个好消息：官方内核文档提供了很多。请在此处查找Linux驱动程序实现者的API指南：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/driver-api/index.html.（在接下来的两章中，我们确实展示了驱动程序probe（）方法的一些示例；在那之前，请耐心等待。）相反，当设备与总线分离或内核模块卸载（或系统关闭）时，分离会导致驱动程序的remove（或disconnect（））方法被调用。在这两者之间，通过其驱动程序（总线和客户端）执行设备的工作！请注意，我们在这里忽略了很多内部细节，因为它们超出了本书的范围。重点是让你对LDM有一个概念上的理解。更多详细信息，请参阅进一步阅读部分的文章和链接。">https://www.kernel.org/doc/html/latest/driver-api/index.html.（在接下来的两章中，我们确实展示了驱动程序probe（）方法的一些示例；在那之前，请耐心等待。）相反，当设备与总线分离或内核模块卸载（或系统关闭）时，分离会导致驱动程序的remove（或disconnect（））方法被调用。在这两者之间，通过其驱动程序（总线和客户端）执行设备的工作！请注意，我们在这里忽略了很多内部细节，因为它们超出了本书的范围。重点是让你对LDM有一个概念上的理解。更多详细信息，请参阅进一步阅读部分的文章和链接。</a></p>
<p>在这里，我们希望保持我们的驱动覆盖范围非常简单和最小化，更多地关注基础知识。因此，我们选择编写一个可能使用最简单的内核框架（misc或杂项内核框架）的驱动程序。在这种情况下，驱动程序甚至不需要向任何总线（驱动程序）显式注册。事实上，它更像这样：我们的驱动程序直接在硬件上工作，不需要任何特定的总线基础设施支持。</p>
<p>​    然而，我们确实需要内核的misc框架支持，因此我们向其注册。接下来，理解这一点也很关键：我们的驱动程序是一个逻辑驱动程序，因为它没有驱动实际的物理设备或芯片。这通常是这种情况（当然，你可以说这里使用的硬件是RAM）。因此，如果我们要编写属于这个misc类的Linux字符设备驱动程序，我们首先需要向它注册。接下来，我们需要一个唯一的（未使用的）minornumber。同样，有一种方法可以让内核动态地为我们分配一个空闲的次要数字。下一节将介绍这些方面以及更多方面。</p>
<h4 id="了解进程、驱动程序和内核之间的联系"><a href="#了解进程、驱动程序和内核之间的联系" class="headerlink" title="了解进程、驱动程序和内核之间的联系"></a>了解进程、驱动程序和内核之间的联系</h4><p>在这里，我们将深入研究Linux上成功注册字符设备驱动程序的内核内部。实际上，您将了解底层原始字符驱动程序框架的工作原理。file_operations结构或fops（发音为eff-oppops）对驱动程序作者至关重要；fops结构的大多数成员都是函数指针&amp;把它们看作是虚方法。它们表示可以在（设备）文件上发出的所有可能的文件相关系统调用。因此，它具有打开、读取、写入、轮询、mmap、释放和其他几个成员（其中大多数是函数指针）。</p>
<p>​    驱动程序作者（或底层内核框架）的一项关键工作是填充这些函数指针，从而将它们链接到驱动程序中的实际代码。当然，你不需要实现每一个功能；有关详细信息，请参阅“处理不支持的方法”一节。现在，让我们假设您已经编写了驱动程序来为一些f_op方法设置函数。一旦您的驱动程序通过内核框架注册，当任何用户空间进程（或线程）打开注册到此驱动程序的设备文件时，内核虚拟文件系统交换机（VFS）层将接管。无需深入细节，只需说VFS为设备文件分配并初始化该进程的开放文件数据结构（结构文件）即可。现在，回想一下结构设备初始化中的最后一行；它是这样的：</p>
<pre class="line-numbers language-none"><code class="language-none">.fops&#x3D;&amp;llkd_misc_fops，&#x2F;*连接到此驱动程序的“功能”*&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    这行代码有一个关键作用：它将进程的文件操作指针（位于进程的打开文件结构中）与设备驱动程序的文件操作结构联系起来。此设备文件的功能（驱动程序将执行的操作）现已设置完毕！</p>
<p>编写一个简单的杂项字符设备驱动程序第1章[24]让我们充实一下。现在（在您的驱动程序初始化后），一个用户模式进程通过对驱动程序发出open（2）系统调用来打开驱动程序的设备文件。假设一切顺利（也应该如此），该进程现在通过内核深处的file_operationsstructure指针连接到驱动程序。这里有一个关键点：在open（2）系统调用成功返回，并且进程在该（设备）文件上发出任何与文件相关的系统调用foo（）之后，内核VFS层将以面向对象的方式（我们在本书中已经指出了这一点！）盲目地、信任地调用已注册的fops-&gt;foo（）方法！用户空间进程打开的文件，通常是/dev中的设备文件，在内部由struct文件元数据结构表示（向此传递的一个指针，struct file*filp，传递给驱动程序）。因此，就伪代码而言，当用户空间发出与文件相关的系统调用foo（）时，这就是内核VFSlayer有效地执行的操作：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;*伪代码：内核VFS层（不是驱动程序）*&#x2F;
if（filp-&gt;f_op-&gt;foo）
	filp-&gt;f_op-&gt;foo（）;&#x2F;*调用与“foo（）”对应的“已注册”驱动程序方法*&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​    因此，如果打开设备文件的用户空间进程调用其上的read（2）系统调用，内核VFS将调用filp-&gt;f_op-&gt;read（…），实际上将控制重定向到设备驱动程序。作为设备驱动程序的作者，你的工作是提供read（2）的功能！所有其他与文件相关的系统调用也是如此。从本质上讲，这就是Unixand Linux如何实现众所周知的——如果不是一个过程，那就是一个文件设计原则。</p>
<h4 id="处理不受支持的方法"><a href="#处理不受支持的方法" class="headerlink" title="处理不受支持的方法"></a>处理不受支持的方法</h4><p>​    您不必填充f_ops结构的每个成员，只需要填充驱动程序支持的那些成员。如果是这样的话，你已经填充了一些方法，但省略了轮询方法，并且用户空间进程在你的设备上调用了poll（2）（也许你已经记录了它不应该这样做的事实，但如果它这样做了呢？），那么会发生什么？在这种情况下，内核VFS检测到foo指针（在本例中为poll）为NULL，返回一个适当的负整数（实际上，遵循相同的0/-E协议）。glibc代码将此值乘以-1，并将调用进程的errno变量设置为该值，表示系统调用失败。</p>
<p>​    需要注意两点：</p>
<p>VFS返回的负errno值通常不是很直观。（例如，如果您将f_op的read（）函数指针设置为NULL，则VFS会导致EINVAL值被发回。这使得用户空间进程认为读取（2）失败是因为“无效参数”错误，而事实根本不是这样！）</p>
<p>​    lseek（2）系统调用让驱动程序查找文件中的指定位置——当然，这里我们指的是设备中的位置。内核故意将f_op函数指针命名为llseek（注意两个’l’）。这只是为了提醒您lseek的返回值可以是64位（长-长）的量。现在，对于大多数硬件设备，lseek值没有意义，因此大多数驱动程序不需要实现它（与文件系统不同）。现在，问题是：即使你不支持lseek（你已经将f_op的llseek成员设置为NULL），它仍然会返回一个随机正值，从而导致用户模式应用程序正确地得出成功的结论。因此，如果你没有实现lseek，你需要执行以下操作：</p>
<p>1。将llseek显式设置为特殊的no_lilseek值，这将导致返回失败值（-ESPIPE；非法查找）。</p>
<p>在这种情况下，您还需要在驱动程序的open（）方法中调用nonsekable_open（）函数，指定文件不可查找（这在open（）法中通常是这样调用的：return nonsekale_open（struct inode<em>inode，struct file</em>filp）；。LWN的文章在这里介绍了细节和更多内容：<a target="_blank" rel="noopener" href="https://lwn.net/Articles/97154/.你可以在这里看到这给许多司机带来的变化：https://lwn.net/Articles/97180/).如果您不支持函数，则返回的适当值是-ENOSYS，这将使用户模式进程看到错误function未实现（当它调用perror（3）或strerror（3）库API时）。这是明确无误的；用户空间的开发者现在将明白您的驱动程序不支持此功能。因此，实现驱动程序的一种方法是设置指向所有文件操作方法的指针，并为驱动程序中所有与文件相关的系统调用（f_op方法）编写一个例程。对于你支持的theos，编写代码；对于那些你没有实现的，只返回值-ENOSYS。虽然这有点费力，但它将为用户空间带来明确的返回值。">https://lwn.net/Articles/97154/.你可以在这里看到这给许多司机带来的变化：https://lwn.net/Articles/97180/).如果您不支持函数，则返回的适当值是-ENOSYS，这将使用户模式进程看到错误function未实现（当它调用perror（3）或strerror（3）库API时）。这是明确无误的；用户空间的开发者现在将明白您的驱动程序不支持此功能。因此，实现驱动程序的一种方法是设置指向所有文件操作方法的指针，并为驱动程序中所有与文件相关的系统调用（f_op方法）编写一个例程。对于你支持的theos，编写代码；对于那些你没有实现的，只返回值-ENOSYS。虽然这有点费力，但它将为用户空间带来明确的返回值。</a></p>
<h4 id="将数据从内核复制到用户空间，反之亦然"><a href="#将数据从内核复制到用户空间，反之亦然" class="headerlink" title="将数据从内核复制到用户空间，反之亦然"></a>将数据从内核复制到用户空间，反之亦然</h4><p>​    设备驱动程序的主要工作是使用户空间应用程序能够透明地线程和写入数据到外围硬件设备（通常是某种芯片；但它可能根本不是硬件），将设备视为一个普通文件。因此，要从设备读取数据，应用程序打开与该设备对应的设备文件，从而获得文件描述符，然后使用该fd简单地发出read（2）系统调用（图1.7中的步骤1）！内核VFS拦截读取，并且，正如我们所看到的，控制流指向底层设备驱动程序的读取方法（当然，这是一个C函数）。驱动程序代码现在与硬件设备“对话”，实际执行I/O和读取操作。（硬件读取（或写入）的具体执行方式在很大程度上取决于硬件的类型——是内存映射设备、端口、网络芯片等吗？我们在此不再深入探讨；下一章会。）驱动程序从设备读取数据后，现在将这些数据放入kernelbuffer，kbuf（下图中的步骤2。当然，我们假设驱动程序通过[k|v]malloc（）或其他合适的内核API为其分配了内存）。我们现在在内核空间缓冲区中有硬件设备数据。我们应该如何将其传输到用户空间进程的内存缓冲区？我们将利用内核API，使其易于实现；接下来将对此进行介绍。</p>
<h4 id="利用内核API执行数据传输"><a href="#利用内核API执行数据传输" class="headerlink" title="利用内核API执行数据传输"></a>利用内核API执行数据传输</h4><p>​    现在，如前所述，让我们假设您的驱动程序已经读取了硬件数据，并且它现在存在于内核内存缓冲区中。我们如何将其转移到用户空间？一种可行的方法是简单地尝试通过memcpy（）执行此操作，但不行，这不起作用（为什么？第一，它不安全；第二，它非常依赖于拱；它在某些架构上有效，而在其他架构上无效）。因此，一个关键点是：内核提供了几个内联函数，用于将数据从内核传输到用户空间，反之亦然。它们分别是copy_to_user（）和copy_from_user（），确实非常常用。</p>
<p>​    使用它们很简单。两者都有三个参数：to指针（目标缓冲区）、from指针（源缓冲区）和n，要复制的字节数（就像memcpy操作一样）：</p>
<p><img src="./image-20240721073938881.png" alt="image-20240721073938881"></p>
<p>​    返回值是未复制的字节数；换句话说，返回值0表示成功，非零返回值表示未复制给定数量的字节。如果出现非零返回，您应该（按照通常的0/-E返回约定）通过返回-EIO或-EFAULT（从而将用户空间中的errno设置为正对应项）返回一个指示I/O故障的错误。以下（伪）代码说明了设备驱动程序如何使用copy_to_user（）函数将一些数据从内核复制到用户空间</p>
<p><img src="./image-20240721074002146.png" alt="image-20240721074002146"></p>
<p>当然，在这里，我们假设您有一个有效的分配的内核内存缓冲区、kbuf和avalid设备指针（struct device*dev）。图1.7说明了前面的（伪）代码试图实现的目标：</p>
<p><img src="./image-20240721074030348.png" alt="image-20240721074030348"></p>
<p>​    相同的语义适用于使用copy_from_user（）内联函数。它通常用于驱动程序写入方法的上下文中，将用户空间进程上下文写入的数据拉入内核空间缓冲区。我们将留给你来想象这一点。同样重要的是要意识到，这两个例程（copy_[from|to]_user（））在运行过程中都可能导致进程上下文（page）出错，从而进入休眠状态；换句话说，调用调度器。因此，它们只能在可以安全睡眠的进程上下文中使用，而不能在任何类型的原子或中断上下文中使用（我们在第4章“处理硬件中断”的“不要阻塞——发现可能阻塞的代码路径”一节中详细解释了light_sleep（）助手——一种调试辅助工具）。</p>
<h2 id="Kernel-Debug-Programming"><a href="#Kernel-Debug-Programming" class="headerlink" title="Kernel Debug Programming"></a>Kernel Debug Programming</h2><p>​    内存到底有什么问题？本章开头的介绍性段落告诉你一个恼人的事实，即尽管用C编程就像拥有一种超能力（至少对于你典型的OS/驱动程序/嵌入式领域来说），但这是一把双刃剑：我们人类无意中会产生缺陷和错误。尤其是内存错误，实在太常见了。事实上，在第2章“内核调试方法”的“错误类型——内存视图”一节中，我们提到了内存视图是错误类型分类的不同方法之一。为了便于回忆，并在这里强调其重要性，我重新列出了常见的内存损坏错误类型的简短列表：</p>
<p>•不正确的内存访问：</p>
<p>使用未初始化的变量，也称为非初始化内存读取（UMR）</p>
<p>错误越界（OOB）内存访问（读/写下溢/上溢错误）</p>
<p>免费使用（UAF）和返回后使用（UAR）（也称为范围外）</p>
<p>错误双重释放错误</p>
<p>•内存泄漏</p>
<p>•数据竞争</p>
<p>•（内部）碎片</p>
<p>​    这些（除最后一个之外）是进程甚至操作系统可能遇到的众所周知的未定义行为（UB）问题之一。在本章中，您将了解这些问题，重点是内核/驱动程序代码，更重要的是，如何使用各种工具和方法来捕捉它们。更确切地说，在本章中，我们将重点介绍前两个：不正确的内存访问——包括各种常见的内存错误：UMR、OOB、UAF/UAR和double free。在下一章中，我们将重点介绍通过SLUB调试框架捕获板状内存中的内存缺陷以及检测内存泄漏。我们将在第8章“锁调试”中介绍数据争用及其复杂性（因为它们最常见的原因是不正确地使用锁），下一章“学习使用slabinfo和相关实用程序”部分将提到（内部）碎片或浪费。</p>
<h4 id="使用KASAN和UBSAN查找内存错误"><a href="#使用KASAN和UBSAN查找内存错误" class="headerlink" title="使用KASAN和UBSAN查找内存错误"></a>使用KASAN和UBSAN查找内存错误</h4><p>​    内核地址清理器（KASAN）是Linux内核地址清理工具（ASAN）的一个端口。事实证明，ASAN项目在检测与记忆相关的缺陷方面非常有用，因此在内核中具有相似的能力是显而易见的。ASAN是少数可以检测缓冲区超限缺陷的工具之一，该缺陷是著名的Heartbleed漏洞的根源！请参阅进一步阅读部分，了解一个非常有趣的XKCD漫画链接，该链接完美地说明了Heartbleed的核心缺陷。了解KASAN——基本知识KASAN的几个要点将帮助您了解更多：•KASAN是一个动态的运行时分析工具；它在代码运行时工作。这应该让你意识到，除非代码实际运行（执行），否则KASAN不会捕获任何错误。这强调了编写真正好的测试用例（包括正面和负面）的重要性，以及使用模糊测试工具来捕获很少运行的代码路径的重要性！在后面的章节中会有更多关于这一点的内容，但这是一个关键点，我也在这里强调KASAN背后的技术称为编译时仪器（CTI）（又名静态仪器）。在这里，我们不打算深入了解它是如何工作的；请参阅进一步阅读部分了解更多信息。简而言之，当使用GCC或Clang-fsanitize=kernel addressoption开关构建内核时，编译器会插入汇编级指令来验证每次内存访问。此外，每个字节的内存都使用1字节的影子内存来跟踪8字节的实际内存开销相对较低（约为2倍至4倍）。这很低，特别是与Valgrind等动态仪器方法相比，后者的开销很容易达到20到50倍。好吧，就KASAN的开销而言，真正受伤的是RAM（比CPU多）开销。这完全取决于你来自哪里。对于企业级服务器系统，使用几兆字节的RAM作为KASAN的开销是可以容忍的。对于资源受限的嵌入式系统来说，情况可能并非如此（典型的Android智能手机、电视、可穿戴设备、低端路由器和类似产品就是很好的例子）。出于这个关键原因，现代Linux内核支持三种类型或模式的KASAN实现：</p>
<ul>
<li>通用KASAN（除非另有说明，否则我们在这里指的是和使用的KASAN）：高开销和仅调试。</li>
<li>基于软件标签的KASAN：实际工作负载的中到低开销。目前仅支持ARM64</li>
<li>基于硬件标签的KASAN：低开销和生产能力。目前，仅支持ARM64。</li>
</ul>
<p>​    第一个是默认值，也是在主动调试（或bug查找）时使用的值。它在三者中具有最大的相对开销，但在bug捕获方面非常有效！基于软件标签的方法具有显著较低的开销；它适用于测试实际工作负载。第三个基于硬件标签的版本开销最低，甚至适合生产使用！用户模式应用程序的内存检查事实上，ASAN工具最初是由谷歌工程师作为用户空间应用程序的GCC（以及很快的Clang）补丁实现的。该套件包括ASAN、泄漏消毒器（LSAN）、内存消毒器（MSAN）、线程消毒器（TSAN）和未定义行为消毒器（UBSAN）。它们——尤其是ASAN——非常强大，是用户空间应用程序内存检查的必备工具！我之前的书《使用Linux进行系统编程实践》详细介绍了使用ASAN（和Valgrind）。在接下来的讨论中，我假设采用了通用KASAN模式，主要是为了（内存）调试。实际上，正如您将在下一节中看到的，这有点没有意义，因为其他基于标记的模式目前仅在ARM64上受支持。使用KASAN的要求首先，由于KASAN（以及UBSAN）是基于编译器的技术，您应该使用哪种编译器？GCC和Clang都支持。您需要相对较新版本的编译器才能利用KASAN——在撰写本文时，您需要以下内容：•GCC版本：8.3.0或更高版本•Clang版本：任何。为了检测全局变量上的OOB访问，需要Clang版本11或更高版本。</p>
<p><img src="./image-20240721075731059.png" alt="image-20240721075731059"></p>
<p>一节中介绍Clang的使用。接下来，在硬件方面，KASAN传统上需要64位处理器。为什么？回想一下，它使用了一个影子内存区域，其大小是内核虚拟地址空间的八分之一。在x86_64上，内核VAS区域为128 TB（用户模式虚拟地址空间（VAS）区域也是如此）。其中八分之一是重要的——它是16TB。那么，KASAN实际上在哪些平台上工作呢？直接引用官方内核文档：目前，通用KASAN支持x86_64、arm、arm64、xtensa、s390和riscv架构，基于标签的KASAN模式仅支持arm64。你注意到了吗？甚至支持ARM——ARM 32位处理器！这是最近的事情，从5.11内核开始。不仅如此，至少在撰写本文时，基于较低开销标签的KASAN类型仅支持ARM64。你有没有停下来想知道，为什么是ARM64？显然，这是由于Android的惊人普及。许多（如果不是大多数）Android设备都是通过片上系统（SoC）内的ARM64内核供电的。在当今的信息经济中，检测Android上的内存缺陷（包括用户空间和内核中的内存缺陷）至关重要。因此，基于标签的KASAN模式在这个关键平台上工作！在表5.2中，我以粗体突出显示了Generic KASAN，因为它是我们在这里要使用的。</p>
<p>正如我们在配套指南《Linux内核编程》第4章“编写你的第一个内核模块——LKM第1部分”的“库和系统调用API”小节中看到的，用户空间应用程序和包含设备驱动程序的内核之间的基本接口是系统调用API。现在，在上一章中，您学习了为Linux编写字符设备驱动程序的基础知识。在此过程中，您还学习了如何通过让用户模式应用程序打开设备文件并发出读取（2）和写入（2）系统调用，在用户和内核地址空间之间传输数据。这导致驱动程序的读/写方法被VFS调用，您的驱动程序通过copy_{from|to}_user（）API执行数据传输。所以，这里的问题是：如果我们已经了解了这一点，那么在这方面还有什么值得学习的呢？啊，相当多！现实情况是，在auser模式应用程序和内核之间还有其他几种接口技术。当然，它们都非常依赖于使用系统调用；毕竟，没有其他（同步、编程）方式可以从用户空间进入内核！然而，技术不同。本章的目的是向您展示各种可用的通信接口，当然，根据项目的不同，其中一个可能比其他接口更适合使用。让我们来看看本章中用于用户和内核地址空间之间接口的各种技术：通过传统的procfs接口通过sysfs通过debugfs通过netlink socket通过ioctl（2）系统调用在本章中，我们将通过提供驱动程序代码示例详细讨论这些接口技术。此外，我们还将简要探讨它们对调试目的的帮助。那么，让我们从使用procfs接口开始。通过proc文件系统（procfs）进行接口在本节中，我们将介绍proc文件系是什么，以及如何将其用作用户和内核地址空间之间的接口。proc文件系统是一个功能强大且易于编程的接口，通常用于状态报告和调试核心内核系统。请注意，从2.6版Linux开始，对于上游贡献，驱动程序作者不得使用此接口（严格来说，这仅意味着forkernel内部使用）。</p>
<p>​    您可以将内核配置选项Instrumentation类型设置为config_KASAN_OUTLINE（默认值）或config_KALAN_INLINE。这是典型的权衡：默认的轮廓类型将导致较小的内核映像，而内联类型将导致较大的映像，但速度更快（1.1倍到2倍）。此外，（特别是对于您的调试内核），启用内核配置config_STACKTRACE是值得的，这样当检测到错误时，您还可以在报告中获得受影响板对象的分配和释放的堆栈跟踪。同样，打开CONFIG_PAGE_OWNER（位于菜单内核黑客|内存调试|跟踪页面所有者中）将为您提供受影响物理页面的分配和释放的堆栈跟踪。默认情况下，它处于关闭状态；您必须使用参数page_owner=on启动。此外，在为KASAN配置x86_64时，您会发现一个关于vmalloc内存损坏检测的额外内核配置。该选项显示如下：[*]在vmalloc空间中使用真实影子内存进行反向映射。这有助于检测与vmalloc相关的内存损坏问题（以运行时更高的内存使用率为代价）。理论和KASAN内核配置到此为止。请配置并（重新）构建（调试）内核，我们很乐意尝试一下！使用KASANI进行Bug搜索将假设到目前为止，您已经配置、构建并引导到使用KASAN启用的（调试）内核中（如前一节详细描述的那样）。在我的设置中——一个x86_64 Ubuntu 20.04 LTS客户机——这已经完成了。为了测试KASAN是否有效，我们需要执行有内存错误的代码（我几乎可以听到你们中的一些老前辈说“是吗？这应该不太难”）。我们总是可以编写自己的测试用例，但为什么要重新发明轮子呢？这是一个很好的机会来查看内核测试基础设施的一部分！以下部分将向您展示我们将如何利用内核的KUnit单元测试框架来运行KASAN测试用例。使用内核的KUnit测试基础架构运行KASAN测试用例当社区已经为我们完成了工作时，为什么还要费心编写我们自己的测试用例来测试KASAN呢？啊，开源的美丽。Linux内核现在已经发展得足够成熟，可以内置多种测试基础设施，包括功能齐全的测试套件；现在，测试内核的各个方面就是正确配置内核并运行测试！</p>
<p>​    两个主要的框架是KUnit框架和kselftest框架。仅供参考，官方内核文档当然有所有的细节。首先，您可以查看以下内容：内核测试指南：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/dev-tools/testing-overview.html\#kernel-testing-guide">https://www.kernel.org/doc/html/latest/dev-tools/testing-overview.html\#kernel-testing-guide</a> -它提供了内核中可用测试框架和工具（包括动态分析）的粗略概述。同样，仅供参考，还有其他几个相关且有用的框架：内核故障注入、通知错误注入、Linux内核转储测试模块（LKDTM）等。您可以在此处的内核配置下找到它们：内核黑客|内核测试和覆盖率。同样，我们不打算深入研究KUnit在这里是如何工作的；目前，我们的想法是只使用KUnit来测试KASAN作为一个实际例子。有关使用这些测试框架的详细信息，它可能会被证明是有用的请参阅“进一步阅读”部分中的链接。作为一件务实的事情，为了开始熟悉它，让我们利用内核的KUnit（Linux内核的单元测试）框架来执行KASAN测试用例！这真的很容易做到。首先，确保您的调试内核配置为使用KUnit:CONFIG_KUnit=y（或CONFIG_KUnit=m）。我们打算运行KASAN测试用例，因此，我们也必须配置KASAN测试模块：CONFIG_KASAN_KUNIT_test=m</p>
<p>​    请注意前面屏幕截图中的以下内容：•在前两行中，KUnit显示了测试标题（作为#Subtest:KASAN），它将运行测试用例1..38。•KASAN成功地检测到了内存缺陷、写溢出，并生成了一份报告。报告以BUG:KASAN:[…]开头，详细内容如下以下几行揭示了根本原因：KASAN显示违规函数的格式为func（）+0xoff_from_func/0xsize_of_func，其中，在名为func的函数中，错误发生在从函数开始偏移0xoff_fom_func字节处，内核估计函数长度为0xsize_of_funk字节。因此，在这里，kmalloc_oob_right（）函数中的代码在内核模块test_kasan（显示在最右侧的方括号内）中，从函数开头偏移0x159字节（后面是对函数长度的有根据的猜测，即0x260字节），试图在指定地址非法写入。缺陷，即bug，是对slab内存缓冲区的OOB写入，如slab越界标记所示：bug:KASAN:kmalloc_ob_right+0x159/0x260[test_KASAN]任务kunit_try_catch/1206在地址ffff8880316a45fb写入大小为1的slab越界。•以下行显示了发生这种情况的进程上下文（我们将在下一章中介绍受污染标志的含义）：CPU:2 PID:1206 Comm:kunit_try _catch tainted:G O 5.10.60-dbg01#6•下一行显示了硬件细节（您可以看到它）虚拟机VirtualBox）大部分输出是调用堆栈（标记为“调用跟踪：”）。通过自下而上阅读（忽略任何前缀为？的行），你可以真正看到控制是如何实现的，这是一段有缺陷的代码任务1206分配的行：以下输出显示了内存分配代码路径的调用轨迹。这可能非常有用，可以显示内存缓冲区最初是由谁分配的，在哪里分配的。</p>
<h4 id="使用我们定制的有缺陷的内核模块进行的剩余测试"><a href="#使用我们定制的有缺陷的内核模块进行的剩余测试" class="headerlink" title="使用我们定制的有缺陷的内核模块进行的剩余测试"></a>使用我们定制的有缺陷的内核模块进行的剩余测试</h4><p>​    您是否注意到，尽管已经运行了所有KASAN KUnit测试用例，但似乎还有一些通用的内存缺陷（正如我们在第4章“通过仪器调试-使用Kprobes”以及本章“内存有什么问题？”一节中发现的那样）是KUnit的测试用例没有涵盖的未初始化内存读取（UMR）错误•返回后使用（UAR）错误？简单的内存泄漏错误（我们将在本章稍后更详细地讨论内存泄漏）因此，我编写了一个内核模块来练习这些测试用例（当然是在运行支持Generic KASAN的调试内核时），以及一些更有趣的测试用例。要针对KASAN进行测试，请记住通过自定义调试内核启动，该内核（显然）具有CONFIG_KASAN=y。</p>
<p>使用KASAN和UBSAN查找内存错误201由于空间限制，我不会在这里显示我们测试模块的整个代码（请参阅本书的GitHub仓库并阅读其中的注释——您可以在ch5/kmembugs_test文件夹下找到它）。为了了解它的味道，让我们来看看其中一个测试用例以及它是如何被调用的。这是UAR测试用例的代码：</p>
<p><img src="./image-20240721081511525.png" alt="image-20240721081511525"></p>
<p>​    该模块设计为通过名为load_testmod的bash脚本加载，测试用例以交互方式运行（通过bash名为run_tests的包装器脚本）。run_tests脚本（您必须以root身份运行）显示可用测试的菜单，并要求您通过键入其分配的编号来选择任何一个。在接下来的部分中，您可以在图5.8中看到菜单的屏幕截图，以及您可以尝试的所有测试用例。然后，脚本将此数字写入我们的debugfs伪文件：/sys/kernel/debug/test_kmembugs/lkd_dbgfs_run_testcase。然后，debugfs写挂钩函数从用户空间接收此数据，对其进行验证，并调用相应的测试用例例程（通过一个相当长的if-else梯形图）。此设计允许您以交互方式进行测试，并根据需要多次执行任何测试用例。以下是一段代码片段，显示了我们的debugfs模块代码如何调用前面的uar（）测试用例：</p>
<p><img src="./image-20240721081625759.png" alt="image-20240721081625759"></p>
<p><img src="./image-20240721081633604.png" alt="image-20240721081633604"></p>
<p>显然，这个测试用例#2是一个缺陷，一个bug。你知道局部变量只在它们的生命周期内有效——当函数执行时。当然，这是因为在执行过程中，局部（或自动）变量被分配到进程上下文的（内核模式）堆栈帧上。因此，一旦超出其包含函数的范围，就必须停止引用局部变量。我们（故意）不这样做！我们试图把它作为回报。问题是，到那时，它已经消失了。。。好吧，在开始运行测试用例之前（尽管现在没有理由不能运行它们），我们陷入了一个有趣的困境：一个已知的bug（比如我们的UAR bug）有时看起来是如何完美工作的。</p>
<h4 id="陈旧的框架——天堂中的麻烦"><a href="#陈旧的框架——天堂中的麻烦" class="headerlink" title="陈旧的框架——天堂中的麻烦"></a>陈旧的框架——天堂中的麻烦</h4><p>​    像这样的bug的惊人（或疯狂）之处——UAR缺陷——是代码有时似乎还能正常工作！怎么会？它是这样的：保存本地（自动）变量内容的内存在堆栈上。现在，尽管我们通俗地说堆栈帧在函数输入时分配，在函数返回时销毁（所谓的函数序言和结语），但现实并不那么戏剧化。</p>
<p>​    使用KASAN和UBSAN查找内存错误203现实情况是，内存通常以页面级粒度分配。这包括堆栈页面的内存。因此，一旦为堆栈分配了一页内存，通常就有足够的内存容纳几帧（当然，这取决于具体情况）。然后，当堆栈需要更多内存时，它就会增长（通过向下分配更多页面，因为它是堆栈）。通过让堆栈指针（SP）寄存器跟踪此内存位置，系统知道堆栈的顶部在哪里。此外，您会意识到所谓的“堆栈顶部”通常是最低的合法地址。因此，当分配帧和/或调用函数时，SP寄存器值会减小。当函数返回时，堆栈会通过添加到SP寄存器而缩小（记住，这是一个向下增长的堆栈！）。下图是（32位）Linux系统上典型内核模式堆栈的表示：</p>
<p><img src="./image-20240721081725223.png" alt="image-20240721081725223"></p>
<p>​    使用UBSAN内核检查器查找未定义行为C等语言的一个严重问题是，编译器为正确的情况生成代码，但当源代码做了一些意外或完全错误的事情时，编译器通常不知道该做什么——它只是轻率地忽略了这些情况。这实际上有助于以（可能的安全）错误为代价生成高度优化的代码！这方面的例子很常见：数组溢出/欠流、算术缺陷（如除以零或溢出/欠流入有符号整数）等等。更糟糕的是，有时有缺陷的代码似乎还能工作（正如我们在stale frames中访问过时的堆栈内存时所见——天堂的麻烦部分）。同样，糟糕的代码可能在优化的情况下工作，也可能不工作。因此，这样的情况无法预测，被称为未定义行为（UB）。内核的Undefined Behavior Sanitizer（UBSAN）捕获了几种类型的运行时UB。与KASAN一样，它使用编译时检测（CTI）来实现这一点。在完全启用UBSAN的情况下，内核代码使用–fsanitize=undefinedoption开关进行编译。UBSAN捕获的UB包括以下内容：</p>
<p>•算术相关UB：算术上溢/下溢/除零/等等……</p>
<p>位移位时的OOB访问</p>
<p>•内存相关UB：数组NULL指针解引用未对齐内存访问对象大小不匹配</p>
<p>其中一些缺陷实际上与Generic KASAN捕获的缺陷重叠。UBSAN检测代码肯定更大、更慢（是原来的2到3倍）。尽管如此，捕捉UB缺陷仍然非常有用，尤其是在开发和单元测试期间。事实上，如果你能负担得起更大的内核文本大小和处理器开销（除了微型嵌入式系统之外，你可能可以负担得起），那么在生产系统上启用UBSAN是可行的。</p>
<h4 id="“每个sysfs文件一个值”规则"><a href="#“每个sysfs文件一个值”规则" class="headerlink" title="“每个sysfs文件一个值”规则"></a>“每个sysfs文件一个值”规则</h4><p>​    到目前为止，您已经了解了如何创建和使用sysfs用于用户空间内核接口目的，但有一个关键点我们一直忽略了。有一个关于使用sysfs文件的“规则”，它规定您只能读取或写入一个值！将此视为每个文件一个值的规则。因此，就像我们使用“压力”值的例子一样，我们只返回压力的当前值，仅此而已。因此，与其他接口技术不同，sysfs不太适合您可能希望向用户空间返回任意冗长的信息包（例如，驱动程序上下文结构的内容）的情况；换句话说，它不适合纯粹的“调试”目的。关于sysfs使用的内核文档和“规则”可以在这里找到：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/sysfs-rules.html\#rules-on-how-to-access-information-in-sysfs.。此外，这里还有关于sysfs">https://www.kernel.org/doc/html/latest/admin-guide/sysfs-rules.html\#rules-on-how-to-access-information-in-sysfs.。此外，这里还有关于sysfs</a> API的文档：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/filesystems/api-summary.html\#the￾用于导出内核对象的文件系统。内核通常提供几种不同的方法来创建sysfsobject；例如，使用sysfs_create_files（）API，可以一次性创建多个sysfs文件：int__must_checksysfs_ccreate_files（structkobject*kobj，const">https://www.kernel.org/doc/html/latest/filesystems/api-summary.html\#the￾用于导出内核对象的文件系统。内核通常提供几种不同的方法来创建sysfsobject；例如，使用sysfs_create_files（）API，可以一次性创建多个sysfs文件：int__must_checksysfs_ccreate_files（structkobject*kobj，const</a> struct attribute*const*attr）；。在这里，您需要向koobject提供apointer和指向属性结构列表的指针。</p>
<p>​    我们对sysfs作为接口技术的讨论；总之，sysfs被认为是驱动程序作者在用户空间中显示和/或设置特定驱动程序值的正确方式。由于“每个sysfs文件一个值”的约定，sysfs确实不适合调试信息分发。这巧妙地把我们带到了下一个主题——debugfs！通过调试文件系统（debugfs）接口想象一下，作为一名驱动程序开发人员，您在Linux上面临的困境：您想实现一种简单而优雅的方式，从驱动程序向用户空间提供调试“钩子”。例如，用户只需在（伪）文件上执行cat（1），就会调用驱动程序的“调试回调”函数。然后，它将继续将一些状态信息（可能是“驱动程序上下文”结构）转储到用户模式进程，该进程将忠实地将其转储到stdout。好的，没问题：在2.6版本发布之前的几天里，我们可以（正如您在通过proc文件系统接口（procfs）一节中所了解的那样）愉快地使用procfs层将我们的驱动程序与用户空间连接起来。然后，从2.6 Linux开始，内核社区否决了这种方法。我们被告知要严格停止使用procfs，而是使用sysfs层作为主题，将我们的驱动程序与用户空间连接起来。然而，正如我们在通过sys文件系统接口（sysfs）一节中看到的那样，它有一个严格的每个文件一个值的规则。这实际上非常适合从驱动程序报告单个值或向驱动程序发送单个值（通常是环境传感器值和类似值），但很快就会排除用户空间中除最微不足道的调试接口之外的所有接口。我们可以使用ioctl方法（我们将看到）来设置调试接口，但这要困难得多。那么，你能做什么呢？幸运的是，从Linux 2.6.12开始，有一个优雅的解决方案，称为debugfs。“调试文件系统”非常易于使用，并且非常明确地表明了驱动程序作者（事实上，任何人）都可以将其用于他们选择的任何目的！每个文件规则没有一个值——别忘了，没有规则。当然，就像我们处理过的其他基于文件系统的方法一样——procfs、sysfs和现在的debugfs——内核社区明确声称所有这些接口都是ABI，因此，它们的稳定性和寿命是无法保证的。尽管采取了正式的立场，但现实情况是，这些接口在现实世界中已经成为事实上的接口；在一个晴朗的日子里，不加序言地把它们摘下来，对任何人都没有好处。</p>
<h4 id="查找debugfs-API文档"><a href="#查找debugfs-API文档" class="headerlink" title="查找debugfs API文档"></a>查找debugfs API文档</h4><p>​    内核在这里提供了关于使用debugfs API的简洁而出色的文档（Jonathan Corbet，LWN）：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/filesystems/debugfs.txt（当然，您也可以直接在内核代码库中查找它）。我强烈建议您参考本文档以学习如何使用debugfs">https://www.kernel.org/doc/Documentation/filesystems/debugfs.txt（当然，您也可以直接在内核代码库中查找它）。我强烈建议您参考本文档以学习如何使用debugfs</a> API，因为它易于阅读和理解；这样，您就可以避免在这里不必要地重复相同的信息。除了上述文档外，现代内核文档系统（基于“Sphinx”的系统）还提供了非常详细的debugfs API页面：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/filesystems/api-summary.html?highlight=debugfs\#the-debugfs-filesystem.。请注意，所有debugfs">https://www.kernel.org/doc/html/latest/filesystems/api-summary.html?highlight=debugfs\#the-debugfs-filesystem.。请注意，所有debugfs</a> API仅以GPL格式导出到内核模块（因此该模块必须以“GPL”许可证发布（这可以是双重许可，但必须有一个是“GPL”））。</p>
<p>通过netlink套接字进行接口在这里，您将学习如何使用熟悉且无处不在的网络抽象——套接字来连接内核和用户空间！熟悉网络应用程序编程的程序员对其优势深信不疑。熟悉C/C++网络编程和套接字API会有所帮助。请参阅“进一步阅读”部分，了解有关此主题的一些好教程。使用套接字的优势在其他方面，套接字技术为我们提供了几个优势（优于其他典型的用户模式IPC机制，如管道、SysV IPC/POSIX IPC机制（消息队列、共享内存、信号量等）），如下：双向同时数据传输（全双工）。在互联网上无损，至少在某些传输层协议上，如TCP，当然在本地主机上也是如此。高速数据传输，特别是在本地主机上！流控制语义始终有效。异步通信；消息可以排队，所以发送者不必等待接收者。特别是关于我们的主题，在其他用户&lt;-&gt;内核通信路径（如procfs、sysfs、debugfs和ioctl）中，用户空间应用程序必须启动向内核空间的传输；使用netlink套接字，内核可以启动传输。此外，对于我们迄今为止看到的所有其他机制（procfs、sysfs和debugfs），散布在文件系统中的各种接口文件可能会导致内核命名空间污染；对于netlink套接字（顺便说一句，还有withitocl），情况并非如此，因为没有文件。这些优势可能会有所帮助，具体取决于您正在开发的产品类型。现在，让我们了解一下什么是netlink套接字。</p>
<h4 id="了解什么是netlink套接字"><a href="#了解什么是netlink套接字" class="headerlink" title="了解什么是netlink套接字"></a>了解什么是netlink套接字</h4><p>​    那么，什么是netlink套接字呢？我们将保持简单——netlink套接字是一个“特殊”的套接字家族，自2.2版本以来仅存在于Linux操作系统上。使用它，您可以在用户模式进程（或线程）和内核中的组件之间设置进程间通信（IPC）；在我们的例子中，是一个内核模块，通常是一个驱动程序。它在许多方面类似于UNIX域数据报套接字；它仅用于在本地主机上进行通信，而不是跨系统通信。UNIX域套接字使用路径名作为其命名空间（一个特殊的“套接字”文件），而netlink套接字使用PID。奇怪的是，这是一个端口ID，而不是进程ID，尽管实际上，进程ID经常被用作名称空间。现代内核核心（除了驱动程序）在许多情况下使用netlinksockets——例如，iproute2网络实用程序使用它来配置无需重新布线的驱动程序。另一个有趣的例子是，udev功能使用netlink套接字来实现内核udev实现和用户空间守护进程（udevd或systemd-udevd，用于设备发现、设备节点配置等）之间的通信。在这里，我们将使用netlink套接字设计和实现一个简单的用户&lt;-&gt;内核消息传递演示。为此，我们必须编写两个程序（至少）——一个是发出基于套接字的系统调用的用户空间应用程序，另一个是内核空间组件（这里是一个内核模块）。我们将让用户空间进程向内核模块发送一条“消息”；内核模块应该接收它并将其打印（到内核日志缓冲区中）。然后，内核模块将回复用户空间进程，该进程正在阻塞此事件。所以，闲话少说，让我们深入学习使用netlink套接字编写一些代码；我们将开始使用用户空间应用程序。继续读！</p>
<h4 id="编写用户空间netlink套接字应用程序"><a href="#编写用户空间netlink套接字应用程序" class="headerlink" title="编写用户空间netlink套接字应用程序"></a>编写用户空间netlink套接字应用程序</h4><p>​    按照以下步骤运行用户空间应用程序：1。我们必须做的第一件事就是给自己弄个插座。传统上，套接字被定义为通信的端点；因此，一对插座形成连接。我们将使用socket（2）系统调用来实现这一点。它的签名是int套接字（int域、int类型、int协议）；。</p>
<p>​    在不深入细节的情况下，我们这样做：我们将域指定为特殊PF_NETLINK家族的一部分，从而请求一个NETLINK套接字。使用原始套接字将类型设置为SOCK_RAW（有效地跳过传输层）。协议是要使用的协议。由于我们使用的是原始套接字，因此协议由我们或内核实现；让内核netlink代码这样做是正确的方法。这里，我们使用一个未使用的协议号；即31.2。下一步是通过通常的bind（2）系统调用语义绑定套接字。首先，我们必须为此目的初始化一个netlink源socketadr结构（其中我们将系列指定为netlink，将PID值指定为调用进程的PID（仅适用于单播））。以下代码用于这里提到的前两个步骤（为了清楚起见，我们在这里不会显示错误检查代码）：</p>
<pre class="line-numbers language-none"><code class="language-none"> &#x2F;&#x2F; kernel netlink protocol \# (registered by our kernel module)
\#define NLSPACE 1024
[...]
 &#x2F;* 1. Get ourselves an endpoint - a netlink socket! *&#x2F;
sd &#x3D; socket(PF_NETLINK, SOCK_RAW, NETLINK_MY_UNIT_PROTO);
printf(&quot;s:PID d: netlink socket created\n&quot;, argv[0], getpid());
&#x2F;* 2. Setup the netlink source addr structure and bind it *&#x2F;
memset(&amp;src_nl, 0, sizeof(src_nl));
src_nl.nl_family &#x3D; AF_NETLINK;
&#x2F;* Note carefully: nl_pid is NOT necessarily the PID of the sender
process; it&#39;s actually &#39;port id&#39; and can be any unique number *&#x2F;
src_nl.nl_pid &#x3D; getpid();
src_nl.nl_groups &#x3D; 0x0; &#x2F;&#x2F; no multicast
bind(sd, (struct sockaddr *)&amp;src_nl, sizeof(src_nl))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>3。接下来，我们必须初始化一个netlink“目的地址”结构。在这里，我们将PID成员设置为0，这是一个特殊的值，表示目标是内核：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;* 3. Setup the netlink destination addr structure *&#x2F;
memset(&amp;dest_nl, 0, sizeof(dest_nl));
dest_nl.nl_family &#x3D; AF_NETLINK;
dest_nl.nl_groups &#x3D; 0x0; &#x2F;&#x2F; no multicast
dest_nl.nl_pid &#x3D; 0; &#x2F;&#x2F; destined for the kernel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>4。接下来，我们必须分配并初始化一个netlink“header”数据结构。除此之外，它还指定了源PID，重要的是，还指定了我们将交付给内核组件的数据“有效载荷”。在这里，我们使用NLMSG_DATA（）等helpermacros来指定换行符标头结构中的正确数据位置：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;* 4. Allocate and setup the netlink header (including the payload)
*&#x2F;
nlhdr &#x3D; (struct nlmsghdr *)malloc(NLMSG_SPACE(NLSPACE));
memset(nlhdr, 0, NLMSG_SPACE(NLSPACE));
nlhdr-&gt;nlmsg_len &#x3D; NLMSG_SPACE(NLSPACE);
nlhdr-&gt;nlmsg_pid &#x3D; getpid();
&#x2F;* Setup the payload to transmit *&#x2F;
strncpy(NLMSG_DATA(nlhdr), thedata, strlen(thedata)+1);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>5.接下来，必须初始化iovec结构以引用netlink标头，必须初始化msghdr数据结构以指向目标地址和iovec:</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;* 5. Setup the iovec and ... *&#x2F;
memset(&amp;iov, 0, sizeof(struct iovec));
iov.iov_base &#x3D; (void *)nlhdr;
iov.iov_len &#x3D; nlhdr-&gt;nlmsg_len;
[...]
&#x2F;* ... now setup the message header structure *&#x2F;
memset(&amp;msg, 0, sizeof(struct msghdr));
msg.msg_name &#x3D; (void *)&amp;dest_nl; &#x2F;&#x2F; dest addr
msg.msg_namelen &#x3D; sizeof(dest_nl); &#x2F;&#x2F; size of dest addr
msg.msg_iov &#x3D; &amp;iov;
msg.msg_iovlen &#x3D; 1; &#x2F;&#x2F; \# elements in msg_iov<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    最后，消息通过sendmsg（2）系统调用发送（传输）（该调用将套接字描述符和上述msghdr结构作为参数）：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;* 6. Actually (finally!) send the message via sendmsg(2) *&#x2F;
nsent &#x3D; sendmsg(sd, &amp;msg, 0);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>7。内核组件——我们稍后将讨论的内核模块——现在应该通过其netlink套接字接收消息并显示消息内容；我们安排它然后礼貌地回复。为了获取回复，我们的用户spaceapp现在必须在套接字</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;* 7. Block on incoming msg from the kernel-space netlink component
*&#x2F;
printf(&quot;s: now blocking on kernel netlink msg via recvmsg()
...\n&quot;, argv[0]);
nrecv &#x3D; recvmsg(sd, &amp;msg, 0);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>我们必须使用recvmsg（2）系统调用来实现这一点。当它被解锁时，它表示消息已被接收。为什么对数据结构进行如此多的抽象和包装？好吧，事情通常是这样发展的——创建msghdr结构是为了让endmsg（2）API可以使用更少的参数。但这意味着参数必须有所变化；它们深入到msghdr内部，msghdr指向目标地址，iovec的基成员指向包含有效载荷的netlink标头结构！呼。作为一项实验，如果我们过早地构建和运行用户模式的netlink应用程序，而没有内核端代码，会怎么样？当然，它会失败的。。。但具体是怎么回事？好吧，使用实证方法。通过古老的strace（1）实用程序进行尝试，我们可以看到socket（2）系统调用返回失败，原因是Protocol不受支持：</p>
<p>​    这是正确的；内核中还没有这样的协议#31（31=0x1f，我们正在使用的协议号）！我们还没有做到这一点。所以，这就是事物的用户空间方面。现在，让我们完成这个谜题，让它真正发挥作用！我们将通过了解内核组件（模块/驱动程序）的编写方式来实现这一点。</p>
<h4 id="将内核空间netlink套接字代码编写为内核模块"><a href="#将内核空间netlink套接字代码编写为内核模块" class="headerlink" title="将内核空间netlink套接字代码编写为内核模块"></a>将内核空间netlink套接字代码编写为内核模块</h4><p>​    内核为netlink提供了基础架构，包括API和数据结构；所有必需的内容都已导出，因此您可以作为模块作者使用。我们使用其中的几个；这里概述了对内核netlink组件（内核模块）进行编程的步骤：1。就像用户空间应用程序一样，我们必须做的第一件事就是给自己找一个线路插座。内核API为netlink_kernel_create（），其签名如下</p>
<pre class="line-numbers language-none"><code class="language-none">struct sock * netlink_kernel_create(struct net *, int , struct
netlink_kernel_cfg *);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>第一个参数是通用网络结构；我们在这里传递内核的现有有效initnet结构。第二个参数是要使用的协议号（单位）；我们将指定与用户spaceapp相同的数字（31）。第三个参数是指向（可选）网络链路配置结构的指针；在这里，我们只将输入成员设置为我们的函数，使theret无效。当用户空间进程（或线程）向内核netlink组件提供任何输入（即传输某些内容）时，会回调此函数。因此，在内核模块的init例程中，我们有</p>
<pre class="line-numbers language-none"><code class="language-none">\#define OURMODNAME &quot;netlink_simple_intf&quot;
\#define
&#x2F;&#x2F; kernel netlink protocol \# that we&#39;re registering
static struct sock *nlsock;
[...]
static struct netlink_kernel_cfg nl_kernel_cfg &#x3D; &#123;
 .input &#x3D; netlink_recv_and_reply,
&#125;;
[...]
nlsock &#x3D; netlink_kernel_create(&amp;init_net, NETLINK_MY_UNIT_PROTO,
 &amp;nl_kernel_cfg);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>2。正如我们之前提到的，当用户空间进程（或线程）向我们的内核（netlink）模块或驱动程序提供任何输入（即传输某些内容）时，回调函数会被调用。重要的是要理解它在进程上下文中运行，而不是在任何类型的中断上下文中运行；我们使用我们的便利.h:PRINT_CTX（）宏来验证这一点（我们将在第4章“处理硬件中断”的“完全弄清楚上下文”一节中介绍这一点）。在这里，我们只需显示收到的消息，然后通过向用户空间对等进程发送示例消息进行回复。从我们的用户空间对等进程传输的数据有效载荷可以从套接字缓冲区结构中检索，该结构作为参数传递给我们的回调函数，也可以从其中的netlink头结构中检索。您可以在这里看到数据和发送方PID是如何检索的</p>
<pre class="line-numbers language-none"><code class="language-none">static void netlink_recv_and_reply(struct sk_buff *skb)
&#123;
 struct nlmsghdr *nlh;
 struct sk_buff *skb_tx;
 char *reply &#x3D; &quot;Reply from kernel netlink&quot;;
 int pid, msgsz, stat;
 &#x2F;* Find that this code runs in process context, the process
 * (or thread) being the one that issued the sendmsg(2) *&#x2F;
 PRINT_CTX();
 nlh &#x3D; (struct nlmsghdr *)skb-&gt;data;
 pid &#x3D; nlh-&gt;nlmsg_pid; &#x2F;*pid of sending process *&#x2F;
 pr_info(&quot;s: received from PID d:\n&quot;
 &quot;\&quot;s\&quot;\n&quot;, OURMODNAME, pid, (char *)NLMSG_DATA(nlh));<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>套接字缓冲区数据结构——结构sk_buff——被认为是Linux内核网络协议栈中的关键数据结构。它保存了所有与网络数据包有关的元数据，包括它的动态指针。它必须快速分配和释放（特别是当网络代码在中断上下文中运行时）；这确实是可能的，因为它位于内核的slab（SLUB）缓存上（有关内核slaballocator的详细信息，请参阅配套指南《Linux内核编程》第7章“内存管理内部-要点”、第8章“模块作者的内核内存分配-第1部分”和第9章“模块作家的内核内存配置-第2部分”）。现在，我们需要了解，我们可以通过首先解引用传递给回调例程的套接字缓冲区（skb）结构的数据成员来从网络数据包中检索有效载荷！接下来，这个数据成员实际上是指向我们的用户spacepeer设置的netlink消息头结构的指针。然后，我们取消引用它以获得实际的有效载荷。</p>
<p>​    3。我们现在想“回复”我们的用户空间对等进程；这样做需要采取一些行动。首先，我们必须使用thelmsg_new（）API分配一个新的netlink消息，它实际上是alloc_skb（）上的瘦包装，通过nlmsg_put（）API将一个tlink消息添加到刚刚分配的套接字缓冲区中，然后使用适当的emacro（nlmsg_data（））将数据（有效负载）复制到netlink头中：</p>
<pre class="line-numbers language-none"><code class="language-none">msgsz &#x3D; strlen(reply);
skb_tx &#x3D; nlmsg_new(msgsz, 0);
[...]
&#x2F;&#x2F; Setup the payload
nlh &#x3D; nlmsg_put(skb_tx, 0, 0, NLMSG_DONE, msgsz, 0);
NETLINK_CB(skb_tx).dst_group &#x3D; 0; &#x2F;* unicast only (cb is the
* skb&#39;s control buffer), dest group 0 &#x3D;&gt; unicast *&#x2F;
strncpy(nlmsg_data(nlh), reply, msgsz);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>4.我们通过nlmsg_unicast（）API向我们的用户空间对等进程发送回复（甚至可以多播netlink消息）：/</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;发送它
stat&#x3D;nlmsg_unicast（nlsock，skb_tx，pid）；<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>5.这只剩下清理（当内核模块被移除时调用）；当netlink_kernel_release（）API清理netlink套接字并关闭它时，它实际上是netlink_kernel_create（）的反转：</p>
<pre class="line-numbers language-none"><code class="language-none">static void __exit netlink_simple_intf_exit（void）&#123;
	netlink_kernel_releases(nlsock);
    pr_info(“s:removed\n”，OURMODNAME);
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>现在我们已经将用户空间应用程序和内核模块都编写为通过一个tlink套接字进行接口，让我们实际尝试一下！</p>
<h4 id="通过ioctl系统调用进行接口连接ioctl是一个系统调用"><a href="#通过ioctl系统调用进行接口连接ioctl是一个系统调用" class="headerlink" title="通过ioctl系统调用进行接口连接ioctl是一个系统调用"></a>通过ioctl系统调用进行接口连接ioctl是一个系统调用</h4><p>​    为什么叫ioctl这个有趣的名字？它是输入输出控制的缩写。虽然读写系统调用（以及其他）用于有效地在设备（或文件）之间传输数据；记住UNIX范式，如果它不是进程，它就是文件！），但ioctl系统调用用于向设备发出命令（通过其驱动程序）。例如，更改控制台设备的终端特性、在格式化时将轨道写入磁盘、向步进电机发送控制命令、控制相机或音频设备等，都是向设备发送命令的实例。让我们考虑一个虚构的例子。我们有一个设备，正在为它开发一个（字符）设备驱动程序。该设备有各种寄存器，通常是设备上的8位、16位或32位硬件存储器，其中一些是控制寄存器。通过适当地对它们执行I/O（读取和写入），我们可以控制设备（好吧，这才是重点，不是吗；下一章将介绍有关使用硬件内存（包括设备寄存器）的细节的实际主题）。那么，作为驱动程序的作者，您将如何与希望在此设备上执行各种控制操作的用户空间程序进行通信或交互？我们经常构建用户空间C（或C++）程序，通常通过在设备文件上执行open（2）来打开设备，随后发出读写系统调用。但是，正如我们刚才提到的，在传输数据时，读取（2）和写入（2）系统调用API是合适的，而在这里，我们打算执行控制操作。因此，我们需要另一个系统调用来实现这一点……那么我们是否需要创建并编码一个或多个新的系统调用？不，它比这简单得多：我们通过ioctl系统调用进行多路复用，利用它在我们的设备上执行任何所需的控制操作！怎么用？啊，回想一下前一章中最重要的file_operations（fops）数据结构；现在，我们将初始化另一个成员，即.ioctl成员到我们的ioctl方法函数中，从而允许我们的设备驱动程序挂接到这个系统调用：</p>
<pre class="line-numbers language-none"><code class="language-none">static struct file_operations ioct_intf_fops &#x3D; &#123;
 .llseek &#x3D; no_llseek,
 .ioctl &#x3D; ioct_intf_ioctl,
 [...]
&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    实际上，我们必须弄清楚是应该使用ioctl还是file_operations结构的unlocked_ictl成员，这取决于该模块是否在Linux内核版本2.6.36或更高版本上运行；下文将对此进行更多介绍。</p>
<p>​    事实上，向内核添加新的系统调用不是一件容易的事情！内核chaps不允许任意添加系统调用——毕竟这是一个安全敏感的接口。更多信息请点击此处：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/kernel-hacking/hacking.html\#ioctls-ioctls-not-writing-a-new-system-call.关于使用ioctl进行接口的更多信息如下。在用户和内核空间中使用ioctl">https://www.kernel.org/doc/html/latest/kernel-hacking/hacking.html\#ioctls-ioctls-not-writing-a-new-system-call.关于使用ioctl进行接口的更多信息如下。在用户和内核空间中使用ioctl</a> ioctl（2）系统调用的签名如下</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;sys&#x2F;ioctl.h&gt;
int ioctl(int fd, unsigned long request, ...);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    参数列表是一个变量参数。实际上，我们通常会传递两到三个参数：第一个参数是显而易见的——（在我们的例子中）打开的设备文件的文件描述符。第二个参数，称为request，是一个有趣的参数：它是要传递给驱动程序的命令。实际上，它是一种编码，封装了一个所谓的ioctl幻数：一个数字和一个类型（读/写）。（可选）第三个参数，通常称为arg，也是一个无符号长量；我们使用它以通常的方式将一些数据传递给底层驱动程序，或者通常通过传递其（虚拟）地址并让内核写入其中，利用C所谓的值结果或输入输出参数样式，将数据返回给用户空间。现在，正确使用ioctl并不像使用许多其他API那样简单。想一想：你很容易就会遇到这样一种情况，即几个用户空间应用程序正在向其底层设备驱动程序发出octl（2）系统调用（发出各种命令）。一个问题变得显而易见：内核VFS层将如何将ioctl请求定向到正确的驱动程序？ioctl通常在具有唯一（主要、次要）编号的char设备文件上执行；因此，另一个驱动程序如何接收您的ioctl命令（除非您有意或恶意地以这种方式设置设备文件）？</p>
<p>​    然而，存在一种协议来实现ioctl的安全和正确使用；每个应用程序和驱动程序都定义了一个幻数，该幻数将被编码到其所有ioctl请求中。首先，驱动程序将验证它收到的每个ioctl请求是否包含其幻数；只有到那时，它才会继续处理它；否则，它将直接丢弃它。当然，这为ABI带来了必要的条件——我们需要为每个“注册”的驱动程序分配唯一的幻数（它可能是一个范围）。由于这创建了一个ABI，内核文档将是相同的；你可以在这里找到谁在使用哪个神奇数字（或代码）的详细信息：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/ioctl/ioctl-number.txt">https://www.kernel.org/doc/Documentation/ioctl/ioctl-number.txt</a>. 对底层驱动程序的ioctl请求基本上可以是四种情况之一：向设备“写入”的命令、从设备“读取”（或查询）的命令、同时进行读/写传输的命令，或者两者都不进行。此信息（再次）通过定义某些位来编码到请求中，以传达其含义：为了使这项工作更容易，我们有四个辅助宏，允许我们构造ioctl命令：_IO（type，nr）：对没有参数的ioctl命令进行编码_IOR（type，nr，datatype）：对用于从内核/driver_IOW读取数据的ioctl指令进行编码（type，nr，datatype tl.h&gt;头文件，在内核中包括/uapi/asm generic/ioctl.h。典型的（也是非常明显的）最佳实践是创建一个通用头文件，定义应用程序/驱动程序的ioctl命令，并在用户模式应用程序和设备驱动程序中包括该文件。在这里，作为演示，我们将设计和实现一个用户空间应用程序和一个内核空间设备驱动程序，以驱动一个通过ioctl（2）系统调用进行通信的虚构设备。因此，我们必须定义一些通过ioctl接口发出的命令。我们将在公共头文件中执行此操作</p>
<p><img src="./image-20240723071721724.png" alt="image-20240723071721724"></p>
<p>我们的三个命令（以粗体突出显示）都前缀为UDT LLKD_，表示它们都是我们虚构的LLKD项目的IOCTL命令；接下来，它们的后缀为IOC{Q|S}，IOCimpling表示这是一个ioctl命令，Q表示这是查询操作，S表示这是aset操作。现在，让我们学习如何从用户空间和内核空间（驱动程序）在代码级别进行设置。用户空间-使用ioctl系统调用ioctl（2）系统调用的用户空间签名如下</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;sys&#x2F;ioctl.h&gt;
int ioctl(int fd, unsigned long request, ...);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>在这里，我们可以看到它需要一个变量参数列表；ioctl的参数如下：第一个参数：要对其执行ioctl操作的文件或设备的文件描述符（在我们的例子中就是这样）（我们通过对设备文件执行open来获得fd）。第二个参数：向底层设备驱动程序（或文件系统或fd表示的任何东西）发出的请求或命令。可选的第三个（或更多）参数：通常，第三个参数是一个整数（或指向整数或数据结构的指针）；我们使用这种方法，在发出一组命令时，向驱动程序传递一些额外的信息，或者通过易于理解的按引用传递C范式从驱动程序检索一些信息，在这种范式中，我们传递指针并让驱动器“戳”它，从而将参数视为返回值。</p>
<p>​    实际上，ioctl通常用作通用系统调用。使用ioctl在硬件和软件上执行命令操作的规模几乎惊人！请参阅内核文档（documentation/ioctl/&lt;…&gt;）以查看许多实际的实际示例。</p>
<p>内核空间——使用ioctl系统调用在上一节中，我们看到内核驱动程序必须初始化其file_operations结构以包含ioctl方法。不过，还有更多：Linux内核不断发展；在早期的内核版本中，开发人员使用了一种非常粗粒度的锁，尽管它有效，但严重损害了它的性能（我们将在第6章“内核同步-第1部分”和第7章“内核同期-第2部分”中详细讨论锁定）。它太糟糕了，所以被戏称为大内核锁（BKL）！好消息是，在内核版本2.6.36中，开发人员摆脱了这个臭名昭著的锁。不过，这样做也有一些副作用：其中之一是，使用名为unlocked_ictl的新方法，发送到内核内ioctl方法的参数数量从四个变为三个，从而在我们的file_operations数据结构中。因此，对于我们的演示驱动程序，在初始化驱动程序的file_operations结构时，我们将使用以下内容初始化ioctl方法：</p>
<p><img src="./image-20240723071850131.png" alt="image-20240723071850131"></p>
<p>显然，正如fops驱动程序中定义的那样，ioctl被认为是一个私有驱动程序接口（驱动程序私有）。此外，在驱动程序代码中的函数定义中，必须考虑到关于较新“解锁”版本的这一事实；我们的驱动程序是这样做的</p>
<p><img src="./image-20240723071859300.png" alt="image-20240723071859300"></p>
<p>这里的关键代码是驱动程序的ioctl方法。想想看：一旦完成了基本的有效性检查，驱动程序真正要做的就是对用户空间应用程序发出的所有可能的有效ioctl命令执行切换。让我们来看一下以下代码（为了可读性，我们将跳过\#if LINUX_VERSION_code&gt;=…宏指令，只显示现代ioctl函数签名，以及一些有效性检查；</p>
<pre class="line-numbers language-none"><code class="language-none">static long ioctl_intf_ioctl(struct file *filp, unsigned int cmd, unsigned
long arg)
&#123;
 int retval &#x3D; 0;
 pr_debug(&quot;In ioctl method, cmd&#x3D;d\n&quot;, _IOC_NR(cmd));
 &#x2F;* Verify stuff: is the ioctl&#39;s for us? etc.. *&#x2F;
 [...]
 switch (cmd) &#123;
 case IOCTL_LLKD_IOCRESET:
 pr_debug(&quot;In ioctl cmd option: IOCTL_LLKD_IOCRESET\n&quot;);
 &#x2F;* ... Insert the code here to write to a control register to reset
 the device ... *&#x2F;
 break;
 case IOCTL_LLKD_IOCQPOWER: &#x2F;* Get: arg is pointer to result *&#x2F;
 pr_debug(&quot;In ioctl cmd option: IOCTL_LLKD_IOCQPOWER\n&quot;
 &quot;arg&#x3D;0xx (drv) power&#x3D;d\n&quot;, (unsigned int)arg, power);
 if (!capable(CAP_SYS_ADMIN))
 return -EPERM;
 &#x2F;* ... Insert the code here to read a status register to query the
 * power state of the device ... * here, imagine we&#39;ve done that
 * and placed it into a variable &#39;power&#39;
 *&#x2F;
 retval &#x3D; __put_user(power, (int __user *)arg);
 break;
 case IOCTL_LLKD_IOCSPOWER: &#x2F;* Set: arg is the value to set *&#x2F;
 if (!capable(CAP_SYS_ADMIN))
 return -EPERM;
 power &#x3D; arg;
 &#x2F;* ... Insert the code here to write a control register to set the
 * power state of the device ... *&#x2F;
 pr_debug(&quot;In ioctl cmd option: IOCTL_LLKD_IOCSPOWER\n&quot;
 &quot;power&#x3D;d now.\n&quot;, power);
 break;
 default:
 return -ENOTTY;
 &#125;
[...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    _IOC_NR宏用于从cmd参数中提取命令号。在这里，我们可以看到驱动程序对通过用户spaceprocess发出的ioctl的三种有效情况做出了“反应”：在收到UDT LLKD_IOCRESET命令时，它会执行设备重置。在收到ArgumentLLKD_IOCQPOWER命令后，它会进行查询（Q表示查询）并返回当前电源状态（通过使用值-结果C编程方法将其值戳入第三个参数arg）。在接收ACKLLKD_IOCSPOWER命令时，它将电源状态设置为（S代表set）（第三个参数arg中传递的值）。当然，由于我们使用的是一个纯粹虚构的设备，我们的驱动程序实际上并没有执行任何注册（或其他硬件）工作。这个驱动程序只是一个你可以使用的模板。如果黑客试图在（相当笨拙的）黑客攻击中发出我们的驾驶员未知的命令怎么办？好吧，最初的有效性检查会发现它；即使它们没有，我们也会在ioctl方法中遇到故障情况，导致驱动程序向用户空间返回-ENOTTY。这将通过glibc“粘合”代码将用户空间进程（或线程）的errno值设置为ENOTTY，通知它无法为ioctl方法提供服务。我们的用户空间perror（3）API将显示设备错误消息的Inappropriate ioctl。事实上，如果驱动程序没有ioctl方法（也就是说，如果file_operations结构中的octl成员设置为NULL），并且用户空间应用程序对其发出ioctl方法，就会发生这种情况；为了方便起见，一旦加载了驱动程序（通过insmod），您就可以使用h2/userspace_ioctl/cr8devnode.sh便利脚本来生成设备文件。设置完成后，运行用户空间应用程序；您会发现，连续运行它会反复切换我们虚构设备的“电源状态”。ioctl作为调试接口。正如我们在本章开头提到的，使用ioctl接口进行调试怎么样？它可以用于此目的。您始终可以在switch case块中插入“debug”命令；它可用于向用户空间应用程序提供有关驱动程序状态、关键变量值（健康监测）等的有用信息。</p>
<p>​    不仅如此，除非明确记录给最终用户或客户，否则通过ioctl接口使用的精确命令是未知的；因此，您需要记录界面，同时为其他团队或客户提供足够的细节，以充分利用它们。这就引出了一个有趣的问题：您可能会选择故意不记录某个ioctl命令；现在，它是一个“隐藏”的命令，例如，现场工程师可以使用它来检查设备。（我将此作为一项任务留给您。）ioctl的内核文档包括以下文件：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/ioctl/botching-up-ioctls.txt.虽然偏向于内核图形堆栈开发人员，但它描述了典型的设计错误、权衡等。">https://www.kernel.org/doc/Documentation/ioctl/botching-up-ioctls.txt.虽然偏向于内核图形堆栈开发人员，但它描述了典型的设计错误、权衡等。</a></p>
<h2 id="Working-with-Hardware-I-O"><a href="#Working-with-Hardware-I-O" class="headerlink" title="Working with Hardware I/O"></a>Working with Hardware I/O</h2><h4 id="从内核访问硬件I-O内存"><a href="#从内核访问硬件I-O内存" class="headerlink" title="从内核访问硬件I/O内存"></a>从内核访问硬件I/O内存</h4><p>​    作为设备驱动程序作者，您可能会面临一个有趣的问题：您需要能够访问和处理外围芯片的I/O内存、硬件寄存器和/或硬件内存。事实上，这通常是驱动程序在“金属”级别对硬件进行编程的方式：通过其寄存器和/或外围存储器向其发出命令。但是，在Linux上直接访问硬件I/O内存会遇到一个问题。在第一节中，我们将研究这个问题并提供解决方案。了解直接访问的问题当然，芯片上的这个硬件内存，即所谓的I/O内存，不是RAM。Linux内核拒绝模块或驱动程序作者直接访问这些硬件I/O位置。我们已经知道原因：在现代基于VM的操作系统上，所有内存访问都必须通过内存管理单元（MMU）和分页表。让我们快速总结一下第7章“内存管理内部-要点”中配套指南《Linux内核编程》中的关键方面：默认情况下，内存是虚拟的，这意味着所有地址都是虚拟的而不是物理的（这包括内核段或VAS中的地址）。这样想吧：一旦进程（或内核）访问了一个虚拟地址进行读取、写入或执行，系统就必须从相应的物理地址获取内存内容。这涉及在运行时将虚拟地址转换为物理地址；硬件优化（CPU缓存、翻译后备缓冲区（TLB）等）可以加快这一速度。</p>
<p>​    执行的过程如下：</p>
<ol>
<li>首先，检查CPU缓存（L1-D/L1-I、L2等），查看此虚拟地址引用的内存是否已在CPUcache芯片上。</li>
<li>如果内存已经在板上，则缓存命中，工作就完成了。如果没有（这是最后一级缓存-LLC丢失-代价高昂！），虚拟地址将被馈送到微处理器MMU.</li>
<li>MMU现在在处理器TLB中查找相应的物理地址。如果它在那里，我们有一个TLB命中，工作就完成了；如果没有，我们有TLB未命中（这很昂贵！）。</li>
<li>MMU现在遍历进行访问的用户空间进程的分页表；或者，如果内核进行了访问，它会遍历内核分页表，将虚拟地址转换为相应的物理地址。此时，物理地址被放置在总线上，工作就完成了。请参阅TI的OMAP35x技术参考手册，网址为<a target="_blank" rel="noopener" href="https://www.ti.com/lit/ug/spruf98y/spruf98y.pdf?ts=1594376085647">https://www.ti.com/lit/ug/spruf98y/spruf98y.pdf?ts=1594376085647</a></li>
</ol>
<p>​    此外，我们还提到，实际的地址翻译过程当然非常依赖于拱。在某些系统中，顺序如下图所示；在其他情况下（通常在ARM上），首先执行MMU（包括TLB查找），然后检查CPU缓存。所以，想想看：即使是正常的RAM位置也不会被现代操作系统上运行的软件直接访问；这是因为它的内存是虚拟化的。在这种情况下，分页表（每个进程以及内核本身）使操作系统能够将虚拟地址转换为物理地址。（我们在我们的配套书籍《Linux内核编程》第7章“内存管理内部——基础”中的“虚拟寻址和地址转换”一节中详细介绍了这些领域；如果需要，请回头看看以刷新这些关键点。）现在，如果我们有一个包含I/O内存的硬件外围设备或芯片，如果我们考虑到这个内存不是RAM的事实，这个问题似乎更加复杂。那么，这个内存不是由分页表映射的吗？是吗？在下一节中，我们将探讨这个问题的两种常见解决方案，请继续阅读！解决方案——通过I/O内存或I/O端口进行映射为了解决这个问题，我们必须明白，现代处理器提供了两种访问和使用硬件I/O（外围芯片）内存的方式：通过为这些外围设备保留处理器地址空间的一些区域；即通过使用内存映射I/O（MMIO）作为I/O的映射类型。</p>
<p>​    通过提供不同的汇编（和相应的机器）CPUi指令来直接访问I/O存储器。将这种映射类型用于I/O称为端口映射I/O（PMIO或简称PIO）。我们将在理解和使用内存映射I/O和理解和使用端口映射I/O部分分别考虑这两种技术。不过，在我们这样做之前，我们需要学习如何礼貌地请求内核允许使用这些I/Oresource！询问内核的权限请考虑一下：即使您知道使用哪个API以某种方式映射或工作I/O内存，首先，您也需要向操作系统请求权限。毕竟，操作系统是系统的整体资源管理器，在使用其资源之前，您必须很好地询问它。当然，还有更多的事情要做——当你问它的时候，你真正要做的是让它设置一些内部数据结构，让内核了解哪个驱动程序或子系统正在使用哪个I/O内存区域或端口。在执行任何外围I/O之前，你需要请求内核的许可，假设你得到了许可，你就可以执行I/O。之后，你需要将I/O区域释放回内核。此过程涉及以下步骤：</p>
<ol>
<li>I/O之前：请求访问内存或端口区域。</li>
<li>收到内核内核内核的绿灯后，执行实际的I/O：您可以使用MMIO或PMIO来执行此操作（详细信息见下表）。</li>
<li>I/O后：将内存或端口区域释放回操作系统。</li>
</ol>
<p>那么，如何执行这些请求、I/O和发布操作呢？有一些API可以做到这一点，您应该使用的API取决于您是使用MMIO还是PMIO。下表总结了在执行I/O之前应该使用的API，然后在完成此工作后释放区域（执行I/O的实际API将在稍后介绍）</p>
<p><img src="./image-20240724075559001.png" alt="image-20240724075559001"></p>
<p><img src="./image-20240724075608430.png" alt="image-20240724075608430"></p>
<p>执行I/O操作后，释放该区域。release_mem_regic（）release_region（）上表所示的函数在linux/iport.h头文件中定义为宏；它们的签名如下：</p>
<pre class="line-numbers language-none"><code class="language-none">request_mem_region(start, n, name); [...] ; release_mem_region(start, n);
request_region(start, n, name); [...] ; release_region(start, n);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    所有这些宏本质上都是__request_region（）和__release_reregion（）内部API的包装器。这些宏的参数如下：start是I/O内存区域或端口的开头；对于MMIO，它是一个物理（或总线）地址，而对于PMIO，它则是一个端口号。n是所请求的区域的长度。name是您想将映射的区域或端口范围与之关联的任何名称。它通常是执行I/O操作的驱动程序的名称（您可以在proc文件系统中看到它；我们将在介绍如何使用MMIO和PMIO时对此进行更详细的介绍）。request_[mem_]region（）API/宏的返回值是一个指向构造资源的指针（同样，在获取设备资源一节中对此有更多介绍）。如果返回NULL，则意味着资源未能被保留；驱动程序通常返回-EBUSY，表示资源现在正忙或不可用（可能是因为另一个组件/驱动程序已经请求并正在使用它）。在接下来的部分中，我们将提供一些使用这些API/宏的实际示例。现在，让我们学习如何实际映射和使用I/O内存。我们将从几乎所有现代处理器都支持的通用方法开始；即MMIO。理解和使用内存映射的I/O在MMIO方法中，CPU理解其地址空间的某个区域（或几个）是为I/O外围存储器保留的。您实际上可以通过参考给定处理器（或SoC）数据表的物理内存映射来查找区域。</p>
<p>正如我们所看到的，这是一个寄存器块（或存储体），一组用于类似目的的32位寄存器（此处为GPIO）。在上图中，我们当前目的的关键列是第一列，即地址列：这是物理或总线地址，也是ARM处理器物理地址空间中看到GPIO寄存器的位置。它从0x7e20 0000开始（因为这是前面屏幕截图中的第一个地址），长度有限（这里，它被记录为每个32位的41个寄存器，所以我们将该区域的长度取为41*4字节）。使用ioremap*（）APIsNow，正如我们在理解直接访问问题一节中看到的，试图直接在这些物理或总线地址上执行I/O根本行不通。我们应该这样做的方式是告诉Linux将这些总线地址映射到内核的VAS中，这样我们就可以通过内核虚拟地址（KVA）访问它！我们该怎么做？内核为此目的提供API；驱动程序作者使用的一个非常常见的方法是theoremap（）API。它的签名如下：</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;asm&#x2F;io.h&gt;
void __iomem *ioremap(phys_addr_t offset, size_t size)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    asm/io.h头文件根据需要成为特定于arch的头文件。请注意ioremap（）的第一个参数是一个物理（或总线）地址（它的数据类型是phys_addr_t）。这是Linux中极少数情况之一，作为驱动程序作者，您必须提供物理地址，而不是虚拟地址（另一种典型情况是在执行直接内存访问（DMA）操作时）。第二个参数很明显；这是我们必须映射的内存I/O区域的大小或长度。当被调用时，ioremap（）例程将把I/Ochips或外围存储器从偏移量开始映射到内核的VAS中，长度为字节！这是必要的——使用内核权限运行时，您的驱动程序现在可以通过返回指针访问此I/Omemory区域，从而在内存区域上执行I/O。想想看！就像mmap（）系统调用允许您将KVA空间的一个区域映射到用户空间进程一样，[devm_]ioremap*（）（和friends）API允许您将外围I/O内存区域映射到KVA空间。ioremap（）API返回一个void*类型的KVA（因为它是一个地址位置）。那么，这里看起来奇怪的__iomem指令是什么（void __iomem*）？它只是一个编译器属性，在构建时会被删除；它只是提醒我们人类（以及执行健全性检查或查看静态分析代码），这是一个I/O地址，而不是您的常规RAM地址！</p>
<p>​    因此，对于前面的示例，在Raspberry Pi设备上，您可以通过执行以下操作将GPIO寄存器库映射到KVA（这不是实际代码，而是向您展示如何调用ioremap（）API的示例）：</p>
<pre class="line-numbers language-none"><code class="language-none">\#define GPIO_REG_BASE 0x7e200000
\#define GPIO_REG_LEN 164 &#x2F;&#x2F; 41 * 4
static void __iomem *iobase;
[...]
if (!request_mem_region(GPIO_REG_BASE, GPIO_REG_LEN, &quot;mydriver&quot;)) &#123;
 dev_warn(dev, &quot;couldn&#39;t get region for MMIO, aborting\n&quot;);
 return -EBUSY; &#x2F;&#x2F; or -EINVAL, as appropriate
&#125;
iobase &#x3D; ioremap(GPIO_REG_BASE, GPIO_REG_LEN);
if (!iobase) &#x2F;&#x2F; handle any error
 [... perform the required IO ... ]
iounmap(iobase);
release_mem_region(GPIO_REG_BASE, GPIO_REG_LEN);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    iobase变量现在保存ioremap（）的返回值；这是一个KVA，一个内核虚拟地址。现在您可以使用它，只要它不是NULL（您需要验证这一点！）。因此，在这个例子中，ioremap（）的返回值是内核VAS中Raspberry Pi的GPIO寄存器（外围I/O存储器）现在映射并可用的位置。一旦完成，您将使用iounmap（）API取消映射（如前面的代码片段所示）；iounmap（）API的参数是显而易见的-I/O映射的开始（ioremap（）返回的值）：void iounmap（volatile void __iomem*io_addr）；因此，当我们将（GPIO寄存器）I/O内存映射到内核VAS中时，我们会得到一个KVA，以便我们可以使用它。有趣的是，ioremap（）API的返回值通常是内核VAS的vmalloc区域内的地址（有关详细信息，请参阅配套指南Linux内核编程-第7章，内存管理内部组件-要素）。这是因为ioremap通常分配并使用从内核的vmalloc区域映射所需的虚拟内存（但情况并非总是如此；ioremap_scache（）等变量可以使用vmalloc之外的区域）。这里，假设返回值——我们的iobase地址——是0xbbed 8000（参见图3.2：这里有一个2:2 GB的VMsplit，你可以看到iobase返回地址确实是内核vmalloc区域内的KVA）。以下是一个概念图，显示了这一点：</p>
<p><img src="./image-20240724075900944.png" alt="image-20240724075900944"></p>
<p>新品种——devm_*管理的API现在你已经了解了如何使用request_mem_regic（）和just-seeniomemap*（）API，你猜怎么着？现实情况是，这两个API现在都被认为是不可预防的；作为一名现代驱动程序作者，您应该使用更好的资源管理dvm_*API。（出于几个原因，我们介绍了较旧的驱动程序，包括许多较旧的驱动器仍然非常使用它们，为了理解使用oremap（）资源管理API的基础知识，以及为了完整性。）首先，让我们在lib/devres.c:</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;**
 * devm_ioremap - Managed ioremap()
 * @dev: Generic device to remap IO address for
 * @offset: Resource address to map
 * @size: Size of map
 *
 * Managed ioremap(). Map is automatically unmapped on driver detach.
 *&#x2F;
void __iomem *devm_ioremap(struct device *dev, resource_size_t offset,
 resource_size_t size)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>正如我们了解到的关于非常常见的kmalloc/kzalloc API（请参阅公司指南Linux内核编程，第8章，模块作者的内核内存分配-第1部分），devm_kmalloc（）和devm_kzallocs（）API简化了我们的生活，因为它们保证会释放在设备拆卸或驱动程序删除时分配的内存。以类似的方式，使用devm_ioremap（）意味着您不需要显式调用iounmap（）API，因为内核的devres框架将处理itupon驱动程序分离！同样，由于这本书主要不是专注于编写设备驱动程序，我们将提到bit，而不是深入探讨使用probe（）和remove（）/disconnect（）钩子的现代Linux设备模型（LDM）的细节。关于这一主题的其他文献可以在本章末尾的进一步阅读部分找到。请注意，任何devm_*（）API的第一个参数都是指向结构设备的指针（我们在第1章“编写简单错误字符设备驱动程序”中介绍了如何获得该指针，当时我们介绍了如何编写简单错误驱动程序）。</p>
<p>​    获取设备资源devm_ioremap（）API的第二个参数（参见前面一节中的签名）是resource_size_t offset。形式参数名称偏移量有点误导——它实际上是用于重新映射到内核VAS的外围I/O内存区域的物理或总线地址（事实上，resource_size_t数据类型只不过是phys_addr_t的typedef，一个物理地址）。本节和下一节的内容对Linux设备驱动程序作者来说很重要，因为它介绍了一些关键思想（设备树（DT）、平台和开发人员API等），并包含了一些常用的策略。但是如何获得devm_ioremap（）API的第一个参数——总线物理地址？确实是FAQ！当然，这是特定于设备的。话虽如此，起始总线或物理地址只是驱动程序作者可以（有时必须）指定的几个I/O资源之一。Linux内核为此提供了一个强大的框架——I/O资源管理框架，因为它允许您获取/设置硬件资源。有几种可用的资源；它包括设备MMIOranges、I/O端口范围、中断请求（IRQ）线、寄存器偏移、DMA和总线值。现在，为了使所有这些工作正常进行，必须在每个设备的基础上指定I/O资源。有两种主要的方法可以做到这一点：</p>
<p>​    传统方法：将它们（I/O资源）硬编码到内核源代码树中，通常称为板特定文件。（例如，对于流行的ARM CPU，这些通常位于arch/ARM/mach-&gt;foo/…，其中foo是机器（mach）或平台/板名称。再举一个例子，在Linux 3.10.6中，这些板特定文件中定义的平台设备数量为1670；迁移到现代DT方法后，5.4.0内核源代码树的这个数字减少到885。）</p>
<p>​    现代方法：通过将它们（I/O资源）放置在操作系统启动时可以发现的位置；这通常是针对嵌入式系统，如ARM-32、AArch64和PPC，通过一种称为DT（类似于VHDL）的硬件专用语言描述机载或平台的硬件拓扑（其上的所有硬件，如SoC、CPU、外围设备、磁盘、闪存芯片、传感器芯片等）来实现的。设备树源代码（DTS）文件位于内核源代码树下（对于ARM，在arch/ARM/boot/DTS/中），并在内核构建时（通过DT编译器；即dtc）编译为称为设备树Blob（DTB）的二进制格式。DTB通常在引导时由引导加载程序传递给内核。在启动初期，内核读取、扁平化并解释DTB，根据需要创建平台（和其他）设备，然后将它们绑定到相应的驱动程序。x86[_64]系统不存在DT。最接近的等价物可能是ACPI表。此外，请注意，DT不是Linux特有的技术；它被设计为与操作系统无关，通用组织被称为开放固件（OF）。正如我们之前提到的，使用这种现代模型，内核和/或设备驱动程序必须从DTB获取资源信息（在dea-include/linux/iport.h中填充：结构资源）。</p>
<p>​    怎么用？平台驱动程序通常通过platform_get_*（）API来实现这一点。我们希望通过内核源代码中的Video For Linux（V4L）媒体控制器驱动程序的一个例子来阐明这一点。此驱动程序适用于三星Exynos 4 SoC上的SP5电视混音器（用于某些Galaxy S2型号）。甚至在V4L驱动程序特定文档部分下也有一些内核文档：<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/v5.4/media/v4l-drivers/fimc.html\#the-samsung-s5p-exynos4-fimc-driver">https://www.kernel.org/doc/html/v5.4/media/v4l-drivers/fimc.html\#the-samsung-s5p-exynos4-fimc-driver</a>.</p>
<p>​    以下代码可以在drivers/gpu/drm/exinos/exinos_mixer.c中找到。这里，驱动程序利用platform_get_resource（）API来获得I/Omemory资源的值；即该外围芯片的I/O内存的起始物理地址</p>
<pre class="line-numbers language-none"><code class="language-none">struct resource *res;
 [...]
 res &#x3D; platform_get_resource(mixer_ctx-pdev, IORESOURCE_MEM, 0);
 if (res &#x3D;&#x3D; NULL) &#123;
 dev_err(dev, &quot;get memory resource failed.\n&quot;);
 return -ENXIO;
 &#125;
 mixer_ctx-&gt;mixer_regs &#x3D; devm_ioremap(dev, res-start,
 resource_size(res));
 if (mixer_ctx-&gt;mixer_regs &#x3D;&#x3D; NULL) &#123;
 dev_err(dev, &quot;register mapping failed.\n&quot;);
 return -ENXIO;
 &#125;
 [...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在前面的代码段中，驱动程序发出platform_get_resource（）API来为IORESOURCE_MEM类型资源（MMOmemory！）刻蚀指向资源结构的指针。然后，它发布devm_ioremap（）API，将该MMIO区域映射到kernelVAS中（如前一节中详细说明的那样）。使用devm版本的alleviatest，当完成此操作（或由于错误）时，需要手动取消映射I/O内存，从而减少泄漏的机会！与devm_ioremap_resource（）API融为一体作为驱动程序的作者，您应该了解并使用这个有用的例程：devm_oremap_resource（）管理的API执行（有效性）检查请求的I/O内存区域的工作，从内核请求（内部通过devm_request_mem_region（）API），并重新映射（内部通过devm_ioremap（））！这使它成为像您这样的驱动程序作者的有用包装器，它的使用非常普遍（在5.4.0内核代码库中，它被使用了1400多次）。其签名如下：void __iomem*devm_ioremap_resource（结构设备*dev，结构资源*res）；下面是drivers/char/hw_random/bcm2835 rng.c中的一个用法示例：</p>
<pre class="line-numbers language-none"><code class="language-none">static int bcm2835_rng_probe(struct platform_device *pdev)
&#123;
 [...]
 struct resource *r;
 [...]
 r &#x3D; platform_get_resource(pdev, IORESOURCE_MEM, 0);
 &#x2F;* map peripheral *&#x2F;
 priv-&gt;base &#x3D; devm_ioremap_resource(dev, r);
 if (IS_ERR(priv-&gt;base))
 return PTR_ERR(priv-&gt;base);
 [...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>同样，与现代LDM的典型情况一样，此代码作为驱动程序探测路由的一部分执行。此外（同样，这是非常常见的），首先使用platform_get_resource（）API，以便获取物理（或总线）地址的值并将其放置在源结构中，该源结构的地址作为第二个参数传递给devm_ioremap_resource（）。现在，使用MMIO检查、请求I/O内存并将其重新映射到内核VAS，准备供驱动程序使用！您可能遇到过devm_request_and_ioremap（）API，它通常用于类似的目的；早在2013年，它就被devm_ioremap_resource（）API所取代。最后，ioremap（）有几个变体。[devm_]ioremap_nocache（）和ioremap_cache（）API就是这样的例子，它们会影响CPU的缓存模式。驱动程序作者最好仔细阅读这些例程所在的内核源代码中的（特定于arch的）注释；例如，在x86上的arch/x86/mm/ioremap.c:ioremap_nocache（）。现在，在介绍了如何获取资源信息和使用现代devm_*（）托管API的这一重要部分后，让我们学习如何解释/proc关于MMIO的输出。</p>
<h4 id="通过-proc-iomem查找新的映射"><a href="#通过-proc-iomem查找新的映射" class="headerlink" title="通过/proc/iomem查找新的映射"></a>通过/proc/iomem查找新的映射</h4><p>​    一旦你执行了映射（通过刚刚覆盖的[devm_]ioremap*（）API之一），它实际上可以通过只读伪文件看到；即/proc/iomem。实际情况是，当您成功调用request_mem_region（）时，/proc/iomem下会生成一个新条目。查看它需要root访问权限（更准确地说，您可以将其视为非root，但只会将所有地址视为0；这是出于安全目的）。那么，让我们在我们值得信赖的x86_64 Ubuntu客户机上看看这个。在以下输出中，由于空间不足，为了清楚起见，我们将显示部分截断的内容</p>
<pre class="line-numbers language-none"><code class="language-none">$ sudo cat &#x2F;proc&#x2F;iomem
[sudo] password for llkd:
00000000-00000fff : Reserved
00001000-0009fbff : System RAM
0009fc00-0009ffff : Reserved
000a0000-000bffff : PCI Bus 0000:00
000c0000-000c7fff : Video ROM
000e2000-000ef3ff : Adapter ROM
000f0000-000fffff : Reserved
000f0000-000fffff : System ROM
00100000-3ffeffff : System RAM
18800000-194031d0 : Kernel code
194031d1-19e6a1ff : Kernel data
1a0e2000-1a33dfff : Kernel bss
3fff0000-3fffffff : ACPI Tables
40000000-fdffffff : PCI Bus 0000:00
[...]
fee00000-fee00fff : Local APIC
fee00000-fee00fff : Reserved
fffc0000-ffffffff : Reserved
$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    要实现的真正重要的是左侧列不是虚拟的，它们是物理（或总线）地址。您可以看到系统（或平台）RAM的映射位置。此外，在其中，您可以看到内核代码、数据和bss部分的确切位置（就物理地址而言）。事实上，我的procmap实用程序(<a target="_blank" rel="noopener" href="https://github.com/kaiwan/procmap)精确地使用这些信息（将物理地址转换为虚拟地址）。为了进行对比，让我们在Raspberry">https://github.com/kaiwan/procmap)精确地使用这些信息（将物理地址转换为虚拟地址）。为了进行对比，让我们在Raspberry</a> Pi 3设备上运行相同的命令（B+型号搭载了Broadcom BCM2837 SoC和四核ARM Cortex A53）。同样，由于空间限制，为了清楚起见，我们将显示输出的部分截断部分：</p>
<pre class="line-numbers language-none"><code class="language-none">pi@raspberrypi:~ $ sudo cat &#x2F;proc&#x2F;iomem
00000000-3b3fffff : System RAM
00008000-00bfffff : Kernel code
00d00000-00e74147 : Kernel data
3f006000-3f006fff : dwc_otg
3f007000-3f007eff : dma@7e007000
[...]
3f200000-3f2000b3 : gpio@7e200000
3f201000-3f2011ff : serial@7e201000
3f201000-3f2011ff : serial@7e201000
3f202000-3f2020ff : mmc@7e202000
[...]
pi@raspberrypi:~ $<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    请注意GPIO寄存器组如何显示为gpio@7e200000，如图3.1所示，这是物理地址。您可能想知道为什么ARM上的格式与x86_64的格式不同。左栏现在是什么意思？在这里，内核允许BSP/平台团队决定如何构建和设置（通过/proc/iomem）用于显示的I/O内存区域，这是有道理的！他们最了解硬件平台。我们之前提到过，但事实是BCM2835SoC（Raspberry Pi使用的）有多个MMU。一个这样的MMU是粗粒度VC/ARM MMU，它将ARM总线地址转换为ARM物理地址，之后常规ARM MMU将物理地址转换为虚拟地址。因此，在这里，ARM总线地址的开始和结束值显示在左列中，ARM物理地址显示为@符号的后缀(gpio@xxx). 因此，对于正在映射的前一个GPIO寄存器，ARM总线地址为3f20000-3f2000b3，ARM物理地址为0x7e200000。让我们通过提及更多关于/proc/iomemppseudo文件的要点来结束本节：</p>
<ul>
<li>/proc/iumem显示内核和/或各种设备驱动程序当前正在映射的物理（和/或总线）地址。然而，确切的显示格式非常依赖于架构和设备。</li>
<li>每当运行request_mem_region（）API时，都会为/proc/iomem生成一个条目。</li>
<li>当相应的release_mem_region（）API运行时，该条目将被删除。</li>
<li>您可以在kernel/resource.c:ioresources_init（）中找到相关的内核代码。</li>
</ul>
<p>​    那么，现在您已经将I/O内存区域成功映射到内核VAS，您将如何实际读取/写入此I/O内存？MMIO的API是什么？下一节将深入探讨这个主题。</p>
<h4 id="MMIO–使用MMIO方法执行实际I-O"><a href="#MMIO–使用MMIO方法执行实际I-O" class="headerlink" title="MMIO–使用MMIO方法执行实际I/O"></a>MMIO–使用MMIO方法执行实际I/O</h4><p>​    外围I/O内存被映射到内核VAS，因此在您（驱动程序作者）看来，它就像RAM一样，是普通的旧内存。我们在这里需要小心：有需要注意的事项和注意事项。您不应该将该区域视为普通的旧RAM，并通过通常的Croutines直接访问它！</p>
<p>​    在接下来的部分中，我们将向您展示如何对通过MMIO方法重新映射的任何外围I/O区域执行I/O（读取和写入）。我们将从执行小（1到8字节）I/O的常见情况开始，然后继续进行重复I/O，然后再研究如何对MMIO区域进行memset和memcpy。在MMIO内存区域执行1到8字节的读写操作。那么，您如何通过MMIO方法访问和执行外围I/O（读写）呢？内核提供了API，允许您读取和写入芯片内存。通过使用这些API（或宏/内联函数），您可以以四种可能的位宽执行I/O，如读取和写入；也就是说，8位、16位、32位，在64位系统上，64位：</p>
<p>MMIO读取：ioread8（）、ioread16（）、ioread32（）和ioread64（）</p>
<p>MMIO写入：iowrite8（），iowrite16（），iowrite32（），和iowrite64（）I/O</p>
<p>读取例程的签名如下：</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;linux&#x2F;io.h&gt;
u8 ioread8(const volatile void __iomem *addr);
u16 ioread16(const volatile void __iomem *addr);
u32 ioread32(const volatile void __iomem *addr);
\#ifdef CONFIG_64BIT
u64 ioread64(const volatile void __iomem *addr);
\#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    API的单个参数是必须从中读取的I/O内存位置的地址。通常，它是从我们看到的<em>ioremap</em>（）API之一获得的返回值，加上偏移量（偏移量可能是0）。向基（__iomem）地址添加偏移量是一件非常常见的事情，因为硬件设计人员精心布局寄存器，使其可以作为数组（或寄存器库）由软件轻松按顺序访问！驱动程序作者利用了这一点。当然，这没有捷径，因为你不能假设任何事情——你必须仔细研究你正在编写驱动程序的特定I/O外围设备的数据表；细节决定成败！u8返回类型是一个指定无符号8位数据类型的typedef（相反，sprefix表示有符号数据类型）。其他数据类型也是如此（有s8、u8、s16、u16、s32、u32、s64和u64，都非常有用且明确）。</p>
<p>​    I/O写入例程的签名如下</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;linux&#x2F;io.h&gt;
void iowrite8(u8 value, volatile void __iomem *addr);
void iowrite16(u16 value, volatile void __iomem *addr);
void iowrite32(u32 value, volatile void __iomem *addr);
\#ifdef CONFIG_64BIT
void u64 iowrite64(u64 value, const volatile void __iomem *addr);
\#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    API的第一个参数是要写入的值（具有适当的位宽），而第二个参数指定要写入的位置；即MMIOaddress（同样，这是通过<em>ioremap</em>（）API之一获得的）。请注意，没有返回值。这是因为这些I/O例程确实在硬件上工作，所以它们不会失败：它们总是成功的！当然，现在您的驱动程序可能仍然无法工作，但这可能是由于多种原因造成的（资源不可用、映射错误、使用错误的偏移、定时或同步问题等）。然而，I/O例程仍然可以工作。驱动程序作者用来从根本上测试驱动器/硬件健全性的一个常见测试是，他们将值n写入寄存器并将其读回；你应该得到相同的值（n）。（当然，只有在寄存器/硬件不会立即更改或使用它的情况下，才会出现这种情况。）</p>
<p>在MMIO内存区域上执行重复I/O </p>
<p>ioread[8|16|32|64]（）和iowrite[8|16| 32|64]()API只能处理1到8字节的小数据量。但是，如果我们想读或写几十个或几百个字节呢？您始终可以在循环中对这些API进行编码。然而，内核正是预见到了这一点，提供了更高效的辅助例程，这些例程在内部使用了一个紧密的汇编循环。这些是所谓的MMIO API的重复版本：为了阅读，我们有ioread[8|16|32|64]_rep（）API集。对于写作，我们有iowrite[8|16|32|64]_rep（）API集。让我们看看其中一个的签名；即8位重复读取。其余的读取完全类似：</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;linux&#x2F;io.h&gt;
void ioread8_rep(const volatile void __iomem *addr, void *buffer, unsigned
int count);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​    这将从源地址addr（MMIO位置）读取计数字节到缓冲区指定的（内核空间）目标缓冲区。同样，以下是重复8位写入的签名：</p>
<pre class="line-numbers language-none"><code class="language-none">void iowrite8_rep(volatile void __iomem *addr, const void *buffer, unsigned
int count);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    这将把源（内核空间）缓冲区（buffer）中的计数字节写入目标地址addr（MMIO位置）。除了这些API，内核确实有一些助手，它们是这种API的变体；例如，对于字节序，它提供ioread32be（），其中be是大端序。在MMIO内存区域上设置和复制内核还为使用MMIO时的memset（）和memcpy（）操作提供了辅助例程。请注意，您必须使用以下帮助程序：</p>
<pre class="line-numbers language-none"><code class="language-none">\#include linux&#x2F;io.h
void memset_io(volatile void __iomem *addr, int value, size_t size);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    这将把I/O内存从起始地址addr（MMIO位置）设置为大小字节的值参数指定的值。为了复制内存，根据内存传输的方向，有两个辅助例程可用</p>
<pre class="line-numbers language-none"><code class="language-none">void memcpy_fromio(void *buffer, const volatile void __iomem *addr, size_t
size);
void memcpy_toio(volatile void __iomem *addr, const void *buffer, size_t
size);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    第一个将内存从MMIO位置地址复制到（内核空间）目标缓冲区（缓冲区），大小为字节；第二例程将内存从（内核空间）源缓冲区（buffer）复制到目标MMIO位置addr，以获得大小字节。同样，对于所有这些助手，请注意没有返回值；他们总是成功的。此外，对于前面的所有例程，请确保包含linux/io.h标头。最初，asm/io.h标头通常包含在内。然而，现在，linux/io.h标头是它上面的一个抽象层，内部包含asm/io.h文件。</p>
<p>需要注意的是，内核有较旧的用于执行MMIO的辅助例程；这些是读取[b|w|l|q]（）和写入[b|v|l|q]（）API助手。在这里，后缀为读/写的字母指定了位宽；其实很简单：</p>
<ul>
<li>b：字节宽（8位）</li>
<li>w：字宽（16位）</li>
<li>l：长宽（32位）</li>
<li>q：四字宽（64位）；仅在64位计算机上可用请注意</li>
</ul>
<p>对于现代内核，不应使用这些例程，而应使用前面提到的ioread/iowrite[8|16|32|64]（）API助手。我们在这里提到它们的唯一原因是，仍然有几个驱动程序在使用这些旧的辅助程序。语法和语义与较新的助手程序完全相似，因此如果需要，我将留给您查找它们。让我们总结一下（不要过多关注我们到目前为止所涵盖的所有细节）驾驶员在执行MMIO时遵循的典型顺序来结束本节：</p>
<ul>
<li>通过Request_mem_region（）从内核请求内存区域（在/proc/iomem中生成一个条目）。</li>
<li>将外围I/O内存重新映射到内核VASvia[devm_]ioremap[_resource|[no]cache（）；现代驱动程序通常使用托管devm_ioremap（）（或devm_iorimap_resource（）API）来实现</li>
<li>通过一个或多个现代辅助程序例程执行实际的I/O操作：ioread[8|16|32|64]（）iowrite[8|16|32|64]（）memset_io（）/mecpy_fromio（）/memcpy_toio（）（较旧的辅助程序例程：read[b|w|l|q]（）和write[b|w|l|q]（））</li>
<li>完成后，取消映射MMIO区域；即iounmap（）。这仅在需要时进行（使用托管devm_ioremap*（）API时，这是不必要的）。</li>
<li>通过Release_mem_region（）将MMIO区域释放回内核（清除/proc/iomem中的条目）。</li>
</ul>
<p>由于MMIO是与外围芯片通信的强大手段，您可以想象所有驱动程序（包括所谓的总线驱动程序）都是使用它（和/或端口I/O）设计和编写的，但事实并非如此。这是由于性能问题。毕竟，在外围设备上执行MMIO（或PMIO）需要处理器的持续交互和关注。在许多类型的设备上（想想在智能手机或平板电脑上流式传输高清媒体内容！），只是太慢了。那么，与外围设备通信的高性能方式是什么？答案是DMA，不幸的是，这超出了本书的范围（请参阅进一步阅读部分，了解有关DMA的有用驱动程序书籍和资源的建议）。那么，MMIO在哪里使用？实际上，它用于许多低速外围设备，包括状态和控制操作。虽然MMIO是在外围设备上执行I/O的最常见方式，但端口I/O是另一种方式。那么，让我们学习如何使用它。</p>
<h4 id="了解和使用我们在解决方案中前面提到的端口映射I-O——通过I-O内存或I-O端口部分进行映射"><a href="#了解和使用我们在解决方案中前面提到的端口映射I-O——通过I-O内存或I-O端口部分进行映射" class="headerlink" title="了解和使用我们在解决方案中前面提到的端口映射I/O——通过I/O内存或I/O端口部分进行映射"></a>了解和使用我们在解决方案中前面提到的端口映射I/O——通过I/O内存或I/O端口部分进行映射</h4><p>​    除了MMIO之外，还有另一种在外围设备内存上执行I/O的方法，称为PMIO，或者通常简称为PIO。它的工作方式与MMIO截然不同。在这里，CPU具有不同的汇编（和相应的机器）指令，使其能够直接读取和写入I/O内存位置。不仅如此，这个I/O内存范围是一个完全独立的地址空间，与RAM不同。这些内存位置称为端口。不要将这里使用的术语端口与网络技术中使用的术语混淆；把这个端口看作是一个硬件寄存器，因为它非常接近意义。（虽然它通常是8位的，但外围芯片寄存器实际上可以有三种位宽：8、16或32位。）现实情况是，大多数现代处理器，即使它们确实支持具有单独I/O端口地址空间的PMIO，也往往主要使用MMIO方法进行外围I/O映射。除了MMIO之外，支持PMIO并经常使用它的主流处理器系列是x86。在这些处理器上，正如其物理内存映射中所记录的那样，是为此目的保留的一系列地址位置。这被称为端口地址范围，通常在x86上，范围从物理地址0x0到0xffff；即长度为64千字节。该地区包含哪些注册信息？通常，在x86上，有用于各种I/O外围设备的寄存器（通常是数据/状态/控制）。一些常见的包括i8042键盘/鼠标控制器芯片、DMA控制器（DMAC）、定时器、RTC等。我们将在通过/proc/iports查找端口一节中更详细地介绍这些。</p>
<p>​    PMIO——与我们在MMIO中看到的所有喧闹相比，执行实际的I/O端口I/O非常简单。这是因为处理器提供机器指令来直接执行工作。当然，就像MMIO一样，你应该礼貌地请求内核允许访问PIOregion（我们在请求内核的权限一节中介绍了这一点）。用于执行此操作的API是request_region（）和release_regio（）（它们的参数与它们的MMIO对应API相同）。那么，如何在I/O端口上访问和执行I/O（读写）呢？同样，内核在底层的汇编/机器指令上提供了API包装器，以完成读取和写入。使用它们，您可以以三种可能的位宽执行I/O读写操作；也就是说，8位、16位和32位：</p>
<ul>
<li>PMIO读取：in（）、inw（）和in（）</li>
<li>PMIO写入：out（）、out（）和outl（）</li>
</ul>
<p>非常直观地说，b表示字节宽（8位），w表示字宽（16位），l表示长宽（32位）。端口I/O读取例程的签名如下</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;linux&#x2F;io.h&gt;
u8 inb(unsigned long addr);
u16 inw(unsigned long addr);
u32 inl(unsigned long addr);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>单个参数是将从中读取的端口I/Omemory位置的端口地址。我们在获取设备资源部分介绍了这一点（对于像您这样的驱动程序开发人员来说，这是一个非常关键的部分！）。端口也是一种资源，这意味着它可以通过通常的方式获得：在现代嵌入式系统上，这是通过解析设备树（或ACPI表）来实现的；旧的方法是在特定于板卡的源文件中硬编码这些值。实际上，对于许多常见的外围设备，端口号或端口地址范围是众所周知的，这意味着它可以硬编码到驱动程序中（这通常发生在驱动程序的头文件中）。同样，最好不要简单地假设任何事情，确保您参考了相关外围设备的数据表。现在，让我们回到API。返回值是一个无符号整数（位宽根据所使用的辅助例程而变化）。它是发出读取时该端口（寄存器）上的当前值。</p>
<p>​    端口I/O写入例程的签名如下：</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;linux&#x2F;io.h&gt;
void outb(u8 value, unsigned long addr);
void outw(u16 value, unsigned long addr);
void outl(u32 value, unsigned long addr);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>第一个参数是写入硬件（端口）的值，而第二个参数是要写入的端口I/O内存的端口地址。同样，与MMIO一样，不存在失败的问题，因为这些辅助I/O例程总是成功的。至少在x86上，对I/O端口的写入保证在执行下一条指令之前完成。一个PIO的例子——i8042为了让事情更清楚，让我们来看看8042键盘和鼠标控制器的设备驱动程序中的一些代码片段，虽然现在被认为很旧，但在x86系统上仍然很常见。您可以在此处找到8042控制器的基本原理图：</p>
<p><img src="./image-20240724081852293.png" alt="image-20240724081852293"></p>
<p>​    有趣的位（至少对我们来说）在驱动程序的头文件中：/</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;*
 * Register numbers.
 *&#x2F;
\#define I8042_COMMAND_REG 0x64
\#define I8042_STATUS_REG 0x64
\#define I8042_DATA_REG 0x60<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    在前面的代码片段中，我们可以看到此驱动程序使用的I/O端口或硬件寄存器。为什么状态寄存器和数据寄存器解析为相同的I/O端口（0x64）地址？方向很重要：读取它时，I/O端口0x64的行为就像状态寄存器，而写入它时，它的行为就像命令寄存器！此外，数据表将显示这些是8位寄存器；因此，在这里，实际的I/O是通过in（）和out（）助手执行的。</p>
<h3 id="Kernel-Debug-Programming-1"><a href="#Kernel-Debug-Programming-1" class="headerlink" title="Kernel Debug Programming"></a>Kernel Debug Programming</h3><p>​    在开始生成Oops任务之前，让我们更好地了解procmap实用程序的作用以及NULL陷阱页面是什么。首先，让我们使用该实用程序。procmap工具能够可视化内核虚拟地址空间（VAS）的完整内存映射以及任何给定进程的用户VAS，这是procmap实用程序的设计目的。（完全披露：我是原作者。）GitHub页面上的描述(<a target="_blank" rel="noopener" href="https://github.com/kaiwan/procmap)综上所述：procmap被设计成一个控制台/CLI实用程序，用于可视化Linux进程的完整内存映射，实际上是可视化内核和用户模式虚拟地址空间（VAS）的内存映射。它以垂直平铺的格式输出给定进程的完整内存映射的简单可视化，按虚拟地址降序排列（见下面的屏幕截图）。该脚本具有显示内核和用户空间映射以及计算和显示将出现的稀疏内存区域的智能。此外，为了可读性，每个片段或映射都（非常近似地）按相对大小和颜色编码进行缩放。在64位系统上，它还显示了所谓的非规范稀疏区域或“洞”（在x86_64上通常接近高达16384">https://github.com/kaiwan/procmap)综上所述：procmap被设计成一个控制台/CLI实用程序，用于可视化Linux进程的完整内存映射，实际上是可视化内核和用户模式虚拟地址空间（VAS）的内存映射。它以垂直平铺的格式输出给定进程的完整内存映射的简单可视化，按虚拟地址降序排列（见下面的屏幕截图）。该脚本具有显示内核和用户空间映射以及计算和显示将出现的稀疏内存区域的智能。此外，为了可读性，每个片段或映射都（非常近似地）按相对大小和颜色编码进行缩放。在64位系统上，它还显示了所谓的非规范稀疏区域或“洞”（在x86_64上通常接近高达16384</a> PB）。该实用程序包括仅查看内核空间或用户空间的选项、详细和调试模式、以方便的CSV格式将其输出导出到指定文件的能力，以及其他选项。它也有一个内核组件（一个模块），目前适用于（自动检测）x86_64、AArch32和AArch64 CPU。不过，请注意，它在任何真正意义上都不完整；开发正在进行中。有几个注意事项。我们非常感谢您的反馈和贡献！从这里下载/克隆它：<a target="_blank" rel="noopener" href="https://github.com/kaiwan/procmap.What这就是NULL陷阱页面吗？在所有基于Linux的系统上（事实上，几乎在所有现代基于虚拟内存的操作系统上），内核将进程可用的虚拟内存区域分为两部分——用户和内核VAS（我们称之为VM分割——在《Linux内核编程，Packt》一书的第7章“内存管理内部-要点”中有非常详细的讨论）。">https://github.com/kaiwan/procmap.What这就是NULL陷阱页面吗？在所有基于Linux的系统上（事实上，几乎在所有现代基于虚拟内存的操作系统上），内核将进程可用的虚拟内存区域分为两部分——用户和内核VAS（我们称之为VM分割——在《Linux内核编程，Packt》一书的第7章“内存管理内部-要点”中有非常详细的讨论）。</a></p>
<p>​    在x86_64上，每个进程的完整VAS大小当然是2^64字节。现在，这是一个惊人的数字。它是16 EB（EB代表EB——1 EB=1024 PB=100万TB=10亿GB！）。VAS太大了。因此，默认情况下，x86_64上的内核被设计为如下分割：锚定在VAS顶部的大小为128 TB的内核VAS（从VAS最顶部的内核虚拟地址（KVA）0xFFFFFFFFFffffffff到KVA 0xffff8000000000）锚定到VAS底部的大小为128TB的用户VAS（从VAS最底部的用户虚拟地址（UVA）0x00007ffffffffFFffff到UVA 0x0）想想这个64位VAS如此之大，在这种情况下，我们最终只使用了一小部分可用地址空间。16EB等于16384PB。其中，在x86_64上，我们使用128 TB+128 TB=256 TB（即256/1024=0.25 PB）。这意味着约0.0015的可用VAS正在使用中。现在，这里有一点值得注意：在用户VAS的低端，第一个虚拟页面——从字节0到字节4095——被称为NULL陷阱页面。让我们在我们的shell进程（恰好有PID 1076）上快速运行procmap实用程序（我们假设您现在已经安装了它），看到它显示NULL陷阱页面：</p>
<pre class="line-numbers language-none"><code class="language-none">$ &lt;&#x2F;path&#x2F;to&#x2F;&gt;procmap
 --pid&#x3D;1076
[...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><img src="./image-20240724082153049.png" alt="image-20240724082153049"></p>
<p>​    您可以在前面的屏幕截图底部找到NULL陷阱页面（bash进程的一些映射在更高的位置可见）。NULL陷阱页面的工作原理是将所有权限-rwx设置为—-，这样任何进程（或线程）都无法读取、写入或执行其中的任何内容！这就是为什么当一个进程试图读取或写入地址0x0处的NULL字节时，它不起作用。简而言之，实际发生的情况是：</p>
<ul>
<li>一个进程尝试访问（读取/写入/执行）或解引用NULL字节。</li>
<li>事实上，访问此页面中的任何字节都会导致相同的事件序列，因为—-模式适用于页面中的所有字节，这就是为什么它被称为NULL陷阱页面！它捕获对其中任何字节的访问。</li>
<li>页面中所有字节的权限为零：不读、不写、不执行。现在（除非缓存），所有虚拟地址最终都会到达MMU。MMU进行检查，然后执行运行时地址转换，将虚拟地址转换为物理地址。</li>
<li>在这里，MMU检测到页面中的所有字节都没有权限，因此引发了故障（通常在x86上，是一般保护故障）操作系统预装了故障（和陷阱/异常）处理程序。控制权被传递给适当的故障处理功能。</li>
<li>此函数（故障处理程序）在导致故障的进程的进程上下文中运行。它通过一个相当复杂的算法找出问题所在。</li>
<li>在这里，故障处理程序将得出结论，在用户模式下执行的进程试图进行有缺陷的访问。因此，它会向它发送一个致命信号（SIGSEGV）。这最终会导致进程死亡，并在控制台上显示分段错误[（核心转储）]消息。当然，该过程可以安装一个信号处理程序来处理这个信号。但最终，在清理之后，它必须终止。</li>
</ul>
<p>现在您已经了解了NULL陷阱页面的确切内容及其工作原理，让我们做一些我们不应该做的事情：尝试在内核模式下读/写NULL地址，从而导致内核错误！一个简单的Oops v1–解引用NULL点在这个有缺陷的内核模块的第一个简单版本中，我们只需读取或写入NULL地址。正如您在上一节中所了解到的，对NULL陷阱页面中的任何字节进行任何访问（读取、写入或执行）都会导致MMU跳起来并触发故障。在内核模式下也是如此。</p>
<h4 id="可能是重新启动的有用（愚蠢）解决方法。"><a href="#可能是重新启动的有用（愚蠢）解决方法。" class="headerlink" title="可能是重新启动的有用（愚蠢）解决方法。"></a>可能是重新启动的有用（愚蠢）解决方法。</h4><p>​    您是否注意到，一旦出现错误，内核模块就无法卸载（通过rmmod），因为引用计数为非零？lsmod验证了这一点：</p>
<pre class="line-numbers language-none"><code class="language-none">$ lsmod |grep oops
oops_tryv1 16384 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    这通常是因为Oops发生在进程上下文（在我们的例子中是insmod）退出之前，因此模块引用计数减少到0。前一个输出最右侧的1表示当前模块引用计数为1，阻止卸载此模块。现在，如果您无法卸载该模块，则无法再次加载（在编辑源文件后重试）。正确的方法是重新启动盒子并重新开始。对于这个恼人的问题，一个非常愚蠢的解决方法是简单地清理（make clean），重命名源文件，编辑Makefile以使用新名称，然后构建它。现在它将以新名称加载！非常愚蠢，但当你处于开发阶段并急于尝试时，它是有效的。做更多的Oops——正如本章开头提到的，在我们的版本2错误模块中，我们将做一些稍微（希望）更现实的事情来触发内核Oops。此模块有三种不同的方法来触发Oops：</p>
<ul>
<li>一种是在NULL陷阱页面中写入随机生成的KVA。</li>
<li>第二，允许用户传递一个（随机）无效的KVA并尝试在其中写入内容（您可以利用procmap实用程序来查找无效的KVA）</li>
<li>第三，我们启动一个简单的工作队列函数。这将使内核工作线程在调度时运行其代码。在工作队列函数中，我们将通过尝试向结构指针为NULL的结构成员写入内容来触发Oops（由于这种情况可能非常现实，我们将在本章中将其作为一个用例）。</li>
</ul>
<p>​    让我们从使用上面提到的第一种方法来触发Oops！</p>
<h5 id="案例1——糟糕的是，写入NULL陷阱页面中的随机位置。"><a href="#案例1——糟糕的是，写入NULL陷阱页面中的随机位置。" class="headerlink" title="案例1——糟糕的是，写入NULL陷阱页面中的随机位置。"></a>案例1——糟糕的是，写入NULL陷阱页面中的随机位置。</h5><p>​    与第一个v1模块非常相似，我不会深入探讨这个问题。只要说我们使用内核接口（get_random_bytes（）API）生成一个随机数并将其缩小到0到4095之间的数字（通过使用模运算符）就足够了。这里可以看到模块init函数中的相关代码：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; ch7&#x2F;oops_tryv2&#x2F;oops_tryv2.c
[...]
static int __init try_oops_init(void)
&#123;
 unsigned int page0_randptr &#x3D; 0x0;
 [...]
&#125; else &#123; &#x2F;&#x2F; no module param passed, write to random kva in NULL
trap
 pr_info(&quot;Generating Oops by attempting to write to a 
random invalid kernel address in NULL trap page\n&quot;); 
 get_random_bytes(&amp;page0_randptr, sizeof(unsigned 
int));
 bad_kva &#x3D; (page0_randptr &#x3D; PAGE_SIZE);
 &#125;
 pr_info(&quot;bad_kva &#x3D; 0xlx; now writing to it...\n&quot;, bad_
kva);
 *(unsigned long *)bad_kva &#x3D; 0xdead;
[...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    这里看到的最后一行是我们试图写入这个坏KVA的地方。当然，这会触发Oops。要尝试这个方法，只需在不传递任何参数的情况下对模块进行insmod。这将使代码指向此用例（我将留给您自己尝试并查看内核日志）。</p>
<p>​    案例2——通过写入内核VASF中无效的未映射位置来产生Oops。对于第二个用例，我们有一个名为mp_randaddr的模块参数。要运行此情况，您需要以通常的方式将其传递给模块，将其设置为无效的内核地址（或KVA）：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; ch7&#x2F;oops_tryv2&#x2F;oops_tryv2.c
[...]
static unsigned long mp_randaddr;
module_param(mp_randaddr, ulong, 0644);
MODULE_PARM_DESC(mp_randaddr, &quot;Random non-zero kernel virtual 
address; deliberately invalid, to cause an Oops!&quot;);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    随机非零内核虚拟地址；故意无效，导致糟糕！”）；现在，当模块的init函数检测到此参数中传递了非零值时，它会调用以下代码：</p>
<pre class="line-numbers language-none"><code class="language-none">&#125; else if (mp_randaddr) &#123;
 pr_info(&quot;Generating Oops by attempting to write to the 
invalid kernel address passed\n&quot;);
 bad_kva &#x3D; mp_randaddr;
 &#125; else &#123;
 [... &lt;&lt; code of the first case above &gt;&gt; ...]
 &#125;
 pr_info(&quot;bad_kva &#x3D; 0xlx; now writing to it...\n&quot;, bad_
kva);
 *(unsigned long *)bad_kva &#x3D; 0xdead;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    这种方法与第一种情况几乎完全相同；有趣的是：我怎么知道要传递哪个内核地址（或KVA）？我如何知道它是内核VAS中无效（或未映射）的位置？啊，这就是procmap实用程序发挥作用的地方！只需运行procmap（传递任何PID并指定—only内核选项开关，因为我们现在对用户VAS不感兴趣）。例如，在我的x86_64客户VM上，我是这样调用它的（您需要更新PATH环境变量以包含安装procmap的目录）：</p>
<pre class="line-numbers language-none"><code class="language-none">$ procmap --pid&#x3D;1 --only-kernel
...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    好的，请仔细查看前面的屏幕截图。标记为&lt;。。。K稀疏区域…&gt;是内核VAS中的空洞。这里没有地图。这很常见。这样的内存通常被称为地址空间中的稀疏区域或孔洞。关键在于：稀疏区域是未映射的区域，因此，如果你试图以任何方式访问这些位置中的任何一个——读取、写入或执行——这是一个错误！所以，让我们在稀疏区域内选择一个KVA。我将在模块区域（内核模块所在的位置）和内核vmalloc区域（vmalloc（）从中分配内存的位置）之间选择一个，即0xffffffffc0000000和0xffffda377ffffff之间的任何地址。因此，我将KVA 0xffffffffc000dead作为无效内核地址的值并使用它运行。对，确保您已经构建了oops_tryv2模块，然后按照刚才讨论的参数加载它：</p>
<pre class="line-numbers language-none"><code class="language-none">$ modinfo -p .&#x2F;oops_tryv2.ko 
mp_randaddr:Random non-zero kernel virtual address; 
deliberately invalid, to cause an Oops! (ulong)
bug_in_workq:Trigger an Oops-generating bug in our workqueue 
function (bool)
$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    我们使用modinfo实用程序来证明我们的模块接受两个参数（请暂时忽略第二个参数——这是我们的下一个主题）。让我们（终于！）开始吧</p>
<pre class="line-numbers language-none"><code class="language-none">$ sudo insmod .&#x2F;oops_tryv2.ko mp_randaddr&#x3D;0xffffffffc000dead
Killed
$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​    哎呀！解释内核错误诊断啊哈！我们的模块（故意）试图写入无效的内核地址0xffffffffc000dead（通过模块参数传递），结果却陷入了错误的结局。我们得到了我们想要的东西——一个Oops击中了我们。以下（部分）屏幕截图显示了其中的一大部分：</p>
<p><img src="./image-20240724082702174.png" alt="image-20240724082702174"></p>
<p>​    我希望关键点是明确的：当然，我们会遇到一个bug——Oops。我们在内核VAS的稀疏区域内写入了一个无效的未映射内核地址，procmap实际上帮助我们看到了。为什么试图访问无效地址会导致问题？答案与我们讨论的NULL陷阱页面非常相似。基本情况如下：1。正在处理（读取、写入或执行）的虚拟地址将发送到MMU。</p>
<p>生成一个简单的内核错误和Oops 3032。MMU知道当前进程上下文的分页表在哪里（对于x86，分页表基的物理地址在CR3寄存器中），现在继续将此虚拟地址（KVA）转换为物理地址（在这里，我们将忽略可能已经保存物理地址的硬件优化，如CPU缓存和转换后备缓冲区（TLB），从而缩短了漫长的转换并提供了加速）。通常，它会找到一个映射并执行转换，将物理地址放置在总线上。CPU接管并完成工作。然而，在这种情况下，传递的内核地址是无效的（故意如此）——它实际上是内核VAS漏洞的一部分！因此，地址转换失败。作为硬件，MMU尽其所能：它通过引发（页面）错误来通知操作系统出了问题。操作系统的页面错误处理程序接管（在导致错误的进程的上下文中运行——当然，这里是insmod）。它认为在内核模式下尝试了无效写入，因此触发了Oops！那么，详细理解和解释这个混乱的Oops事情呢？这正是我们在下一节要做的，魔鬼在细节中——解码Oops。坚持住——我们会到的！</p>
<h5 id="案例3——当结构指针为NULL时写入结构成员，这会导致问题。"><a href="#案例3——当结构指针为NULL时写入结构成员，这会导致问题。" class="headerlink" title="案例3——当结构指针为NULL时写入结构成员，这会导致问题。"></a>案例3——当结构指针为NULL时写入结构成员，这会导致问题。</h5><p>这个使用（或测试）案例有点复杂，也有助于使其更加逼真。最终结果与前两种情况相同——我们让内核触发Oops。这一次，我们希望有缺陷的代码路径不要在insmod进程上下文中运行。为了实现这一点，我们初始化一个（内核默认）工作队列并对其进行调度，执行其代码。内核默认工作队列的执行是在内核工作线程的上下文中完成的。我们安排工作函数有一个bug——写入一个无效的内存位置，一个没有分配任何内存的指针（指向一个结构）。这当然会触发Oops。以下是相关的代码片段（和往常一样，我敦促您浏览完整的代码并亲自尝试这些东西）</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; ch7&#x2F;oops_tryv2&#x2F;oops_tryv2.c
[...]
static bool bug_in_workq;
module_param(bug_in_workq, bool, 0644);
MODULE_PARM_DESC(bug_in_workq, &quot;Trigger an Oops-generating bug 
in our workqueue function&quot;);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="./image-20240724083050622.png" alt="image-20240724083050622"></p>
<p>​    我们在工作队列上调用schedule_work（），让内核实际运行我们的工作函数的代码：</p>
<p><img src="./image-20240724083111444.png" alt="image-20240724083111444"></p>
<p>好吧，回想起来很明显：指向我们名为oopsie的结构的指针没有内存（它的值是NULL，因为它是我们模块中的全局静态变量）。然而，我们试图通过它写入结构的一个成员。这会触发Oops。以下是我调用它的方式：</p>
<pre class="line-numbers language-none"><code class="language-none">sudo insmod&#x2F;oops_tryv2.ko bug_in_workq&#x3D;yes<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>你注意到了吗？这一次，Killed消息不会出现。这是因为insmod进程没有被杀死。相反，使用我们的工作队列函数的内核工作线程将遭受该错误的后果。</p>
<p><img src="./image-20240724083134576.png" alt="image-20240724083134576"></p>
<p>顺便说一句，如果需要，你可以在我早期的Linux内核编程第2部分书（电子书可免费下载）的第5章“使用内核计时器、线程和工作队列”中阅读设置和使用内核工作队列、计时器和内核线程的详细信息。当然，这里我们总是假设您确实可以访问内核日志（通过dmesg、journalctl、闪存芯片上的安全位置等）。如果你一开始不知道Oops消息在哪里怎么办？那么，内核社区已经记录了您可以在这里做些什么：Oops消息位于哪里？(<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/admin-guide/bug-hunting.html\#where-is-the-oops-message-is-located）。此外，我们稍后将介绍其中提到的一些技术。Netconsole在“ARM">https://www.kernel.org/doc/html/latest/admin-guide/bug-hunting.html\#where-is-the-oops-message-is-located）。此外，我们稍后将介绍其中提到的一些技术。Netconsole在“ARM</a> Linux系统上的Oops和使用Netconsole”一节中介绍，kdump/crash在第12章“更多内核调试方法”中简要介绍。好了，你现在知道如何以多种方式触发内核错误，哎呀！下面快速了解一下内核Oops是什么和不是什么。</p>
<p>一个内核的Oops及其含义307A内核的Oots及其含义这里有一些关于内核Oops的快速认识。首先，Oops与segfault不同——分割错误。。。作为副作用，它可能会导致segfault发生，因此进程上下文可能会收到致命的SIGSEGV信号。当然，这让糟糕的过程陷入了交火之中。接下来，Oops与全面的内核恐慌不是一回事。恐慌意味着系统处于不可用状态。这可能会导致这种情况，尤其是在生产系统上（我们在第10章“内核恐慌、锁定和挂起”中介绍了内核恐慌）。不过请注意，内核提供了几个sysctl可调参数（当然可以由root编辑），用于了解什么情况会导致内核恐慌。我们可以查看它们——在我的x86_64 Ubuntu 20.04客户机上运行我们的自定义生产内核，它们是：</p>
<pre class="line-numbers language-none"><code class="language-none">$cd&#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;$ls panic_on*panic_on_io_nmi panic_on-oops panic_o_nurc_stall panic_on&#x2F;unrecovered_nmi panic _on_warn<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    正如你所看到的，如果你把它们分类，默认情况下它们的所有值都是零，这意味着不会触发内核恐慌。它还向我们表明，例如，将panic_on_oops设置为1将导致内核在任何oops上死机，无论它看起来多么微不足道。重要的是要明白，在许多安装中，这可能是正确的做法。当一个系统出现Oops时，我们通常希望出现一个亮红灯——一个信号停止，一种理解系统处于（或曾经处于）不健康状态的方式！这确实取决于项目或产品的性质：一个深度嵌入式系统可能无法承受因内核恐慌而停机的后果。在那里，看门狗通常会检测到系统处于不健康状态并重新启动。我们将在第10章“内核恐慌、锁定和挂起”中介绍使用看门狗等。即使Oops不是内核恐慌，但根据情况和错误的严重程度，内核可能会变得无响应、不稳定或两者兼而有之。或者，它可能会继续工作，就像没有发生任何令人担忧的事情一样！无论如何，Oops最终都是一个内核级的bug；它必须被检测、解释和修复！好的，让我们来看看有趣的部分：学习如何详细解释Oops内核输出。走吧！</p>
<h4 id="魔鬼在于细节——解码Oops我们将使用第三种场景（或使用-测试用例）"><a href="#魔鬼在于细节——解码Oops我们将使用第三种场景（或使用-测试用例）" class="headerlink" title="魔鬼在于细节——解码Oops我们将使用第三种场景（或使用/测试用例）"></a>魔鬼在于细节——解码Oops我们将使用第三种场景（或使用/测试用例）</h4><p>​    在案例3一节中介绍——当结构指针为NULL时，通过向结构成员写入Oops。快速回顾一下，这就是我们触发这个特定内核Oops的方法（案例3）：cd ch7/Oops_tryv2makesudo insmod/oops_tryv2.ko bug_in_workq=yes如前所述，它会触发oops。现在我们到了有趣的部分——逐行解读Oops。在开始之前，重要的是要意识到下面的详细讨论必然是特定于arch的，这里和现在都与x86_64平台有关（当然，Oops输出的部分内容非常特定于archs）。在后面的部分中，我们还将展示典型的Oops如何出现在ARM平台上。Oops的逐行解释我们得到的Oops最初也是真正关键的部分如图7.5所示。现在，为了帮助逐行参考，这是同一屏幕截图的注释图（为了清楚起见，放大了一点）：</p>
<p><img src="./image-20240724083304100.png" alt="image-20240724083304100"></p>
<p><img src="./image-20240724083311862.png" alt="image-20240724083311862"></p>
<p>在Oops中解释调用堆栈字符串call Trace:下方的行稍微向右缩进表示调用或堆栈跟踪。当然，这是导致Oops的进程上下文的内核模式堆栈（尽管它也可能是中断的堆栈——稍后将详细介绍……）。此调用跟踪对开发团队和您调试Oops非常有价值。为什么？它从字面上向你展示了这个bug的历史——我们是如何到达目的地的。那么，你怎么解释呢？以下是几个关键点：•首先，Call Trace下方的每一行（略微向右缩进）表示调用路径中的一个函数，由调用帧抽象出来。•每一帧都有与我们之前看到的相同的符号，funcname+x/y，其中x是从函数开始的距离（以字节为单位）（开始偏移量），y是函数的大小（长度）（以字节计）当然，自下而上阅读调用跟踪（图7.14中的垂直箭头指向上方以显示此内容）。回想一下，几乎所有现代处理器都遵循堆栈向下语义增长忽略任何以问号符号（？）开头的行。这意味着调用帧很可能是无效的，可能是早期堆栈内存使用的陈旧遗留物。内核的堆栈展开算法（有几个——它们甚至是可配置的！）足够聪明，几乎可以保证做到这一点，所以相信它。把我们学到的东西放在一起，这就是导致我们的Oops的调用序列：ret_from_fork（）—&gt;kthread（）-&gt;worker_tread（）-&gt;process_one_work()</p>
<p>​    当然，要正确理解这一点，至少需要基本了解Oops发生时我们的代码在做什么。我们确实知道Oops实际上是在函数do_the_work（）中触发的。请参阅我们在“查找发生Oops的代码”一节中的注释。此函数是我们的自定义工作队列例程。现在它是如何被调用的？啊，间接地，当我们的模块调用schedule_work（）API时，将指针传递到我们的工作结构（如果需要，请回头看代码ch7/oops_tryv2/oops_tryv2.c）。此工作函数由内核的默认事件工作队列提供服务。服务——实际上意味着消耗或执行我们的工作函数——是通过启动（或使用现有的）内核工作线程（属于内核的默认事件工作队列）来完成的。您在上面的调用序列中看到的kthread（）例程是一个执行此任务的内部内核接口，它启动了一个内核线程。它调用内核工作队列函数worker_thread（），其任务是处理工作队列上的所有工作项。这反过来是通过调用循环中的每个工作项来完成的，在循环中调用函数process_one_work（），其唯一的工作是处理它给出的一个工作项——我们的！所以我们到了——内核堆栈确实揭示了我们是如何到达worker例程do_the_work（）的。呼——这可能是一项艰苦的工作！但是，话说回来，你是工作中的法医侦探。没有人说这很容易！提示–查看所有CPU内核的内核模式堆栈内核有一个可调的/proc/sys/Kernel/ops_All_CPU_backtrace，其默认值为0，处于关闭状态。打开它（以root身份写入1），系统上所有CPU核的调用堆栈将显示为oops诊断的一部分。这在深度调试场景中非常有用。（在内部，其他CPU内核上的调用跟踪是通过不可屏蔽中断（NMI）回溯工具完成的。）调用跟踪后的行（以字符串Modules linked in:开头的行）显示了Oops时内核中加载的所有模块。为什么？模块通常是第三方代码（用于设备驱动程序、自定义网络防火墙规则、自定义文件系统等），因此当内核遇到错误时，它们非常可疑！因此，所有模块的列表。事实上，我们自己的错误模块oops_trv2自豪地站在这个列表的第一位，因为它是最后一个加载的模块。此外，受污染的标志OE表示它是一个树外无符号模块。最后，Oops诊断中的最后一行是内核开发人员所说的执行摘要——CR2寄存器的值！现在你应该意识到原因：是错误的（虚拟）地址，对该地址的访问导致了Oops。</p>
<p>提示位置的工具和技术-强制暂停以读取Oops诊断在发生Oops时打印详细的Oops分析是很好的，但如果它从控制台窗口滚动出来呢？或者，后面还有其他的次要Oopses，导致主要Oopses的内容滚动离开？对于这种情况，传递pause_on_oops=n内核参数。在打印第一个内核Oops后，它将使所有CPU暂停n秒。最后，我们非常详细地解释了我们的Oops，从字面上看，一行一行，在旅途中学习了很多（嘿，重要的是旅程，而不是目的地）。我们还想顺便提一下，有几个框架可以帮助捕获内核Oops并将其报告给供应商（或分销商）。其中包括kerneloops（8）程序（手册页：<a target="_blank" rel="noopener" href="https://linux.die.net/man/8/kerneloops">https://linux.die.net/man/8/kerneloops</a>). </p>
<p>​    许多现代发行版使用kdump功能在发生Oops或死机时收集整个内核内存映像，以供以后分析（通常通过崩溃应用程序）。练习通过在自定义调试内核上传递模块参数bug_in_workq=yes来运行此相同的Oopsing测试用例（ch7/try_oopsv2），看看会发生什么。在我的版本中，启用KASAN后，内核会出现Oops，但不会在KASAN发现错误之前！太好了——现在，继续下一节很重要，我们将介绍如何使用各种工具和技术来发现有问题的代码行！帮助确定Oops位置的工具和技术在分析内核Oops时，我们当然可以使用我们能得到的所有帮助，对吧？！有几个工具和辅助脚本可以利用。其中，作为（交叉）工具链的一部分，有objdump、GNU DeBugger（GDB）和addr2line程序。除此之外，一些内核辅助脚本（位于内核源代码树中）也可以证明非常有用。</p>
<p>​    在本节中，我们将开始学习如何利用这些工具来帮助解释Oops。提示–使用调试符号获取未拆分的vmlinux内核映像许多（如果不是大多数）帮助调试内核问题的工具和技术确实取决于您是否拥有一个带有调试符号的未拆分的未压缩vmlinux内核镜像。现在，如果你已经构建了调试和生产内核，正如我们从本书一开始就建议的那样，你当然会有调试vmlinux内核映像文件（它满足了这一要求）。如果不是呢？好吧，几乎所有的企业（和桌面）Linux发行版都提供了一个软件包——为集成到发行版中的常用内核版本提供单独的软件包——这将提供它（以及更多）。通常，该包被命名为linux-devel<em>或linux headers</em>。它本质上只是一个压缩的存档，其中包含内核头文件、带有调试符号的未拆分vmlinux，以及其中可能包含的更多好东西。下载该包，安装它，然后亲自查看。例如，关于Red Hat RHEL 8的kernel-*RPM的说明可以在这里找到：<a target="_blank" rel="noopener" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_monitoring_and_updating_the_kernel/the-linux-kernel-rpm_managing-monitoring-and-updating-the-kernel\#the-linux-kernel-rpm-package-overview_the-linux-kernel-rpm">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_monitoring_and_updating_the_kernel/the-linux-kernel-rpm_managing-monitoring-and-updating-the-kernel\#the-linux-kernel-rpm-package-overview_the-linux-kernel-rpm</a></p>
<p>​    此外，作为另一个例子，这里有一个链接，可以下载以下Linux发行版的内核开发Linux包的RPM包——AlmaLinux、ALT Linux、CentOS、Fedora、Mageia、OpenMandriva、openSUSE、PCLinuxOS和Rocky Linux：<a target="_blank" rel="noopener" href="https://pkgs.org/download/kernel-devel">https://pkgs.org/download/kernel-devel</a>.</p>
<p>​    接下来，重要的是要意识到，在非原生arch（例如ARM、ARM64、PowerPC等）上调试Oops时，您需要运行我们下面检查和使用的跨工具链版本的工具。作为一个具体的例子，如果你正在调试ARM-32上发生的Oops，该Oops是使用ARM-linux gnuabihfᦙ工具链前缀编译的（这将是环境变量CROSS_COMPILE的值），那么你需要运行的不是objdump，而是${CROSS_COMPILE}objdump也就是说，arm linux gnuabihf objdump。工具链中的其他工具（如GDB、readelf、addr2line等）也是如此。好的，让我们开始使用这些工具！</p>
<h3 id="处理硬件中断"><a href="#处理硬件中断" class="headerlink" title="处理硬件中断"></a>处理硬件中断</h3><p>​    在本章中，我们将重点介绍编写设备驱动程序的一个真正关键的方面：什么是硬件中断，更重要的是，作为驱动程序作者，你到底是如何处理它们的。事实上，很大一部分外围设备（您有兴趣为其编写设备驱动程序）通过断言一个中断来指示他们需要通过操作系统或驱动程序立即采取行动。实际上，这是一个最终提醒处理器控制单元的电信号（通常，此警报必须将控制重定向到受影响外围设备的中断处理程序例程，因为它需要立即关注）。要处理这类中断，您需要了解它们如何工作的一些基本原理；也就是说，操作系统如何处理它们，最重要的是，作为adriver的作者，你应该如何使用它们。Linux作为一个基于VM的富操作系统，在处理中断时需要并使用一些抽象，这增加了额外的复杂性。因此，您将首先学习如何处理硬件中断的（非常）基本工作流程。然后，我们将看看像你这样的驱动程序作者主要感兴趣的主题：如何准确分配IRQ并编写处理程序例程本身的代码——有一些非常具体的注意事项！然后，我们将介绍新线程中断模型背后的动机和使用方法，启用/禁用特定的IRQ，查看有关IRQ行viaproc的信息，以及上半部分和下半部分的用途以及如何使用它们。我们将通过回答一些关于中断处理的常见问题来结束本章。在本章中，我们将介绍以下主题：硬件中断以及内核如何处理它们分配硬件IRQ实现中断处理程序路由使用线程中断模型启用和禁用IRQ处理硬件中断第4章[151]查看所有分配的中断（IRQ）行理解和使用上下半程还有几个常见问题解答让我们开始吧！技术要求本章假设您已经阅读了前言部分，以充分利用本书，并适当准备了一个运行Ubuntu 18.04 LTS（或更高版本）的客户机，并安装了所有必需的软件包。如果没有，我强烈建议你先这样做。为了充分利用这本书，我强烈建议你首先设置workspace环境，包括为代码克隆这本书的GitHub存储库，并以动手的方式进行操作。</p>
<h3 id="硬件中断以及内核如何处理中断"><a href="#硬件中断以及内核如何处理中断" class="headerlink" title="硬件中断以及内核如何处理中断"></a>硬件中断以及内核如何处理中断</h3><p>​    许多（如果不是大多数）外围控制器使用硬件中断来通知操作系统或设备驱动程序需要一些（通常是紧急的）操作。典型的例子包括网络适配器（NIC）、块设备（磁盘）、USB设备、AV设备、人机界面设备（HID），如键盘、鼠标、触摸屏和视频屏幕、时钟/时序、DMA控制器等。硬件中断背后的主要思想是效率。中断不是持续轮询芯片（在电池支持的设备上，这可能会导致电池迅速耗尽！），而是一种让低级软件仅在需要时运行的方法。这里有一个快速的硬件级概述（不涉及太多细节）：现代系统主板将有一种中断控制器芯片，通常称为[IO][a]PIC，是IO-[高级]可编程中断控制器的缩写，为了简单起见，我们只使用通用术语PIC）有一行到CPU的中断引脚。能够断言中断的板载外围设备将有一条IRQ线连接到PIC。</p>
<p>​    IRQ是中断请求的常用缩写词；它表示分配给外围设备的中断行。假设所讨论的外围设备是一个网络适配器（NIC），并且接收到一个网络数据包。（高度简化的）流程如下：1。外围设备（NIC）现在需要发出（断言）硬件中断；因此，它在PIC上声明其线路（根据需要为低或高逻辑；所有这些都是硬件内部的）。PIC在看到外围线路已被断言后，将断言的线路值保存在寄存器中。然后，PIC断言CPU的中断引脚。处理器上的控制单元在每条机器指令运行后检查每个CPU是否存在硬件中断。因此，如果发生硬件中断，它肯定会几乎立即知道。然后，CPU将引发硬件中断（当然，中断可以被屏蔽；我们将在稍后的启用和禁用IRQ部分对此进行更详细的讨论）。操作系统上的低级（BSP/平台）代码将与此挂钩并做出反应（这通常是汇编级别的代码）；例如，在ARM-32上，硬件中断的低级C入口点是arch/ARM/kernel/irq.C：asm_do_irq（）。从这里开始，操作系统执行代码路径，最终调用此中断所服务的驱动程序的registered中断处理程序例程。（同样，我们不打算在本章中关注硬件层，甚至硬件中断的特定平台级细节。我想重点谈谈作为驱动程序作者与你相关的内容——如何处理它们！）。硬件中断实际上是Linux操作系统上的首要任务：它抢占了当前正在运行的任何东西——无论是用户还是内核空间代码路径——以便运行。话虽如此，稍后我们将看到，在现代Linux内核上，可以采用线程中断模型来改变事物；请耐心一点，我们会到的！现在，让我们离题。我们提到了一个典型的外围设备示例，即网络控制器（或NIC），并基本上说它通过硬件中断为数据包传输和接收（Tx/Rx）提供服务。这曾经是真的，但现代高速NIC（通常为10Gbps或更高）的情况并不总是如此。为什么？答案很有趣：中断会真正中断处理器的极端速度会导致系统陷入一种称为活锁的有问题的情况；它无法应对极高的中断需求！与死锁（第6章，内核同步-第1部分）一样，系统实际上往往会冻结或挂起。那么，关于livelock，我们该怎么办？大多数高端现代NIC支持轮询操作模式；像Linux这样的现代操作系统有一个名为NAPI的网络接收路径基础结构（请注意，这与婴儿无关——它是New API的缩写），允许驱动程序根据需求在中断和轮询模式之间切换，并更有效地处理网络数据包（在接收路径上）。现在我们已经介绍了硬件中断，让我们学习一下作为驱动程序作者，如何使用它们。本章剩下的大部分章节将讨论这个问题。让我们从学习如何分配或注册IRQ行开始。分配硬件IRQOften，编写设备驱动程序的一个关键部分实际上是捕获和处理您正在编写驱动程序的芯片发出的硬件中断。你怎么做到的？问题在于，硬件中断从中断控制器芯片到CPU的路由方式差异很大；它具有很强的平台特异性。好消息是Linux内核提供了一个抽象层来抽象掉所有硬件级别的差异；它被称为通用中断（或IRQ）处理层。本质上，它在幕后执行所需的工作，并公开完全通用的API和数据结构。因此，至少在理论上，你的代码可以在任何平台上运行。当然，我们主要作为驱动程序作者将使用这个通用的IRQ层；我们使用的所有API和辅助例程都属于这一类。</p>
<p>​    回想一下，至少在最初，处理中断的是核心内核（正如我们在上一节中所学到的）。然后，它引用一个链表数组（Linux上非常常见的数据结构；在这里，数组的索引是IRQ号）来计算要调用的驱动级函数。</p>
<p>​    但是，如何将驱动程序的中断处理程序函数添加到此列表中，以便内核在设备发生中断时可以调用它？啊，这就是关键：你在内核中注册它。现代Linux提供了至少四种方法（API），您可以通过这些方法在中断行中注册兴趣，如下所示：</p>
<pre class="line-numbers language-none"><code class="language-none">request_irq()
devm_request_irq()
request_threaded_irq()
devm_request_threaded_irq() (recommended!)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    在此过程中，我们将查看一些驱动程序的代码，并学习如何处理线程中断。有很多东西要学和做；让我们继续吧！使用request_irq（）分配中断处理程序正如我们在I/O内存和I/O端口中看到的那样，irq行被认为是内核负责的资源。request_irq（）内核API可以被认为是驱动程序作者注册他们对irq的兴趣并将此资源分配给他们自己的传统方法，从而允许内核在中断异步到达时调用他们的处理程序。</p>
<p>你可能会觉得，这个讨论似乎与用户空间信号处理非常相似。在那里，我们调用sigaction（2）系统调用来注册对信号的兴趣。当信号（异步）到达时，内核调用已注册的信号处理程序（用户模式）例程！这里有一些关键的区别。首先，用户空间信号句柄不是中断；第二，用户空间信号处理程序运行纯innon特权用户模式；相比之下，驱动程序的内核空间中断句柄（异步）以内核权限在中断的上下文中运行！此外，一些信号实际上是处理器异常引发的软件副作用；广义上讲，当发生非法事件时，处理器将引发故障、陷阱或中止，并且必须“陷阱”（切换）到内核空间来处理它。试图访问无效页面（或没有足够权限）的进程或线程会导致MMU引发故障或中止；这导致操作系统故障处理根据进程上下文（即当前）对SIGSEGV信号进行编码！然而，引发某种异常并不总是意味着存在问题——系统调用只不过是操作系统的陷阱；即程序异常（通过x86/ARM上的syscall/SWI）。内核源代码中的以下注释（在下面的代码段中部分重现）告诉我们更多关于request[_thread]_irq（）API的功能：</p>
<p>​    处理硬件中断第4章[156]始终包含linux/encrupt.h头文件。让我们逐一检查request_irq（）的每个参数：int irq：这是您试图注册或捕获/挂入的irq行。这意味着，当这个特定的中断触发时，您的中断handlerfunction（第二个参数handler_func）将被调用。关于irq的问题是：我如何知道irq号码是什么？我们在（reallykey）获取设备资源部分的第3章“使用硬件I/O内存”中解决了这个通用问题。快速重申，IRQ行是aresource，这意味着它是以通常的方式获得的——在现代嵌入式系统上，它是通过解析设备树（DT）获得的；旧的方法是在特定于板的源文件中硬编码值（放松，您将看到一个通过IRQ分配中的DT查询IRQ行的示例——现代方式——受管中断设施部分）。在PC类型的系统上，您可能不得不询问设备所在的总线（对于冷设备）。在这里，PCI总线（和朋友）非常常见。内核甚至提供了PCI helperroroutines，您可以使用它来查询资源，从而找到分配的irq line.irq_handler_t（*handler_func）（int，void*）：此参数是中断处理程序函数的apointer（在C中，只需提供函数的名称就足够了）。当然，这是硬件中断触发时将异步调用的代码。它的工作是为中断提供服务（稍后将详细介绍）。内核如何知道它在哪里？回想一下结构irqaction，它是由request_irq（）例程填充的结构。它的一个成员是handler，并设置为第二个参数。设计的长标志：这是request_irq（）的第三个参数，是标志掩码。当它设置为零时，它实现了默认行为（我们将在设置中断标志部分讨论一些关键的中断标志）。const char*name：这是拥有中断的代码/驱动程序的名称。通常，这被设置为设备驱动程序的名称（这样，/proc/enterrupts可以显示在中断中使用的驱动程序名称；它位于最右侧的列；详细信息请参见查看所有已分配的中断（IRQ）行部分。）</p>
<p>​    处理硬件中断第4章[157]void*dev：这是request_irq（）的第五个也是最后一个参数，允许您将任何想要的数据项（通常称为cookie）传递给中断处理例程，这是一种常见的软件技术。在第二个参数中，您可以看到中断处理程序例程是void*类型的。这就是传递此参数的地方。大多数现实世界的驱动程序都有某种上下文或私有数据结构，在那里它们存储了所有必需的信息。此外，这种上下文结构通常嵌入到驱动程序的设备（通常由子系统ordriver框架专门化）结构中。事实上，内核通常会帮助你做到这一点；例如，网络驱动程序使用alloc.etherdev（）将数据嵌入到结构net_device中，平台驱动程序将数据嵌入结构platform_device的platform_device.device.platform_data成员中，I2C客户端驱动程序使用I2C_set_clientdata（）助手将其私有/上下文数据“设置”到I2C_client结构中，等等。请注意，当您使用共享中断时（我们稍后会对此进行解释），您必须将此参数初始化为非NULL值（否则，free_irq（）如何知道要释放哪个处理程序？）。如果你没有文本结构或任何特定的东西可以传递，在这里传递THIS_MODULE宏就可以了（假设你使用可加载的内核模块框架编写驱动程序；它是指向内核模块元数据结构的指针；即struct模块）。根据通常的0/-E内核约定，request_irq（）的返回值是一个整数（请参阅配套指南Linux内核编程-第4章，编写你的第一个内核模块-LKM第1部分，0/-E返回约定一节），成功时为0，失败时为负errno值。</p>
<p>由于__must_check编译器属性明确指定，您当然需要检查故障情况（无论如何，这都是很好的编程实践）。Linux驱动程序验证（LDV）项目：在配套指南《Linux内核编程》第1章“内核工作区设置”的LDV-Linux驱动程序校验-项目一节中，我们提到该项目在Linux模块（主要是驱动程序）的各个编程方面以及核心内核方面都有有用的“规则”。关于我们当前的话题，这里有一条规则，一条否定的规则，暗示你不能这样做：“在探测IRQ时不要拖延”(<a target="_blank" rel="noopener" href="http://linuxtesting.org/ldv/online?action=show_rulerule_id=0037">http://linuxtesting.org/ldv/online?action=show_rulerule_id=0037</a>). 这个讨论确实适用于x86[_64]系统。在某些情况下，您可能需要实际探测正确的IRQ行号。为此，内核通过probe_irq_{on|off}（）API提供了一个“自动探测”功能（probe_irq_on（）返回一个可以使用的bitmaskof潜在irq行）。问题是，probe_irq_on（）和probe_irq_off（）API之间需要延迟；不考虑这种延迟可能会导致问题。前面提到的LDV页面对此进行了详细介绍，所以一定要看看。用于执行播放的实际API通常是udelay（）。不用担心，我们将在第5章“在内核中延迟给定时间”一节中详细介绍它（以及其他几个）。在驱动程序代码中，您应该在哪里调用request_irq（）API（或其等价物）？对于几乎所有遵循现代Linux设备模型（LDM）的现代驱动程序，即用于设备和驱动程序的现代内核框架，probe（）方法（这实际上是一个函数）是正确的选择。释放IRQ行相反，当驱动程序被卸载或设备被分离时，remove（或disconnect（））方法是正确的地方，你应该在那里调用converse例程–free_IRQ（）–将IRQ行释放回内核：</p>
<pre class="line-numbers language-none"><code class="language-none">void *free_irq(unsigned int, void *);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>free_irq（）的第一个参数是释放回内核的irq行。第二个参数与传递给中断处理程序的值相同（通过request_irq（）的last参数），因此您通常必须用devicestructure指针（嵌入驱动程序的上下文或私有数据结构）或THIS_MODULE宏填充它。</p>
<p>​    返回值是设备名称参数，成功时作为request_irq（）例程的第四个参数传递（是的，它是一个字符串），失败时为NULL。作为驱动程序的作者，您必须注意以下几点：当共享irq行时，在调用free_irq（）之前禁用板上的中断。仅从进程上下文中调用它。此外，free_irk（）只有在该irq行的任何和所有执行中断完成时才会返回。在我们查看一些代码之前，我们需要简要介绍另外两个领域：中断标志和级别/边缘触发中断的概念。在分配中断（IRQ线路）时设置中断标志{devm_}request{_threaded}_irq（）API（我们稍后将介绍request_irq（）的变量），您可以指定某些中断标志，这些标志将影响中断行的配置和/或行为。负责此操作的参数是设计好的长标志（正如我们在用request_irq（）分配中断处理程序一节中提到的那样）。重要的是要意识到这是一个比特掩码；您可以按位或多个标志来获得它们的组合效果。标志值大致分为几类：与IRQ行共享、中断线程和挂起/恢复行为相关的标志。它们都在IRQF_foo格式的thelinux/encrupt.h标头中。以下是一些最常见的：IRQF_SHARED：这允许您在多个设备之间共享IRQ线路（PCI总线上的设备需要）。IRQF_ONESHOT:在hardirq处理程序完成执行后，IRQ未启用。此标志通常由线程中断（在“使用线程中断模型”一节中介绍）使用，以确保IRQ在线程处理程序完成之前保持禁用状态。</p>
<p>__IRQF_TIMER标志是一种特殊情况。它用于将中断标记为定时器中断。如配套指南《Linux内核编程》第10章“CPU调度器-第1部分”和第11章“CPU调度程序-第2部分”所示，当我们研究CPU调度时，定时器中断以周期性间隔触发，并负责实现内核的定时器/超时机制、与调度程序相关的内务管理等。定时器中断标志由以下宏指定：</p>
<pre class="line-numbers language-none"><code class="language-none">\#define IRQF_timer（__IRQF_timer|IRQF_NO_SUSPEND|IRQFNOT_THREAD）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>除了指定它被标记为定时器中断（__IRQF_timer）外，IRQF_NO_SUSPEND标志还指定即使在系统进入挂起状态。此外，IRQF_NO_THREAD标志指定此中断不能使用线程模型（我们将在使用线程中断模型一节中介绍这一点）。我们还可以使用其他几个中断标志，包括IRQF_PROBE_SHARED、IRQF_PERCPU、IRQF_NOBALANCING、IRQF_IRQPOLL、IRQF_FORCE_RESUME、IRQF_EARLY_RESUME和IRQF_COND_SUSPEND。我们在这里不会明确地介绍它们（请查看linux/encrupt.h头文件中简要描述它们的注释头）。现在，让我们简要了解一下什么是级别和边缘触发的中断。</p>
<h3 id="理解电平和边缘触发的中断"><a href="#理解电平和边缘触发的中断" class="headerlink" title="理解电平和边缘触发的中断"></a>理解电平和边缘触发的中断</h3><p>注意当外围设备断言中断时，中断控制器会被触发以锁存此事件。它用于触发CPUfall中硬件中断的电气特性分为两大类：级别触发：当级别发生变化（从非活动到活动或断言）时触发中断；在取消断言之前，该行将保持断言状态。即使在处理程序返回后也会发生这种情况；如果该行仍然有效，您将再次收到中断。边缘触发：当级别从非活动状态变为活动状态时，中断只触发一次。外，中断可能在上升或下降（时钟）沿被高或低触发。内核允许通过额外的标志进行配置和指定，如IRQF_TRIGGER_NONE、IRQF_TRICGER_RISING、IRQF-TRIGGER_FALLING、IRQF_TRIGGER_HIGH、IRQF.TRIGGER_LOW等。外围芯片的这些低级电气特性通常在BSP级代码或DT中指定的代码中预先配置。级别触发的中断迫使您了解中断源，以便您可以正确地取消（或确认）它（在共享IRQ的情况下，在检查它是否适合您之后）。通常，这是维修时必须做的第一件事；否则，它将继续触发。例如，如果中断是在某个设备寄存器达到值0xff时触发的，那么驱动程序必须在断言之前将寄存器设置为0x0！这很容易看到，但很难正确处理。另一方面，边缘触发中断很容易使用，因为不需要知道中断源，但它们也很容易被错过！一般来说，固件设计人员使用边缘触发中断（尽管这不是一个规则）。同样，这些特征实际上处于硬件/固件边界。您应该研究为您编写驱动程序的外围设备提供的数据表和任何相关文档（如OEM的应用程序说明）。您现在可能已经意识到，编写设备驱动程序（好吧！）需要两个不同的知识领域。首先，你需要深入了解硬件/固件及其工作原理——它的操作理论（TOO）、控制/数据平面、寄存器组、I/O内存等。其次，你需要对操作系统（Linux）及其内核/驱动程序框架、Linux的工作原理、内存管理、调度、中断模型等有深入（足够）的了解。此外，你需要了解现代LDM和内核驱动程序框架，以及如何调试和分析它们。你在这些方面做得越好，你就越能写出驱动程序！我们将学习如何在查看所有分配（IRQ）行部分中找出使用了哪种触发。查看进一步阅读部分，了解更多关于IRQedge/level触发的链接。现在，让我们继续看一些有趣的东西。为了帮助您吸收到目前为止学到的知识，我们将查看Linux网络驱动程序中的一些小代码片段！</p>
<h3 id="中断上下文指南——做什么和不做什么"><a href="#中断上下文指南——做什么和不做什么" class="headerlink" title="中断上下文指南——做什么和不做什么"></a>中断上下文指南——做什么和不做什么</h3><p>​    中断处理程序例程是典型的C代码，但有一些注意事项。关于硬件中断处理程序的设计和实现，有几个关键点如下：处理程序在中断上下文中运行，所以不要阻塞：首先，这段代码总是在中断上下文下运行；即原子上下文。在可接受的内核上，抢占是禁用的，因此对于它能做什么和不能做什么有一些限制。特别是，它不能直接或间接调用调度器（schedule（））！实际上，您不能执行以下操作：在内核和用户空间之间传输数据，因为这可能会导致页面错误，这在原子上下文中是不允许的。在内存分配中使用GFP_KERNEL标志。您必须使用GFP_ATOMIC标志，以便分配是非阻塞的——它要么立即成功，要么立即失败。调用任何正在阻塞的API（即，调用sschedule（））。换句话说，它必须是纯粹的非阻塞代码路径。</p>
<p>​    中断屏蔽：默认情况下，当您的中断处理程序运行时，您的处理程序正在执行的本地CPU核心上的所有中断都会被屏蔽（禁用），并且您正在处理的特定中断会在所有核心上被屏蔽。因此，你的代码本质上是可重入安全的。保持快速！：你正在编写的代码会真正中断其他进程——在你粗鲁地中断之前系统正在运行的其他“业务”；因此，您必须尽可能快地执行所需的操作，并返回，允许中断的代码路径继续。重要的系统软件指标包括最坏情况中断长度和最坏情况下中断的禁用时间（我们将在本章末尾的测量指标和延迟部分对此进行更多介绍）。这些要点非常重要，值得更详细地介绍，因此我们将在以下小节中更全面地介绍它们。</p>
<p>​    不要阻塞——发现可能阻塞的代码路径这实际上归结为这样一个事实，即当你处于中断或原子上下文中时，不要做任何会调用schedule（）的事情。现在，让我们来看看如果我们的中断处理程序的伪代码看起来像这样会发生什么：</p>
<pre class="line-numbers language-none"><code class="language-none">my_interrupt()
&#123;
 struct mys *sp;
 ack_intr();
 x &#x3D; read_regX();
 sp &#x3D; kzalloc(SIZE_HWBUF, GFP_KERNEL);
 if (!sp)
 return -ENOMEM;
 sp &#x3D; fetch_data_from_hw();
 copy_to_user(ubuf, sp, count);
 kfree(sp);
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    你发现了这里潜在的大错误（尽管可能仍然很微妙）吗？（在继续之前，请花点时间发现它们。）首先，使用GFP_KERNEL标志调用kzalloc（）可能会导致其内核代码调用schedule（）！如果是这样，这将导致“糟糕”，这是一个内核错误。在典型的生产环境中，这会导致内核死机（因为sysctlnamed panic_on_oops在生产环境中通常设置为1；执行sysctlkernel.parin_oops将显示当前设置）。接下来，copy_to_user（）调用可能会导致页面错误，因此需要一个上下文开关，当然，这将调用schedule（）；这在原子或中断环境中是不可能的，这也是一个严重的错误！因此，更一般地说，让你的中断处理程序调用一个函数a（），a（）的调用链如下：</p>
<pre class="line-numbers language-none"><code class="language-none">a() -- b() -- c() -- [...] -- g() -- schedule() -- [...]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    在这里，你可以看到调用a（）最终会导致schedule（）被调用，正如刚才指出的，这将导致“Oops”，这是一个内核错误。所以，这里的问题是，作为驱动程序开发人员，你如何知道当你调用a（）时，会导致schedule（）被调用？关于这一点，你需要理解和利用几点：（正如配套指南《Linux内核编程》第8章“模块作者的内核内存分配”第1部分所述）一种提前发现内核代码是否会进入原子或中断上下文的方法是直接查看内核。当你配置内核时（同样，如配套指南《Linux内核编程》中所示，请回忆一下《Linux内核程序设计》第2章“从源代码构建5.x LinuxKernel”第1部分中的makemenuconfig），你可以打开一个内核配置选项，帮助你准确地发现这种情况。请查看“内核黑客/锁定调试”菜单。在那里，您将找到一个名为Sleepinside原子部分检查的布尔可调变量。打开它！配置选项名为config_DEBUG_ATOMIC_SLEEP；您也可以为它创建内核的配置文件。如公司指南《Linux内核编程》第5章“编写第一个内核模块”第2部分“配置调试内核”部分所示，我们指定应打开此选项！接下来（这有点迂腐，但会对你有所帮助！），养成查找有关函数的内核文档的习惯（更好的是，简要查找它的代码）。这是一个阻塞调用的事实通常会在注释头中记录或指定。内核有一个名为might_sleep（）的辅助宏；对于这些情况，它是一个有用的调试辅助工具！以下截图（来自kernelsource，include/linux/kernel.h）清楚地解释了这一点：</p>
<p><img src="./image-20240726094522886.png" alt="image-20240726094522886"></p>
<h3 id="中断掩码——默认值和控制"><a href="#中断掩码——默认值和控制" class="headerlink" title="中断掩码——默认值和控制"></a>中断掩码——默认值和控制</h3><p>​    中断控制器芯片（PIC/GIC）将有一个掩码寄存器。操作系统可以根据需要对其进行编程以屏蔽或阻止硬件中断（当然，一些中断可能是不可屏蔽的；不可屏蔽中断（NMI）是我们在本章讨论的一个典型案例）。不过，重要的是要意识到，尽可能多地保持中断启用（未屏蔽）是衡量操作系统质量的关键指标！为什么？如果中断被阻止，外围设备将无法响应，从而导致系统性能滞后或受损（仅仅按下和释放键盘键就会导致两次硬件中断）。您必须尽可能长时间地启用中断。使用自旋锁锁定将导致中断和抢占被禁用！关键部分要简短（我们将在本书的最后两章深入探讨锁定）。接下来，当涉及到Linux操作系统上的默认行为时，当发生硬件中断并且该中断未被屏蔽（始终是默认的）时，假设它是IRQn（其中n是IRQ数字），内核确保在其中断（hardirq）处理程序执行时，处理程序执行的本地CPU核上的所有中断都被禁用，并且IRQn在所有CPU上都被禁用。因此，您的处理程序代码本质上是可重入安全的。这很好，因为这意味着你永远不必担心以下问题：屏蔽会中断你自己。何时在该CPU上原子性地运行，完成且不中断。正如我们稍后将看到的，下半部分仍然可以被上半部分中断，从而终止锁定。当IRQn在CPU核1上执行时，除核1外，其他中断在所有CPU核上都保持启用（未屏蔽）状态。因此，在多核系统硬件上，中断可以在不同的CPU核上并行运行。就全球数据而言，只要他们不踩到对方的脚趾，这很好！如果他们这样做，你将不得不使用锁定，我们将在本书的最后两章中详细介绍这一点。</p>
<p>此外，在Linux上，所有中断都是对等的，因此它们之间没有优先级；换句话说，它们都以相同的优先级运行。只要没有屏蔽，任何硬件中断都可以在任何时间点中断系统；中断甚至可以中断中断！然而，他们通常不会做后者。这是因为，正如我们刚刚了解到的，当中断IRQn在CPU内核上运行时，该内核上的所有中断都被禁用（屏蔽），IRQn被全局禁用（跨所有内核），直到它完成；例外情况是NMI。</p>
<h3 id="保持快速"><a href="#保持快速" class="headerlink" title="保持快速"></a>保持快速</h3><p>​    中断是指：它会中断机器的正常工作；这有点令人沮丧，必须容忍。必须保存上下文，必须执行处理程序（以及下半部分，我们将在理解和使用上半部分和下半部分部分中介绍），然后必须将上下文恢复到被中断的状态。所以，你明白了：这是一条关键的代码路径，所以不要拖拖拉拉——要快速、无阻塞！这也提出了一个问题，速度有多快？当然，答案取决于平台，但一个启发式方法是：尽可能快地处理中断，在微秒内。如果它持续超过100微秒，那么确实需要采取替代策略。我们将在本章稍后介绍发生这种情况时您可以做些什么。关于我们简单的my_interrupt（）伪代码片段（如“不要阻塞——发现可能阻塞的代码路径”一节所示），首先，问问自己，我是否真的必须在关键的非阻塞需求中分配内存来执行快速代码路径，如中断处理程序？你能设计模块/驱动程序来提前分配内存（只使用指针）吗？同样，现实情况是，有时必须做很多工作才能正确地为中断提供服务（网络/块驱动程序就是很好的例子）。我们将很快介绍一些可以用来处理这个问题的典型策略。</p>
<p>​    现在，让我们快速学习它的机械部分。硬件中断处理程序例程（通常称为hardirq例程）的签名如下：</p>
<pre class="line-numbers language-none"><code class="language-none">static irqreturn_t interrupt_handler(int irq, void *data);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    当驱动程序注册感兴趣的硬件IRQ（通过request_IRQ（）或friends API）被触发时，中断处理程序例程由内核的通用IRQ层调用。它接收两个参数：第一个参数是IRQ行（整数）。触发此操作会导致调用此处理程序。第二个参数是通过最后一个参数传递给request_irq（）的值。正如我们之前提到的，嵌入驱动程序上下文或私有数据的通常是驱动程序的专用设备结构。因此，它的数据类型是泛型void*，允许request_irq（）传递任何类型，在处理程序例程中适当地进行类型转换并使用它。处理程序是常规的C代码，但有我们在前一节中提到的所有注意事项！请务必遵循这些指导方针。虽然细节是特定于硬件的，但通常情况下，中断处理程序的首要职责是清除板上的中断，实际上是确认并告知PIC。这通常是通过将一些特定位写入板或控制器上的指定硬件寄存器来实现的；阅读您的特定芯片、芯片组或硬件设备的数据表以了解这一点。在这里，in_irq（）宏将返回true，通知您的代码当前处于hardirq上下文中。处理程序完成的其余工作显然是特定于设备的。例如，输入驱动程序希望扫描刚刚从某个寄存器或外围存储器位置按下或释放的按键代码（或触摸屏坐标或鼠标按键/移动或其他任何东西），并可能将其保存在某个存储缓冲区中。或者，它可能会立即将其向上传递到堆栈之上的通用输入层。我们在这里不会试图深入探讨这些细节。同样，驱动程序框架是您需要了解的驱动程序类型；这超出了本书的范围。那么从hardirq处理程序返回的值呢？irqreturn_t返回值是一个枚举，如下所示：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; include&#x2F;linux&#x2F;irqreturn.h
&#x2F;**
 * enum irqreturn
 * @IRQ_NONE interrupt was not from this device or was not handled
 * @IRQ_HANDLED interrupt was handled by this device
 * @IRQ_WAKE_THREAD handler requests to wake the handler thread
 *&#x2F;
enum irqreturn &#123;
 IRQ_NONE &#x3D; (0 0),
 IRQ_HANDLED &#x3D; (1 0),
 IRQ_WAKE_THREAD &#x3D; (1 1),
&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    前面的评论标题清楚地指出了它的含义。本质上，通用IRQframework坚持认为，如果驱动程序处理了中断，则返回IRQ_HANDLED值。如果中断不是你的，或者你无法处理它，你应该返回IRQ_NONE值。（这也有助于内核检测虚假中断。如果您无法确定这是否是您的中断，只需返回IRQ_HANDLED。）我们稍后将了解IRQ_WAKE_THREAD的使用方法。现在，让我们看看更多的代码！在下一节中，我们将查看两个驱动程序的硬件中断处理程序代码（我们在本章和上一章的前面遇到了这些代码）。代码视图2–i8042驱动程序的中断处理程序在上一章第3章“使用硬件I/O内存”的A PIO示例中的i8042部分，我们学习了i8042设备驱动程序如何使用一些非常简单的辅助例程在i8042芯片（通常是x86系统上的键盘/鼠标控制器）的I/O端口上执行I/O（读/写）。以下代码片段显示了其硬件中断处理程序例程的一些代码；您可以清楚地看到它正在读取状态和数据寄存器：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;*
 * i8042_interrupt() is the most important function in this driver -
 * it handles the interrupts from the i8042, and sends incoming bytes
 * to the upper layers.
 *&#x2F;
static irqreturn_t i8042_interrupt(int irq, void *dev_id)
&#123;
 unsigned char str, data;
 [...]
 str &#x3D; i8042_read_status();
 [...]
 data &#x3D; i8042_read_data();
 [...]
 if (likely(serio &amp;&amp; !filtered))
 serio_interrupt(serio, data, dfl);
 out:
 return IRQ_RETVAL(ret);
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="IRQ分配——现代方式——管理中断设施"><a href="#IRQ分配——现代方式——管理中断设施" class="headerlink" title="IRQ分配——现代方式——管理中断设施"></a>IRQ分配——现代方式——管理中断设施</h3><p>​    许多现代驱动程序都将内核的开发人员或管理API框架用于各种目的。现代Linux内核中的托管API使您无需担心释放已分配的资源（我们已经介绍了其中的一些，包括devm_k{m,z}alloc（）和devm_ioremap{_resource}（））。当然，您必须适当地使用它们，通常是在驱动程序的探测方法（或初始化代码）中。在编写驱动程序时，建议您使用这种较新的API样式。在这里，我们将展示如何使用devm_request_irq（）API来分配（注册）硬件中断。其签名如下：</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;linux&#x2F;interrupt.h&gt;
int __must_check
devm_request_irq(struct device *dev, unsigned int irq, irq_handler_t
handler,
 unsigned long irqflags, const char *devname, void
*dev_id);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    第一个参数是指向设备结构的指针（正如我们在第1章“编写简单的杂项字符设备驱动程序”中看到的，必须通过注册到适当的内核框架来获得）。剩下的五个参数是相同的torequest_irq（）；我们在此不再赘述。关键在于，一旦注册，您就无需调用free_irq（）；内核将根据需要自动调用它（驱动程序删除或设备分离）。这极大地帮助我们开发人员避免了常见和不知名的泄漏类型的错误。为了帮助阐明它的用途，让我们快速看一个例子。以下是V4L电视调谐器驱动程序的一段代码：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; drivers&#x2F;gpu&#x2F;drm&#x2F;exynos&#x2F;exynos_mixer.c
[...]
 res &#x3D; platform_get_resource(mixer_ctx-&gt;pdev, IORESOURCE_IRQ, 0);
 if (res &#x3D;&#x3D; NULL) &#123;
 dev_err(dev, &quot;get interrupt resource failed.\n&quot;);
 return -ENXIO;
 &#125;
 ret &#x3D; devm_request_irq(dev, res-&gt;start, mixer_irq_handler,
 0, &quot;drm_mixer&quot;, mixer_ctx);
 if (ret) &#123;
 dev_err(dev, &quot;request interrupt failed.\n&quot;);
 return ret;
 &#125;
 mixer_ctx-irq &#x3D; res-&gt;start;
[...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    正如我们在第3章“使用硬件I/O内存”中关于获取MMIO的物理地址所看到的，在获取设备资源部分，这里，相同的驱动程序使用platform_get_resource（）API来提取IRQ编号（使用IORESOURCE_IRQ将资源类型指定为IRQ行）。一旦有了它，它就会发出devm_request_irq（）API来分配或注册中断！因此，在该驱动程序中搜索free_irq（）不会得到任何结果。接下来，我们将学习什么是线程中断，如何使用线程中断，更重要的是，它的原因。</p>
<p>​    实时Linux（RTL）项目的工作已经稳定地移植到主流Linux内核中。RTL带来的一个关键变化是将线程中断功能合并到主线内核中。这发生在内核版本2.6.30（2009年6月）中。这项技术做了一件乍一看很奇怪的事情：它将硬件中断处理程序“转换”为内核线程。正如您将在下一章中了解到的那样，内核线程与用户模式线程非常相似——它在进程上下文中独立运行，并具有自己的任务结构（以及自己的PID、TGID等），这意味着它可以被调度；也就是说，当处于不可运行状态时，它会与其他竞争者线程竞争在CPU内核上运行。关键区别在于，用户模式线程总是有两个地址空间——它所属的进程VAS（用户空间）和内核VAS，当它发出系统调用时，它会切换到内核VAS。另一方面，内核线程纯粹在内核空间中运行，没有用户空间视图；它只看到它始终在其中执行的内核VAS（从技术上讲，其当前的mm值始终为NULL！）。那么，如何决定是否应该使用线程中断呢？在这一点变得完全清楚之前，我们需要涵盖更多的主题（对于那些不耐烦的人来说，简短的答案是：当（作为快速启发式）中断工作需要超过100微秒时，使用线程中断处理程序；跳到Hardirqs、tasklets、threadedcandlers（何时使用什么）部分，并快速查看那里的表）。现在，让我们通过查看可用的API（包括常规API和托管API）来学习如何使用线程中断模型。然后，我们将学习如何使用managedversion以及如何在驱动程序中使用它。之后，我们将看看它的内部实现，并深入探讨它的原因。使用线程中断模型——API为了理解线程中断模型的内部工作原理，让我们来看看相关的API。我们已经介绍过使用request_irq（）API。让我们来看看它的实现：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; include&#x2F;linux&#x2F;interrupt.h
static inline int __must_check
request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags,
const char *name, void *dev)
&#123;
 return request_threaded_irq(irq, handler, NULL, flags, name, dev);
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    这个API只是request_threadsed_inq（）API的精简包装！其签名如下：</p>
<pre class="line-numbers language-none"><code class="language-none">int __must_check
request_threaded_irq(unsigned int irq, irq_handler_t handler,
 irq_handler_t thread_fn,
 unsigned long flags, const char *name, void *dev);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>除了第三个参数外，其他参数与request_irq（）相同。以下是需要注意的几个关键点：irq_handle_t处理程序：第二个参数是指向常用中断处理程序函数的指针。我们现在将其称为主处理程序。如果它为null并且thread_fn（第三个参数）为非null，则会自动安装（内核的）默认主处理程序（如果你想知道这个默认主处理函数，我们将在内部实现threadininterrupt部分中更详细地介绍它）；API的行为取决于您是否将此参数传递为null：如果它不是null，则中断的实际服务由此函数执行。它在指定内核线程的上下文（进程）中运行——这是一个线程中断！如果它为null，这是调用request_irq（）时的默认值，则只运行主处理程序，不创建内核线程。</p>
<p>​    如果指定了主处理程序（第二个参数），它将在所谓的hardirq或硬中断上下文中运行（与request_irq（）的情况一样）。如果主处理程序不为空，那么您需要编写它的代码，并（至少）在其中执行以下操作：验证中断是否适合您；如果不是，则返回IRQ_NONE。如果适合您，则可以清除和/或禁用板/设备上的中断。返回IRQ_WAKE_THREAD；这将导致内核唤醒代表线程中断处理程序的kernelthread。内核线程的名称将采用irq/irq#-name格式。这个内核线程现在将在内部调用thread_fn（）函数，在那里你执行实际的中断处理工作。另一方面，如果主处理程序为空，那么当中断触发时，只有你的线程处理程序——由第三个参数指定的函数——将由操作系统自动作为内核线程运行。与request_irq（）一样，request_threaded_irq的返回值是一个整数，遵循通常的0/-E内核约定：成功时为0，失败时为负的errno值。你应该检查一下。使用托管线程中断模型——推荐的方法再次，使用托管API分配线程中断将是现代驱动程序的推荐方法。内核为这个目的提供devm_request_threadd_irq（）API</p>
<pre class="line-numbers language-none"><code class="language-none">\#include linux&#x2F;interrupt.h
int __must_check
 devm_request_threaded_irq(struct device *dev, unsigned int irq,
 irq_handler_t handler, irq_handler_t thread_fn,
 unsigned long irqflags, const char *devname,
 void *dev_id);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    除了第一个参数（指向设备结构的指针）外，所有参数都与request_threaded_irq（）的参数相同。这样做的主要优点是，您不需要担心释放IRQ行。内核将在设备分离或删除时自动释放它，正如我们在devm_request_irq（）中学到的那样。与request_threaded_irq（）一样，devm_request_threadd_irq（）的返回值是一个整数，遵循通常的0/-E内核约定：成功时为0，失败时为负errno值；你应该检查一下。别忘了！使用托管的devm_request_threaded_irq（）API是分配线程中断的现代推荐方法。然而，请注意，这并不总是正确的方法；有关更多信息，请参阅使用线程处理程序时的约束部分。线程中断处理程序函数的签名与hardirqinterrupt处理程序的签名相同：</p>
<pre class="line-numbers language-none"><code class="language-none">static irqreturn_t threaded_handler(int irq, void *data);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这些参数也具有相同的含义。线程中断通常使用IRQF_ONESHOT中断标志；内核注释include/linux/encrupt.h对其进行了最好的描述：<em>IRQF_ONESHOT-在hardirq句柄完成后，中断不会重新启用。</em>由线程中断使用，线程中断需要在线程处理程序运行之前保持*irq行禁用。事实上，当驱动程序包含线程处理程序并且主处理程序是内核默认值时，内核坚持使用IRQF_ONESHOT标志。当输入电平触发的中断时，不使用IRQF_ONESHOT标志将是致命的。为了安全起见，即使在边缘触发时，当irqflagsbitmask参数中不存在此标志时，内核也会抛出错误。如果你很好奇，atkernel/irq/manage.c:__setup_irq（）代码会检查这一点（链接：<a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v5.4/source/kernel/irq/manage.c\#L1486).存在一个名为threadirqs的内核参数，您可以将其传递给内核命令行（通过引导加载程序）。此强制线程化所有中断处理程序，但显式标记为IRQF_NO_THREAD的处理程序除外。要了解有关此内核参数的更多信息，请访问https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html">https://elixir.bootlin.com/linux/v5.4/source/kernel/irq/manage.c\#L1486).存在一个名为threadirqs的内核参数，您可以将其传递给内核命令行（通过引导加载程序）。此强制线程化所有中断处理程序，但显式标记为IRQF_NO_THREAD的处理程序除外。要了解有关此内核参数的更多信息，请访问https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html</a>.</p>
<h3 id="在内部实现线程中断"><a href="#在内部实现线程中断" class="headerlink" title="在内部实现线程中断"></a>在内部实现线程中断</h3><p>正如我们之前提到的，如果主处理程序为null，线程函数为非null，内核将使用默认的主处理程序。该函数名为irq_default_primary_handler（），它所做的就是返回irq_WAKE_THREAD值，从而唤醒（并使其可调度）内核线程。此外，运行thread_fn例程的实际内核线程是在request_threadd_irq（）API的代码中创建的。调用图（从Linux内核的5.4.0版本开始）如下：kernel/irq/manage.c:request_threadd_irq（）—__setup_irq（）—setup_irq_thread（）—kernel/kthread.c:kthread_create（）调用kthread_create（（）API如下。在这里，您可以清楚地看到新内核线程名称的格式将采用irq/irq#-name格式：t=kthread_create（irq_thread，new，“irq/d-s”，irq，new-&gt;name）；在这里（我们没有显示代码），新的内核线程被编程为设置为SCHED_FIFO调度策略和MAX_USER_RT_PRIO/2实时调度优先级，该优先级通常为50（SCHED_FIFO范围为1到99，MAX_USER_LT_PRIO为100）。我们将在“为什么使用线程中断”中介绍为什么这很重要？部分。如果您不确定线程调度策略及其优先级，请参阅配套指南Linux内核编程-第10章，CPUScheduler-第1部分，POSIX调度策略部分。内核管理这个代表整个线程中断处理程序的内核线程。正如我们已经看到的，它通过[devm_]request_threaded_inrq（）API在IRQ分配上创建它；然后，内核线程只是休眠。每当分配的IRQ被触发时，它都会被内核按需唤醒；当调用freeirq（）时，内核将销毁它。现在不要担心细节；我们将在下一章介绍内核线程和其他有趣的主题。到目前为止，尽管您已经学会了如何使用线程中断模型，但还没有清楚地解释为什么（以及何时）应该使用它。下一节将对此进行详细介绍。</p>
<h3 id="为什么要使用线程中断？"><a href="#为什么要使用线程中断？" class="headerlink" title="为什么要使用线程中断？"></a>为什么要使用线程中断？</h3><p>​    一个通常被问到的关键问题是，当存在规则的hardirq类型中断时，我为什么要使用线程中断？完整的答案有点复杂；以下是主要原因：真正做到实时。它消除/减少了软硬件瓶颈。由于线程处理程序实际上在进程上下文中运行代码，因此它不被认为是像ahardirq处理程序那样重要的代码路径；因此，中断处理可能需要更长的时间。当hardirq执行IRQn时，系统中所有内核上的IRQ线路都被禁用。如果执行到完成需要一段时间（当然，您应该将其设计为不需要），那么系统的响应可能会显著下降；另一方面，当线程处理程序执行时，默认情况下会启用硬件IRQ行。这对性能和响应性都有好处。（请注意，在许多情况下，驱动程序不希望出现这种行为；也就是说，它希望在处理IRQ时禁用IRQ。为此，请指定IRQF_ONSEHOT标志。）简而言之，作为一条快速经验法则，当中断处理持续超过100微秒时，使用线程中断模型（见Hardirqs、小任务、线程处理程序——何时使用）。在接下来的小节中，我们将详细介绍这些要点。线程中断——真正做到实时这是一个关键点，需要一些解释。标准Linux操作系统的优先级从最高优先级到最低优先级，如下所示（我们将在每个项目符号后加上它运行的上下文；它将是进程或中断。如果你不清楚这一点，了解这一点非常重要；请参阅公司指南《Linux内核编程》-第6章，内核内部基础知识-进程和线程，了解进程和中断上下文部分，以获取更多信息）：硬件中断：这些抢占任何东西。hardirq处理程序在CPU上以原子方式运行（直到完成，不中断）；上下文：中断。实时线程（SCHED_FIFO或SCHED_RR调度策略），包括内核和用户空间，具有正实时优先级（rtprio）；上下文：进程：具有相同实时优先级（当前rtprio）的内核线程在相同实时优先级的用户空间线程上获得了轻微的优先级提升。处理器异常：这包括系统调用（它们实际上是同步异常；例如，x86上的系统调用、ARM上的SWI）、页面错误、保护错误等；上下文：过程。用户模式线程：默认情况下，它们使用SCHED_OTHER调度策略，rtprio为0；上下文：过程。下图显示了Linux上的相对优先级（此图有点简单；稍后通过图4.10和图4.11可以看到更精细的图）</p>
<p><img src="./image-20240726095351078.png" alt="image-20240726095351078"></p>
<p>假设您正在开发一个实时多线程应用程序。在进程中活跃的数十个线程中，有三个（为简单起见，我们称之为线程A、B和C）被认为是关键的“实时”线程。因此，您可以让应用程序分别向线程a、B和C授予SCHED_FIFO的调度策略和30、45和60的实时优先级（如果您对这些点不清楚，请参阅公司指南《Linux内核编程》第10章“CPU调度器”第1部分和第11章“CPU调度程序”第2部分，了解CPU调度）。由于这是一个实时应用程序，这些线程完成工作所需的最长时间被缩短了。换句话说，存在一个截止日期；对于我们的示例场景，假设读取B完成其工作的最坏截止时间为12毫秒。现在，就相对优先级而言，这将如何运作？为简单起见，假设系统有一个CPU内核。现在，另一个线程X（使用schedulingpolicy SCHED_OTHER运行，实时优先级为0，这是默认的schedulingpolicy/priority值）当前正在CPU上执行代码。但是，如果您的任何实时线程正在等待的“事件”发生，它将抢占当前正在执行的线程并运行。这是人们所期望的；回想一下，实时调度的基本规则非常简单：最高优先级的可运行线程必须是正在运行的线程。可以；那很好。现在，我们需要考虑硬件中断。正如我们所见，硬件中断具有最高优先级。这意味着它将抢占任何东西，包括你的（所谓的）实时线程（见上图）！</p>
<p>\假设中断处理需要200微秒；在Linux等丰富的操作系统上，这并不算太糟糕。然而，在这种情况下，五个硬件中断将消耗1毫秒；如果设备变得繁忙（例如，许多传入数据包）并连续发出20个硬件中断怎么办？这肯定会被赋予优先级，并将消耗（至少）4毫秒！当中断处理运行时，您的实时线程肯定会被抢占，并且将无法获得所需的CPU，直到为时已晚！（12毫秒）的最后期限将早已到期，系统将失败（如果你的应用程序是真正的实时应用程序，这可能是灾难性的）。下图从概念上表示了这种情况（为了简洁明了，我们只显示了一个用户空间SCHED_FIFO实时线程；即线程Bat-rtprio 45）：</p>
<p><img src="./image-20240726095424449.png" alt="image-20240726095424449"></p>
<p>实时线程B被描绘为从时间t0开始运行（在x轴上；y轴表示实时优先级；线程B的rtprio为45）；它有12毫秒（一个艰难的截止日期）来完成它的工作。但是，假设在6毫秒过去后（在时间t1），硬件中断。在图4.5中，我们没有显示执行的低级中断设置代码。现在，在时间t1触发一个中断会导致中断处理程序被调用；即hardirq（如上图中的黑色垂直双箭头所示）。显然，硬件中断抢占了线程B。现在，假设执行需要200微秒；这并不多，但如果大量中断（比如20个中断，占用4毫秒）到来怎么办！如上图所示：中断以快速速率持续到时间t2；只有在它们全部完成之后，上下文才会恢复。因此，调度代码运行，（假设）上下文切换回线程B，给它处理器（在现代英特尔CPU上，我们采用50微秒的保守上下文切换时间：<a target="_blank" rel="noopener" href="https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-text.html）。然而，不久之后，在时间t3，硬件中断再次触发，再次抢占B。这可能会无限期地持续下去；RT线程最终将运行（当中断风暴完成时），但可能会也可能不会达到其截止日期！这是主要问题。前一段中描述的问题不会通过简单地提高用户模式线程的实时优先级来解决；无论其优先级如何，hardirq硬件中断仍将始终抢占它们。通过将线程中断从RTL项目反向移植到主流Linux，我们可以解决这个问题。怎么用？想想看：使用线程中断模型，大部分中断处理工作现在由实时优先级为50的SCHED_FIFO内核线程执行。因此，只需将用户空间应用程序设计为在必要时具有实时优先级高于50的SCHED_FIFO">https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-text.html）。然而，不久之后，在时间t3，硬件中断再次触发，再次抢占B。这可能会无限期地持续下去；RT线程最终将运行（当中断风暴完成时），但可能会也可能不会达到其截止日期！这是主要问题。前一段中描述的问题不会通过简单地提高用户模式线程的实时优先级来解决；无论其优先级如何，hardirq硬件中断仍将始终抢占它们。通过将线程中断从RTL项目反向移植到主流Linux，我们可以解决这个问题。怎么用？想想看：使用线程中断模型，大部分中断处理工作现在由实时优先级为50的SCHED_FIFO内核线程执行。因此，只需将用户空间应用程序设计为在必要时具有实时优先级高于50的SCHED_FIFO</a> RT线程。这将确保它们优先于硬件中断处理程序运行！这里的关键思想是，在SCHED_FIFO策略和实时优先级50下的用户模式线程实际上可以抢占（线程化）硬件中断！确实是一件大事。因此，对于我们的示例场景，现在假设我们使用线程中断。接下来，调整用户空间多线程应用程序的设计：为我们的三个实时线程分配SCHED_FIFO和60、65和70的实时优先级。下图从概念上描述了这种情况（为了清楚起见，我们只显示了一个用户空间SCHED_FIFO线程，线程B，这次是65的rtprio）：</p>
<p><img src="./image-20240726095649410.png" alt="image-20240726095649410"></p>
<p>在上图中，RT线程B现在处于SCHED_FIFO调度策略，rtprio为65。它最多需要12毫秒才能完成（达到截止日期）。再次假设它执行了6ms（t0到t1）；在时间t1，硬件中断触发。在这里，低级设置代码和（内核默认值或驱动程序的）hardirq处理程序将立即执行，抢占处理器上的任何内容。然而，hardirq或主处理程序的执行时间非常短（最多几微秒）。正如我们已经讨论过的，这是现在正在执行的主处理程序；它将在返回IRQ_WAKE_THREAD值之前完成所需的最少工作，这将使内核唤醒代表线程处理程序的内核线程。然而，这是关键，线程中断（优先级为50的SCHED_FIFO）现在正在与其他可运行线程竞争CPU资源。由于线程B是一个rtprio为65的SCHED_FIFO实时线程，它将向CPU发送线程处理程序，然后运行！总结一下，在上图中，发生了以下情况：时间t0到t1：用户模式RT线程（SCHED_FIFO，rtprio 65）正在执行其代码（持续6毫秒）。在时间t1，细灰色条表示hardirq低级设置/BSP代码。细的黑色双箭头垂直线表示主hardirq处理程序（上述两个处理程序只需几微秒即可完成）。蓝色条是调度代码。紫色条（在t3+50us处）表示在rtprio 50上运行的线程中断处理程序。所有这一切的结果是线程B在其截止日期内很好地完成了工作（例如，在这里，它在10多毫秒内就完成了截止日期）。除非时间限制非常关键，否则使用线程中断模型来处理设备的中断对于大多数设备和驱动程序来说都非常有效。在撰写本文时，倾向于保持传统上半部分/下半部分方法（在理解和使用上半部分和下半部分部分中详细介绍）的设备通常是高性能网络、块和（一些）多媒体设备。</p>
<h3 id="使用线程处理程序时的约束"><a href="#使用线程处理程序时的约束" class="headerlink" title="使用线程处理程序时的约束"></a>使用线程处理程序时的约束</h3><p>关于线程处理程序的最后一件事：内核不会盲目地允许您对任何IRQ使用athreaded处理程序；它尊重一些约束。在注册线程处理程序时（通过[devm_]request_threaded_irq（）API），它会执行几次有效性检查，其中之一我们已经提到过：IRQF_ONESHOT必须存在于线程处理程序中。这也取决于实际的IRQ线；例如，我曾经尝试在x86上使用IRQ 1的线程句柄（它通常是i8042键盘/鼠标控制器芯片的中断线）。失败，内核显示以下内容：genirq:Flags不匹配irq 1。00002080（驱动程序名称）与00000080（i8042）因此，从前面的输出中可以看出，i8042只接受IRQ标志的0x80位掩码，而我传递了0x2080的值；稍加检查就会发现0x2000标志确实是IRQF_ONESHOT标志；显然，这会导致不匹配，而且不合理。不仅如此，请注意是谁标记了错误——这是内核的通用IRQlayer（genirq）在幕后检查的事情。（请注意，这种错误检查并不局限于线程中断。）此外，某些关键设备会发现使用线程处理程序实际上会减慢它们的速度；这对于现代NIC、块设备和一些多媒体设备来说是非常典型的。他们通常使用hardirq上半部和tasklet/softirq下半部机制（这将在理解和使用上半部和下半部部分中解释）。使用hardirq或线程处理程序在我们结束本节之前，还有一个更有趣的问题需要考虑：内核提供了一个IRQ分配API，根据某些情况，它将把中断处理程序设置为传统的hardirq处理程序或线程处理程序。这个API被称为request_any_contact_irq（）；请注意，它只被移植为GPL。其签名如下</p>
<pre class="line-numbers language-none"><code class="language-none">int __must_check
request_any_context_irq(unsigned int irq, irq_handler_t handler,
 unsigned long flags, const char *name, void *dev_id);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>参数与request_irq（）的参数相同。当被调用时，此例程将决定中断处理程序函数（处理程序参数）是在解剖hardirq上下文中运行，还是在具有睡眠功能的进程上下文中运行。你怎么知道哪个上下文句柄（）会运行？返回值根据handler（）将运行的上下文让你知道：如果它将在hardirq上下文中运行，它将返回IRQC_IS_hardirq的值。如果它将运行在进程/线程上下文中，它返回IRQC_ID_NESTED的值。失败时将返回负错误号（您需要检查此项）。然而，这到底意味着什么？从本质上讲，有些控制器位于慢速总线上（I2C就是一个很好的例子）；它们产生了使用所谓的“嵌套”中断的处理程序，这实际上意味着处理程序本质上不是原子的。它可能涉及休眠功能（I2C功能就是一个很好的例子），因此需要被抢占。使用request_any_context_inrq（）API可以确保如果是这种情况，底层的通用irq代码会检测到它，并为您提供适当的处理接口。GPIO驱动的矩阵键盘驱动程序是另一个使用此API的示例（drivers/input/backet/matrix_keypad.c）。有了这个覆盖范围，您现在可以了解什么是线程中断，以及为什么它们非常有用。现在，让我们来看一个简短的主题：作为驱动程序作者，您如何选择性地启用/禁用IRQ行。</p>
<h3 id="理解和使用上下中断"><a href="#理解和使用上下中断" class="headerlink" title="理解和使用上下中断"></a>理解和使用上下中断</h3><p>很多人都强调中断处理程序必须快速完成其工作（如Keep it fast部分和其他地方所解释的）。话虽如此，实际问题确实出现了。让我们考虑一下这个场景：您已经分配了IRQn，并编写了中断处理程序函数，以便在中断到达时处理它。您可能还记得，我们在这里谈论的函数，通常称为hardirq或ISR（中断服务例程）或主处理程序，是请求的第二个参数_{threaded}_irq（）API，devm_request_irq（）API的第三个参数，以及devm_request_threadd_irq（）API的第四个参数。正如我们之前提到的，有一个快速的启发式方法：如果你的hardirq路由的处理持续超过100微秒，那么你需要使用替代策略。假设你的处理程序在这段时间内完成得很好；在这种情况下，根本就没有噪音！但如果确实需要更多时间呢？也许外围设备的低级规范要求您在中断到达时执行许多操作（比如有10个项目需要完成）。你正确地编写了代码，但它几乎总是超过时间限制（根据经验，100微秒）！那么，你是做什么的？一方面，有一些内核人员要求你快点完成；另一方面，外围设备的低级别规范要求您遵循几个关键步骤来正确处理中断！（说到进退两难！）正如我们之前暗示的那样，在这种情况下有两种主要的策略：使用线程中断来处理大部分工作；考虑了现代方法。使用“下半部分”例程来处理大部分工作；传统的方法。我们在“使用线程中断模型”一节中详细介绍了线程中断的概念理解、实际使用和原因。在上下半部分模型中，这是一种方法：所谓的上半部分是在触发硬件中断时最初调用的函数。因此，这对你来说很熟悉——它只不过是你通过<em>request_</em>irq（）API之一注册的hardirq、ISR或主处理程序例程（为了清楚起见：通过以下API之一：request_irq() / devm_request_irq() / request_threaded_irq() /devm_request_threaded_irq().)我们还注册了一个所谓的下半部分例程来执行大部分中断处理工作。换句话说，中断处理分为上半部分和下半部分。然而，这并不是一种令人愉快的描述方式（因为英语单词“half”会让你直观地认为这些例程的大小大致相同）；现实情况更像这样：上半部分执行所需的最低限度的工作（通常，确认中断，也许在上半部分的持续时间内在板上关闭它，然后执行任何（最低限度的）硬件特定的工作，包括从设备接收/向设备发送所需的一些数据）。下半部分例程执行大部分中断处理工作。那么，下半部分是什么？它只是一个在内核中适当注册的C函数。您应该使用的实际注册API取决于您打算使用的下半部分的类型。有三种类型：旧的下半部分机制，现在已被弃用；它缩写为BH（你几乎可以忽略它）。现代推荐的（如果你首先使用这种上下半部分技术）机制是：小任务。底层内核机制：softirq。您将看到，小任务实际上是建立在内核softirq之上的。事情是这样的：正如我们之前提到的，上半部分——我们一直在使用的hardirq处理程序——只做了最基本的工作；然后，它“安排”其下半部分并退出（返回）。这里的schedule一词并不意味着它调用schedule（），因为这太荒谬了（毕竟我们处于中断上下文中！）；这只是用来描述事实的词。内核将保证一旦上半部分完成，下半部分将尽快运行；特别是，没有用户或内核线程会永远抢占它。</p>
<p>​    等一下：即使我们把处理程序分成两半，让它们共同执行工作，那么我们如何节省时间呢？毕竟，这是最初的意图。现在不需要调用两个函数而不是一个函数来完成，不会需要更长的时间吗？啊，这给我们带来了一个真正的关键点：上半部分（hardirq）总是在当前CPU上禁用（屏蔽）所有中断的情况下运行，它在所有CPU上处理的IRQ都禁用（屏蔽了），但下半部分处理程序在启用所有中断的情况下运行。请注意，下半部分仍然在原子或中断上下文中运行！因此，适用于hardirq（上半部分）处理程序的警告也适用于下半部分处理程序：您不能（向或从用户内核空间）传输数据。您只能使用GFP_ATOMIC标志分配内存（如果确实必须）。你永远不能直接或间接地调用schedule（）。这种下半部分处理是所谓的内核延迟功能能力的一个子集；内核有几个这样的延迟功能机制：工作队列（基于内核线程）；上下文：进程下半部分/任务集（基于softirqs）；上下文：中断软件；上下文：中断内核定时器；上下文：interruption我们将在第5章“使用内核计时器、线程和工作队列”中介绍内核计时器和工作队列。所有这些机制都允许内核（或驱动程序）指定在安全的情况下必须稍后完成某些工作（它被推迟）。此时，您应该能够理解我们已经讨论过的线程中断机制有点类似于延迟功能机制。这被认为是现代的使用方法；同样，尽管它的性能对于大多数外围设备来说是可以接受的，但一些设备类别（通常是网络/块/多媒体）可能仍然需要传统的上下半部分机制来提供足够高的性能。此外，我们再次强调：上半部分和下半部分始终在原子（中断）上下文中运行，而线程处理程序实际上在进程上下文中运行；你可以将此视为优势或劣势。事实上，尽管线程处理程序在技术上位于进程上下文中，但最好在其中执行快速的非阻塞操作。</p>
<p>使用内核计时器、线程和工作队列如果设备驱动程序的低级规范要求在执行func_a（）和func_b（）之间应该有50毫秒的延迟怎么办？此外，根据您的情况，当您在进程或中断上下文中运行时，延迟应该有效。如果在驱动程序的另一部分中，您需要异步和定期（比如每秒）执行某种监控功能，该怎么办？或者，您是否需要在后台但在内核内有一个（或多个）线程进行静默的打字工作？这些是各种软件中非常常见的要求，包括我们宇宙的一角——Linux内核模块（和驱动程序）开发！</p>
<p>​    在本章中，您将学习如何在内核空间中运行时设置、理解和使用延迟，以及如何使用内核计时器、内核线程和工作队列。在本章中，您将学习如何以最佳方式执行这些任务。简而言之，我们将涵盖以下主题:在内核中延迟给定时间设置和使用内核计时器创建和使用内核线程使用内核工作让我们开始吧！</p>
<h4 id="在内核中的给定时间"><a href="#在内核中的给定时间" class="headerlink" title="在内核中的给定时间"></a>在内核中的给定时间</h4><p>​    通常，您的内核或驱动程序代码需要等待给定的时间才能继续执行下一条指令。这可以通过一组延迟API在Linux内核空间内实现。从一开始，要理解的一个关键点是，你可以通过两种方式来强制延迟:通过非阻塞或原子API的延迟，这些API永远不会导致睡眠进程发生（换句话说，它永远不会排出去）通过阻塞API的延迟导致当前进程上下文睡眠（换句话说，通过排出去）（正如我们在配套指南《Linux内核编程》中详细介绍的那样，我们的CPU调度章节第10章“CPU调度器-第1部分”和第11章“CPU调度程序-第2部分”），将进程上下文内部置于睡眠状态意味着内核的核心schedule（）函数在某个时候被调用，最终导致上下文切换发生。这就引出了一个非常重要的问题（我们之前已经提到过！）:在任何类型的原子或中断上下文中运行时，您都不能调用schedule（）。</p>
<p>​    使用内核计时器、线程和工作队列第5章[238]通常，就像我们在这里插入延迟的情况一样，你必须弄清楚你打算插入延迟的代码在什么上下文中运行。我们在公司指南《Linux内核编程》第6章“内核内部要素——进程和线程”的“确定上下文”一节中介绍了这一点；如果你不清楚，请回头看。（我们在第4章“处理硬件中断”中对此进行了更详细的介绍。）接下来，仔细想想:如果你确实处于原子（或中断）环境中，真的需要延迟吗？原子或中断上下文的全部意义在于，它内的执行被限制在尽可能短的持续时间内；强烈建议您以这种方式进行设计。这意味着您不会在原子代码中插入延迟，除非您无法避免这样做。使用第一种类型:这些是永远不会发生睡眠的非阻塞或原子API。当您的代码处于原子（或中断）上下文中，并且确实需要短时间的非阻塞延迟时，您应该使用此选项；但那有多短？根据经验，将这些API用于1毫秒或更短的非阻塞原子延迟。即使你需要在原子上下文中延迟超过一毫秒的时间，比如在中断处理程序的代码中（但为什么在中断中延迟！？），也可以使用这些*delay（）API（*字符表示通配符；在这里，正如你将看到的，它表示delay（，delay）和mdelay（）例程）。使用第二种类型:这些是导致当前进程上下文休眠的阻塞API。当你的代码处于进程（或任务）上下文中时，你应该使用它，因为延迟本质上是阻塞的，持续时间更长；实际上，对于超过一毫秒的延迟。这些内核API遵循*sleep（）的形式。（同样，在不深入细节的情况下，想想这个:如果你处于进程上下文中，但在自旋锁的关键部分，这是一个原子上下文——如果你必须包含延迟，那么你必须使用*delay（）API！我们将在本书的最后两章中介绍spinlocks和更多内容。）现在，让我们看看这些内核API，看看它们是如何使用的。我们将首先看*delay（）原子API。</p>
<h4 id="了解如何使用-delay（）原子API。"><a href="#了解如何使用-delay（）原子API。" class="headerlink" title="了解如何使用*delay（）原子API。"></a>了解如何使用*delay（）原子API。</h4><p>​    不用再费吹灰之力，让我们看看一个表，它快速总结了可用的（对usmodule作者来说）非阻塞或原子*delay的内核API；它们用于任何类型的原子或中断上下文，在这些上下文中您不能阻止或休眠（或调用schedule（））:API Commendelay（ns）；延迟ns纳秒。udelay（us）；延迟微秒.mdelay（ms）；延迟毫秒。表5.1–*delay（）非阻塞API关于这些API、它们的内部实现及其用法，有几点需要注意:使用这些宏/API时，始终包含<linux/delay.h>标头。您需要根据必须延迟的时间调用适当的例程；例如，如果你需要执行30毫秒的原子无阻塞延迟，你应该调用mdelay（30）而不是udelay（30*1000）。内核代码提到了这一点:linux/delay.h–“对大于几毫秒的间隔使用udelay（）可能会导致高循环概率（highbogomips）机器溢出…”。这些API的内部实现，就像Linux上的许多API一样，是微妙的:在<Linux/delay.h>标头中，这些函数（或宏，视情况而定）有一个更高级的抽象实现；在特定于arch的头文件（<asm-\<arch>/delay.h&gt;或<asm-general/delay.h>；其中arch当然意味着sCPU）中通常有一个特定于arc的低级实现，它将在调用时自动覆盖高级版本（链接将确保这一点）。</p>
<p>​    在当前的实现中，这些API最终归结为wrappersover udelay（）；这个函数本身归结为一个紧凑的组装循环，执行所谓的“忙碌循环”！（对于x86，可以在arch/x86/lib/delay.c:__const_udelay（）中找到代码）。在引导过程的早期，内核会校准几个值:所谓的bogomips（伪MIPS）和每jiffy循环（lpj）值。本质上，内核会计算出在特定系统上，一个循环必须经过多少次才能经过1个定时器滴答声或一瞬间。这个值被称为系统的bogomips值，可以在内核日志中看到。例如，在我的Core-i7笔记本电脑上，它如下:校准延迟循环（跳过），使用时间频率计算值。。5199.98 BogoMIPS（lpj=10399968）对于超过MAX_UDELAY_MS（设置为5毫秒）的延迟，内核将在循环中内部调用UDELAY（）函数。请记住，当您在任何类型的原子上下文中需要延迟时，都必须使用*delay（）API，例如中断处理程序（上半部分或下半部分），因为它们保证不会发生睡眠，因此不会调用schedule（）。提醒一下（我们在第4章“处理硬件中断”中提到了这一点）:might_sleep（）用作调试辅助工具；内核（和驱动程序）在代码库中代码在进程上下文中运行的地方内部使用might_sleep（）宏；也就是说，它可以在哪里睡觉。</p>
<p>​    现在，如果在原子上下文中调用了ifmight_sleep（），那就大错特错了——然后会发出anoisy printk堆栈跟踪，从而帮助您及早发现并解决这些问题。您也可以在流程上下文中使用这些*delay（）API。在这些讨论中，您经常会遇到jiffies内核变量；本质上，将jiffies视为一个全局无符号64位值，在每次定时器中断（或定时器滴答声；它具有内部防溢出保护）时递增。因此，持续递增的变量被用作衡量正常运行时间的一种方法，也是实现简单超时和延迟的一种手段。现在，让我们看看第二种可用的延迟API——阻塞类型。</p>
<p>​    了解如何使用*sleep（）阻塞API让我们看看另一个表，该表快速总结了可用的（对我们模块作者来说）阻塞*sleep*（）内核API；这些只适用于睡眠安全的过程环境；也就是说，调用schedule（）不是问题。换句话说，延迟是由进程上下文实现的，该进程上下文实际上在延迟持续时间内处于睡眠状态，然后在完成后被唤醒:</p>
<p><img src="./image-20240727080009414.png" alt="image-20240727080009414"></p>
<p>有几点需要注意:</p>
<ul>
<li>使用这些宏/API时，请确保包含<linux/delay.h>标头。</li>
<li>所有这些*sleep（）API都是以这样的方式在内部实现的，即它们会导致当前进程上下文休眠（即通过内部调用schedule（））；因此，当然，它们只能在“可以安全睡眠”的过程上下文中被调用。同样，仅仅因为你的代码在进程上下文中并不一定意味着你可以安全地睡觉；例如，自旋锁的关键部分是原子的；因此，您不能在那里调用上述*sleep（）API！</li>
<li>我们提到，当您想要短暂睡眠时，usleep_range（）是首选/推荐使用的API，但为什么？在之后这一点将变得更加清晰——延迟和睡眠到底需要多长时间？部分。如您所知，Linux上的睡眠有两种类型:可中断和不可中断。后者意味着没有信号任务可以“干扰”睡眠。所以，当你调用sleep（ms）；它通过内部调用以下命令将当前进程上下文休眠ms</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">__set_current_state(TASK_UNINTERRUPTIBLE);
return schedule_timeout(timeout);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>​    schedule_timeout（）例程的工作原理是设置一个内核计时器（我们的下一个主题！），该计时器将在所需的时间到期，然后通过调用schedule（）立即使进程进入睡眠状态！（对于好奇的人，请看一下它的代码:kernel/time/tiimer.c:schedule_timeout（）。）msleep_ interruptible（）的实现非常相似，除了它调用__set_current_state（TASK_interruptible）；。作为一种设计启发式，遵循UNIX范式的提供机制，而不是策略；这样，在用户空间应用程序中止工作（可能是用户按^C）的情况下，调用sleep_interruptible（）可能是一个好主意，内核或驱动程序会顺从地释放任务:它的进程上下文被唤醒，它运行适当的信号处理程序，生命继续。在内核空间不受用户生成信号干扰的情况下，使用msleep（）变量。同样，根据经验，使用以下API，具体取决于延迟的持续时间:对于超过10毫秒的延迟:msleep（）或msleep_interruptible（）对于超过1秒的延迟:ssleep；并变为msleep（秒*1000）；。实现用户空间睡眠（3）API的（近似）等价物的一种简单方法可以在我们方便的.h头中看到；在本质上，它使用了API的schedule_timeout（）:</p>
<pre class="line-numbers language-none"><code class="language-none">\#ifdef __KERNEL__
void delay_sec(long);
&#x2F;*------------ delay_sec --------------------------------------------------
 * Delays execution for @val seconds.
 * If @val is -1, we sleep forever!
 * MUST be called from process context.
 * (We deliberately do not inline this function; this way, we can see it&#39;s
 * entry within a kernel stack call trace).
 *&#x2F;
void delay_sec(long val)
&#123;
 asm (&quot;&quot;); &#x2F;&#x2F; force the compiler to not inline it!
 if (in_task()) &#123;
 set_current_state(TASK_INTERRUPTIBLE);
 if (-1 &#x3D;&#x3D; val)
 schedule_timeout(MAX_SCHEDULE_TIMEOUT);
 else
 schedule_timeout(val * HZ);
 &#125;
&#125;
\#endif &#x2F;* \#ifdef __KERNEL__ *&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    既然你已经学会了如何延迟（是的，请微笑），让我们继续学习一个有用的技能:给内核代码打时间戳。这允许您快速计算执行特定代码所需的时间。在内核代码中获取时间戳非常重要的是，当内核开放时，能够获取准确的时间戳。例如，dmesg（1）实用程序以微秒格式显示系统启动后的时间；Ftrace跟踪通常显示函数执行所需的时间。在用户模式下，我们经常使用gettimeofday（2）系统调用来获取atimestamp。在内核中，存在多个接口；通常，为了获得准确的时间戳，会使用ktimeget*（）系列例程。为了我们的目的，以下例程很有用:</p>
<pre class="line-numbers language-none"><code class="language-none">u64 ktime_get_real_ns（void）;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    该例程通过ktime_get_real（）API内部查询墙壁（时钟）时间，然后将结果转换为纳秒数量。我们不想在这里讨论内部细节。此外，此API的几种变体也可用；例如，ktime_get_real_fast_ns（）、ktime_get_real_ts64（）等。前者既安全又安全。</p>
<p>​    既然你知道如何获取时间戳，你就可以计算出一些代码执行所需的时间，并达到很高的精度，分辨率不低于纳秒！您可以使用以下伪代码来实现这一点</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;linux&#x2F;ktime.h&gt;
t1 &#x3D; ktime_get_real_ns();
foo();
bar();
t2 &#x3D; ktime_get_real_ns();
time_taken_ns &#x3D; (t2 -&gt; t1);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    在这里，计算（虚构的）foo（）和bar（）函数执行所需的时间，结果（以纳秒为单位）在time_taken_ns变量中可用。<linux/ktime.h>内核头本身包括<linux/timekeep.h>头，这是定义ktime_get_*（）例程家族的地方。我们方便的.h头文件中提供了一个宏来帮助您计算两个时间戳之间的时间:SHOW_DELTA（稍后，较早）；。确保将后面的时间戳作为第一个参数传递，将第一个时间戳作为第二个参数传递。下一节中的代码示例将帮助我们采用这种方法。让我们试试看——延迟和睡眠到底需要多长时间？到目前为止，您已经知道如何使用*delay（）和*sleep（）API来构造延迟和睡眠（分别为非阻塞和阻塞）。不过，等等——我们还没有在内核模块中真正尝试过。不仅如此，延迟和睡眠是否如我们所相信的那样准确？让我们像往常一样，以经验为基础（这很重要！），不要做出任何假设。让我们亲自尝试一下！我们将在本小节中看到的演示内核模块按顺序执行两种延迟:首先，它使用<em>delay（）例程（您在了解如何使用\</em>delay（）原子API一节中了解到的）来实现10ns、10us和10ms的原子阻塞延迟。接下来，它使用*sleep（）例程来实现10us、10ms和1秒的阻塞延迟。</p>
<p>​    您可以通过几种方式缓解这些问题:在标准Linux上，在用户模式下，请执行以下操作:首先，最好使用高分辨率计时器（HRT）接口以获得高精度。这也是从RTL项目合并到主流Linux中的代码（早在2006年）。它支持分辨率小于一次抖动的计时器（如你所知，它与计时器“滴答”（内核CONFIG_HZ值）紧密耦合）；例如，当HZ值为100时，抖动为1000/100=10ms；HZ为250，一瞬间为4ms，以此类推。一旦你做到了这一点，为什么不采用Linux的软RT调度功能呢？在这里，您可以为您的用户模式线程指定SCHED_FIFO或SCHED_RR的调度策略和高优先级（范围为1到99；我们在公司指南《Linux内核编程》第10章《CPUScheduler》第1部分中介绍了这些细节）。大多数现代Linux系统都将支持HRT。然而，你是如何利用它的？这很简单:建议您在用户空间中编写timercode，并使用标准的POSIX计时器API（如timer_create（2）和timer_settime（2）系统调用）。由于本书关注的是内核开发，我们在这里不会深入研究这些用户空间API。事实上，这个主题在我早期的书《Linux下的动手系统编程》第13章“定时器”中，在较新的POSIX（间隔）定时器机制一节中有一些详细的介绍。内核开发人员已经费心清楚地记录了在内核中使用这些延迟和睡眠API时的一些优秀建议。在官方内核文档中浏览此文档非常重要:<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/timers/timers-howto.rst">https://www.kernel.org/doc/Documentation/timers/timers-howto.rst</a>. 将Linux操作系统构建为RTOS；这将大大减少调度“抖动”（我们在配套指南《Linux内核编程》第11章“CPU调度器”第2部分“将主线Linux转换为RTOS”一节中详细介绍了这个主题）。</p>
<h4 id="“sed”驱动程序——用于演示内核计时器、kthreads和工作队列"><a href="#“sed”驱动程序——用于演示内核计时器、kthreads和工作队列" class="headerlink" title="“sed”驱动程序——用于演示内核计时器、kthreads和工作队列"></a>“sed”驱动程序——用于演示内核计时器、kthreads和工作队列</h4><p>​    为了使本章更有趣、更实用，我们将开始开发一个被称为简单加密解密（简称sed）驱动程序的非单细胞类字符“驱动程序”（不要与众所周知的sed（1）实用程序混淆）。不，你不会因为猜测它提供了某种非常简单的文本加密/解密支持而获得大奖。</p>
<p>​    这里的重点是，我们应该想象一下，在这个驱动程序的规范中，有一个条款要求工作（实际上是加密/解密功能）在给定的时间间隔内完成——实际上是在给定的截止日期内。为了检查这一点，我们将设计我们的驱动程序，使其具有一个内核计时器，该计时器将在给定的时间间隔内过期；驱动程序将检查功能是否确实在此时间限制内完成！我们将开发一系列sed驱动程序及其用户空间对应程序（应用程序）:</p>
<ul>
<li>第一个驱动程序——sed1驱动程序和用户模式应用程序（ch5/sed1）——将执行我们刚才描述的功能:演示用户模式应用程序将使用ioctl系统调用与驱动程序进行交互，并启动加密/解密消息功能。驱动程序将关注一个内核计时器，我们将设置该计时器在给定的截止日期前到期。如果它确实到期，我们认为操作失败了；如果没有，则取消计时器，操作成功。</li>
<li>第二个版本sed2（ch5/sed2）将执行与sed1相同的操作，除了这里的实际加密/解密消息功能将在单独创建的内核线程的文本中执行！这改变了项目的设计。</li>
<li>第三个版本sed3（ch5/sed3）将再次执行与sed1和sed2相同的操作，只是这次实际的加密/解密消息功能将由内核工作队列完成！</li>
</ul>
<p>​    现在您已经学习了如何执行延迟（原子和阻塞）和捕获时间戳，让我们学习如何设置和使用内核计时器。</p>
<h4 id="设置和使用内核计时器"><a href="#设置和使用内核计时器" class="headerlink" title="设置和使用内核计时器"></a>设置和使用内核计时器</h4><p>​    计时器为软件提供了一种在经过指定时间时异步通知的方法。用户和内核空间中的各种软件都需要计时器；这通常包括网络协议实现、块层代码、设备驱动程序和各种内核子系统。此计时器提供了一种同步通知的方式，从而允许驱动程序与正在运行的计时器并行执行工作。一个重要的问题是，我如何知道计时器何时到期？在用户空间应用程序中，内核通常会向相关进程发送信号（信号通常是SIGALRM）。</p>
<p>​    在内核空间中，它有点微妙。正如您从我们对硬件中断的上半部分和下半部分的讨论中所知道的那样（见第4章，处理硬件中断，理解和使用上下半部分），在定时器中断的上半部（或ISR）完成后，内核将确保它运行定时器中断的下半部或timersoftirq（如我们在第4章处理硬件中断部分可用软件及其用途的表中所示）。这是一个非常高优先级的软件，名为TIMER_SOFTIRQ。这个软件会消耗过期的计时器！实际上——理解这一点非常重要——定时器的“回调”函数——定时器到期时运行的函数——是由定时器softirq运行的，因此在原子（中断）上下文中运行。因此，它能做什么和不能做什么是有限的（同样，这在第4章“处理硬件中断”中有详细解释）。在下一节中，您将学习如何设置和使用内核计时器。使用内核计时器为了使用内核计时器，您必须遵循几个步骤。简而言之，这是要做的事情（我们稍后会更详细地讨论这个问题）:</p>
<ol>
<li>使用timer_setup（）宏初始化计时器元数据结构（结构timer_list）。这里初始化的关键项如下:到期时间（jiffies应该达到的值，以便计时器到期）计时器到期时调用的函数——实际上是计时器“回调”函数</li>
<li>编写定时器回调例程的代码。</li>
<li>在适当的时候，通过调用add_timer（或mod_timer（））函数来“武装”计时器，即启动计时器。</li>
<li>当计时器超时（到期）时，操作系统将自动调用计时器的回调函数（您在步骤2中设置的函数）；记住，它将在计时器软件或原子或中断上下文中运行。</li>
<li>计时器不是循环的，默认情况下是一次性的。要使计时器再次运行，您必须调用mod_timer（）API；这就是如何设置一个间隔定时器&amp;一个以给定的固定时间间隔超时的定时器。如果你不执行这一步，你的计时器将是一个单次计时器——它将倒计时并恰好结束一次。</li>
<li>完成后，使用del_timer[_sync]（）删除计时器；这也可以用来取消超时。它返回一个值，表示等待定时器是否已被停用；也就是说，它为活动计时器返回1，为取消非活动计时器返回0。</li>
</ol>
<p>​    timer_list数据结构与我们在这里的工作相关；其中，相关成员（模块/驱动程序作者）显示为:</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; include&#x2F;linux&#x2F;timer.h
struct timer_list &#123;[ ... ]
 	unsigned long expires;
 	void (*function)(struct timer_list *);
 	u32 flags;
	[ ...] 
&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>使用timer_setup（）宏对其进行初始化:timer_set（计时器、回调、标志）；timer_setup（）的参数如下:</p>
<p>@timer:指向timer_list数据结构的指针（这应该首先分配内存；此外，在形式参数名称前加上@是一种常见的约定）</p>
<p>@callback:指向回调函数的指针。这是定时器到期时操作系统调用的函数（在softirq上下文中）。它的签名是void（*function）（struct timer_list*）。回调函数中收到的参数是指向timer_list数据结构的指针。那么，我们如何在定时器回调中传递和访问一些任意数据呢？我们很快就会回答这个问题@flags:这些是计时器标志。我们通常将其传递为0（表示没有特殊行为）。您可以指定的标志是TIMER_DEFERRABLE、TIMER_PINNED和TIMER_IRQSAFE。让我们看看内核源代码中的这两个</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; include&#x2F;linux&#x2F;timer.h
&#x2F;**
 * @TIMER_DEFERRABLE: A deferrable timer will work normally when
the
 * system is busy, but will not cause a CPU to come out of idle
just
 * to service it; instead, the timer will be serviced when the CPU
 * eventually wakes up with a subsequent non-deferrable timer.
 [ ... ]
  * @TIMER_PINNED: A pinned timer will not be affected by any timer
 * placement heuristics (like, NOHZ) and will always expire on the
CPU
 * on which the timer was enqueued.
  * @TIMER_PINNED: A pinned timer will not be affected by any timer
 * placement heuristics (like, NOHZ) and will always expire on the
CPU
 * on which the timer was enqueued.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="使用内核工作队列"><a href="#使用内核工作队列" class="headerlink" title="使用内核工作队列"></a>使用内核工作队列</h4><p>​    工作队列是创建和管理内核工作线程的抽象层。它们有助于解决一个关键问题:直接使用内核线程，特别是当涉及多个线程时，不仅困难，而且很容易导致危险的错误，如争用（从而可能导致死锁），以及糟糕的线程管理，从而导致效率损失。工作队列是Linux内核中使用的下半部分机制（以及小任务和软任务）。Linux内核中的现代工作队列实现——称为并发管理工作队列（cmwq）——实际上是一个非常复杂的框架，具有各种策略，可以根据特定要求动态有效地配置内核线程。</p>
<p>​    在本书中，我们更喜欢关注内核全局工作队列的使用，而不是其内部设计和实现。如果你想了解更多关于内核的信息，我建议你阅读这里的“官方”内核文档:<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/core-api/workqueue.rst.进一步阅读部分还包含一些有用的资源。工作队列的关键特征如下:工作队列任务（回调）总是在可抢占的进程上下文中执行。一旦你意识到它们是由在可抢占的进程上下文中运行的内核（工作线程）线程执行的，这一点就很明显了。默认情况下，所有中断都处于启用状态，并且不采取任何锁。上述几点意味着您可以在工作队列函数中执行漫长的阻塞I/O边界工作（这与hardirq、tasklet或softirq等解剖上下文完全相反！）。正如您了解了内核线程一样，在用户空间之间传输数据（通过典型的copy_[to|from]_user（）和类似的例程）是不可能的；这是因为你的工作队列处理程序（函数）在它自己的进程上下文（内核线程的上下文）中执行。众所周知，内核线程有nouser映射。内核工作队列框架维护工作池。这些实际上是根据需要以不同方式组织的几个内核工作线程。内核处理管理它们的所有复杂性，以及加密货币问题。下面的屏幕截图显示了几个工作队列内核工作线程（这是在我的x86_64">https://www.kernel.org/doc/Documentation/core-api/workqueue.rst.进一步阅读部分还包含一些有用的资源。工作队列的关键特征如下:工作队列任务（回调）总是在可抢占的进程上下文中执行。一旦你意识到它们是由在可抢占的进程上下文中运行的内核（工作线程）线程执行的，这一点就很明显了。默认情况下，所有中断都处于启用状态，并且不采取任何锁。上述几点意味着您可以在工作队列函数中执行漫长的阻塞I/O边界工作（这与hardirq、tasklet或softirq等解剖上下文完全相反！）。正如您了解了内核线程一样，在用户空间之间传输数据（通过典型的copy_[to|from]_user（）和类似的例程）是不可能的；这是因为你的工作队列处理程序（函数）在它自己的进程上下文（内核线程的上下文）中执行。众所周知，内核线程有nouser映射。内核工作队列框架维护工作池。这些实际上是根据需要以不同方式组织的几个内核工作线程。内核处理管理它们的所有复杂性，以及加密货币问题。下面的屏幕截图显示了几个工作队列内核工作线程（这是在我的x86_64</a> Ubuntu 20.04客户机上拍摄的）:</p>
<p><img src="./image-20240727081132754.png" alt="image-20240727081132754"></p>
<p>使用内核计时器、线程和工作队列第5章[282]正如我们在创建和使用内核线程一节中提到的，一种理解kthread名称并了解kthreads的许多实际用途（以及如何调整它们以减少抖动）的方法是阅读相关的内核文档；也就是说，减少由于每cpu k线程引起的操作系统抖动(<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/kernel-per￾CPU">https://www.kernel.org/doc/Documentation/kernel-per￾CPU</a> kthreads.txt）。关于如何使用工作队列（和其他下半部分机制），请参阅第4章“处理硬件中断”、Hardirq、小任务和线程处理程序——何时使用什么部分，特别是那里的表。重要的是要理解内核有一个随时可用的默认工作队列；它被称为内核全局工作队列或系统工作队列。为了避免给系统带来压力，强烈建议您使用它。我们将使用内核的全局工作队列，查询我们的工作任务，并让它消耗我们的工作。您甚至可以使用和创建其他类型的工作队列！内核提供了精化cmwq框架以及一组API，以帮助您创建特定类型的工作队列。我们将在下一节中更详细地介绍这一点。最基本的工作队列内部我们在这里没有深入探讨工作队列的内部；事实上，我们只是触及了表面（正如我们之前提到的，我们在这里的目的只是专注于使用内核全局工作队列）。我们始终建议您使用默认的内核全局（系统）工作队列来完成异步后台工作。如果认为这还不够，请不要担心——某些接口是公开的，可以让您创建工作队列。（请记住，这样做会增加系统的压力！）要分配新的工作队列实例，可以使用alloc_workqueue（）API；这是用于创建（分配）工作队列（通过现代cmwq框架）的主要API:</p>
<pre class="line-numbers language-none"><code class="language-none">include&#x2F;linux&#x2F;workqueue.h
struct workqueue_struct *alloc_workqueue(const char *fmt, unsigned int
flags, int max_active, ...);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>使用内核计时器、线程和工作队列第5章[283]请注意，它是通过EXPORT_SYMBOL_GPL（）导出的，这意味着它只适用于使用GPL许可证的tomodules和驱动程序。fmt（以及后面的参数max_active）指定了如何命名池中的工作队列线程。flagspameter指定了特殊行为值或其他特征的位掩码，例如:当工作队列在内存压力下需要转发进度保证时，使用WQ_MEM_RECLAIM标志。当工作项由具有更高优先级的kthreads工作池提供服务时，使用WQ_HIGHPRI标志。使用WQ_SYSFS标志，通过SYSFS让用户空间可以看到一些工作队列详细信息（实际上，请查看/sys/devices/virtual/workqueue/）。同样，还有其他几面旗帜。查看官方kernel文档以了解更多详细信息(<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/core-api/workqueue.rst">https://www.kernel.org/doc/Documentation/core-api/workqueue.rst</a>; 它提供了一些关于减少内核内工作队列执行导致的“抖动”的有趣报道）。max_active参数用于指定每个CPU可以分配给工作项的最大内核线程数。广义上讲，有两种类型的工作队列:单线程（ST）工作队列或有序工作队列:在这里，在整个系统的任何给定时间点，只有一个线程可以处于活动状态。它们可以用alloc_ordered_workqueue（）创建（它实际上只是alloc_workqueuee（）的一个包装器，指定了max_active设置为1的有序标志）。多线程（MT）工作队列:这是默认选项。确切的标志指定了行为；max_active指定工作项每个CPU可能拥有的最大workerkernel线程数。所有工作队列都可以通过alloc_workqueue（）API创建。创建它们的代码如下:</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;kernel&#x2F;workqueue.cint __init workqueue_init_early（void）&#123;[…]system_wq&#x3D;alloc_workqueue（“事件”，0,0）；system_highpri_wq&#x3D;alloc_workqueue（“事件highpri”，wq_highpri，0）；system _long_wq&#x3D;allow_workqueue，
WQ_UNBOUND_MAX_ACTIVE);
 system_freezable_wq &#x3D; alloc_workqueue(&quot;events_freezable&quot;, WQ_FREEZABLE,
0);
 system_power_efficient_wq &#x3D; alloc_workqueue(&quot;events_power_efficient&quot;,
WQ_POWER_EFFICIENT, 0);
 system_freezable_power_efficient_wq &#x3D;
alloc_workqueue(&quot;events_freezable_power_efficient&quot;,
 WQ_FREEZABLE | WQ_POWER_EFFICIENT, 0);
[ ... ]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    这发生在引导过程的早期（字面意思是在早期的init内核代码路径中）。第一个以粗体突出显示；这是正在创建的内核全局工作队列或系统工作队列。它的工作池被命名为events。（属于此池的内核线程的名称遵循此命名约定，其名称中包含单词events；再次参见图5.10。属于其他工作池的kthreads也是如此。）底层框架已经发展了很多；早期的遗留workqueue框架（2010年之前），用于使用create_workqueue（）和friends API；然而，这些现在被认为是不推荐的。有趣的是，现代并发管理工作队列（cmwq）框架（大约从2010年开始）与旧框架向后兼容。下表总结了旧的工作队列API到现代cmwq API的映射:旧的（旧的和不推荐使用的）工作队列API现代的（cmwq）工作队列</p>
<p><img src="./image-20240727081244783.png" alt="image-20240727081244783"></p>
<p>下图（以一种简单的概念方式）总结了内核工作队列子系统:</p>
<p><img src="./image-20240727081333770.png" alt="image-20240727081333770"></p>
<p>​    视图内核的工作队列框架动态维护这些（内核线程的）工作池；一些是通用的，如事件工作队列（对应于内核全局工作队列），而另一些是为特定目的创建和维护的（根据其内核线程的名称，如blockI/O、kworker*blockd、内存控制、kworkr*mm_percpu_wq，设备特定的线程，如tpm、tpm_dev_wq、CPU频率调节器驱动程序、devfreq_wq等）。</p>
<h3 id="内核同步-第1部分"><a href="#内核同步-第1部分" class="headerlink" title="内核同步-第1部分"></a>内核同步-第1部分</h3><h4 id="关键部分、独占执行和原子性"><a href="#关键部分、独占执行和原子性" class="headerlink" title="关键部分、独占执行和原子性"></a>关键部分、独占执行和原子性</h4><p>想象一下，你正在为多核系统编写软件（好吧，现在，你通常会在多核系统上工作，即使是在大多数嵌入式项目上）。正如我们在引言中提到的，并行运行多个代码路径不仅安全，而且是可取的（为什么要花这些钱呢，对吧？）。另一方面，在以任何方式访问共享可写数据（也称为共享状态）的并发（并行和同时）代码路径中，您需要保证在任何给定时间点，一次只能有一个线程处理该数据！这真的很关键；为什么？想想看:如果你允许多个并发代码路径在共享可写数据上并行工作，你实际上是在自找麻烦:结果可能会导致数据损坏（“竞争”）。什么是关键部分？可以并行执行并处理（读取和/或写入）共享可写数据（共享状态）的代码路径称为关键部分。它们需要防止并行。识别和保护关键部分免受同时执行是您（设计师/架构师/开发人员）必须处理的正确软件的一项重要要求。关键部分是一段必须以独占方式运行的代码；也就是说，单独（序列化）或原子；也就是说，不可分割地完成，不间断地完成。通过排他性，我们暗示在任何给定的时间点，一个线程正在运行关键部分的代码；出于数据安全原因，这显然是必需的。这一概念也提出了原子性的重要概念:单个原子操作是不可分割的。在任何现代处理器上，两个操作都被认为是原子操作；也就是说，它们不能被中断，并且会运行到完成:</p>
<ul>
<li>执行单个机器语言指令。</li>
<li>读取或写入处理器字大小（通常为32或64位）内的对齐原始数据类型；例如，在64位系统上读取或写入64位整数保证是原子性的。读取该变量的线程永远不会看到介于两者之间、撕裂或肮脏的结果；他们要么会看到旧的价值，要么会看到新的价值。</li>
</ul>
<p>​    因此，如果你有一些处理共享（全局或静态）可写数据的代码行，在没有任何显式同步机制的情况下，它不能保证独占运行。请注意，有时需要以原子方式运行关键部分的代码，也可以以独占方式运行，但并非总是如此。当关键部分的代码在安全睡眠进程上下文中运行时（例如通过用户应用程序在驱动程序上进行的典型文件操作（打开、读取、写入、ioctl、mmap等），或者内核线程或工作队列的执行路径），很可能不接受关键部分是真正原子的。然而，当它的代码在非阻塞原子上下文（如hardirq、tasklet或softirq）中运行时，它必须以原子方式和独占方式运行（我们将在互斥或自旋锁？何时使用一节中更详细地介绍这些要点）。一个概念性的例子将有助于澄清事情。假设三个线程（来自用户spaceapp）试图在多核系统上或多或少同时打开并读取您的驱动程序。如果没有任何干预，他们很可能最终会并行运行关键部分的代码，从而并行处理共享的可写数据，因此很可能会损坏它！现在，让我们来看一个概念图，看看关键部分代码路径中的非独占执行是如何错误的（我们甚至不会在这里谈论原子性）</p>
<p><img src="./image-20240727081550055.png" alt="image-20240727081550055"></p>
<p>​    如上图所示，在您的设备驱动程序中，在其（比如）读取方法中，您让它运行一些代码以执行其任务（从硬件读取一些数据）。让我们从不同时间点进行的数据访问的角度更深入地看看这个图:从时间t0到t1:没有或只有局部变量数据被访问。这是并发安全的，不需要保护，可以并行运行（因为每个线程都有自己的私有堆栈）。从时间t1到t2:访问全局/静态共享可写数据。这不是并发安全的；这是一个关键部分，因此必须防止并发访问。它应该只包含独占运行的代码（单独运行，一次只运行一个线程，序列化），也许是原子运行的代码。从时间t2到t3:不访问或仅访问局部变量数据。这是并发安全的，不需要保护，可以并行运行（因为每个线程都有自己的私有堆栈）。在本书中，我们假设您已经意识到同步关键部分的必要性；我们不会再讨论这个特别的话题了。有兴趣的人可以参考我早期的书《Linux系统编程实践》（Packt，2018年10月），该书详细介绍了这些要点（特别是第15章，使用Pthreads的多线程第二部分——同步）。因此，知道这一点后，我们现在可以重申关键部分的概念，同时也可以在出现这种情况时提及（如项目符号中的方括号和斜体所示）。关键部分是必须按如下方式运行的代码:（始终）独占:单独（序列化）（在原子上下文中时）原子:不可分割地完成，不中断。</p>
<h4 id="概念-锁"><a href="#概念-锁" class="headerlink" title="概念-锁"></a>概念-锁</h4><p>我们需要同步，因为在没有任何干预的情况下，线程可以同时执行正在处理共享可写数据（共享状态）的关键部分。为了克服并发性，我们需要摆脱并行性，并且需要对关键部分内的代码进行序列化，关键部分是处理共享数据（用于读取和/或写入）的地方。为了强制代码路径序列化，一种常见的技术是使用锁。本质上，锁的工作原理是保证在任何给定的时间点，只有一个执行线程可以“获取”或拥有锁。因此，使用锁来保护代码中的关键部分将为您提供我们想要的东西——以独占方式运行关键部分的代码（也许在经济上；稍后会有更多介绍）:图6.3——一个概念图，显示了在给定独占性的情况下，如何使用锁来遵守关键部分代码路径。上图显示了一种解决上述情况的方法:使用alock来保护关键部分！从概念上讲，锁（和解锁）是如何工作的？</p>
<p>锁的基本前提是，每当有争用时，即当多个竞争线程（比如n个线程）试图获取锁（lock操作）时，只有一个线程会成功。这被称为锁的“赢家”或“所有者”。它将锁API视为一个非阻塞调用，从而在执行关键部分的代码时继续以独占方式愉快地运行（关键部分实际上是锁和解锁操作之间的代码！）。n-1个“失败者”线程会发生什么？他们（也许）将锁定API看作一个阻塞调用；实际上，他们一直在等待。等等什么？当然，解锁操作是由锁的所有者（“赢家”线程）执行的！一旦解锁，剩余的n-1个线程将争夺下一个“获胜者”插槽；当然，他们中只有一个人会“赢”并继续前进；在此期间，n-2名失败者现在将等待（新的）获胜者解锁；重复此过程，直到所有n个线程（最终和顺序地）获取锁。现在，锁定当然有效，但是——这应该是相当直观的——它会导致（prettsteep！）开销，因为它会破坏并行性并序列化执行流！为了帮助你想象这种情况，想象一个漏斗，窄杆是关键部分，一次只能安装一根螺纹。所有其他线程都被阻塞了；锁定会产生瓶颈:</p>
<p><img src="./image-20240727081719800.png" alt="image-20240727081719800"></p>
<p>​    另一个经常被提及的物理模拟是一条有几条车道的高速公路合并成一条非常繁忙且交通堵塞的车道（可能是一个设计不佳的收费站）。同样，并行性——汽车（线程）与不同车道（CPU）上的其他汽车并行行驶——也会丢失，需要串行化行为——汽车被迫排在另一辆后面。因此，作为软件架构师，我们必须尝试设计我们的产品/项目，以便将锁定要求降至最低。虽然在大多数实际项目中完全消除全局变量实际上是不可能的，但需要优化和最小化它们的使用。稍后，我们将对此进行更多介绍，包括一些非常有趣的无锁编程技术。另一个真正关键的点是，新手程序员可能会天真地认为，在共享的可写数据对象上执行读取是完全安全的，因此不需要明确的保护（处理器总线大小范围内的对齐基元数据类型除外）；这是不真实的。这种情况可能会导致所谓的脏ortorn读取，在这种情况下，可能会在另一个写入线程同时写入时读取过时的数据，而您正在读取完全相同的数据项（不正确，没有锁定）。正如我们刚刚学到的，由于我们讨论的是原子性的话题，在典型的现代微处理器上，唯一能保证原子性的是单机器语言指令或对处理器总线宽度内对齐的原始数据类型的读/写。那么，我们如何标记几行“C”代码，使其真正具有原子性呢？在用户空间中，这甚至是不可能的（我们可以接近，但不能保证原子性）。你如何在用户空间应用程序中“接近”原子性？您始终可以构造一个用户线程来使用SCHED_FIFO策略和99的实时优先级。这样，当它想要运行时，除了硬件中断/异常之外，几乎没有什么可以抢占它。（旧的音频子系统实现严重依赖于此。）在内核空间中，我们可以编写真正原子化的代码。如何，确切地说？简短的回答是，我们可以使用自旋锁！我们稍后将更详细地了解自旋锁。</p>
<h4 id="关键点总结"><a href="#关键点总结" class="headerlink" title="关键点总结"></a>关键点总结</h4><p>让我们总结一些关于关键部分的关键点。仔细阅读这些内容非常重要，把它们放在手边，并确保在实践中使用它们:</p>
<ul>
<li>关键部分是一个可以并行执行的代码路径，它处理（读取和/或写入）共享的可写数据（也称为“共享状态”）。</li>
<li>因为它适用于共享的可写数据，所以关键部分需要以下保护:并行性（即它必须单独运行/序列化/以互斥的方式运行）在原子（中断）非阻塞上下文中运行时——原子性:不可分割地完成，不中断。一旦受到保护，您就可以安全地访问共享状态，直到您“解锁”。</li>
<li><p>代码库中的每个关键部分都必须被识别和保护:识别关键部分至关重要！仔细检查你的代码，确保你不会错过它们。保护它们可以通过各种技术来实现；一种非常常见的技术是锁定（还有无锁编程，我们将在下一章中介绍）。一个常见的错误是只保护写入全局可写数据的关键部分；您还必须保护读取全局可写数据的关键部分；否则，你就有被撕裂或弄脏的危险！为了帮助明确这一关键点，请将在32位系统上读写的无符号64位数据项可视化；在这种情况下，操作不能是原子操作（需要两个加载/存储操作）。因此，如果在一个线程中读取数据项的值时，另一个线程正在同时写入它，该怎么办！？writer线程采用某种“锁”，但由于你认为阅读是安全的，所以reader线程不会采用该锁；由于一个不幸的时间巧合，你最终可能会做出不完整/撕裂/肮脏的阅读！在接下来的章节和下一章中，我们将学习如何使用各种技术来克服这些问题。另一个致命的错误是没有使用相同的锁来保护一个数据项。</p>
</li>
<li><p>未能保护关键部分会导致数据竞争，在这种情况下，结果（被擦除/写入的数据的实际值）是“活跃的”，这意味着它会根据运行时环境和时间而变化。这被称为bug。（一个一旦进入“现场”就极难看到、重现、确定其根本原因并修复的错误。我们将在下一章内核部分的Lockdebugging中介绍一些非常强大的东西来帮助您解决这个问题；一定要阅读它！）</p>
</li>
<li>异常:在以下情况下，您是安全的（隐式的，没有显式的保护）:当您处理局部变量时。它们被分配在线程的私有堆栈上（或者在中断上下文中，在localIRQ堆栈上），因此根据定义是安全的。当你在不可能在另一个上下文中运行的代码中处理共享的可写数据时；也就是说，它天生就是序列化的。在我们的上下文中，LKM的init和cleanup方法是合格的（它们仅在insmod和rmmod上连续运行一次）。当你处理真正恒定且仅可读的共享数据时（不过，不要让C的const关键字欺骗你！）。</li>
<li>锁定本身就很复杂；您必须仔细思考、设计和实现这一点，以避免死锁。我们将在锁定指南和死锁部分更详细地介绍这一点。</li>
</ul>
<h4 id="Linux内核中的并发问题"><a href="#Linux内核中的并发问题" class="headerlink" title="Linux内核中的并发问题"></a>Linux内核中的并发问题</h4><p>识别内核代码中的关键部分至关重要；如果你甚至看不见它，你怎么能保护它呢？以下是一些指导方针，可以帮助你，作为一个初露头角的内核/驱动程序开发人员，认识到并发问题可能出现的地方——以及相应的章节:对称多处理器（SMP）系统（CONFIG_SMP）的存在可抢占内核的存在阻止I/O硬件中断（在SMP或UP系统上）</p>
<p><img src="./image-20240727082014583.png" alt="image-20240727082014583"></p>
<p>这与我们在图6.1和6.3中显示的情况类似；只是在这里，我们用伪代码来展示并发性。显然，从时间t2到时间t3，驱动器正在处理一些全局共享的可写数据，因此这是一个关键部分。现在，想象一个有四个CPU核的系统（SMP系统）；两个用户空间进程P1（在CPU 0上运行）和P2（在CPU 2上运行）可以同时打开设备文件并同时发出read（2）系统调用。现在，两个进程将同时执行驱动程序读取“方法”，从而同时处理共享的可写数据！这（t2和t3之间的代码）是一个关键部分，由于我们违反了基本的排他性规则——关键部分在任何时间点都只能由一个线程执行——我们很可能最终会破坏数据、应用程序，甚至更糟。</p>
<p>​    换句话说，这现在是一场数据竞赛；根据微妙的时间巧合，我们市长可能不会产生错误（bug）。正是这种不确定性——微妙的时间巧合——使得发现和修复这样的错误变得极其困难（它可以逃脱你的测试工作）。不幸的是，这句格言是真的:测试可以检测到错误的存在，而不是它们的缺失。此外，如果你的测试未能捕捉到竞争（和错误），让它们在现场自由发挥，你的处境会更糟。您可能会觉得，由于您的产品是在一个CPUcore（UP）上运行的小型嵌入式系统，因此关于控制并发性（通常是通过锁定）的讨论对您不适用。我们不敢苟同:几乎所有的现代产品，如果还没有的话，都将转向多核（也许在下一代阶段）。更重要的是，正如我们将探讨的那样，即使是UP系统也存在并发问题。可抢占内核、阻塞I/O和数据通道想象一下，你正在一个配置为可抢占的Linux内核上运行内核模块或驱动程序（即CONFIG_PREEMPT已打开；我们在公司指南《Linux内核编程》第10章“CPU调度器-第1部分”中介绍了这个主题）。考虑一个进程P1正在进程上下文中运行驱动程序的读取方法代码，处理全局数组。现在，当它处于关键部分（在时间t2和t3之间）时，如果内核抢占进程P1并将上下文切换到另一个进程P2，该进程正在等待执行此代码路径，该怎么办？这很危险，而且是一场数据竞赛。这甚至可能发生在UP系统上！另一种情况有点相似（也可能发生在单核（UP）或多核系统上）:进程P1正在运行驱动程序方法的关键部分（在时间t2和t3之间；再次参见图6.5）。这一次，如果在关键部分，它遇到阻塞呼叫怎么办？阻塞调用是一种函数，它使调用进程上下文进入睡眠状态，等待事件发生；当该事件发生时，内核将“唤醒”任务，并从中断的位置恢复执行。这也称为I/O阻塞，非常常见；许多API（包括几个用户空间库和系统调用，以及一些内核API，本质上都是阻塞的）。在这种情况下，进程P1有效地关闭了CPU并进入睡眠状态，这意味着schedule（）的代码运行并将其排队到等待队列中。</p>
<p>​    在此期间，在P1被切换回之前，如果另一个进程P2被调度为torun怎么办？如果该进程也在运行此特定的代码路径怎么办？想想看——当P1回来时，共享数据可能已经“在它下面”发生了变化，导致各种错误；再一次，一场数据竞赛，一个bug！硬件中断和数据通道最后，设想一下这样的场景:进程P1再次无辜地运行驱动程序的读取方法代码；它进入临界区（在时间t2和t3之间；再次见图6.5）。它取得了一些进展，但随后，唉，硬件中断触发了（在同一CPU上）！在Linux操作系统上，硬件（外围设备）中断具有最高优先级；默认情况下，它们抢占任何代码（包括内核代码）。因此，进程（或线程）P1将至少暂时搁置，从而失去处理器；中断处理代码将抢占它并运行。好吧，你可能会想，那又怎样？事实上，这是一个完全常见的事件！在现代系统中，硬件中断非常频繁地触发，有效地（和真正地）中断了各种任务上下文（在shell上快速执行vmstat 3；中标记的系统下的列显示了过去1秒内在系统上触发的硬件中断数量！）。要问的关键问题是:中断处理代码（无论是hardirq上半部分还是所谓的tasklet或softirq下半部分，以发生者为准）是否共享并处理它刚刚中断的进程上下文的同一共享可写数据？如果这是真的，那么，休斯顿，我们有一个问题——数据竞赛！如果没有，那么您的中断代码就不是中断代码路径的关键部分，这很好。大多数设备驱动程序确实处理中断的事实；因此，驱动程序作者（您的！）有责任确保进程上下文和中断代码路径之间没有共享全局或静态数据（实际上没有关键部分）。如果是（确实发生了），您必须以某种方式保护这些数据免受数据竞争和可能的破坏。这些场景可能会让你觉得，防止这些并发问题是一项艰巨的任务；面对存在的关键部分以及各种可能的并发问题，您究竟如何实现数据安全？有趣的是，实际的API并不难学习使用；我们再次强调，识别关键部分是关键所在。</p>
<p>​    同样，关于锁（概念上）如何工作的基础知识、锁定指南（非常重要；我们将很快对其进行回顾）以及死锁的类型和如何防止死锁，都在我早期的书《Linux系统编程实践》（Packt，2018年10月）中有所论述。本书在第15章“使用P线程的多线程第二部分——同步”中详细介绍了这些要点。闲话少说，让我们深入了解一下将用于保护我们关键部分的主要同步技术——锁定。锁定准则和死锁锁定本质上是一种复杂的野兽；它往往会引发复杂的联锁场景。对它的理解不够深入可能会导致性能问题和错误——死锁、循环依赖、中断不安全锁定等等。以下锁定指南是确保使用锁定时正确编写代码的关键:锁定粒度:锁定和解锁之间的“距离”（实际上是关键部分的长度）不应太粗（关键部分太长），而应“足够细”；这是什么意思？以下几点解释了这一点:你在这里需要小心。当你在处理大型项目时，锁太少是一个问题，锁太多也是一个问题！锁太少会导致性能问题（因为相同的锁被重复使用，因此往往会引起高度竞争）。拥有大量锁实际上对性能有好处，但对复杂性控制不利。这也导致了另一个需要理解的关键点:在代码库中有很多锁的情况下，你应该非常清楚哪个锁保护哪个共享数据对象。如果你使用lockA来保护mystructX，这完全没有意义，但在远处的代码路径中（可能是中断处理程序），你忘记了这一点，在处理同一结构时尝试使用其他锁lockB来保护！现在，这些事情听起来可能很明显，但是（作为经验丰富的开发人员），在足够的压力下，即使是显而易见的事情也不总是显而易见的！试着平衡一下。在大型项目中，使用一个锁来保护一个全局（共享）数据结构是典型的。（很好地命名锁变量本身就可能成为一个大问题！这就是为什么我们将保护数据结构的锁作为成员放置在其中的原因。）</p>
<p>​    锁顺序至关重要；锁在整个过程中必须以相同的顺序使用，并且应该记录它们的顺序，并由参与项目的所有开发人员遵循（注释锁也很有用；下一章关于锁的部分将对此进行更多介绍）。不正确的锁顺序通常会导致死锁。尽可能避免递归锁定。注意防止饥饿；验证锁一旦被取下，是否“足够快”地解锁。简单是关键:尽量避免复杂性或过度设计，尤其是在涉及锁的复杂场景中。关于锁的话题，死锁（危险）问题出现了。僵局是指无法取得任何进展；换句话说，应用程序和/或内核组件似乎无限期挂起。虽然我们不打算在这里深入探讨死锁的血腥细节，但我会很快提到一些可能发生的更常见的死锁场景:简单情况、单锁、进程上下文:我们试图两次获取相同的锁；这会导致自死锁。简单的情况，多个（两个或多个）锁，进程上下文——例如:在CPU 0上，线程A获取锁A，然后需要锁B。同时，在CPU 1上，线程B获取锁B，然后想要锁A。结果是死锁，通常称为AB-BA死锁。它可以扩展；例如AB-BC-CA循环依赖性（A-B-C锁链）导致死锁。复杂情况、单锁以及进程和中断上下文:锁A接受中断上下文。如果发生中断（在另一个核心上）并且处理器试图获取锁A怎么办？僵局就是结果！因此，在中断上下文中获取的锁必须始终在禁用的中断中使用。（如何实现？我们将在介绍自旋锁时更详细地了解这一点。）更复杂的情况、多个锁以及进程和中断（hardirq和softirq）上下文</p>
<p>​    在更简单的情况下，始终遵循锁排序准则就足够了:始终以有据可查的顺序获取和释放锁（我们将在使用互斥锁部分的内核代码中提供一个例子）。然而，这可能会变得非常复杂；复杂的死锁场景甚至会让有经验的开发人员陷入困境。幸运的是，lockdep（Linux内核的运行时锁依赖验证器）可以捕获每一个死锁情况！（别担心，我们会到的:我们将在下一章详细介绍lockdep）。当我们介绍自旋锁（使用自旋锁部分）时，我们会遇到与前面提到的类似的进程和/或中断上下文场景；自旋锁的类型在那里很清楚。关于死锁，Steve Rosedt在2011年的Linux Plumber会议上对lockdep进行了非常详细的介绍；相关幻灯片内容丰富，探讨了简单和复杂的死锁场景，以及lockdep如何检测它们(<a target="_blank" rel="noopener" href="https://blog.linuxplumbersconf.org/2011/ocw/sessions/153">https://blog.linuxplumbersconf.org/2011/ocw/sessions/153</a>). 此外，现实情况是，不仅死锁，甚至活锁情况也可能同样致命！Livelock本质上是一种类似于死锁的情况；只是参与任务的状态是正在运行而不是等待。例如，中断“风暴”可能会导致活锁；现代网络驱动程序通过关闭中断（中断负载不足）并采用称为新API的轮询技术来减轻这种影响；切换中断（NAPI）（在适当的时候重新打开中断；好吧，它比这更复杂，但我们在这里就讲到这里）。对于那些生活在岩石下的人来说，你会知道Linux内核有两种主要类型的锁:互斥锁和自旋锁。实际上，有几种类型，包括其他同步（和“无锁”编程）技术，所有这些都将在本章和下一章的课程中介绍。互斥还是自旋锁？何时使用学习使用互斥锁和旋转锁的确切语义非常简单（在内核API集合中具有适当的抽象，使典型的开发人员或模块作者更容易）。在这种情况下，关键的问题是一个概念性的问题:这两个锁之间的真正区别是什么？更重要的是，在什么情况下应该使用哪把锁？您将在本节中了解这些问题的答案。</p>
<p>​    以我们之前的驱动程序读取方法的伪代码（图6.5）为基础示例，假设三个线程——tA、tB和tC——通过此代码并行运行（在SMP系统上）。我们将通过在关键部分开始之前（时间t2）获取锁，并在关键部分代码路径结束后（时间t3）释放锁（解锁），来解决这个并发问题，同时避免任何数据竞争。让我们再次看看伪代码，这次是锁定以确保其正确:</p>
<p><img src="./image-20240727082232047.png" alt="image-20240727082232047"></p>
<p>​    当三个线程试图同时获取锁时，系统保证只有一个线程会获得锁。假设tB（线程B）获得锁:它现在是“赢家”或“所有者”线程。这意味着线程tA和tC是“失败者”；他们做什么？他们等待解锁！当“胜利者”（tB）完成关键部分并解锁锁时，之前的失败者之间的战斗就会重新开始；其中一个将是下一个赢家，这个过程会重复。</p>
<p>​    两种锁类型（互斥锁和自旋锁）之间的关键区别在于失败者如何等待解锁。使用互斥锁，失败线程将进入睡眠状态；也就是说，他们通过睡觉来等待。获胜者执行解锁的那一刻，内核唤醒失败者（所有人），他们再次运行，争夺锁。（事实上，互斥体和信号量有时被称为睡眠锁。）然而，有了自旋锁，就没有睡眠的问题了；失败者通过旋转锁来等待，直到它被解锁。从概念上讲，这看起来如下:</p>
<pre class="line-numbers language-none"><code class="language-none">while(locked);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>请注意，这只是概念性的。想想看——这实际上是民意调查。然而，作为一名优秀的程序员，你会明白，轮询通常被认为是一个糟糕的想法。那么，为什么自旋锁会这样工作呢？好吧，事实并非如此；它只是为了概念目的而以这种方式呈现的。正如您很快就会理解的那样，spinlocks只有在多核（SMP）系统上才真正有意义。在这样的系统中，当winnerthread离开并运行关键部分代码时，失败者会通过在其他CPU内核上旋转来等待！实际上，在实现层面上，用于实现现代自旋锁的代码是高度优化的（并且是特定于拱形的），不能通过琐碎的“旋转”来工作（例如，许多<strong>ARM的自旋锁实现使用等待事件（WFE）机器语言指令</strong>，该指令使CPU在低功耗状态下最佳地等待；有关pinlocks内部实现的几个资源，请参阅进一步阅读部分）。确定使用哪个锁——在理论上，自旋锁是如何实现的，在这里我们真的不关心；我们感兴趣的是，自旋锁的开销比互斥锁低。这是怎么回事？这很简单，真的:为了使互斥锁工作，失败者线程必须进入睡眠状态。为此，在内部调用schedule（）函数，这意味着失败者将互斥锁API视为一个锁定调用！对调度器的调用最终将导致处理器关闭上下文。相反，当所有者线程解锁锁时，必须唤醒失败者线程；同样，它将被上下文切换回处理器。因此，互斥锁/解锁操作的最小“成本”是在给定机器上执行两次上下文切换所需的时间。（请参阅下一节的信息框。）通过再次查看前面的屏幕截图，我们可以确定一些事情，包括关键部分（“锁定”代码路径）所花费的时间；即t_locked=t3-t2。</p>
<p>​    假设t_ctxsw表示上下文切换的时间。正如我们所了解到的，互斥锁/解锁操作的最小成本是2*t_ctxsw。现在，假设以下表达式为真:t_locked&lt;2<em>t_ctxsw换句话说，如果在关键部分花费的时间小于两次上下文切换所需的时间怎么办？在这种情况下，使用互斥锁是错误的，因为这会带来太多的开销；执行元工作所花费的时间比实际工作要多，这种现象被称为“鞭打”。正是这种精确的用例——存在非常短的关键部分——在Linux等现代操作系统上经常出现这种情况。因此，总之，对于短的非阻塞关键部分，使用自旋锁（远远）优于使用互斥锁。确定使用哪种锁——在实践中，在t_locked&lt;2\</em>t_ctxsw“规则”下操作在理论上可能很好，但等等:你真的希望精确测量上下文切换时间和存在一个（关键部分）的每种情况下的关键部分所花费的时间吗？不，当然不是——这是相当不切实际和迂腐的。实际上，可以这样想:互斥锁的工作原理是让失败线程在解锁时休眠；旋转锁不会（失败者“旋转”）。让我们回顾一下Linux内核的黄金法则:内核在任何原子上下文中都不能休眠（调用schedule（））。因此，我们永远不能在中断上下文中使用互斥锁，也不能在任何睡眠不安全的上下文中使用；然而，使用自旋锁是可行的。（记住，阻塞API是通过调用schedule（）使调用上下文进入休眠状态的API。）让我们总结一下:关键部分是在原子（中断）上下文中运行，还是在进程上下文中无法休眠？使用旋转锁。关键部分是否在流程上下文中运行，关键部分是否需要睡眠？使用互斥锁。当然，使用自旋锁被认为比使用互斥体的开销更低；因此，只要关键部分没有阻塞（睡眠），您甚至可以在进程上下文中使用自旋锁（例如我们虚构的驱动程序的读取方法）。</p>
<h4 id="锁定和中断-1"><a href="#锁定和中断-1" class="headerlink" title="锁定和中断"></a>锁定和中断</h4><p>​    到目前为止，我们已经学习了如何使用互斥锁，以及对于自旋锁，如何使用basicspin_[un]lock（）API。还有一些关于自旋锁的其他API变体，我们将在这里研究更常见的变体。为了准确理解为什么您可能需要其他API来处理自旋锁，让我们来看一个场景:作为驱动程序作者，您发现您正在处理的设备断言了硬件中断；因此，您为它编写了中断处理程序。现在，在为驱动程序实现read方法时，您发现其中有一个非阻塞的关键部分。这很容易处理:正如您所学到的，您应该使用自旋锁来保护它。太好了！但是，如果在读取方法的关键部分，设备的硬件中断怎么办？如您所知，硬件中断会抢占任何东西；因此，控制权将转到抢占驱动程序读取方法的中断处理程序代码。</p>
<p>​    这里的关键问题是:这是一个问题吗？这个答案取决于你的中断处理程序和读取方法在做什么，以及它们是如何实现的。让我们想象一下几个场景:中断处理程序（理想情况下）只使用局部变量，所以即使therad方法位于关键部分，也没关系；中断处理将很快完成，控制权将交还给任何被中断的人（同样，还有更多的事情要做；如你所知，任何现有的下半部分，如tasklet或softirq，也可能需要执行）。换句话说，在这种情况下，真的没有种族。中断处理程序正在处理（全局）共享的可写数据，但不处理读取方法正在使用的数据项。因此，再次强调，与读取的代码没有冲突，也没有竞争。当然，您应该意识到，中断代码确实有一个关键部分，必须对其进行保护（可能使用另一个自旋锁）。中断处理程序正在处理与读取方法使用的全局共享可写数据相同的数据。在这种情况下，我们可以看到arace的潜力肯定存在，所以我们需要锁定！让我们专注于第三种情况。显然，我们应该使用自旋锁来保护中断处理代码中的关键部分（回想一下，当我们处于任何类型的中断上下文中时，都不允许使用互斥体）。此外，除非我们在therad方法和中断处理程序的代码路径中使用相同的自旋锁，否则它们根本不会受到保护！（在使用锁时要小心；花点时间仔细思考你的设计和代码。）让我们试着让这变得更有实践性（现在使用伪代码）:假设我们有一个名为gCtx的全局（共享）数据结构；我们在驱动程序中的read方法和中断处理程序（hardirq处理程序）中对其进行操作。由于它是共享的，因此它是一个充满争议的部分，因此需要保护；由于我们在原子（中断）上下文中运行，因此不能使用互斥体，因此必须使用自旋锁（在这里，自旋锁变量称为slock）。以下伪代码显示了这种情况下的一些时间戳（t1、t2、…）:</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; Driver read method ; WRONG !
driver_read(...) &lt;&lt; time t0 &gt;&gt;
&#123;
 [ ... ]
 spin_lock(&amp;slock);
 &lt;&lt;--- time t1 : start of critical section &gt;&gt;
... &lt;&lt; operating on global data object gCtx &gt;&gt; ...
 spin_unlock(&amp;slock);
 &lt;&lt;--- time t2 : end of critical section &gt;&gt;
 [ ... ]
&#125; &lt;&lt; time t3 &gt;&gt;
The following pseudocode is for the device driver&#39;s interrupt handler:
handle_interrupt(...) &lt;&lt; time t4; hardware interrupt fires!
&gt;&gt;
&#123;
 [ ... ]
 spin_lock(&amp;slock);
 &lt;&lt;--- time t5: start of critical section &gt;&gt;
 ... &lt;&lt; operating on global data object gCtx &gt;&gt; ...
 spin_unlock(&amp;slock);
 &lt;&lt;--- time t6 : end of critical section &gt;&gt;
 [ ... ]
&#125; &lt;&lt; time t7 &gt;&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    幸运的是，一切进展顺利——“幸运的是”，因为硬件中断是在therad函数的关键部分完成后触发的。当然，我们不能指望运气是我们产品的唯一安全标志！硬件中断是异步的；如果它在一个不太合适的时间（对我们来说）触发怎么办？比如，当read方法的关键部分在时间t1和t2之间运行时？那么，自旋锁难道不会完成它的工作并保护我们的数据吗？此时，中断处理程序的代码将尝试获取相同的自旋锁（&amp;slock）。等一下，它无法“获取”它，因为它当前已锁定！在这种情况下，它会“旋转”，实际上是在等待解锁。但它怎么能解锁呢？它不能，这就是:（自我）僵局。有趣的是，自旋锁在SMP（多核）系统上更直观，也更有意义。让我们假设read方法在CPU核1上运行；中断可以在另一个CPU核心（例如核心2）上传递。中断代码路径将在CPUcore 2上的锁上“旋转”，而core 1上的读取方法完成关键部分，然后解锁旋转锁，从而解锁中断处理程序。但是UP（单处理器，只有一个CPU核）呢？那么，它将如何运作？啊，这就是这个难题的解决方案:当与中断“比赛”时，无论是单处理器还是SMP，只需使用spinlock API的_irq变体:</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;linux&#x2F;spinlock.h&gt;
void spin_lock_irq(spinlock_t *lock);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>spin_lock_irq（）API在内部禁用正在运行的处理器内核上的中断；即本地核心。因此，通过在我们的读取方法中使用这个API，将在本地内核上禁用中断，从而使任何可能的“竞赛”都无法通过中断实现。（如果中断确实在另一个CPU核上触发，那么自旋锁技术将像之前讨论的那样正常工作！）spin_lock_irq（）实现非常嵌套（与大多数自旋锁功能一样），但速度很快；最后，它结束了对local_irq_disable（）和preced_disable）宏的调用，在运行它的本地处理器核心上禁用中断和内核抢占。（禁用硬件中断也会产生禁用内核抢占的（理想的）副作用。）spin_lock_irq（）与相应的spin_unlock_irqneneneba API配对。因此，对于这种情况（与我们之前看到的相反），自旋锁的正确用法如下:</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; Driver read method ; CORRECT !
driver_read(...) &lt;&lt; time t0 &gt;&gt;
&#123;
[ ... ]
 spin_lock_irq(&amp;slock);
 &lt;&lt;--- time t1 : start of critical section &gt;&gt;
[now all interrupts + preemption on local CPU core are masked (disabled)]
... &lt;&lt; operating on global data object gCtx &gt;&gt; ...
 spin_unlock_irq(&amp;slock);
 &lt;&lt;--- time t2 : end of critical section &gt;&gt;
 [ ... ]
&#125; &lt;&lt; time t3 &gt;&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    在给自己一个沉重的打击并休息一天之前，让我们考虑另一种情况。这一次，在一个更复杂的产品（或项目）上，很有可能，在从事代码库工作的几位开发人员中，有人故意将中断掩码设置为某个值，从而阻止一些中断，同时允许其他中断。为了我们的例子，让我们假设这发生在更早的时间点t0。现在，正如我们之前所描述的，另一个开发人员（你！）出现了，为了保护驱动程序读取方法中的关键部分，使用spin_lock_irq（）API。听起来不错，是吗？是的，但这个API有能力关闭（屏蔽）本地CPU内核上的所有硬件中断（以及内核抢占，我们现在将忽略它）。它通过在较低级别操纵（非常特定于拱门的）硬件中断掩码寄存器来实现这一点。假设将与中断对应的位设置为1会启用该中断，而将该位（设置为0）会禁用或屏蔽它。因此，我们可能会出现以下情况:时间t0:中断掩码设置为某个值，例如0x8e（10001110b），启用一些中断并禁用一些中断。这对项目很重要（为了简单起见，我们假设有一个8位掩码寄存器）[…时间流逝…]。时间t1:就在进入驱动程序读取方法的关键部分callspin_lock_irq（&amp;slock）；之前；。此API将具有清除注册为0的中断掩码中的所有位的内部效果，从而禁用所有中断（正如我们所希望的）。时间t2:现在，硬件中断无法在此CPU内核上激发，因此我们继续并完成关键部分。完成后，我们调用spin_unlock_irq（&amp;slock）；。这个API的内部效果是将中断屏蔽寄存器中的所有位设置为1，重新启用所有中断。然而，中断掩码寄存器现在被错误地“恢复”为0xff（1111111b）的值，而不是原始开发人员想要、要求和假设的值0x8e！这可能会（也可能会）破坏项目中的某些东西。解决方案非常简单:不要做任何假设，只需保存并恢复中断掩码。这可以通过以下API对实现</p>
<pre class="line-numbers language-none"><code class="language-none">\#include &lt;linux&#x2F;spinlock.h&gt;&gt;
 unsigned long spin_lock_irqsave(spinlock_t *lock, unsigned long flags);
 void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>锁定和解锁功能的第一个参数是要使用的spinlock变量。第二个参数flags必须是无符号long类型的局部变量。这将用于保存和恢复中断掩码:spinlock_t-slock；spin_lock_init（&amp;slock）；[…]driver_read（…）｛[…]spin_lock_irqsave（&amp;slock，flags）；&lt;&lt;…critical section…&gt;&gt;spin_unlock_irqrestore（&amp;sock，flags；为了便于阅读，我们将其展示为API。此外，虽然此宏的返回值不是void，但它是一个内部细节（此处更新了flags参数变量）。如果一个小任务或softirq（一种下半部分中断机制）有一个关键部分与您的进程上下文代码路径“竞争”，该怎么办？在这种情况下，使用thespin_lock_bh（）例程可能是必需的，因为它可以禁用本地处理器上的下半部分，然后获取自旋锁，从而保护关键部分（类似于spin_lock_irq[save]（）通过禁用本地内核上的硬件中断来保护进程上下文中的关键部分）:</p>
<pre class="line-numbers language-none"><code class="language-none">void spin_lock_bh(spinlock_t *lock);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    当然，在对性能高度敏感的代码路径中，开销确实很重要（网络堆栈就是一个很好的例子）。因此，使用最简单的自旋锁形式将有助于更复杂的变体。话虽如此，但肯定会有一些场合要求使用更强形式的spinlock API。例如，在5.4.0 Linux内核上，这是我们看到的不同形式的自旋锁API的使用实例数量的近似值:spin_lock（）:超过9400个使用实例；spin_lock_irq（）:3600多个使用实例；spin_lock_irqsave（）:超过15000个使用实例；以及spin_lock_bh（）:超过3700个使用实例。（我们没有从中得出任何重大推论；我们只是想指出，在Linux内核中使用自旋锁API的强性能是相当普遍的）。最后，让我们简要介绍一下自旋锁的内部实现:就底层内部而言，实现往往是非常特殊的代码，通常由在微处理器上执行速度非常快的原子机器语言指令组成。例如，在流行的x86[_64]架构上，自旋锁最终归结为原子测试，并在自旋锁结构的成员上设置机器指令（通常通过cmpxchg机器语言指令实现）。在ARM机器上，正如我们之前提到的，实现的核心通常是wfe（等待事件，以及SetEvent（SEV））机器指令。（您将在进一步阅读部分找到有关其内部实现的资源）。无论如何，作为内核或驱动程序的作者，在使用自旋锁时，您应该只使用公开的API（和宏）。使用自旋锁——快速总结让我们快速总结自旋锁:最简单、最低的开销:在保护进程上下文中的关键部分时使用非irq自旋锁原语spin_lock（）/spin_unlock（）（要么没有中断需要处理，要么有中断，但我们根本不与它们竞争；实际上，当中断不起作用或无关紧要时使用它）。中等开销:使用irq禁用（以及内核抢占禁用）版本，spin_lock_irq（）/spin_unlock_irk（），当中断正在发挥作用并且很重要时（进程和中断上下文可以“竞争”；也就是说，它们共享全局数据）。</p>
<p>​    最强（相对），开销高:这是使用自旋锁最安全的方法。它与中等开销相同，除了它通过spin_lock_irqsave（）/spin_unlock_irqrestore（）对中断掩码执行保存和还原，以确保之前的中断掩码设置不会被无意中覆盖，这可能会在之前的情况下发生。正如我们之前看到的，自旋锁——在等待锁的时候在它运行的处理器上“旋转”——在UP上是不可能的（你怎么能在一个可用的CPU上旋转，而另一个线程在同一个CPU上同时运行？）。事实上，在UP系统上，自旋锁API的唯一真正效果是它可以禁用处理器上的硬件中断和内核抢占！然而，在SMP（多核）系统上，锁定逻辑实际上发挥了作用，因此锁定语义按预期工作。但请稍等——这不应该让你感到压力，作为刚刚起步的内核/驱动程序开发人员；事实上，关键在于你应该简单地使用所描述的自旋锁API，你永远不必担心UP和SMP；所做和未做的细节都被内部实现所隐藏。虽然这本书基于5.4 LTS内核，但实时Linux（RTL，以前称为PREEMPT_RT）项目在5.8内核中添加了一个新功能，值得在这里快速提及:“本地锁”。虽然本地锁的主要用例是用于（硬）实时内核，但它们也有助于非实时内核，主要是通过静态分析进行锁调试，以及通过lockdep进行运行时调试（我们将在下一章介绍lockdep）。以下是LWN关于这个主题的文章:<a target="_blank" rel="noopener" href="https://lwn.net/Articles/828477/.With在此，我们完成了关于自旋锁的部分，自旋锁是Linux内核中几乎所有子系统（包括驱动程序）都使用的一种极其常见的密钥锁。">https://lwn.net/Articles/828477/.With在此，我们完成了关于自旋锁的部分，自旋锁是Linux内核中几乎所有子系统（包括驱动程序）都使用的一种极其常见的密钥锁。</a></p>
<h3 id="内核同步-第2部分"><a href="#内核同步-第2部分" class="headerlink" title="内核同步-第2部分"></a>内核同步-第2部分</h3><h4 id="使用atomic-t和refcount-t接口"><a href="#使用atomic-t和refcount-t接口" class="headerlink" title="使用atomic_t和refcount_t接口"></a>使用atomic_t和refcount_t接口</h4><p>​    在我们简单的演示misc字符设备驱动程序（miscdrv_rdwr/miscdrv.rdwr.c）的开放方法（和其他地方）中，我们定义并操纵了两个静态全局整数ga和gb:</p>
<pre class="line-numbers language-none"><code class="language-none">static int ga, gb &#x3D; 1;
[...]
ga++; gb--;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​    到目前为止，您应该很清楚，如果保持原样，我们对这些整数进行操作的地方是一个潜在的错误:它是共享的可写数据（处于共享状态），因此是关键部分，因此需要防止并发访问。你明白了；所以，我们逐步改进了这一点。在上一章中，为了理解这个问题，在我们的12/1_miscdrv_rdwr_mutexlock/1_miscdrv_rdwr_motexlock.c程序中，我们首先使用了互斥锁来保护关键部分。后来，您了解到，使用自旋锁保护像这样的非阻塞关键部分在性能方面（远远）优于使用amutex；因此，在我们的下一个驱动程序ch12/2_miscdrv_rdwr_spinlock/2_miscdrv-rdwr_spinlock.c中，我们使用了</p>
<pre class="line-numbers language-none"><code class="language-none">spinlock instead:
spin_lock(&amp;lock1);
ga++; gb--;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>这很好，但我们还可以做得更好！对全局整数进行操作在内核中非常常见（想想引用或资源计数器递增和递减等），以至于内核提供了一类称为refcount和原子整数运算符或接口的运算符；这些是非常专门设计的，只对整数进行原子（安全和不可分割）操作。较新的refcount_t与较旧的atomic_ttinterface在本主题领域的开头，有一点很重要:从4.11内核开始，有一组更新更好的接口，称为refcount_tAPI，用于内核空间对象的引用计数器。它极大地改善了内核的安全状态（通过大大改进的整数溢出（IoF）和自由使用（UAF）保护以及内存排序保证，这是旧的atomic_t API所缺乏的）。refcount_tinterfaces与Linux上使用的其他几种安全技术一样，起源于PaX团队所做的工作<a target="_blank" rel="noopener" href="https://pax.grsecurity.net/（它被称为PAX_REFCOUNT）。">https://pax.grsecurity.net/（它被称为PAX_REFCOUNT）。</a></p>
<p>​    话虽如此，但现实情况是（截至撰写本文时）旧的atomic_t接口仍在内核内核和驱动程序中大量使用（它们正在缓慢转换，旧的atomic_t接口被移动到新的refcount_tmodel和API集）。因此，在本主题中，我们涵盖了这两个方面，指出了不同之处，并指出了在适用的情况下，refcount_t API将取代atomic_t API。将refcount_t接口视为（较旧的）atomic_t接口的变体，后者专门用于引用计数。atomic_t运算符和refcount_t运算符之间的一个关键区别是，前者适用于有符号整数，而后者本质上是设计用于非无符号整数；更具体地说，这很重要，它只在严格指定的范围内工作:1到UINT_MAX-1（或当！CONFIG_REFCOUNT_FULL时为[1..INT_MAX]）。内核有一个名为config_REFCOUNT_FULL的配置选项；如果设置了，它将执行（更慢、更彻底的）“完整”引用计数验证。这有利于安全性，但可能会导致性能略有下降（典型的默认设置是关闭此配置；我们的x86_64 Ubuntu客户机就是这种情况）。尝试将refcount_t变量设置为0或负数，或设置为[U]INT_MAX或更高，是不可能的；这有助于防止整数下溢/上溢问题，从而在许多情况下避免释放类后的使用错误！（好吧，这并非不可能；它会导致通过WARN（）宏发出（嘈杂的）警告。）想想看，refcount_t变量只用于内核对象引用计数，其他什么都不用。因此，这确实是所需的行为；引用计数器必须从正值开始（当对象新实例化时通常为1），每当代码获得或获取引用时，引用计数器都会递增（或相加），而每当代码在对象上放置或留下引用时，它都会递减（或相减）。您需要小心操作参考计数器（匹配您的买入和卖出），始终将其值保持在合法范围内。非常不直观的是，至少对于依赖于arch的一般refcount_t实现，refcount_tAPI是在atomic_t API集合上内部实现的。例如，refcount_set（）API——它原子性地将refcount的值设置为传递的参数——在内核中是这样实现的:</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; include&#x2F;linux&#x2F;refcount.h
&#x2F;**
 * refcount_set - set a refcount&#39;s value
 * @r: the refcount
 * @n: value to which the refcount will be set
 *&#x2F;
static inline void refcount_set(refcount_t *r, unsigned int n)
&#123;
 atomic_set(&amp;r-&gt;refs, n);
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    它是atomic.set（）的一个薄包装器（我们将很快介绍）。这里显而易见的常见问题是:为什么要使用refcount API？有几个原因:计数器在REFCOUNT_SATRATED值处饱和（默认设置为UINT_MAX），一旦达到该值就不会移动。这一点至关重要:它避免了敲击计数器，这可能会导致奇怪和虚假的UAF错误；这甚至被认为是一个关键的安全修复(<a target="_blank" rel="noopener" href="https://kernsec.org/wiki/index.php/Kernel_Protections/refcount_t).一些较新的refcount">https://kernsec.org/wiki/index.php/Kernel_Protections/refcount_t).一些较新的refcount</a> API确实提供了内存排序保证；特别是refcount_t API（与较旧的atomic_t表亲相比）及其提供的内存排序保证在<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/core-api/refcount-vs-atomic.html\#refcount-t-api-compared">https://www.kernel.org/doc/html/latest/core-api/refcount-vs-atomic.html\#refcount-t-api-compared</a> to atomic-t（如果你对低级细节感兴趣，请使用alook）。此外，请注意，依赖于arch的refcount实现（当它们存在时；例如，x86确实有，而ARM没有）可能与前面提到的通用实现不同。记忆顺序究竟是什么，它对我们有什么影响？事实上，这是一个复杂的话题，不幸的是，这方面的内在细节超出了本书的范围。了解基础知识是值得的:我建议你阅读Linux内核内存模型（LKMM），其中包括处理器内存排序等内容。我们建议您参考这里的良好文档:Linux内核内存模型说明(<a target="_blank" rel="noopener" href="https://github.com/torvalds/linux/blob/master/tools/memory￾模型/文档/解释.txt）。更简单的atomic_t和refcount_t接口关于atomic-t接口，我们应该提到的是，以下所有atomic_tconstruct仅适用于32位整数；当然，随着64位整数的普及，64位原子整数运算符也可用。通常，它们在语义上与32位对应物相同，区别在于名称（atomic_foo（）变为atomic64_foo（（）））。因此，64位原子簇的主要数据类型称为atomic64_t（又名atomic_long_t）。另一方面，refcount_t接口同时支持32位和64位整数。">https://github.com/torvalds/linux/blob/master/tools/memory￾模型/文档/解释.txt）。更简单的atomic_t和refcount_t接口关于atomic-t接口，我们应该提到的是，以下所有atomic_tconstruct仅适用于32位整数；当然，随着64位整数的普及，64位原子整数运算符也可用。通常，它们在语义上与32位对应物相同，区别在于名称（atomic_foo（）变为atomic64_foo（（）））。因此，64位原子簇的主要数据类型称为atomic64_t（又名atomic_long_t）。另一方面，refcount_t接口同时支持32位和64位整数。</a></p>
<p><img src="./image-20240727082954783.png" alt="image-20240727082954783"><img src="./image-20240727082959057.png" alt="image-20240727082959057"></p>
<p>使用RMW原子运算符还有一组更高级的原子运算符，称为RMW API。它的许多用途（我们将在下一节中显示一个列表）是对位执行原子RMW操作，换句话说，以原子方式（安全、不可分割）执行位操作。作为一名在设备或外围寄存器上操作的设备驱动程序作者，这是您需要使用的东西。本节中的材料假设您至少对访问外围设备（芯片）内存和寄存器有基本的了解；我们在第3章“使用硬件I/O内存”中对此进行了详细介绍。在继续之前，请确保你理解它。通常，您需要在寄存器上执行位操作（位AND&amp;和位OR|是最常见的运算符）；这样做是为了修改它的值，设置和/或清除其中的一些位。问题是，仅仅执行一些C操作来查询或设置设备寄存器是不够的。不，先生:别忘了并发问题！继续阅读完整的故事。RMW原子操作——在设备寄存器上操作让我们先快速复习一些基本知识:一个字节由8位组成，从0位（最低有效位（LSB））到7位（最高有效位（MSB）编号。（这实际上在include/linux/BITS.h中被正式定义为BITS_PER_BYTE宏，以及其他一些有趣的定义。）寄存器基本上是外围设备内的一小块内存；通常，其大小，即寄存器位宽，是8、16或32位之一。设备寄存器提供控制、状态和其他信息，并且通常是可编程的。事实上，这在很大程度上就是作为驱动程序作者所要做的——对设备注册进行适当的编程，使设备执行某些操作，并对其进行查询。</p>
<p>​    为了充实这一讨论，让我们考虑一个假设的设备，它有两个寄存器:一个状态寄存器和一个控制寄存器，每个寄存器的宽度为8位。（在现实世界中，每个设备或芯片都有一个数据表，提供芯片和寄存器级硬件的详细规格；这对驱动程序作者来说是一份必不可少的文件）。硬件人员通常以这样的方式设计设备，即几个寄存器在更大的内存中顺序地润滑在一起；这被称为注册银行。通过拥有第一个寄存器的基址和后续每个寄存器的偏移量，可以很容易地处理任何给定的寄存器（在这里，我们不会深入研究寄存器是如何在Linux等操作系统上“映射”到虚拟地址空间的）。例如，（纯假设的）寄存器可以在头文件中这样描述:</p>
<pre class="line-numbers language-none"><code class="language-none">\#define REG_BASE 0x5a00
\#define STATUS_REG (REG_BASE+0x0)
\#define CTRL_REG (REG_BASE+0x1)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>现在，假设为了打开我们的虚构设备，数据表通知我们可以通过将控制寄存器的位7（MSB）设置为1来打开。正如每一位驾驶者作家所迅速认识到的那样，修改登记簿有一个神圣的顺序:1。将寄存器的当前值读入临时变量。将变量修改为所需的值。将变量写回寄存器。这通常被称为RMW序列；所以，很好，我们编写这样的（伪）代码:</p>
<pre class="line-numbers language-none"><code class="language-none">turn_on_dev()
&#123;
 u8 tmp;
 tmp &#x3D; ioread8(CTRL_REG); &#x2F;* read: current register value into tmp *&#x2F;
 tmp |&#x3D; 0x80; &#x2F;* modify: set bit 7 (MSB) *&#x2F;
 iowrite8(tmp, CTRL_REG); &#x2F;* write: new tmp value into register *&#x2F;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>（仅供参考，Linux MMIO上使用的实际例程-内存映射I/O-areioread[8|16|32]（）和iowrite[8|16|12]（）。）这里有一个关键点:这还不够好；原因是并发性、数据竞争！想想看:寄存器（CPU和设备寄存器）实际上是一个全局共享的可写内存位置；因此，访问它构成了一个关键部分，您必须注意保护它免受并发访问！怎么做很容易；我们可以使用自旋锁（至少目前是这样）。修改前面的伪代码以在关键部分（RMW序列）中插入spin_[un]lock（）API是很容易的。</p>
<p>然而，在处理整数等少量数据时，有一种更好的方法来实现数据安全；我们已经介绍过了:原子运算符！然而，Linux更进一步，为以下两种操作提供了一组原子API:</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; Documentation&#x2F;atomic_t.txt
[ ... ]
Non-RMW ops:
 atomic_read(), atomic_set()
 atomic_read_acquire(), atomic_set_release()
RMW atomic operations:
Arithmetic:
 atomic_&#123;add,sub,inc,dec&#125;()
 atomic_&#123;add,sub,inc,dec&#125;_return&#123;,_relaxed,_acquire,_release&#125;()
 atomic_fetch_&#123;add,sub,inc,dec&#125;&#123;,_relaxed,_acquire,_release&#125;()
Bitwise:
 atomic_&#123;and,or,xor,andnot&#125;()
 atomic_fetch_&#123;and,or,xor,andnot&#125;&#123;,_relaxed,_acquire,_release&#125;()
Swap:
 atomic_xchg&#123;,_relaxed,_acquire,_release&#125;()
 atomic_cmpxchg&#123;,_relaxed,_acquire,_release&#125;()
 atomic_try_cmpxchg&#123;,_relaxed,_acquire,_release&#125;()
Reference count (but please see refcount_t):
 atomic_add_unless(), atomic_inc_not_zero()
 atomic_sub_and_test(), atomic_dec_and_test()
 Misc:
 atomic_inc_and_test(), atomic_add_negative()
 atomic_dec_unless_positive(), atomic_inc_unless_negative()
[ ... ]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>好；现在您已经了解了这些RMW（和非RMW）运算符，让我们开始实践吧——接下来我们将了解如何将RMW运算符用于位操作。在这里，我们将重点介绍如何使用RMW位运算符；我们将让您来探索其他内容（请参阅提到的内核文档）。那么，让我们再次思考如何更有效地编写我们的伪代码示例。我们可以使用set_bit（）API将任何寄存器或内存项中的任何给定位设置为（1）:void set_bit，unsigned int nr，volatile unsigned long*p；这在原子层面上——安全且不可分割地——将p的第n位设置为1。（现实情况是，设备寄存器（可能还有设备内存）被映射到内核虚拟地址空间，因此看起来就像RAM位置一样可见，比如这里的地址p。这被称为MMIO，是驱动程序作者映射和使用设备内存的常见方式。）因此，使用RMW原子运算符，我们可以通过一行代码安全地实现我们之前（错误地）尝试过的操作——打开我们的（虚构的）设备:set_bit（7，CTRL_REG）；下表总结了常见的RMW逐位原子API:</p>
<p><img src="./image-20240727083144944.png" alt="image-20240727083144944"></p>
<h4 id="有一句话要提醒"><a href="#有一句话要提醒" class="headerlink" title="有一句话要提醒"></a><img src="./image-20240727083148383.png" alt="image-20240727083148383">有一句话要提醒</h4><p>​    读者和写者之间确实存在问题。一个典型的问题是，不幸的是，作家在屏蔽几个读者时可能会饿死。想想看:假设目前有三个读取器线程具有读取器-写入器锁。现在，一位作家正沿着锁走来。它必须等到所有三个读卡器都执行解锁。但是，如果在内部出现更多的读者（这是完全可能的）呢？这对作家来说是一场灾难，他现在不得不等待更长的时间——实际上是挨饿。（可能需要仔细检测或分析所涉及的代码路径，以确定是否属实。）不仅如此，当不同CPU核上的多个读取器线程并行读取相同的共享状态时（同时保持读取器-写入器锁定），缓存效应（称为缓存乒乓）也会经常发生；事实上，我们在缓存效果和虚假共享部分讨论了这一点）。关于自旋锁的内核文档(<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/locking/spinlocks.txt)说的几乎是一样的。这里有一句名言:“注意！读写器锁比简单的自旋锁需要更多的原子内存操作。除非读写器关键部分很长，否则最好只使用自旋锁。”事实上，内核社区正在努力尽可能地删除读写器自旋锁，将其转移到更高级的无锁技术（如RCU-读取复制更新，一种高级无锁技术)。因此，无端使用读写器的刺是不可取的。">https://www.kernel.org/doc/Documentation/locking/spinlocks.txt)说的几乎是一样的。这里有一句名言:“注意！读写器锁比简单的自旋锁需要更多的原子内存操作。除非读写器关键部分很长，否则最好只使用自旋锁。”事实上，内核社区正在努力尽可能地删除读写器自旋锁，将其转移到更高级的无锁技术（如RCU-读取复制更新，一种高级无锁技术)。因此，无端使用读写器的刺是不可取的。</a></p>
<p>​    关于自旋锁使用的简洁明了的内核文档（由Linus Torvalds本人编写）非常值得一读，可以在这里找到:<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/locking/spinlocks.txt.The读写器semaphore我们之前提到了信号量对象（第6章，内核同步-第1部分，信号量和互斥量部分），并将其与互斥量进行了对比。在那里，您明白最好简单地使用互斥体。在这里，我们指出，在内核中，正如存在读写器自旋锁一样，也存在读写信号量。用例和语义与读写器的pinlock相似。相关的宏/API是（在">https://www.kernel.org/doc/Documentation/locking/spinlocks.txt.The读写器semaphore我们之前提到了信号量对象（第6章，内核同步-第1部分，信号量和互斥量部分），并将其与互斥量进行了对比。在那里，您明白最好简单地使用互斥体。在这里，我们指出，在内核中，正如存在读写器自旋锁一样，也存在读写信号量。用例和语义与读写器的pinlock相似。相关的宏/API是（在</a><linux/rwsem.h>中）{down,up}_{read,write}_{trylock，killable}（）。结构mm_struct结构（本身位于任务结构内）中的一个常见示例是，其中一个成员是读写器信号量:结构rw_semaphore mmap_sem；。最后，我们将只提到内核中其他几个相关的同步机制。一种在用户空间应用程序开发中常用的同步机制（我们特别考虑Linux用户空间中的Pthreads框架）是条件变量（CV）。简而言之，它提供了两个或多个线程根据数据项的值或某些特定状态相互同步的能力。Linux内核中的等效机制称为完成机制。请在kernel文档中找到有关其使用的详细信息，网址为<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/scheduler/completion.html\#completions-等待完成屏障api。序列锁主要用于写入情况（与读取器writespinlock/信号量锁相反，后者适用于大多数读取情况），其中writesfar超过了受保护变量的读取。正如你所想象的，这种情况并不常见；使用序列锁的一个很好的例子是更新jiffies_64全局。对于好奇的人来说，jiffies_64全局更新代码的开头是:kernel/time/tick">https://www.kernel.org/doc/html/latest/scheduler/completion.html\#completions-等待完成屏障api。序列锁主要用于写入情况（与读取器writespinlock/信号量锁相反，后者适用于大多数读取情况），其中writesfar超过了受保护变量的读取。正如你所想象的，这种情况并不常见；使用序列锁的一个很好的例子是更新jiffies_64全局。对于好奇的人来说，jiffies_64全局更新代码的开头是:kernel/time/tick</a> sched.c:tick_do_update_iffies64（）。此函数计算是否需要更新jiffies，如果需要，则调用do_timer（++ticks）；一直以来，write_seq[un]锁（&amp;jiffies_lock）；API为写关键部分提供保护。</p>
<h4 id="缓存效应和错误共享"><a href="#缓存效应和错误共享" class="headerlink" title="缓存效应和错误共享"></a>缓存效应和错误共享</h4><p>​    现代处理器利用其中的多级并行缓存，以便在处理内存时提供非常显著的加速（webriefly在配套指南Linux内核编程-第8章，模块作者的内核内存分配-第1部分，在分配板内存部分中提到了这一点）。我们意识到，现代CPU并不能直接读写RAM；不，当软件指示从某个地址开始读取RAM的一个字节时，CPU实际上会从起始地址读取几个字节——一整行字节（通常为64个字节）到所有CPU缓存中（比如L1、L2和L3:级别1、2和3）。这样，在缓存中首次检查时（首先在L1中，然后在L2中，然后是L3中，然后很可能会出现缓存命中），访问顺序存储器的接下来的几个元素会导致一个tremendouspuedup。它（快得多）的原因很简单:访问CPU缓存通常需要一到几（个位数）纳秒，而访问RAM可能需要50到100纳秒（当然，这取决于所讨论的硬件系统和您愿意支付的金额！）。软件开发人员通过以下方式利用这种现象:将数据结构的重要成员放在一起（希望放在一个缓存行内）并放在结构的顶部添加一个结构成员，这样我们就不会从缓存行上掉下来（同样，这些点在配套指南《Linux内核编程》第8章“模块作者的内核内存分配”第1部分“数据结构”中的“一些设计技巧”一节中也有介绍）。然而，这涉及风险，事情确实会出错。例如，考虑两个这样声明的变量:u16 ax=1，bx=2；（u16表示无符号16位整数值）。现在，由于它们被声明为彼此相邻，它们在运行时很可能会占用相同的CPU缓存行。为了理解问题所在，让我们举一个例子:考虑一个具有两个CPU核的多核系统，每个核都有两个CPU缓存L1和L2，以及一个通用或统一的L3缓存。现在，一个线程T1正在以无变量ax工作，另一个线程T2正在并发（在另一个CPU核上）以无变量bx工作。所以，想想看:当在CPU 0上运行的线程T1从主内存（RAM）访问ax时，它的CPU缓存将填充ax和bx的当前值（因为它们位于同一缓存行中！）。同样，当运行在CPU 1上的线程T2从RAM访问bx时，其CPU缓存也将填充这两个变量的当前值。图7.4从概念上描述了这种情况:</p>
<p><img src="./image-20240727083251494.png" alt="image-20240727083251494"></p>
<p>​    到目前为止，每个变量都在一个不同的变量上；但是，如果T1执行一个操作，比如ax++，而T2同时执行bx++呢？那又怎样？（顺便问一下，你可能会想:为什么它们不使用锁？有趣的是，这与本次讨论无关；当每个线程访问不同的变量时，没有数据竞争。问题在于它们位于同一CPU缓存行中。）问题是:缓存一致性。处理器和/或操作系统与处理器（这都是非常依赖于拱的东西）必须保持缓存和RAM的同步或一致。因此，在T1修改ax的时刻，CPU 0的特定缓存行将必须无效，也就是说，CPU缓存行的CPU 0缓存到RAM刷新将发生，以将RAM更新为新值，然后立即，RAM到CPU 1缓存的更新也必须发生，以保持一切一致！但是缓存行也包含bx，正如我们所说，bx也在CPU 1by T2上进行了修改。因此，大约在同一时间，CPU 1缓存行将用新的bx值刷新到RAM中，随后更新到CPU 0的缓存中（同时，统一的L3缓存也将被读取/更新）。正如你所想象的，这些变量的任何更新都会导致缓存和RAM上的大量流量；它们会反弹。事实上，这通常被称为缓存乒乓球！这种影响非常有害，大大减缓了处理速度。这种现象被称为虚假分享。</p>
<p>​    识别虚假共享是难点；我们必须寻找存在于sharedcacheline上的变量，这些变量由不同的上下文（线程或其他任何东西）同时更新。有趣的是，内存管理层中一个关键数据结构的早期实现，包括/linux/mmzone.h:structure-zone，也遇到了同样的错误共享问题:两个自旋锁被声明为彼此相邻！这个问题早就被解决了（我们在公司指南《Linux内核编程》第7章“内存管理内部-基础”中的物理RAM组织/区域部分简要讨论了内存区域）。如何修复这种虚假共享？简单:只需确保变量之间的间距足够大，以确保它们不共享同一缓存行（为此，通常在变量之间插入虚拟填充字节）。请同时参阅“进一步阅读”部分中的参考文献以进行分享。使用per-CPU变量进行无锁编程正如您所了解的，在对共享可写数据进行操作时，必须以某种方式保护关键部分。锁定可能是实现这种保护的最常见技术。不过，情况并不乐观，因为表现可能会受到影响。要理解其中的原因，可以考虑一些与锁的类比:一个是漏斗，漏斗的杆刚好足够宽，一次只能让一根线流过，不能再多了。另一种是繁忙高速公路上的单一收费站或繁忙十字路口的红绿灯。这些类比有助于我们可视化并理解为什么锁定会导致瓶颈，在某些极端情况下会使性能下降到爬行。更糟糕的是，这些不利影响可能会在拥有几百个内核的高端多核系统上成倍增加；实际上，锁定并不能很好地扩展。另一个问题是锁争用；获取特定锁的频率是多少？增加系统内锁的数量有利于降低两个或多个进程（或线程）之间对特定锁的竞争。这被称为锁熟练度。然而，这在很大程度上是不可扩展的:一段时间后，在一个系统上拥有数千个锁（事实上是Linux内核的情况）并不是好消息——出现微妙死锁情况的可能性大大增加。</p>
<p>​    因此，存在许多挑战——性能问题、死锁、优先级反转风险、卷积（由于锁排序，快速代码路径可能需要等待第一个较慢的代码路径，而较快的代码路径也需要锁）等等。以可扩展的方式进一步发展内核，要求在内核中使用无锁算法及其实现。这些导致了几种创新技术，其中包括每CPU（PCP）数据、无锁数据结构（通过设计）和RCU。不过，在这本书中，我们选择只详细介绍每个CPU的无锁编程技术。关于RCU（及其设计的相关无锁数据结构）的细节超出了本书的范围。请参阅本章的进一步阅读部分，了解有关RCU、其含义及其在Linux内核中的使用的几个有用资源。每CPU变量顾名思义，每CPU变量的工作原理是保留分配给系统上每个（活动）CPU的变量（有问题的数据项）的副本。实际上，我们通过避免读取之间的数据共享，摆脱了并发的问题区域，即关键部分。使用每CPU数据技术，由于每个CPU都引用其自己的数据副本，因此在该处理器上运行的线程可以操纵它而不必担心竞争。（这大致类似于局部变量；由于局部变量位于每个线程的私有堆栈上，它们不在线程之间共享，因此没有关键部分，也不需要锁定。）在这里，也消除了锁定的需要——使其成为一种无锁技术！所以，想想看:如果你在一个有四个活动CPU核的系统上运行，那么该系统上的每CPUvariable本质上是一个由四个元素组成的数组:元素0表示第一个CPU上的数据值，元素1表示第二个CPU核上的数据值，以此类推。理解这一点后，您会意识到每个CPU变量也大致类似于用户空间Pthreads线程本地存储（TLS）实现，其中每个线程自动获得标记有__Thread关键字的（TLS）变量的副本。在这里，对于每CPU变量，应该很明显:只对小数据项使用每CPU变量。这是因为数据项是用每个CPU核一个实例来再现（复制）的（在具有几百个核的高端系统上，开销为doclimb）。我们提到了内核代码库中每CPU使用率的一些示例（在内核中的每6553 CPU使用率部分）</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/Charliechen114514">Charlie Chen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://charliechen114514.github.io/2024/07/30/Linux%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/">http://charliechen114514.github.io/2024/07/30/Linux%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">全体目光向我看齐，我宣布个事！是我Charliechen写的这篇文章！(?)</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/C-C/">C/C++</a><a class="post-meta__tags" href="/tags/Linux/">Linux</a></div><div class="post_share"><div class="social-share" data-image="/img/passagepage.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/07/30/Linux-Debug%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" title="Linux Debug学习之路"><img class="cover" src="/img/passagepage.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Linux Debug学习之路</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/04/03/Linux-%E5%86%85%E6%A0%B8-Linux%E7%AE%80%E5%8D%95%E7%AE%80%E5%8F%B2%E4%B8%8E%E6%A6%82%E8%AE%BA/" title="Linux-内核-Linux简单简史与概论"><img class="cover" src="/img/passagepage.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-03</div><div class="title">Linux-内核-Linux简单简史与概论</div></div></a></div><div><a href="/2024/04/03/Linux%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%88%E5%BC%95%E8%AE%BA%EF%BC%89/" title="Linux深度学习教程（引论）"><img class="cover" src="/img/passagepage.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-03</div><div class="title">Linux深度学习教程（引论）</div></div></a></div><div><a href="/2024/07/27/Linux%E8%BF%9B%E7%A8%8B%E5%90%AF%E5%8A%A8%E4%B8%8ESystemd/" title="Linux进程启动与Systemd"><img class="cover" src="/img/passagepage.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-27</div><div class="title">Linux进程启动与Systemd</div></div></a></div><div><a href="/2024/07/30/Linux-Debug%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" title="Linux Debug学习之路"><img class="cover" src="/img/passagepage.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-30</div><div class="title">Linux Debug学习之路</div></div></a></div><div><a href="/2024/01/19/Linux%E6%BC%AB%E6%B8%B8%E5%90%88%E9%9B%86/" title="Linux漫游合集"><img class="cover" src="/img/passagepage.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-19</div><div class="title">Linux漫游合集</div></div></a></div><div><a href="/2023/08/23/TCP-IP-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%941%EF%BC%8C2%EF%BC%8C3/" title="TCP&#x2F;IP 网络编程笔记——1，2，3"><img class="cover" src="/img/passagepage.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-23</div><div class="title">TCP&#x2F;IP 网络编程笔记——1，2，3</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/webicon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Charlie Chen</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">72</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Charliechen114514"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Charliechen114514" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=725610365&amp;site=qq&amp;menu=yes" target="_blank" title="QQ"><i class="fab fa-qq"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">上传了一些在CSDN和博客园写的博客(喜)</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Linux-Kernel-Programming"><span class="toc-number">1.</span> <span class="toc-text">Linux Kernel Programming</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E6%88%91%E4%BB%AC%E5%BC%80%E5%A7%8B%E4%B9%8B%E5%89%8D%E2%80%A6"><span class="toc-number">1.1.</span> <span class="toc-text">在我们开始之前…</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">目标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%89%E6%8B%A9-Linux-%E5%8F%91%E8%A1%8C%E7%89%88%E5%92%8C%E5%86%85%E6%A0%B8"><span class="toc-number">1.1.0.2.</span> <span class="toc-text">选择 Linux 发行版和内核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E9%9D%A2%EF%BC%8C%E6%98%AF%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E6%97%B6%E9%97%B4"><span class="toc-number">1.1.0.3.</span> <span class="toc-text">下面，是软件安装时间</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-QEMU-%E5%92%8C%E4%BA%A4%E5%8F%89%E5%B7%A5%E5%85%B7%E9%93%BE"><span class="toc-number">1.1.0.4.</span> <span class="toc-text">安装 QEMU 和交叉工具链</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E6%96%87"><span class="toc-number">1.2.</span> <span class="toc-text">正文</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E6%9E%84%E5%BB%BA%E7%9A%84%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C%EF%BC%88Preliminaries-for-the-kernel-build%EF%BC%89"><span class="toc-number">1.2.0.1.</span> <span class="toc-text">内核构建的准备工作（Preliminaries for the kernel build）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E5%86%85%E6%A0%B8%E7%89%88%E6%9C%AC%E6%88%96%E7%89%88%E6%9C%AC%E5%8F%B7%E5%91%BD%E5%90%8D%E6%B3%95"><span class="toc-number">1.2.0.2.</span> <span class="toc-text">理解内核版本或版本号命名法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B8%E5%9E%8B%E7%9A%84%E5%86%85%E6%A0%B8%E5%BC%80%E5%8F%91%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">1.2.0.3.</span> <span class="toc-text">典型的内核开发工作流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E5%86%85%E6%A0%B8"><span class="toc-number">1.2.1.</span> <span class="toc-text">构建内核</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E6%BA%90%E7%A0%81"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">下载源码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%BC%E8%A7%88%E6%88%91%E4%BB%AC%E7%9A%84%E5%86%85%E6%A0%B8%E6%BA%90%E7%A0%81"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">导览我们的内核源码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E9%87%8D%E7%82%B9"><span class="toc-number">1.2.1.3.</span> <span class="toc-text">一些重点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%86%85%E6%A0%B8"><span class="toc-number">1.2.2.</span> <span class="toc-text">配置内核</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8EKconfig%E5%92%8CKbuild%E7%9A%84%E6%9C%80%E5%BF%AB%E7%90%86%E8%A7%A3"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">关于Kconfig和Kbuild的最快理解</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%88%E8%81%8A%E6%80%8E%E4%B9%88%E8%8E%B7%E5%8F%96%E9%BB%98%E8%AE%A4%E7%9A%84%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">先聊怎么获取默认的配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%8E%B7%E5%BE%97%E5%86%85%E6%A0%B8%E9%85%8D%E7%BD%AE%E7%9A%84%E8%89%AF%E5%A5%BD%E8%B5%B7%E7%82%B9"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">获得内核配置的良好起点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%88%86%E5%8F%91%E9%85%8D%E7%BD%AE%E4%BD%9C%E4%B8%BA%E8%B5%B7%E7%82%B9%E7%9A%84%E5%86%85%E6%A0%B8%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">使用分发配置作为起点的内核配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87-localmodconfig-%E6%96%B9%E6%B3%95%E8%B0%83%E6%95%B4%E5%86%85%E6%A0%B8%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.2.5.</span> <span class="toc-text">通过 localmodconfig 方法调整内核配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8make-help%E6%9F%A5%E7%9C%8B"><span class="toc-number">1.2.2.6.</span> <span class="toc-text">使用make help查看</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8menuconfig%E8%BF%9B%E8%A1%8C%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.2.7.</span> <span class="toc-text">使用menuconfig进行配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8-menuconfig-UI-%E4%B8%AD%E6%90%9C%E7%B4%A2"><span class="toc-number">1.2.2.8.</span> <span class="toc-text">在 menuconfig UI 中搜索</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E6%89%BE%E9%85%8D%E7%BD%AE%E4%B8%AD%E7%9A%84%E5%B7%AE%E5%BC%82"><span class="toc-number">1.2.2.9.</span> <span class="toc-text">查找配置中的差异</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%86%85%E6%A0%B8%E7%9A%84%E9%85%8D%E7%BD%AE%E8%84%9A%E6%9C%AC%E6%9F%A5%E7%9C%8B-%E7%BC%96%E8%BE%91-%E5%86%85%E6%A0%B8%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.2.10.</span> <span class="toc-text">使用内核的配置脚本查看&#x2F;编辑 内核配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%8F%90%E7%A4%BA-%E2%80%93-%E5%86%85%E6%A0%B8%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.2.11.</span> <span class="toc-text">其他提示 – 内核配置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E8%AF%91%E5%86%85%E6%A0%B8"><span class="toc-number">1.2.3.</span> <span class="toc-text">编译内核</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4-4-%E2%80%93-%E6%9E%84%E5%BB%BA%E5%86%85%E6%A0%B8%E6%98%A0%E5%83%8F%E5%92%8C%E6%A8%A1%E5%9D%97"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">步骤 4 – 构建内核映像和模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4-5-%E2%80%93-%E5%AE%89%E8%A3%85%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97"><span class="toc-number">1.2.3.2.</span> <span class="toc-text">步骤 5 – 安装内核模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4-6-%E2%80%93-%E7%94%9F%E6%88%90-initramfs-%E6%98%A0%E5%83%8F%E5%92%8C%E5%BC%95%E5%AF%BC%E5%8A%A0%E8%BD%BD%E7%A8%8B%E5%BA%8F%E8%AE%BE%E7%BD%AE%EF%BC%8C%E4%BA%86%E8%A7%A3-initramfs-%E6%A1%86%E6%9E%B6"><span class="toc-number">1.2.3.3.</span> <span class="toc-text">步骤 6 – 生成 initramfs 映像和引导加载程序设置，了解 initramfs 框架</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E5%90%8E%E5%8F%B0%E7%94%9F%E6%88%90-initramfs-%E6%98%A0%E5%83%8F"><span class="toc-number">1.2.3.4.</span> <span class="toc-text">在后台生成 initramfs 映像</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3-initramfs-%E6%A1%86%E6%9E%B6"><span class="toc-number">1.2.3.5.</span> <span class="toc-text">了解 initramfs 框架</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3-x86-%E4%B8%8A%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">1.2.3.6.</span> <span class="toc-text">了解 x86 上启动过程的基础知识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%89%E5%85%B3-initramfs-%E6%A1%86%E6%9E%B6%E7%9A%84%E6%9B%B4%E5%A4%9A%E4%BF%A1%E6%81%AF"><span class="toc-number">1.2.3.7.</span> <span class="toc-text">有关 initramfs 框架的更多信息</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E9%99%84%E5%BD%95%E6%96%87%E7%AB%A0"><span class="toc-number">2.</span> <span class="toc-text">一些附录文章</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%9C%A8Linux%E4%B8%8A%E6%9E%84%E5%BB%BARaspberry-Pi%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83"><span class="toc-number">3.</span> <span class="toc-text">如何在Linux上构建Raspberry Pi虚拟环境</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E9%9C%80%E6%B1%82"><span class="toc-number">3.1.</span> <span class="toc-text">前置环境需求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Older-Version"><span class="toc-number">3.2.</span> <span class="toc-text">Older Version</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B0%E7%89%88%E6%9C%AC%E5%90%AF%E5%8A%A8"><span class="toc-number">3.3.</span> <span class="toc-text">新版本启动</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%99%84%E5%BD%95%E6%96%87%E7%AB%A0"><span class="toc-number">4.</span> <span class="toc-text">附录文章</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kbuild-and-Kconfig"><span class="toc-number">4.1.</span> <span class="toc-text">Kbuild and Kconfig</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kconfig"><span class="toc-number">4.2.</span> <span class="toc-text">Kconfig</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kbuild"><span class="toc-number">4.3.</span> <span class="toc-text">kbuild</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Understanding-vmlinux-vs-bzImage"><span class="toc-number">4.3.1.</span> <span class="toc-text">Understanding vmlinux vs. bzImage</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dependency-tracking"><span class="toc-number">4.3.2.</span> <span class="toc-text">Dependency tracking</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Looking-ahead"><span class="toc-number">4.4.</span> <span class="toc-text">Looking ahead</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E6%88%91%E4%BB%AC%E7%9A%84%E6%A8%A1%E5%9D%97"><span class="toc-number">4.5.</span> <span class="toc-text">编写我们的模块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E5%B1%95%E5%BC%80%E4%B9%8B%E5%89%8D%EF%BC%8C%E5%85%88%E8%AF%B4%E8%AF%B4%E2%80%A6"><span class="toc-number">4.5.1.</span> <span class="toc-text">在展开之前，先说说…</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E5%92%8C%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4"><span class="toc-number">4.5.1.1.</span> <span class="toc-text">用户空间和内核空间</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BA%93%E5%92%8C%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8API"><span class="toc-number">4.5.1.2.</span> <span class="toc-text">库和系统调用API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E7%BB%84%E4%BB%B6"><span class="toc-number">4.5.1.3.</span> <span class="toc-text">内核空间组件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A5%E5%85%A5%E4%B8%BB%E8%A7%92%EF%BC%9ALKM%EF%BC%88Linux-Kernel-Modules%EF%BC%89"><span class="toc-number">4.5.1.4.</span> <span class="toc-text">步入主角：LKM（Linux Kernel Modules）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LKM-%E6%A1%86%E6%9E%B6"><span class="toc-number">4.5.1.5.</span> <span class="toc-text">LKM 框架</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%B2%EF%BC%81%E5%86%99%E6%88%91%E4%BB%AC%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%A8%A1%E5%9D%97"><span class="toc-number">4.5.1.6.</span> <span class="toc-text">干！写我们的第一个模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E6%AD%A5%E6%AD%A5%E7%9C%8B%EF%BC%9A"><span class="toc-number">4.5.1.7.</span> <span class="toc-text">一步步看：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AE%8F"><span class="toc-number">4.5.1.7.1.</span> <span class="toc-text">模块的宏</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%A5%E5%8F%A3%E7%82%B9%E5%92%8C%E5%87%BA%E5%8F%A3%E7%82%B9"><span class="toc-number">4.5.1.7.2.</span> <span class="toc-text">入口点和出口点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E5%80%BC"><span class="toc-number">4.5.1.7.3.</span> <span class="toc-text">返回值</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#0-E-%E8%BF%94%E5%9B%9E%E7%BA%A6%E5%AE%9A"><span class="toc-number">4.5.1.7.4.</span> <span class="toc-text">0&#x2F;-E 返回约定</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#init-and-exit"><span class="toc-number">4.5.1.7.5.</span> <span class="toc-text">__init and __exit</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3%E5%86%85%E6%A0%B8%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E5%92%8C-printk"><span class="toc-number">4.5.2.</span> <span class="toc-text">了解内核日志记录和 printk</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E7%8E%AF%E5%BD%A2%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-number">4.5.2.1.</span> <span class="toc-text">使用内核内存环形缓冲区</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E4%B8%8Esystemd%E7%9A%84journalctl"><span class="toc-number">4.5.2.2.</span> <span class="toc-text">内核日志记录与systemd的journalctl</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#printk%E7%9A%84%E6%97%A5%E5%BF%97%E5%B1%9E%E6%80%A7"><span class="toc-number">4.5.3.</span> <span class="toc-text">printk的日志属性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E5%8C%96%E7%9A%84%E5%87%BD%E6%95%B0"><span class="toc-number">4.5.3.1.</span> <span class="toc-text">简化的函数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E4%B8%80%E8%88%AC%E5%90%91%E4%BD%95%E5%8E%BB%EF%BC%9F"><span class="toc-number">4.5.4.</span> <span class="toc-text">输出一般向何去？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%BA%9Btips"><span class="toc-number">4.5.5.</span> <span class="toc-text">一些tips</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%91%E5%86%85%E6%A0%B8%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5%E8%B0%83%E8%AF%95%E4%BF%A1%E6%81%AF"><span class="toc-number">4.5.6.</span> <span class="toc-text">向内核日志写入调试信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%90%E5%88%B6%E6%89%93%E5%8D%B0%E9%80%9F%E5%BA%A6"><span class="toc-number">4.5.7.</span> <span class="toc-text">限制打印速度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95"><span class="toc-number">4.5.8.</span> <span class="toc-text">动态调试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E4%B8%80%EF%BC%9A%E5%86%85%E6%8F%92%E8%B0%83%E8%AF%95%E5%8F%98%E9%87%8F"><span class="toc-number">4.5.8.1.</span> <span class="toc-text">方法一：内插调试变量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E5%AE%9A%E6%89%93%E5%8D%B0%E8%B0%83%E8%AF%95%E4%BF%A1%E6%81%AF%E7%9A%84%E5%86%85%E5%AE%B9%E5%92%8C%E6%96%B9%E5%BC%8F"><span class="toc-number">4.5.9.</span> <span class="toc-text">指定打印调试信息的内容和方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E5%90%AF%E5%8A%A8%E5%92%8C%E6%A8%A1%E5%9D%97%E5%88%9D%E5%A7%8B%E5%8C%96%E6%97%B6%E6%BF%80%E6%B4%BB%E8%B0%83%E8%AF%95%E6%89%93%E5%8D%B0"><span class="toc-number">4.5.10.</span> <span class="toc-text">在启动和模块初始化时激活调试打印</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E5%8F%B0%E5%90%AF%E5%8A%A8%E5%89%8D%E7%9A%84%E6%89%93%E5%8D%B0%E2%80%94%E6%97%A9%E6%9C%9F%E7%9A%84-printk"><span class="toc-number">4.5.11.</span> <span class="toc-text">控制台启动前的打印—早期的 printk</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E5%8F%B0%E8%AE%BE%E5%A4%87%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">4.5.11.1.</span> <span class="toc-text">控制台设备到底是什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%82%E7%94%A8%E4%BA%8E%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%9A%84%E2%80%9C%E6%9B%B4%E5%A5%BD%E2%80%9D-Makefile-%E6%A8%A1%E6%9D%BF"><span class="toc-number">4.5.11.2.</span> <span class="toc-text">适用于内核模块的“更好” Makefile 模板</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E4%B8%80%E4%B8%AA%E8%B0%83%E8%AF%95%E5%86%85%E6%A0%B8"><span class="toc-number">4.5.11.3.</span> <span class="toc-text">配置一个调试内核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E7%B3%BB%E7%BB%9F%E4%BB%A5%E8%BF%9B%E8%A1%8C%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91"><span class="toc-number">4.5.11.4.</span> <span class="toc-text">设置系统以进行交叉编译</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%9D%E8%AF%95-1-%E2%80%93-%E8%AE%BE%E7%BD%AE-ARCH-%E5%92%8C-CROSS-COMPILE-%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">4.5.11.5.</span> <span class="toc-text">尝试 1 – 设置 ARCH 和 CROSS_COMPILE 环境变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%9D%E8%AF%95-2-%E2%80%93-%E5%B0%86-Makefile-%E6%8C%87%E5%90%91%E7%9B%AE%E6%A0%87%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%86%85%E6%A0%B8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%A0%91"><span class="toc-number">4.5.11.6.</span> <span class="toc-text">尝试 2 – 将 Makefile 指向目标的正确内核源代码树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%9D%E8%AF%95-3-%E2%80%93-%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91%E6%88%91%E4%BB%AC%E7%9A%84%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97"><span class="toc-number">4.5.11.7.</span> <span class="toc-text">尝试 3 – 交叉编译我们的内核模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5-Linux-%E5%86%85%E6%A0%B8-ABI-%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98"><span class="toc-number">4.5.11.8.</span> <span class="toc-text">检查 Linux 内核 ABI 兼容性问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%9D%E8%AF%95-4-%E2%80%93-%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91%E6%88%91%E4%BB%AC%E7%9A%84%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97"><span class="toc-number">4.5.11.9.</span> <span class="toc-text">尝试 4 – 交叉编译我们的内核模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-cross-build-load-%E6%A8%A1%E5%9D%97%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E4%BF%AE%E5%A4%8D"><span class="toc-number">4.5.11.10.</span> <span class="toc-text">总结 cross-build&#x2F;load 模块出了什么问题以及如何修复</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E8%81%94%E5%86%85%E6%A0%B8%E4%BB%A3%E7%A0%81%E7%9A%84%E8%AE%B8%E5%8F%AF"><span class="toc-number">4.5.11.11.</span> <span class="toc-text">内联内核代码的许可</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%91%E5%A4%96%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%9A%84%E8%AE%B8%E5%8F%AF"><span class="toc-number">4.5.11.12.</span> <span class="toc-text">树外内核模块的许可</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E6%A8%A1%E6%8B%9F%E2%80%9C%E7%B1%BB%E4%BC%BC%E5%BA%93%E2%80%9D%E7%9A%84%E5%8A%9F%E8%83%BD"><span class="toc-number">4.5.11.13.</span> <span class="toc-text">为内核模块模拟“类似库”的功能</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E9%93%BE%E6%8E%A5%E5%A4%9A%E4%B8%AA%E6%BA%90%E6%96%87%E4%BB%B6%E6%89%A7%E8%A1%8C%E5%BA%93%E4%BB%BF%E7%9C%9F"><span class="toc-number">4.5.11.14.</span> <span class="toc-text">通过链接多个源文件执行库仿真</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E4%B8%AD%E7%9A%84%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%98%E9%87%8F%E4%BD%9C%E7%94%A8%E5%9F%9F"><span class="toc-number">4.5.11.15.</span> <span class="toc-text">了解内核模块中的函数和变量作用域</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E6%A8%A1%E5%9D%97%E5%A0%86%E5%8F%A0"><span class="toc-number">4.5.11.16.</span> <span class="toc-text">理解模块堆叠</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E6%8B%9F%E2%80%9C%E7%B1%BB%E5%BA%93%E2%80%9D%E5%8A%9F%E8%83%BD-%E6%80%BB%E7%BB%93%E5%92%8C%E7%BB%93%E8%AE%BA"><span class="toc-number">4.5.11.17.</span> <span class="toc-text">模拟“类库”功能 - 总结和结论</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92%E7%BB%99%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97"><span class="toc-number">4.5.11.18.</span> <span class="toc-text">将参数传递给内核模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A3%B0%E6%98%8E%E5%92%8C%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%9D%97%E5%8F%82%E6%95%B0"><span class="toc-number">4.5.11.19.</span> <span class="toc-text">声明和使用模块参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E4%B8%8D%E5%85%81%E8%AE%B8%E6%B5%AE%E7%82%B9%E6%95%B0"><span class="toc-number">4.5.11.20.</span> <span class="toc-text">内核不允许浮点数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E5%86%85%E6%A0%B8%E4%B8%AD%E5%BC%BA%E5%88%B6%E6%89%A7%E8%A1%8C-FP"><span class="toc-number">4.5.11.21.</span> <span class="toc-text">在内核中强制执行 FP</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%99%84%E5%BD%95"><span class="toc-number">5.</span> <span class="toc-text">附录</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MakeFile"><span class="toc-number">5.1.</span> <span class="toc-text">MakeFile</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%EF%BC%9A%E7%BA%BF%E7%A8%8B%E5%92%8C%E8%BF%9B%E7%A8%8B"><span class="toc-number">5.2.</span> <span class="toc-text">内核编程基础：线程和进程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E8%BF%9B%E7%A8%8B%E5%92%8C%E4%B8%AD%E6%96%AD%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="toc-number">5.2.0.1.</span> <span class="toc-text">理解进程和中断上下文</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3%E8%BF%9B%E7%A8%8B%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4-VAS-%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">5.2.0.2.</span> <span class="toc-text">了解进程虚拟地址空间 (VAS) 的基础知识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%84%E7%BB%87%E8%BF%9B%E7%A8%8B%E3%80%81%E7%BA%BF%E7%A8%8B%E5%8F%8A%E5%85%B6%E5%A0%86%E6%A0%88-%E7%94%A8%E6%88%B7%E5%92%8C%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4"><span class="toc-number">5.2.0.3.</span> <span class="toc-text">组织进程、线程及其堆栈 - 用户和内核空间</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E4%B8%80%E4%B8%AA%E5%B0%8F%E8%84%9A%E6%9C%AC%E6%9D%A5%E6%9F%A5%E7%9C%8B%EF%BC%8C%E6%B4%BB%E8%B7%83%E7%9A%84%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%95%B0%E9%87%8F"><span class="toc-number">5.2.0.4.</span> <span class="toc-text">运行一个小脚本来查看，活跃的进程和线程的数量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E7%BB%84%E7%BB%87"><span class="toc-number">5.2.0.5.</span> <span class="toc-text">用户空间组织</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E7%BB%84%E7%BB%87"><span class="toc-number">5.2.0.6.</span> <span class="toc-text">内核空间组织</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E5%86%85%E6%A0%B8%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E3%80%81%E4%BB%BB%E5%8A%A1%E7%BB%93%E6%9E%84%E5%92%8C%E5%A0%86%E6%A0%88"><span class="toc-number">5.2.0.7.</span> <span class="toc-text">总结内核中的线程、任务结构和堆栈</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E7%94%A8%E6%88%B7%E5%92%8C%E5%86%85%E6%A0%B8%E5%A0%86%E6%A0%88"><span class="toc-number">5.2.0.8.</span> <span class="toc-text">查看用户和内核堆栈</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#eBPF-%E2%80%93-%E6%9F%A5%E7%9C%8B%E4%B8%A4%E4%B8%AA%E5%A0%86%E6%A0%88%E7%9A%84%E7%8E%B0%E4%BB%A3%E6%96%B9%E6%B3%95"><span class="toc-number">5.2.0.9.</span> <span class="toc-text">eBPF – 查看两个堆栈的现代方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E5%92%8C%E8%AE%BF%E9%97%AE%E5%86%85%E6%A0%B8%E4%BB%BB%E5%8A%A1%E7%BB%93%E6%9E%84"><span class="toc-number">5.2.0.10.</span> <span class="toc-text">理解和访问内核任务结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A1%AE%E5%AE%9A%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="toc-number">5.2.0.11.</span> <span class="toc-text">确定上下文</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%86%85%E5%B9%95"><span class="toc-number">5.2.1.</span> <span class="toc-text">内核内存管理内幕</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%88%86%E5%89%B2"><span class="toc-number">5.2.1.1.</span> <span class="toc-text">理解虚拟机分割</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8Ehello-c-%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%E5%85%A5%E6%89%8B"><span class="toc-number">5.2.1.2.</span> <span class="toc-text">从hello.c 发生了什么入手</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B6%85%E8%B6%8A-printf-API"><span class="toc-number">5.2.1.3.</span> <span class="toc-text">超越 printf() API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%AF%BB%E5%9D%80%E5%92%8C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2"><span class="toc-number">5.2.1.4.</span> <span class="toc-text">虚拟寻址和地址转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E5%88%B0%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80%E2%80%94%E2%80%94%E9%9D%9E%E5%B8%B8%E7%AE%80%E7%9F%AD%E7%9A%84%E6%A6%82%E8%BF%B0"><span class="toc-number">5.2.1.5.</span> <span class="toc-text">从虚拟地址到物理地址——非常简短的概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#64-%E4%BD%8D-Linux-%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%9A%84-VM-%E6%8B%86%E5%88%86"><span class="toc-number">5.2.1.6.</span> <span class="toc-text">64 位 Linux 系统上的 VM 拆分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E-x86-64-Linux-%E5%AF%BB%E5%9D%80%E7%9A%84%E8%AF%B4%E6%98%8E"><span class="toc-number">5.2.1.7.</span> <span class="toc-text">关于 x86_64 Linux 寻址的说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E-AArch64-Linux-%E5%AF%BB%E5%9D%80%E7%9A%84%E8%AF%B4%E6%98%8E"><span class="toc-number">5.2.1.8.</span> <span class="toc-text">关于 AArch64 Linux 寻址的说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E8%BF%9B%E7%A8%8B-VAS-%E2%80%93-%E5%AE%8C%E6%95%B4%E8%A7%86%E5%9B%BE"><span class="toc-number">5.2.1.9.</span> <span class="toc-text">理解进程 VAS – 完整视图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5%E8%BF%9B%E7%A8%8B-VAS"><span class="toc-number">5.2.1.10.</span> <span class="toc-text">检查进程 VAS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%A6%E7%BB%86%E6%A3%80%E6%9F%A5%E7%94%A8%E6%88%B7-VAS"><span class="toc-number">5.2.1.11.</span> <span class="toc-text">详细检查用户 VAS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-procfs-%E7%9B%B4%E6%8E%A5%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84"><span class="toc-number">5.2.1.12.</span> <span class="toc-text">使用 procfs 直接查看进程内存映射</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E9%87%8A-proc-PID-maps-%E8%BE%93%E5%87%BA"><span class="toc-number">5.2.1.13.</span> <span class="toc-text">解释 &#x2F;proc&#x2F;PID&#x2F;maps 输出</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84%E7%9A%84%E5%89%8D%E7%AB%AF"><span class="toc-number">5.2.1.14.</span> <span class="toc-text">查看进程内存映射的前端</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3-VMA-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">5.2.1.15.</span> <span class="toc-text">了解 VMA 基础知识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5%E5%86%85%E6%A0%B8-VAS"><span class="toc-number">5.2.1.16.</span> <span class="toc-text">检查内核 VAS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E4%BB%A5%E6%98%BE%E7%A4%BA%E6%9C%89%E5%85%B3%E5%86%85%E6%A0%B8-VAS-%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="toc-number">5.2.1.17.</span> <span class="toc-text">编写内核模块以显示有关内核 VAS 的信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8F%8F%E8%BF%B0%E5%86%85%E6%A0%B8-VAS-%E5%B8%83%E5%B1%80%E7%9A%84%E5%AE%8F%E5%92%8C%E5%8F%98%E9%87%8F"><span class="toc-number">5.2.1.18.</span> <span class="toc-text">描述内核 VAS 布局的宏和变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87-procmap-%E7%9A%84%E5%86%85%E6%A0%B8-VAS"><span class="toc-number">5.2.1.19.</span> <span class="toc-text">通过 procmap 的内核 VAS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A9%BA%E9%99%B7%E9%98%B1%E9%A1%B5"><span class="toc-number">5.2.1.20.</span> <span class="toc-text">空陷阱页</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8C%96%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80-%E2%80%93-KASLR"><span class="toc-number">5.2.1.21.</span> <span class="toc-text">随机化内存布局 – KASLR</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-ASLR-%E8%BF%9B%E8%A1%8C%E7%94%A8%E6%88%B7%E5%86%85%E5%AD%98%E9%9A%8F%E6%9C%BA%E5%8C%96"><span class="toc-number">5.2.1.22.</span> <span class="toc-text">使用 ASLR 进行用户内存随机化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-KASLR-%E8%BF%9B%E8%A1%8C%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%E9%9A%8F%E6%9C%BA%E5%8C%96"><span class="toc-number">5.2.1.23.</span> <span class="toc-text">使用 KASLR 进行内核内存布局随机化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87"><span class="toc-number">5.2.1.24.</span> <span class="toc-text">了解物理内存组织</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%A9%E7%90%86-RAM-%E7%BB%84%E7%BB%87"><span class="toc-number">5.2.1.25.</span> <span class="toc-text">物理 RAM 组织</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E5%92%8C-NUMA"><span class="toc-number">5.2.1.26.</span> <span class="toc-text">节点和 NUMA</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E5%86%85%E7%9A%84%E5%8C%BA%E5%9F%9F"><span class="toc-number">5.2.1.27.</span> <span class="toc-text">节点内的区域</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B"><span class="toc-number">5.2.1.28.</span> <span class="toc-text">物理内存模型简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E8%A6%81%E4%BA%86%E8%A7%A3-sparsemem-vmemmap-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.2.1.29.</span> <span class="toc-text">简要了解 sparsemem[-vmemmap] 内存模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kernel-Memory-Allocation"><span class="toc-number">5.3.</span> <span class="toc-text">Kernel Memory Allocation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8-vmalloc-%E7%B3%BB%E5%88%97-API"><span class="toc-number">5.3.0.1.</span> <span class="toc-text">学习使用 vmalloc 系列 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E4%B8%AD%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D-%E2%80%93%E4%BD%95%E6%97%B6%E4%BD%BF%E7%94%A8%E5%93%AA%E4%BA%9B-API"><span class="toc-number">5.3.0.2.</span> <span class="toc-text">内核中的内存分配 –何时使用哪些 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D-API-%E9%9B%86"><span class="toc-number">5.3.0.3.</span> <span class="toc-text">可视化内核内存分配 API 集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%89%E6%8B%A9%E9%80%82%E5%90%88%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%9A%84-API"><span class="toc-number">5.3.0.4.</span> <span class="toc-text">选择适合内核内存分配的 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E-DMA-%E5%92%8C-CMA-%E7%9A%84%E8%AF%B4%E6%98%8E"><span class="toc-number">5.3.0.5.</span> <span class="toc-text">关于 DMA 和 CMA 的说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%E2%80%94%E2%80%94%E5%86%85%E6%A0%B8%E7%9A%84%E4%B8%80%E9%A1%B9%E5%85%B3%E9%94%AE%E5%86%85%E5%8A%A1%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1"><span class="toc-number">5.3.0.6.</span> <span class="toc-text">内存回收——内核的一项关键内务处理任务</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DAMON%EF%BC%88%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE%E7%9B%91%E6%8E%A7%E5%8A%9F%E8%83%BD%EF%BC%89%E7%9A%84%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.3.0.7.</span> <span class="toc-text">DAMON（数据访问监控功能）的简要介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%9D%E6%8C%81%E6%B4%BB%E5%8A%9B-%E2%80%93-OOM-%E6%9D%80%E6%89%8B"><span class="toc-number">5.3.0.8.</span> <span class="toc-text">保持活力 – OOM 杀手</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%85%E6%84%8F%E8%B0%83%E7%94%A8-OOM-%E6%9D%80%E6%89%8B"><span class="toc-number">5.3.0.9.</span> <span class="toc-text">故意调用 OOM 杀手</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3-OOM-%E5%88%86%E6%95%B0"><span class="toc-number">5.3.0.10.</span> <span class="toc-text">了解 OOM 分数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CPU%E8%B0%83%E5%BA%A6%E7%A8%8B%E5%BA%8F%E2%80%93%E7%AC%AC1%E9%83%A8%E5%88%86"><span class="toc-number">5.4.</span> <span class="toc-text">CPU调度程序–第1部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Linux%E4%B8%8A%E7%9A%84KSE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">5.4.0.1.</span> <span class="toc-text">Linux上的KSE是什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#POSIX%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5"><span class="toc-number">5.4.0.2.</span> <span class="toc-text">POSIX调度策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E4%BC%98%E5%85%88%E7%BA%A7"><span class="toc-number">5.4.0.3.</span> <span class="toc-text">线程优先级</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E6%B5%81%E7%A8%8B"><span class="toc-number">5.4.0.4.</span> <span class="toc-text">可视化流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8gnome%E7%B3%BB%E7%BB%9F%E7%9B%91%E8%A7%86%E5%99%A8GUI%E6%9D%A5%E5%8F%AF%E8%A7%86%E5%8C%96%E6%B5%81%E7%A8%8B"><span class="toc-number">5.4.0.5.</span> <span class="toc-text">使用gnome系统监视器GUI来可视化流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8perf%E5%8F%AF%E8%A7%86%E5%8C%96flow"><span class="toc-number">5.4.0.6.</span> <span class="toc-text">使用perf可视化flow</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0CPU%E8%B0%83%E5%BA%A6%E5%86%85%E9%83%A8%E2%80%94%E2%80%94%E7%AC%AC2%E9%83%A8%E5%88%86"><span class="toc-number">5.4.0.7.</span> <span class="toc-text">学习CPU调度内部——第2部分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E4%B8%AA%E6%9C%89%E5%8A%A9%E4%BA%8E%E7%90%86%E8%A7%A3%E8%B0%83%E5%BA%A6%E7%B1%BB%E7%9A%84%E6%A6%82%E5%BF%B5%E6%80%A7%E4%BE%8B%E5%AD%90"><span class="toc-number">5.4.0.8.</span> <span class="toc-text">一个有助于理解调度类的概念性例子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B%E5%AE%8C%E5%85%A8%E5%85%AC%E5%B9%B3%E8%B0%83%E5%BA%A6%EF%BC%88CFS%EF%BC%89%E7%B1%BB%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">5.4.0.9.</span> <span class="toc-text">简介完全公平调度（CFS）类的工作原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8ECFS-vruntime%E5%80%BC%E5%8F%8A%E5%85%B6%E8%BF%90%E8%A1%8C%E9%98%9F%E5%88%97%E7%9A%84%E8%AF%B4%E6%98%8E"><span class="toc-number">5.4.0.10.</span> <span class="toc-text">关于CFS vruntime值及其运行队列的说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8ECFS%E8%B0%83%E5%BA%A6%E5%91%A8%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E7%9A%84%E8%AF%B4%E6%98%8E"><span class="toc-number">5.4.0.11.</span> <span class="toc-text">关于CFS调度周期和时间的说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0CPU%E8%B0%83%E5%BA%A6%E5%86%85%E9%83%A8%E6%9C%BA%E5%88%B6%E2%80%94%E2%80%94%E7%AC%AC3%E9%83%A8%E5%88%86"><span class="toc-number">5.4.0.12.</span> <span class="toc-text">学习CPU调度内部机制——第3部分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E5%8F%AF%E6%8A%A2%E5%8D%A0%E5%86%85%E6%A0%B8%E7%89%B9%E6%80%A7"><span class="toc-number">5.4.0.13.</span> <span class="toc-text">动态可抢占内核特性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#schedule%EF%BC%88%EF%BC%89%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E8%BF%90%E8%A1%8C%EF%BC%9F"><span class="toc-number">5.4.0.14.</span> <span class="toc-text">schedule（）什么时候运行？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E6%97%B6%E5%99%A8%E4%B8%AD%E6%96%AD%E5%86%85%E5%8A%A1%E7%AE%A1%E7%90%86%E2%80%93%E8%AE%BE%E7%BD%AETIF-NED-RESCHED"><span class="toc-number">5.4.0.15.</span> <span class="toc-text">定时器中断内务管理–设置TIF_NED_RESCHED</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2"><span class="toc-number">5.4.0.16.</span> <span class="toc-text">上下文切换</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CPU%E8%B0%83%E5%BA%A6%E7%A8%8B%E5%BA%8F-%E7%AC%AC2%E9%83%A8%E5%88%86"><span class="toc-number">5.5.</span> <span class="toc-text">CPU调度程序-第2部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E3%80%81%E6%9F%A5%E8%AF%A2%E5%92%8C%E8%AE%BE%E7%BD%AECPU%E5%85%B3%E8%81%94%E6%8E%A9%E7%A0%81"><span class="toc-number">5.5.0.1.</span> <span class="toc-text">理解、查询和设置CPU关联掩码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E5%92%8C%E8%AE%BE%E7%BD%AE%E7%BA%BF%E7%A8%8B%E7%9A%84%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E5%92%8C%E4%BC%98%E5%85%88%E7%BA%A7"><span class="toc-number">5.5.0.2.</span> <span class="toc-text">查询和设置线程的调度策略和优先级</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E5%86%85%E6%A0%B8%E4%B8%AD%E8%AE%BE%E7%BD%AE%E7%AD%96%E7%95%A5%E5%92%8C%E4%BC%98%E5%85%88%E7%BA%A7"><span class="toc-number">5.5.0.3.</span> <span class="toc-text">在内核中设置策略和优先级</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E4%B8%AA%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E4%BE%8B%E5%AD%90%E2%80%94%E2%80%94%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F"><span class="toc-number">5.5.0.4.</span> <span class="toc-text">一个真实世界的例子——线程中断处理程序</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#cgroups%E7%AE%80%E4%BB%8B"><span class="toc-number">5.5.0.5.</span> <span class="toc-text">cgroups简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#C%E7%BB%84-%E6%8E%A7%E5%88%B6%E5%99%A8"><span class="toc-number">5.5.0.6.</span> <span class="toc-text">C组 控制器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E7%94%A8%E6%88%96%E7%A6%81%E7%94%A8%E6%8E%A7%E5%88%B6%E5%99%A8"><span class="toc-number">5.5.0.7.</span> <span class="toc-text">启用或禁用控制器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#systemd%E5%92%8Ccgroups"><span class="toc-number">5.5.0.8.</span> <span class="toc-text">systemd和cgroups</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3%E5%86%85%E6%A0%B8%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4"><span class="toc-number">5.5.0.9.</span> <span class="toc-text">快速了解内核命名空间</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%9D%E8%AF%951-1%E2%80%93%E5%9C%A8%E6%B2%A1%E6%9C%89%E8%B5%84%E6%BA%90%E7%BA%A6%E6%9D%9F%E3%80%81SCHED-FIFO%E7%AD%96%E7%95%A5%E5%92%8Crtprio-83Right%E7%9A%84systemd%E4%B8%8B%E6%89%A7%E8%A1%8C%E7%B4%A0%E6%95%B0%E7%94%9F%E6%88%90%E5%99%A8%E3%80%82"><span class="toc-number">5.5.0.10.</span> <span class="toc-text">尝试1.1–在没有资源约束、SCHED_FIFO策略和rtprio 83Right的systemd下执行素数生成器。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%9D%E8%AF%951-2%E2%80%93%E5%9C%A8systemd%E4%B8%8B%E6%89%A7%E8%A1%8C%E7%B4%A0%E6%95%B0%E7%94%9F%E6%88%90%E5%99%A8%EF%BC%8C%E5%B9%B6%E5%AF%B9CPU%E8%B5%84%E6%BA%90%E3%80%81SCHED-OTHER%E5%92%8Crtprio0%E8%BF%9B%E8%A1%8C%E7%BA%A6%E6%9D%9F%E3%80%82"><span class="toc-number">5.5.0.11.</span> <span class="toc-text">尝试1.2–在systemd下执行素数生成器，并对CPU资源、SCHED_OTHER和rtprio0进行约束。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E6%96%B9%E5%BC%8F%E2%80%93cgroups-v2"><span class="toc-number">5.5.0.12.</span> <span class="toc-text">手动方式–cgroups v2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86Linux%E4%BD%9C%E4%B8%BARTOS%E8%BF%90%E8%A1%8C"><span class="toc-number">5.5.0.13.</span> <span class="toc-text">将Linux作为RTOS运行</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E5%B9%B6%E5%8F%91"><span class="toc-number">5.6.</span> <span class="toc-text">内核并发</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%B4%E7%95%8C%E5%8C%BA%E3%80%81%E7%8B%AC%E5%8D%A0%E6%89%A7%E8%A1%8C%E5%92%8C%E5%8E%9F%E5%AD%90%E6%80%A7"><span class="toc-number">5.6.0.1.</span> <span class="toc-text">临界区、独占执行和原子性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E4%B8%AA%E7%BB%8F%E5%85%B8%E7%9A%84%E4%BE%8B%E5%AD%90%E2%80%94%E2%80%94%E5%85%A8%E5%B1%80i"><span class="toc-number">5.6.0.2.</span> <span class="toc-text">一个经典的例子——全局i++</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5%E2%80%94%E2%80%94%E9%94%81"><span class="toc-number">5.6.0.3.</span> <span class="toc-text">概念——锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E9%83%A8%E5%88%86%E2%80%94%E2%80%94%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93"><span class="toc-number">5.6.0.4.</span> <span class="toc-text">关键部分——关键点总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%AB%9E%E4%BA%89%E2%80%94%E2%80%94%E4%B8%80%E4%B8%AA%E6%9B%B4%E6%AD%A3%E5%BC%8F%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">5.6.0.5.</span> <span class="toc-text">数据竞争——一个更正式的定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AF%E6%8A%A2%E5%8D%A0%E5%86%85%E6%A0%B8%E3%80%81%E9%98%BB%E5%A1%9EI-O%E5%92%8C%E6%95%B0%E6%8D%AE%E9%80%9A%E9%81%93"><span class="toc-number">5.6.0.6.</span> <span class="toc-text">可抢占内核、阻塞I&#x2F;O和数据通道</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E4%B8%AD%E6%96%AD%E5%92%8C%E6%95%B0%E6%8D%AE%E8%B7%9F%E8%B8%AA"><span class="toc-number">5.6.0.7.</span> <span class="toc-text">硬件中断和数据跟踪</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%94%81%E5%AE%9A%E5%87%86%E5%88%99%E5%92%8C%E6%AD%BB%E9%94%81"><span class="toc-number">5.6.0.8.</span> <span class="toc-text">锁定准则和死锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B%E5%BA%94%E8%AF%A5%E4%BD%BF%E7%94%A8%E5%93%AA%E7%A7%8D%E9%94%81-%E4%BA%92%E6%96%A5%E8%BF%98%E6%98%AF%E8%87%AA%E6%97%8B%E9%94%81%EF%BC%9F"><span class="toc-number">5.6.0.9.</span> <span class="toc-text">在什么情况下应该使用哪种锁,互斥还是自旋锁？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%92%E6%96%A5%E9%94%81%E2%80%94%E2%80%94%E5%89%A9%E4%B8%8B%E7%9A%84%E5%87%A0%E4%B8%AA%E8%A6%81%E7%82%B9"><span class="toc-number">5.6.0.10.</span> <span class="toc-text">互斥锁——剩下的几个要点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%92%8Cmutex"><span class="toc-number">5.6.0.11.</span> <span class="toc-text">信号量和mutex</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E8%87%AA%E6%97%8B%E9%94%81"><span class="toc-number">5.6.0.12.</span> <span class="toc-text">使用自旋锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Spinlock%E2%80%93%E7%AE%80%E5%8D%95%E7%94%A8%E6%B3%95"><span class="toc-number">5.6.0.13.</span> <span class="toc-text">Spinlock–简单用法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%94%81%E5%AE%9A%E5%92%8C%E4%B8%AD%E6%96%AD"><span class="toc-number">5.6.0.14.</span> <span class="toc-text">锁定和中断</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF1%E2%80%94%E2%80%94%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E6%96%B9%E6%B3%95%E5%92%8C%E7%A1%AC%E4%BB%B6%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F%E6%8C%89%E9%A1%BA%E5%BA%8F%E4%B8%B2%E8%A1%8C%E8%BF%90%E8%A1%8C%E3%80%82"><span class="toc-number">5.6.0.15.</span> <span class="toc-text">场景1——驱动程序方法和硬件中断处理程序按顺序串行运行。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF2%E2%80%94%E2%80%94%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E6%96%B9%E6%B3%95%E5%92%8C%E7%A1%AC%E4%BB%B6%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F%E4%BA%A4%E9%94%99%E8%BF%90%E8%A1%8C%E3%80%82"><span class="toc-number">5.6.0.16.</span> <span class="toc-text">场景2——驱动程序方法和硬件中断处理程序交错运行。</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8D%95%E6%A0%B8%EF%BC%88UP%EF%BC%89%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%9A%84%E5%9C%BA%E6%99%AF2"><span class="toc-number">5.6.0.16.1.</span> <span class="toc-text">单核（UP）系统上的场景2</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%9A%E6%A0%B8%EF%BC%88SMP%EF%BC%89%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%9A%84%E5%9C%BA%E6%99%AF2"><span class="toc-number">5.6.0.16.2.</span> <span class="toc-text">多核（SMP）系统上的场景2</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF3%E2%80%94%E2%80%94%E4%B8%80%E4%BA%9B%E4%B8%AD%E6%96%AD%E8%A2%AB%E5%B1%8F%E8%94%BD%EF%BC%8C%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E6%96%B9%E6%B3%95%E5%92%8C%E7%A1%AC%E4%BB%B6%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F%E4%BA%A4%E9%94%99%E8%BF%90%E8%A1%8C%E3%80%82"><span class="toc-number">5.6.0.17.</span> <span class="toc-text">场景3——一些中断被屏蔽，驱动程序方法和硬件中断处理程序交错运行。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%E3%80%81%E4%B8%8B%E5%8D%8A%E9%83%A8%E5%88%86%E5%92%8C%E9%94%81%E5%AE%9A"><span class="toc-number">5.6.0.18.</span> <span class="toc-text">中断处理、下半部分和锁定</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Linux%E4%B8%8A%E7%9A%84%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%85%B3%E9%94%AE%E7%82%B9"><span class="toc-number">5.6.0.18.1.</span> <span class="toc-text">Linux上的中断处理——关键点</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8spinlocks%E2%80%93%E5%BF%AB%E9%80%9F%E6%80%BB%E7%BB%93"><span class="toc-number">5.6.0.19.</span> <span class="toc-text">使用spinlocks–快速总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%94%81%E5%AE%9A-%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E5%92%8C%E6%8C%87%E5%8D%97"><span class="toc-number">5.6.0.20.</span> <span class="toc-text">锁定-常见错误和指南</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF"><span class="toc-number">5.6.0.20.1.</span> <span class="toc-text">常见错误</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%94%81%E5%AE%9A%E6%8C%87%E5%8D%97"><span class="toc-number">5.6.0.20.2.</span> <span class="toc-text">锁定指南</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8"><span class="toc-number">5.7.</span> <span class="toc-text">字符设备驱动</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3%E8%AE%BE%E5%A4%87%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86%E3%80%82"><span class="toc-number">5.7.0.1.</span> <span class="toc-text">了解设备基本知识。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8ELinux%E8%AE%BE%E5%A4%87%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BF%AB%E9%80%9F%E8%AF%B4%E6%98%8E"><span class="toc-number">5.7.0.2.</span> <span class="toc-text">关于Linux设备模型的快速说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3%E8%BF%9B%E7%A8%8B%E3%80%81%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E5%92%8C%E5%86%85%E6%A0%B8%E4%B9%8B%E9%97%B4%E7%9A%84%E8%81%94%E7%B3%BB"><span class="toc-number">5.7.0.3.</span> <span class="toc-text">了解进程、驱动程序和内核之间的联系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E4%B8%8D%E5%8F%97%E6%94%AF%E6%8C%81%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">5.7.0.4.</span> <span class="toc-text">处理不受支持的方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E6%95%B0%E6%8D%AE%E4%BB%8E%E5%86%85%E6%A0%B8%E5%A4%8D%E5%88%B6%E5%88%B0%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%EF%BC%8C%E5%8F%8D%E4%B9%8B%E4%BA%A6%E7%84%B6"><span class="toc-number">5.7.0.5.</span> <span class="toc-text">将数据从内核复制到用户空间，反之亦然</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E5%86%85%E6%A0%B8API%E6%89%A7%E8%A1%8C%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93"><span class="toc-number">5.7.0.6.</span> <span class="toc-text">利用内核API执行数据传输</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kernel-Debug-Programming"><span class="toc-number">5.8.</span> <span class="toc-text">Kernel Debug Programming</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8KASAN%E5%92%8CUBSAN%E6%9F%A5%E6%89%BE%E5%86%85%E5%AD%98%E9%94%99%E8%AF%AF"><span class="toc-number">5.8.0.1.</span> <span class="toc-text">使用KASAN和UBSAN查找内存错误</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%88%91%E4%BB%AC%E5%AE%9A%E5%88%B6%E7%9A%84%E6%9C%89%E7%BC%BA%E9%99%B7%E7%9A%84%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E8%BF%9B%E8%A1%8C%E7%9A%84%E5%89%A9%E4%BD%99%E6%B5%8B%E8%AF%95"><span class="toc-number">5.8.0.2.</span> <span class="toc-text">使用我们定制的有缺陷的内核模块进行的剩余测试</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%99%88%E6%97%A7%E7%9A%84%E6%A1%86%E6%9E%B6%E2%80%94%E2%80%94%E5%A4%A9%E5%A0%82%E4%B8%AD%E7%9A%84%E9%BA%BB%E7%83%A6"><span class="toc-number">5.8.0.3.</span> <span class="toc-text">陈旧的框架——天堂中的麻烦</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%80%9C%E6%AF%8F%E4%B8%AAsysfs%E6%96%87%E4%BB%B6%E4%B8%80%E4%B8%AA%E5%80%BC%E2%80%9D%E8%A7%84%E5%88%99"><span class="toc-number">5.8.0.4.</span> <span class="toc-text">“每个sysfs文件一个值”规则</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E6%89%BEdebugfs-API%E6%96%87%E6%A1%A3"><span class="toc-number">5.8.0.5.</span> <span class="toc-text">查找debugfs API文档</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3%E4%BB%80%E4%B9%88%E6%98%AFnetlink%E5%A5%97%E6%8E%A5%E5%AD%97"><span class="toc-number">5.8.0.6.</span> <span class="toc-text">了解什么是netlink套接字</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4netlink%E5%A5%97%E6%8E%A5%E5%AD%97%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F"><span class="toc-number">5.8.0.7.</span> <span class="toc-text">编写用户空间netlink套接字应用程序</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%86%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4netlink%E5%A5%97%E6%8E%A5%E5%AD%97%E4%BB%A3%E7%A0%81%E7%BC%96%E5%86%99%E4%B8%BA%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97"><span class="toc-number">5.8.0.8.</span> <span class="toc-text">将内核空间netlink套接字代码编写为内核模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87ioctl%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E8%BF%9B%E8%A1%8C%E6%8E%A5%E5%8F%A3%E8%BF%9E%E6%8E%A5ioctl%E6%98%AF%E4%B8%80%E4%B8%AA%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8"><span class="toc-number">5.8.0.9.</span> <span class="toc-text">通过ioctl系统调用进行接口连接ioctl是一个系统调用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Working-with-Hardware-I-O"><span class="toc-number">5.9.</span> <span class="toc-text">Working with Hardware I&#x2F;O</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8E%E5%86%85%E6%A0%B8%E8%AE%BF%E9%97%AE%E7%A1%AC%E4%BB%B6I-O%E5%86%85%E5%AD%98"><span class="toc-number">5.9.0.1.</span> <span class="toc-text">从内核访问硬件I&#x2F;O内存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87-proc-iomem%E6%9F%A5%E6%89%BE%E6%96%B0%E7%9A%84%E6%98%A0%E5%B0%84"><span class="toc-number">5.9.0.2.</span> <span class="toc-text">通过&#x2F;proc&#x2F;iomem查找新的映射</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MMIO%E2%80%93%E4%BD%BF%E7%94%A8MMIO%E6%96%B9%E6%B3%95%E6%89%A7%E8%A1%8C%E5%AE%9E%E9%99%85I-O"><span class="toc-number">5.9.0.3.</span> <span class="toc-text">MMIO–使用MMIO方法执行实际I&#x2F;O</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8%E6%88%91%E4%BB%AC%E5%9C%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E4%B8%AD%E5%89%8D%E9%9D%A2%E6%8F%90%E5%88%B0%E7%9A%84%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84I-O%E2%80%94%E2%80%94%E9%80%9A%E8%BF%87I-O%E5%86%85%E5%AD%98%E6%88%96I-O%E7%AB%AF%E5%8F%A3%E9%83%A8%E5%88%86%E8%BF%9B%E8%A1%8C%E6%98%A0%E5%B0%84"><span class="toc-number">5.9.0.4.</span> <span class="toc-text">了解和使用我们在解决方案中前面提到的端口映射I&#x2F;O——通过I&#x2F;O内存或I&#x2F;O端口部分进行映射</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kernel-Debug-Programming-1"><span class="toc-number">5.9.1.</span> <span class="toc-text">Kernel Debug Programming</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AF%E8%83%BD%E6%98%AF%E9%87%8D%E6%96%B0%E5%90%AF%E5%8A%A8%E7%9A%84%E6%9C%89%E7%94%A8%EF%BC%88%E6%84%9A%E8%A0%A2%EF%BC%89%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E3%80%82"><span class="toc-number">5.9.1.1.</span> <span class="toc-text">可能是重新启动的有用（愚蠢）解决方法。</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B1%E2%80%94%E2%80%94%E7%B3%9F%E7%B3%95%E7%9A%84%E6%98%AF%EF%BC%8C%E5%86%99%E5%85%A5NULL%E9%99%B7%E9%98%B1%E9%A1%B5%E9%9D%A2%E4%B8%AD%E7%9A%84%E9%9A%8F%E6%9C%BA%E4%BD%8D%E7%BD%AE%E3%80%82"><span class="toc-number">5.9.1.1.1.</span> <span class="toc-text">案例1——糟糕的是，写入NULL陷阱页面中的随机位置。</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B3%E2%80%94%E2%80%94%E5%BD%93%E7%BB%93%E6%9E%84%E6%8C%87%E9%92%88%E4%B8%BANULL%E6%97%B6%E5%86%99%E5%85%A5%E7%BB%93%E6%9E%84%E6%88%90%E5%91%98%EF%BC%8C%E8%BF%99%E4%BC%9A%E5%AF%BC%E8%87%B4%E9%97%AE%E9%A2%98%E3%80%82"><span class="toc-number">5.9.1.1.2.</span> <span class="toc-text">案例3——当结构指针为NULL时写入结构成员，这会导致问题。</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AD%94%E9%AC%BC%E5%9C%A8%E4%BA%8E%E7%BB%86%E8%8A%82%E2%80%94%E2%80%94%E8%A7%A3%E7%A0%81Oops%E6%88%91%E4%BB%AC%E5%B0%86%E4%BD%BF%E7%94%A8%E7%AC%AC%E4%B8%89%E7%A7%8D%E5%9C%BA%E6%99%AF%EF%BC%88%E6%88%96%E4%BD%BF%E7%94%A8-%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B%EF%BC%89"><span class="toc-number">5.9.1.2.</span> <span class="toc-text">魔鬼在于细节——解码Oops我们将使用第三种场景（或使用&#x2F;测试用例）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E7%A1%AC%E4%BB%B6%E4%B8%AD%E6%96%AD"><span class="toc-number">5.9.2.</span> <span class="toc-text">处理硬件中断</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E4%B8%AD%E6%96%AD%E4%BB%A5%E5%8F%8A%E5%86%85%E6%A0%B8%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E4%B8%AD%E6%96%AD"><span class="toc-number">5.9.3.</span> <span class="toc-text">硬件中断以及内核如何处理中断</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E7%94%B5%E5%B9%B3%E5%92%8C%E8%BE%B9%E7%BC%98%E8%A7%A6%E5%8F%91%E7%9A%84%E4%B8%AD%E6%96%AD"><span class="toc-number">5.9.4.</span> <span class="toc-text">理解电平和边缘触发的中断</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%AD%E6%96%AD%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8C%87%E5%8D%97%E2%80%94%E2%80%94%E5%81%9A%E4%BB%80%E4%B9%88%E5%92%8C%E4%B8%8D%E5%81%9A%E4%BB%80%E4%B9%88"><span class="toc-number">5.9.5.</span> <span class="toc-text">中断上下文指南——做什么和不做什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%AD%E6%96%AD%E6%8E%A9%E7%A0%81%E2%80%94%E2%80%94%E9%BB%98%E8%AE%A4%E5%80%BC%E5%92%8C%E6%8E%A7%E5%88%B6"><span class="toc-number">5.9.6.</span> <span class="toc-text">中断掩码——默认值和控制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%9D%E6%8C%81%E5%BF%AB%E9%80%9F"><span class="toc-number">5.9.7.</span> <span class="toc-text">保持快速</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#IRQ%E5%88%86%E9%85%8D%E2%80%94%E2%80%94%E7%8E%B0%E4%BB%A3%E6%96%B9%E5%BC%8F%E2%80%94%E2%80%94%E7%AE%A1%E7%90%86%E4%B8%AD%E6%96%AD%E8%AE%BE%E6%96%BD"><span class="toc-number">5.9.8.</span> <span class="toc-text">IRQ分配——现代方式——管理中断设施</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD"><span class="toc-number">5.9.9.</span> <span class="toc-text">在内部实现线程中断</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD%EF%BC%9F"><span class="toc-number">5.9.10.</span> <span class="toc-text">为什么要使用线程中断？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F%E6%97%B6%E7%9A%84%E7%BA%A6%E6%9D%9F"><span class="toc-number">5.9.11.</span> <span class="toc-text">使用线程处理程序时的约束</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8%E4%B8%8A%E4%B8%8B%E4%B8%AD%E6%96%AD"><span class="toc-number">5.9.12.</span> <span class="toc-text">理解和使用上下中断</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E5%86%85%E6%A0%B8%E4%B8%AD%E7%9A%84%E7%BB%99%E5%AE%9A%E6%97%B6%E9%97%B4"><span class="toc-number">5.9.12.1.</span> <span class="toc-text">在内核中的给定时间</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%86%E8%A7%A3%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-delay%EF%BC%88%EF%BC%89%E5%8E%9F%E5%AD%90API%E3%80%82"><span class="toc-number">5.9.12.2.</span> <span class="toc-text">了解如何使用*delay（）原子API。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%80%9Csed%E2%80%9D%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E2%80%94%E2%80%94%E7%94%A8%E4%BA%8E%E6%BC%94%E7%A4%BA%E5%86%85%E6%A0%B8%E8%AE%A1%E6%97%B6%E5%99%A8%E3%80%81kthreads%E5%92%8C%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97"><span class="toc-number">5.9.12.3.</span> <span class="toc-text">“sed”驱动程序——用于演示内核计时器、kthreads和工作队列</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%E5%86%85%E6%A0%B8%E8%AE%A1%E6%97%B6%E5%99%A8"><span class="toc-number">5.9.12.4.</span> <span class="toc-text">设置和使用内核计时器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%86%85%E6%A0%B8%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97"><span class="toc-number">5.9.12.5.</span> <span class="toc-text">使用内核工作队列</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5-%E7%AC%AC1%E9%83%A8%E5%88%86"><span class="toc-number">5.9.13.</span> <span class="toc-text">内核同步-第1部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E9%83%A8%E5%88%86%E3%80%81%E7%8B%AC%E5%8D%A0%E6%89%A7%E8%A1%8C%E5%92%8C%E5%8E%9F%E5%AD%90%E6%80%A7"><span class="toc-number">5.9.13.1.</span> <span class="toc-text">关键部分、独占执行和原子性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5-%E9%94%81"><span class="toc-number">5.9.13.2.</span> <span class="toc-text">概念-锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E7%82%B9%E6%80%BB%E7%BB%93"><span class="toc-number">5.9.13.3.</span> <span class="toc-text">关键点总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Linux%E5%86%85%E6%A0%B8%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98"><span class="toc-number">5.9.13.4.</span> <span class="toc-text">Linux内核中的并发问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%94%81%E5%AE%9A%E5%92%8C%E4%B8%AD%E6%96%AD-1"><span class="toc-number">5.9.13.5.</span> <span class="toc-text">锁定和中断</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5-%E7%AC%AC2%E9%83%A8%E5%88%86"><span class="toc-number">5.9.14.</span> <span class="toc-text">内核同步-第2部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8atomic-t%E5%92%8Crefcount-t%E6%8E%A5%E5%8F%A3"><span class="toc-number">5.9.14.1.</span> <span class="toc-text">使用atomic_t和refcount_t接口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%89%E4%B8%80%E5%8F%A5%E8%AF%9D%E8%A6%81%E6%8F%90%E9%86%92"><span class="toc-number">5.9.14.2.</span> <span class="toc-text">有一句话要提醒</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E6%95%88%E5%BA%94%E5%92%8C%E9%94%99%E8%AF%AF%E5%85%B1%E4%BA%AB"><span class="toc-number">5.9.14.3.</span> <span class="toc-text">缓存效应和错误共享</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/07/30/Linux%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" title="Linux学习之路"><img src="/img/passagepage.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux学习之路"/></a><div class="content"><a class="title" href="/2024/07/30/Linux%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" title="Linux学习之路">Linux学习之路</a><time datetime="2024-07-30T02:02:02.000Z" title="发表于 2024-07-30 10:02:02">2024-07-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/30/Linux-Debug%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" title="Linux Debug学习之路"><img src="/img/passagepage.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux Debug学习之路"/></a><div class="content"><a class="title" href="/2024/07/30/Linux-Debug%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" title="Linux Debug学习之路">Linux Debug学习之路</a><time datetime="2024-07-30T01:10:54.000Z" title="发表于 2024-07-30 09:10:54">2024-07-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/29/%E5%A6%82%E4%BD%95%E5%9C%A8Linux%E4%B8%8A%E6%9E%84%E5%BB%BARaspberry-Pi%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/" title="如何在Linux上构建Raspberry Pi虚拟环境"><img src="/img/passagepage.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何在Linux上构建Raspberry Pi虚拟环境"/></a><div class="content"><a class="title" href="/2024/07/29/%E5%A6%82%E4%BD%95%E5%9C%A8Linux%E4%B8%8A%E6%9E%84%E5%BB%BARaspberry-Pi%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/" title="如何在Linux上构建Raspberry Pi虚拟环境">如何在Linux上构建Raspberry Pi虚拟环境</a><time datetime="2024-07-29T14:11:04.000Z" title="发表于 2024-07-29 22:11:04">2024-07-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/27/%E5%A6%82%E4%BD%95%E5%9C%A8Windows%E4%B8%8A%E7%BC%96%E8%AF%91%E5%8F%AF%E7%94%A8%E7%9A%84Tesseract-OCR-in-C-%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%9C%A8Visual-Studio%E4%B8%8EQt6%E4%B8%8A/" title="如何在Windows上编译可用的Tesseract OCR in C++ 并部署在Visual Studio与Qt6上"><img src="/img/passagepage.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何在Windows上编译可用的Tesseract OCR in C++ 并部署在Visual Studio与Qt6上"/></a><div class="content"><a class="title" href="/2024/07/27/%E5%A6%82%E4%BD%95%E5%9C%A8Windows%E4%B8%8A%E7%BC%96%E8%AF%91%E5%8F%AF%E7%94%A8%E7%9A%84Tesseract-OCR-in-C-%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%9C%A8Visual-Studio%E4%B8%8EQt6%E4%B8%8A/" title="如何在Windows上编译可用的Tesseract OCR in C++ 并部署在Visual Studio与Qt6上">如何在Windows上编译可用的Tesseract OCR in C++ 并部署在Visual Studio与Qt6上</a><time datetime="2024-07-27T09:13:46.000Z" title="发表于 2024-07-27 17:13:46">2024-07-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/27/STM32%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95%E2%80%94%E2%80%94%E5%85%B3%E4%BA%8EPlatformIO-VSCode-CubeMX%E7%9A%84%E9%9B%86%E6%88%90%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" title="STM32开发环境配置记录——关于PlatformIO + VSCode + CubeMX的集成环境配置"><img src="/img/passagepage.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="STM32开发环境配置记录——关于PlatformIO + VSCode + CubeMX的集成环境配置"/></a><div class="content"><a class="title" href="/2024/07/27/STM32%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95%E2%80%94%E2%80%94%E5%85%B3%E4%BA%8EPlatformIO-VSCode-CubeMX%E7%9A%84%E9%9B%86%E6%88%90%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" title="STM32开发环境配置记录——关于PlatformIO + VSCode + CubeMX的集成环境配置">STM32开发环境配置记录——关于PlatformIO + VSCode + CubeMX的集成环境配置</a><time datetime="2024-07-27T09:07:15.000Z" title="发表于 2024-07-27 17:07:15">2024-07-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Charlie Chen</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="哼啊啊啊啊啊啊啊啊啊啊啊啊,人民万岁！,兄啊，别点力" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>